<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
  <head>
    <title>Planet Neuroscientists</title>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet"> 
    <link href="https://fonts.googleapis.com/css?family=Comfortaa" rel="stylesheet">
  </head>

  <body>
    <div class="container">
      <div class="page-header">
        <h1>Planet Neuroscientists</h1>
        <p>
        last updated by <a href="http://intertwingly.net/code/venus/">Venus</a> 
        on Nov. 25, 2016, 2:30 p.m. on behalf of Ankur Sinha.
        </p>
      </div>
    </div>

    <div class="container">
      <div class="col-md-9">
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://biocomputation.herts.ac.uk/2016/11/23/a-stepwise-neuron-model-fitting-procedure-designed-for-recordings-with-high-spatial-resolution-application-to-layer-5-pyramidal-cells.html">A stepwise neuron model fitting procedure designed for recordings with high spatial resolution: application to layer 5 pyramidal cells</a></h2></div>
            <p class="text-muted">by <a href="http://biocomputation.herts.ac.uk/">UH Biocomputation group</a> on November 23, 2016 04:10 PM.</p>
          </div>
          <div class="panel-body">

            <p><a class="reference external" href="http://www.med.uio.no/klinmed/english/people/aca/tuomomm/">Tuomo Mäki-Marttunen</a> joins us for a special journal club session this week.</p>
<hr class="docutils" />
<p>The recent progress in electrophysiological and optical methods for neuronal recordings provides vast amounts of high-resolution data. In parallel, the development of computer technology has allowed simulating ever larger neuronal circuits. A challenge in taking advantage of these developments is the construction of single-cell and network models in a way that faithfully reproduces neuronal biophysics with subcellular level of details while keeping the simulation costs at an acceptable level. In this talk, I will present our work on a stepwise method for fitting a neuron model to data with fine spatial resolution, such as that achievable with voltage sensitive dyes (VSDs) and Ca2+ imaging.</p>
<p>We applied our method to simulated data from layer 5 pyramidal cells (L5PCs) and constructed a model with reduced neuronal morphology. We connected the reduced-morphology neurons into a network and validated against simulated data from a high-resolution L5PC network model. The reduced-morphology neuron model obtained using our approach reliably reproduced the membrane potential dynamics across the dendrites as predicted by the full-morphology model, and was more than 20 times faster to simulate. The network models produced using our method are cost-efficient and predict that interconnected L5PCs, largely due to the medium afterhyperpolarization mediated by the Ca2+-activated SK current, are able to amplify delta-range oscillatory inputs across a large range of network sizes and topologies.</p>
<p><strong>Date:</strong> 25/11/2016 <br />
<strong>Time:</strong> 12:00 <br />
<strong>Location</strong>: LB252/C258 (TBD)</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://feeds.plos.org/~r/plos/blogs/neuro/~3/08y30TfVuws/">How to Give Thanks like a Neuroscientist (by Anita Ramanathan)</a></h2></div>
            <p class="text-muted">by <a href="http://blogs.plos.org/neuro">PLOS Neuroscience Community</a> on November 21, 2016 08:31 PM.</p>
          </div>
          <div class="panel-body">

            <img alt="Thanksgiving_1" class="attachment-thumbnail size-thumbnail wp-post-image" height="150" src="http://blogs.plos.org/neuro/files/2016/11/Thanksgiving_1-150x150.jpg" style="display: block; margin-bottom: 5px; clear: both;" width="150" /><ul>
<li>You’re on your way to the traditional Thanksgiving family get-together. You drive down a familiar street, locate your familiar house, and park in a familiar spot.<br />
<em>Thank you, hippocampus, for dutifully encoding Wisteria Drive, the light-blue-colored Colonial house and the parking spot next to the creepy oak tree almost twenty-eight years ago. I owe you one.</em></li>
</ul>
<p>Wait a minute. <em>Whose new convertible is that on our driveway?</em><br />
<em>Hippocampus, remind me to find out.</em></p>
<ul>
<li>You step out of your car and notice that the neighbors still have their Halloween pumpkins on display. Ew! They look hideous.<br />
<em>Well, at least I can decipher a ‘face’ in those god-awful, shriveled carvings. Thanks, fusiform gyrus.</em></li>
</ul>
<ul>
<li>You quickly snap a picture, and send it to your roommate, along with, of course, the face-with-tears-of-joy emoji.<br />
<em>Thanks, again, dear fusiform gyrus, to help comprehend the world of two hundred and seventy nine emojis. You’ve revolutionized the way we text.</em></li>
</ul>
<ul>
<li>You stare at the magnificent spread on the dining table. But tonight, you resolve to eat in moderation. No matter how delicious the food is, as an evolved human, you have the ability to suppress an urge.<br />
<em>Thank you, prefrontal cortex, for being my sleek, determined executive controller. Your strong-willed decisions have saved my many embarrassments, especially around free food.</em></li>
</ul>
<ul>
<li>As soon as you open the door, you catch a whiff of blissful aroma from the kitchen. Ah! You smell pumpkin pie.<br />
<em>Wow, olfactory receptor neurons, you went from transducing smells to the olfactory bulb to making my stomach growl in no time! Thanks. Now I really have to eat.</em></li>
</ul>
<ul>
<li>The ovoid, curvaceous gravy boat sits proudly next to the turkey, fulfilling its sole responsibility on Thanksgiving Day. You’ve always cracked up at its odd shape.<br />
<em>Hey, visual cortex, thanks to your ventral pathway for helping make sense of shapes. They sure ask “what” a lot, but I know they mean well.</em></li>
</ul>
<ul>
<li>Your pants feel tighter as you eat, but you continue gorging the smooth, creamy mashed potatoes. <em>I can’t stop! This is so good!</em></li>
</ul>
<p>Congratulations. You’ve fallen for the moves of the neural seductress, the ventral tegmental area. She has the (electrical) potential to make you feel so loved, so rewarded, and so addicted.<em> <em>Thank you, thank you, and I don’t care!</em></em></p>
<p><em><em><img alt="Thanksgiving_2" class=" wp-image-19005 aligncenter" height="252" src="http://blogs.plos.org/neuro/files/2016/11/Thanksgiving_2-300x196.jpg" width="386" /></em></em></p>
<p>Meanwhile, the prefrontal cortex shakes his head in utter disappointment.</p>
<p>Psst! Cerebral gossip: Ever since you made a New Year’s resolution to lose weight earlier this year, the steadfast prefrontal cortex has been in a complicated relationship with the ravenous ventral tegmental area.</p>
<ul>
<li>Amid the clatter of forks and plates, your aunt interrupts your intimate moment with the pumpkin pie with, “Say, when are you going to graduate and get a “real” job?”<br />
<em>Whaaa, where did this come from?</em> Your vigilant amygdala senses potential fear, and nudges the hypothalamus to sort out a fight or flight response. Your eyes widen. Your heart is beating faster.</li>
</ul>
<p>But let’s face it. You’re too stuffed for a fight. You’re too stuffed for a flight.</p>
<p>The amygdala makes a note: <em>Your mind wanders to an ongoing manuscript revision. Do not fear unsolicited questions about career. Especially when eating dessert.</em></p>
<ul>
<li>Your mind wanders to an ongoing manuscript revision.</li>
</ul>
<p>[In reviewer voice] You missed being thankful for the brain stem.<br />
<em>Wait, really? Why should I?</em><br />
[In reviewer voice] Because no one messes with the Mr. Brain Stem. We’re all just happy to have the support, and always cite him.<br />
<em>You sure have the nerve to randomly name-drop Mr. Bigwig Brain Stem.</em><br />
[In reviewer voice] Yes, (cranial) nerves III – IX, to be specific.</p>
<p>Your corrected manuscript now reads: <em>I’m extremely thankful for the brain stem.</em></p>
<ul>
<ul>
<ul>
<li>It’s 10:30 PM. You try to keep your eyes open, but the idea of snuggling into your bed seems rather appealing. Oh, the sweet relief of melatonin. Yawn.<br />
<em>Thanks, suprachiasmatic nucleus. Nighty-night.</em></li>
</ul>
</ul>
</ul>
<hr />
<p style="text-align: justify;"><span style="color: #000000;"><em>Any views expressed are those of the author, and do not necessarily reflect those of PLOS. </em></span></p>
<p style="text-align: justify;"><span style="color: #000000;"><i>Graphics designed by <strong>Joo Yeun Lee</strong>.</i></span></p>
<p style="text-align: justify;"><span style="color: #000000;"><br />
<strong><a href="http://blogs.plos.org/neuro/files/2016/11/Anita-Headshot-2016-e1479759426148.jpg"><img alt="Anita, Headshot, 2016" class="wp-image-19008 alignleft" height="146" src="http://blogs.plos.org/neuro/files/2016/11/Anita-Headshot-2016-e1479759426148-300x291.jpg" width="150" /></a></strong></span></p>
<p style="text-align: justify;"><span style="color: #000000;"><strong>Anita Ramanathan</strong> is a researcher, science writer and storyteller. She is an editor at the award-winning neuroscience education website, <a href="http://knowingneurons.com/" target="_blank"><i>Knowing Neurons</i></a>. You can follow her at <a href="https://twitter.com/anitarrn" target="_blank">@anitarrn</a><b><br />
</b></span></p>
<img alt="" height="1" src="http://feeds.feedburner.com/~r/plos/blogs/neuro/~4/08y30TfVuws" width="1" />
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://feeds.plos.org/~r/plos/blogs/neuro/~3/XiTZRoBN3KQ/">Molecular and neuroimaging biomarkers of Alzheimer’s disease at #SfN16</a></h2></div>
            <p class="text-muted">by <a href="http://blogs.plos.org/neuro">PLOS Neuroscience Community</a> on November 18, 2016 06:42 PM.</p>
          </div>
          <div class="panel-body">

            <img alt="23979876034_e8355a8294_b" class="attachment-thumbnail size-thumbnail wp-post-image" height="150" src="http://blogs.plos.org/neuro/files/2016/11/23979876034_e8355a8294_b-150x150.jpg" style="display: block; margin-bottom: 5px; clear: both;" width="150" /><p>This year’s <a href="https://www.sfn.org/annual-meeting/neuroscience-2016" target="_blank">Society for Neuroscience</a> (SfN) conference was rich with emerging advances in the detection of neuropathological changes that occur during Alzheimer’s disease. The cutting edge of this research was presented at the nanosymposium on <strong><a href="http://www.abstractsonline.com/pp8/index.html#!/4071/session/424" target="_blank">Molecular and Neuroimaging Biomarkers of Alzheimer’s Disease</a></strong> Saturday afternoon. From genetics to brain structure to molecular markers, this session highlighted the diversity of tools researchers are employing to better understand the neural effects of both normal and pathological aging.</p>
<p><strong>Structural Biomarkers</strong></p>
<p>Alzheimer’s disease pathology is known to originate in the brain’s medial temporal lobe – most notably in the entorhinal cortex and hippocampus – before spreading to more extensive cortical regions. Although prior research has therefore focused largely on structural changes in this region, new evidence shared at SfN this year suggests that aberrant brain structure <em>beyond the medial temporal lobe</em> may serve as an additionally powerful disease biomarker.</p>
<p><strong><a href="http://www.neuroscience.cam.ac.uk/directory/profile.php?taylor" target="_blank">Taylor Schmidt</a></strong> from the University of Cambridge presented findings that basal forebrain gray matter atrophy precedes atrophy in the entorhinal cortex, in cognitively impaired and healthy older adults with high amyloid burden, a pathological hallmark of Alzheimer’s disease. Not only did basal forebrain atrophy predict delayed recall performance, but this effect was mediated by amyloid levels. Could subcortical atrophy, perhaps driven by amyloid deposition, precede cortical degeneration to serve as an earlier biomarker of Alzheimer’s pathology?</p>
<p><strong><a href="https://sites.ualberta.ca/~nikolai/arash_ahamohammadi_sereshki.html" target="_blank">Arash Sereshki</a></strong> of the University of Alberta expanded upon these findings, encouraging researchers to look beyond the hippocampus for signatures of brain aging. Using high-resolution MRI, his work showed that volume of the amygdala, a region involved in fear and reward learning among other functions, was a strong predictor of age-related neural changes. The basal nucleus of the amygdala showed the most robust atrophy with age, but this association only occurred in men.</p>
<p><strong><a href="https://med.stanford.edu/profiles/owen-phillips" target="_blank">Owen Philips</a></strong> from Stanford University explored the effects of Alzheimer’s disease on white matter, delving beyond the thick, deep fibers that characterize the brain’s celebrated connective superhighway. Instead of examining the white matter of the cingulum, corpus callosum or fornix, his group evaluated whether superficial white matter – which myelinates later and is more complex than deep white matter – is affected by Alzheimer’s disease. Using vertex-wise analysis, they found widespread increased diffusivity in the superficial white matter of Alzheimer’s disease patients compared to healthy controls, most prominently in the temporal lobe. This diffusion signal negatively correlated with global cognitive function, indicating that greater superficial white matter diffusion was a good indicator of the severity of cognitive impairment.</p>
<p><strong>Genetics</strong></p>
<p>Various factors integratively determine the type and extent of neuropathology that one may sustain in older age, and which may ultimately lead to the neurodegenerative changes discussed by Schmidt, Sereshki and Phillips. Although genetics only play one part in this pathological cascade, the APOE and BDNF genes are well-documented contributors to risk for cognitive impairment in older age.</p>
<p><strong><a href="https://www.linkedin.com/in/melanie-sweeney-67a2b01b" target="_blank">Melanie Sweeney</a></strong> of the University of Southern California examined effects of the APOE4 allele, which increases risk for Alzheimer’s disease, on neurovascular health. Her group reported that breakdown of the blood brain barrier, which selectively filters substances into the brain from the blood, is greater in individuals with APOE4 than those without the risk gene. APOE4 carriers also demonstrated increased permeability of the blood brain barrier, even at preclinical stages (i.e., before any disease symptoms), beginning first in the hippocampus, one of the earliest sites to undergo neurodegeneration in Alzheimer’s disease.</p>
<p><strong><a href="https://sites.ualberta.ca/~nikolai/nikolai_malykhin.html" target="_blank">Nikolai Malykhin</a></strong>, also from the University of Alberta, looked more closely as how genetics affect morphometry in subregions of the hippocampus. In cognitively normal adults, volumes of all hippocampal subregions were greater for those carrying the APOE2 variant, which lowers risk for Alzheimer’s disease. Volume of the dentate gyrus – but no other hippocampal subregions – was reduced for BDNF met-carriers, showing that BDNF effects on hippocampal size were more specific than APOE effects.</p>
<p><strong>Molecular biomarkers</strong></p>
<p>Although amyloid and tau are the molecular hallmarks of Alzheimer’s disease, they have been remarkably challenging to detect in the living human brain. However, thanks to impressive methodological advances, there has been a recent surge in the development of tools to visualize the most sensitive molecular disease biomarkers.</p>
<p><strong><a href="http://katalog.uu.se/profile/?id=N13-1271" target="_blank">Xiaotian Fang</a></strong> from Uppsala University presented a novel imaging technique that uses an antibody that, fused with a blood brain barrier-passage molecule, can enter the brain and bind to amyloid protofibrils, suspected to be the toxic component of amyloid plaques. This tracer effectively labeled amyloid protofibrils in a mouse model of Alzheimer’s disease and holds promise as a more sensitive imaging tool than current amyloid plaque tracers.</p>
<p>Finally, <strong><a href="https://www.researchgate.net/profile/Maja_Mustapic" target="_blank">Maja Mustapic</a></strong> of the NIA explored the potential of extracellular vesicles in the blood – which can transport molecules such as amyloid or tau to the brain – as Alzheimer’s disease biomarkers. Levels of phosphorylated tau in these vesicles distinguished Alzheimer’s disease patients from normal controls with high accuracy, both at disease onset and before symptoms were manifest. Analysis of other vesicular molecules is underway.</p>
<p>As exemplified by the diverse techniques presented in this session, a multimodal approach may be our best bet for the most accurate early detection of neuropathological events. I’m already eagerly awaiting #SfN17 for updates on the ongoing advances in the development of Alzheimer’s disease biomarkers over the coming year.</p>
<p><em>Image credit https://www.flickr.com/photos/nihgov/</em></p>
<hr />
<p><em>Any views expressed are those of the author, and do not necessarily reflect those of PLOS.</em></p>
<p><b><a href="http://blogs.plos.org/neuro/files/2015/09/Reas_headshot-150x150.jpg"><img alt="" class="alignright size-full wp-image-17356" height="150" src="http://blogs.plos.org/neuro/files/2015/09/Reas_headshot-150x150.jpg" width="150" /></a></b><strong>Emilie Reas</strong> received her PhD in Neuroscience from UC San Diego, where she used fMRI to study memory. As a postdoc at UCSD, she currently studies how the brain changes with aging and disease. In addition to her tweets for <a href="https://twitter.com/PLOSNeuro" target="_blank">@PLOSNeuro</a> she is <a href="https://twitter.com/etreas" target="_blank">@etreas</a>.</p>
<img alt="" height="1" src="http://feeds.feedburner.com/~r/plos/blogs/neuro/~4/XiTZRoBN3KQ" width="1" />
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://blogs.biomedcentral.com/bmcseriesblog/2016/11/16/apha-2016-highlights-zika-epidemic-suicide-prescription-drug-overdose/">APHA 2016 highlights: Zika epidemic, suicide, and prescription drug overdose</a></h2></div>
            <p class="text-muted">by <a href="http://blogs.biomedcentral.com/bmcseriesblog">BMC Series blog</a> on November 16, 2016 02:04 PM.</p>
          </div>
          <div class="panel-body">

            <img alt="APHA 2016 was held in the Mile-High city at the Colorado Convention Center" class="attachment-thumbnail size-thumbnail wp-post-image" height="110" src="http://blogs.biomedcentral.com/bmcseriesblog/wp-content/uploads/sites/9/2016/11/Grizzly_Bear__at_Denver_Convention_Center_IMG_5518-140x110.jpg" style="display: block; margin-bottom: 5px; clear: both;" width="140" /><p>Everyone has the right to the highest attainable standard of physical and mental health, which also includes access to health services, sanitation, sufficient food, decent housing and a clean environment. Public health officials this year, along with <a href="http://bmcpublichealth.biomedcentral.com/"><em>BMC Public Health</em></a>, convened in Denver, Colorado to discuss these rights at the <a href="http://www.apha.org/">American Public Health Association’s</a> (APHA’s) Annual Meeting and Expo which took place from the 29th October to the 2nd November. This year’s theme, “Creating the Healthiest Nation: Ensuring the Right to Health,” brought to the forefront a diverse range of public health issues, including the Zika epidemic, suicide and prescription drug overdose which gained particular attention this year<em>.<br />
</em></p>
<p><strong>Public health approach to suicide prevention</strong></p>
<p>Opening session speakers included Colorado Governor John Hickenlooper who <span class="st"> discussed sexual and reproductive health care, legal marijuana, drug abuse and suicide, which is one of the major challenges facing Colorado considering that it has the seventh highest suicide rate in the nation.<br />
</span></p>
<figure class="wp-caption alignleft" id="attachment_8175" style="width: 310px;"><img class="wp-image-8175 size-medium" height="229" src="http://blogs.biomedcentral.com/bmcseriesblog/wp-content/uploads/sites/9/2016/11/suicide-300x229.jpg" width="300" /><div class="attachment-image--caption">Suicide in middle aged men is on the rise</div><div class="attachment-image--source">Flickr: Mic445</div></figure>
<p>Alex Crosby, the Branch Chief of the Surveillance Branch of the Division of Violence Prevention in the National Center for Injury Prevention and Control at the CDC, gave an intriguing talk about the CDC’s unique role in suicide prevention. To address the 10th leading cause of death in the United States, the CDC looks at promoting individual, family and community connectedness in order to prevent suicidal behavior. It has also helped produce a common language to facilitate identifying and monitoring such behavior.</p>
<p>A new CDC report has shown that overall suicide rates in middle aged men aged 45-64 has increased by 43 percent in the last 15 years compared to overall suicide rates which rose 24 percent. There doesn’t seem to be one cause that can explain this spike but there is likely a convergence of multiple factors within middle aged men that makes them especially vulnerable. The CDC have made it a priority to fund programs looking into suicide behavior in this group further.</p>
<p>Unfortunately, the stigma and taboo surrounding suicide means that funding is affected. Jarrod Hindman, Director of the Suicide Prevention Center in Denver, explained that, in the last 10 years, federal funding has been invested in research on leading causes of death such as HIV/AIDS, heart disease, and prostate cancer. Major progress has led to decreased mortality rates and so it’s time the same is done with suicide where death rates are on the rise.</p>
<p><strong>Prescription drug overdose</strong></p>
<figure class="wp-caption alignright" id="attachment_8174" style="width: 310px;"><img alt="The number of pain relievers prescribed in the US has skyrocketed" class="size-medium wp-image-8174" height="225" src="http://blogs.biomedcentral.com/bmcseriesblog/wp-content/uploads/sites/9/2016/11/drugs-300x225.jpg" width="300" /><div class="attachment-image--caption">The number of pain relievers prescribed in the US has skyrocketed</div><div class="attachment-image--source">Flickr: frankieleon
</div></figure>
<p>In his opening speech, Governor John Hickenlooper also discussed drug abuse and proudly announced that Colorado had expanded access to naloxone, which reverses the effects of an opioid overdose, noting that he learned how to administer the medicine and carries a dose of it in his state trooper’s vehicle in case he encounters someone in need.</p>
<p>Availability of prescribed drugs, which is the second most abused type of drug in adolescents following marijuana, can be an important determinant of suicidal behavior. Opioids, CNS depressants for anxiety and sleep disorders and stimulants often prescribed for ADHD are the classes most commonly abused. An astonishing 2.4 million Americans have used prescription drugs non medically for the first time within the last year and an estimated 52 million people have used these drugs for non medical reasons at least once in their lifetime. Mian Hossein, a Professor at Morgan State University, discussed the mental health consequences of nonmedical prescription drug use among youths aged 12-17 in the United States. His research, which uses data from 176,200 youths over a period of 10 years documents a relationship between the use of nonmedical prescription drugs and major depressive episodes in this group.</p>
<p><strong>A public health emergency – the Zika virus</strong></p>
<p>As concerns about the spread of the Zika virus continue to grow, APHA is one of 11 national organizations funded by the Centers for Disease Control and Prevention to support and disseminate evidence based approaches for preventing and controlling the spread of the virus.</p>
<figure class="wp-caption alignright" id="attachment_8173" style="width: 310px;"><img alt="Aedes aegypti mosquito" class="size-medium wp-image-8173" height="202" src="http://blogs.biomedcentral.com/bmcseriesblog/wp-content/uploads/sites/9/2016/11/mosquito-300x202.jpg" width="300" /><div class="attachment-image--caption"><em>Aedes aegypti</em> mosquito</div><div class="attachment-image--source">Flickr: Sanofi Pasteur</div></figure>
<p>A special session organized at the conference discussed staging a multisectoral and epidemiological approach to the emergent threat of the virus. Lyle Petersen, Director of the Division of Vector-Borne Diseases in the National Center for Emerging and Zoonotic Infectious Diseases (NCEZID), spoke about the virus’ presence in the United States. He explained that, as there was no previous experience with the virus in the western hemisphere, diseases such as Dengue Fever and Chikungunya had to be looked at to give an idea of how the virus might spread.</p>
<p>Zika prevention strategies currently include vector control, warnings against travel for pregnant women, blood donor screening and providing access to contraceptives. However, there is still a lot which is not known regarding other possible modes of transmission, what the duration and magnitude of risk is in sexual transmission of the virus as well as what the preconception risk is.</p>
<p><strong>APHA 2017</strong></p>
<p>We left APHA this year with an encouraging message from Governor John Hickenlooper to the thousands of public health practitioners attending this year: <strong>“You guys are gonna save the world.” </strong></p>
<p>We can’t wait to attend next year’s conference in Atlanta where ongoing efforts will be recognized and shared with the goal of achieving healthier communities and health equity globally.</p>
<p>The post <a href="http://blogs.biomedcentral.com/bmcseriesblog/2016/11/16/apha-2016-highlights-zika-epidemic-suicide-prescription-drug-overdose/" rel="nofollow">APHA 2016 highlights: Zika epidemic, suicide, and prescription drug overdose</a> appeared first on <a href="http://blogs.biomedcentral.com/bmcseriesblog" rel="nofollow">BMC Series blog</a>.</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://blogs.biomedcentral.com/bmcseriesblog/2016/11/15/confronting-resistance-47th-union-world-conference-lung-health/">Confronting resistance at 47th Union World Conference on Lung Health</a></h2></div>
            <p class="text-muted">by <a href="http://blogs.biomedcentral.com/bmcseriesblog">BMC Series blog</a> on November 15, 2016 12:09 PM.</p>
          </div>
          <div class="panel-body">

            <p>This year marked the <a href="http://liverpool.worldlunghealth.org/">47<sup>th</sup> Union World Conference on Lung Health</a>, held in Liverpool, UK, and <a href="http://bmcinfectdis.biomedcentral.com/"><em>BMC Infectious Diseases</em></a> was lucky enough to attend.</p>
<p>The annual conference, run by the <a href="http://www.theunion.org/">International Union Against Tuberculosis and Lung Disease</a> (The Union), includes many aspects of lung health; however the main focus is tuberculosis (TB) research, with this year’s theme being ‘Confronting Resistance: Fundamentals to Innovations’.</p>
<figure class="wp-caption alignleft" id="attachment_8163" style="width: 310px;"><img alt="Barry Skeates/Flickr" class="wp-image-8163 size-medium" height="156" src="http://blogs.biomedcentral.com/bmcseriesblog/wp-content/uploads/sites/9/2016/11/liverpool-300x156.jpg" width="300" /><div class="attachment-image--caption">Barry Skeates/Flickr</div><div class="attachment-image--source"></div></figure>
<p>Given the release of the <a href="http://www.who.int/tb/publications/global_report/en/">World Health Organization’s 2016 Global Tuberculosis Report</a> which showed a sizable increase in deaths due to tuberculosis (due to improved reporting of cases) it is clear that much more needs to be done if we are to achieve the <a href="http://www.who.int/tb/post2015_strategy/en/">End TB goals</a>.</p>
<p>Outside of the specific scientific sessions there was a huge effort towards engaging both the patient and local communities. Alongside the <a href="http://liverpool.worldlunghealth.org/programme/community-common">Community Common</a>, which was open to the public, local charities and organizations relevant to the scope of the conference had prominent space to discuss their work and speakers such as <a href="http://liverpool.worldlunghealth.org/updates/plenary-three-social-protection-for-a-more-holistic-approach-to-ending-tb">Amy McConville</a>, a TB survivor,  ensured that the human side to the diseases was not forgotten.</p>
<p>Given the theme of the conference it was not surprising that multi-drug-resistant tuberculosis (MDR-TB), was a major focus. As well as many insightful talks on new drugs and diagnostics there was also acknowledgment that we could be doing better with the tools we already have. In addition ways to reduce transmission were discussed, such as the use of UV disinfection in a talk by <a href="https://www.hsph.harvard.edu/edward-nardell/">Edward Nardell</a>, and the upcoming <a href="http://www.impaactnetwork.org/studies/IMPAACT2003B.asp">PHOENIx trial</a> highlighted by <a href="http://www.auruminstitute.org/index.php?option=com_k2&amp;view=item&amp;id=57:prof-gavin-churchyard&amp;Itemid=126">Gavin Churchyard</a> for investigating reducing household transmission (the primary cause of MDR-TB in children).</p>
<figure class="wp-caption alignright" id="attachment_8167" style="width: 274px;"><img alt="WHO/http://www.who.int/tb/strategy/en/" class=" wp-image-8167" height="171" src="http://blogs.biomedcentral.com/bmcseriesblog/wp-content/uploads/sites/9/2016/11/TB-300x194.jpg" width="264" /><div class="attachment-image--caption">WHO/http://www.who.int/tb/strategy/en/</div><div class="attachment-image--source"></div></figure>
<p>It is clear that in order to reduce TB deaths by 95% and to cut new cases by 90% between 2015 and 2035 a huge amount more needs to be done. However we left Liverpool with confidence everything possible will be done by the attendees to meet these targets.</p>
<p>The post <a href="http://blogs.biomedcentral.com/bmcseriesblog/2016/11/15/confronting-resistance-47th-union-world-conference-lung-health/" rel="nofollow">Confronting resistance at 47th Union World Conference on Lung Health</a> appeared first on <a href="http://blogs.biomedcentral.com/bmcseriesblog" rel="nofollow">BMC Series blog</a>.</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://blogs.biomedcentral.com/bmcseriesblog/2016/11/15/boosting-fitness-astronauts/">Boosting Fitness for Astronauts</a></h2></div>
            <p class="text-muted">by <a href="http://blogs.biomedcentral.com/bmcseriesblog">BMC Series blog</a> on November 15, 2016 11:07 AM.</p>
          </div>
          <div class="panel-body">

            <img alt="NASA Goddard Space Flight Center (Flickr, CC)" class="attachment-thumbnail size-thumbnail wp-post-image" height="110" src="http://blogs.biomedcentral.com/bmcseriesblog/wp-content/uploads/sites/9/2016/11/NASA-Goddard-Space-Flight-Center-140x110.jpg" style="display: block; margin-bottom: 5px; clear: both;" width="140" /><p>Keeping up one’s physical fitness is a battle for anyone, but trying to stay fit in outer space, where living quarters are cramped and the exercise regimen is rigorous and monotonous, is an extra challenge. Exercise is extremely important during space travel because prolonged weightlessness decreases muscle strength, bone density, and cardiovascular functioning. Motivation and adherence to high intensity exercise, coupled with a socially isolating environment with atypical access to social support, may be compromised. Exercising with a partner can help with motivation, but that is not possible for astronauts where space and exercise equipment is limited. Even using earth-based virtual partners is impractical due to reduced communication and scheduling, especially the further one goes into deep space.</p>
<p> </p>
<img alt="feltz_gameshot_5375" class="wp-image-8152 size-medium alignright" height="200" src="http://blogs.biomedcentral.com/bmcseriesblog/wp-content/uploads/sites/9/2016/11/Feltz_gameshot_5375-300x200.jpg" title="D Feltz CC" width="300" />
<p>Our research grant from the National Space Biomedical Research Institute of NASA is exploring the best ways to keep astronauts motivated to exercise when they go on long-duration space flights by using an exercise-video game (exergame) with a software-generated partner–one that is anthropomorphic but clearly artificial and synthetic. Our software-generated partner incorporates group-dynamics principles (behaviors and psychological processes occurring within, or between, social groups), such as upward social comparison and indispensability to group achievement, to address lack of motivation for vigorous physical exercise (i.e., the level of effort).</p>
<p> </p>
<p>Of course, we can’t conduct our research with astronauts themselves at this stage, so have recruited men and women, ages 35 to 62 (the average age of an astronaut is 48), who were as physically healthy as astronauts, to test our exergame and software-generated partner.</p>
<p> </p>
<img alt="interval-track-male" class="wp-image-8154 size-medium alignleft" height="168" src="http://blogs.biomedcentral.com/bmcseriesblog/wp-content/uploads/sites/9/2016/11/Interval-Track-Male-300x168.png" title="D Feltz CC" width="300" />
<p>We are using an exergame that involves a stationary bike, where individuals exercise on a variety of bike trails with or without a software-generated partner, under high-intensity interval training conditions. The partner is programmed to be slightly superior to the exerciser (upward social comparison) and to be a teammate, where the team score (exercise effort) is based on the weaker partner, thus creating a sense of value and indispensability (not letting the partner down) for the exerciser.</p>
<p> </p>
<p>We have been testing various features of the game and different versions of the partner to see what works best to keep participating exercisers motivated to give their best efforts while exercising at vigorous intensities 6 days per week over a 6-month time period.</p>
<p> </p>
<p>While this research is important for astronauts, it also has practical applications for those of us who remain earth-bound. Interpersonal and social concerns (for comparing favorably with others or for not letting a partner down) have the potential to add powerful sources of motivation to exercise. These sources of motivation could open up a set of new tools in exergame design for fitness, especially for those with social physique anxiety, those who lack the time and/or resources to join an exercise group, and those in exercise rehabilitation therapies. None of the existing exercise games currently on the market incorporate the critical design features suggested by contemporary social psychological research, particularly research on motivation gains in task groups (namely immediate feedback on performance of one or more other players, the ability to control the discrepancy in abilities of players, and most importantly, the indispensability of individual player effort for determining group outcomes). Thus, our research has the potential for earth-based commercial applications to build more engaging and enjoyable exercise video games for various populations.</p>
<p>The post <a href="http://blogs.biomedcentral.com/bmcseriesblog/2016/11/15/boosting-fitness-astronauts/" rel="nofollow">Boosting Fitness for Astronauts</a> appeared first on <a href="http://blogs.biomedcentral.com/bmcseriesblog" rel="nofollow">BMC Series blog</a>.</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://biocomputation.herts.ac.uk/2016/11/14/error-correction-over-optical-transmission.html">Error correction over optical transmission</a></h2></div>
            <p class="text-muted">by <a href="http://biocomputation.herts.ac.uk/">UH Biocomputation group</a> on November 14, 2016 03:12 PM.</p>
          </div>
          <div class="panel-body">

            <p>Reducing bit error rate and improving performance of modern coherent optical communication system is a significant issue. As the distance travelled by the information signal increases, bit error rate will degrade. Support Vector Machines are the most up to date machine learning method for error correction in optical transmission systems. Wavelet transform has been a popular method to signals processing. In this study, the properties of most used Haar and Daubechies wavelets are implemented for signals correction. Our results show that the bit error rate can be improved by using classification based on wavelet transforms (WT) and support vector machine (SVM).</p>
<p><strong>Date:</strong> 18/11/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://blogs.biomedcentral.com/bmcseriesblog/2016/11/14/evolution-bitter-taste-new-world-monkeys/">The evolution of bitter taste in New World monkeys</a></h2></div>
            <p class="text-muted">by <a href="http://blogs.biomedcentral.com/bmcseriesblog">BMC Series blog</a> on November 14, 2016 10:11 AM.</p>
          </div>
          <div class="panel-body">

            <img alt="videodb_5501_77229_9071157_16x9_04_hd" class="attachment-thumbnail size-thumbnail wp-post-image" height="110" src="http://blogs.biomedcentral.com/bmcseriesblog/wp-content/uploads/sites/9/2016/11/videodb_5501_77229_9071157_16x9_04_HD-140x110.jpg" style="display: block; margin-bottom: 5px; clear: both;" width="140" /><p></p>
<p>The post <a href="http://blogs.biomedcentral.com/bmcseriesblog/2016/11/14/evolution-bitter-taste-new-world-monkeys/" rel="nofollow">The evolution of bitter taste in New World monkeys</a> appeared first on <a href="http://blogs.biomedcentral.com/bmcseriesblog" rel="nofollow">BMC Series blog</a>.</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://feeds.plos.org/~r/plos/blogs/neuro/~3/yML-WQ1x0Lk/">#SfN16 must-sees on adolescent brain development, adversity, and mental health, By Lizanne Schweren</a></h2></div>
            <p class="text-muted">by <a href="http://blogs.plos.org/neuro">PLOS Neuroscience Community</a> on November 14, 2016 06:50 AM.</p>
          </div>
          <div class="panel-body">

            <img alt="23107749152_bd1d95a0b2_z" class="attachment-thumbnail size-thumbnail wp-post-image" height="150" src="http://blogs.plos.org/neuro/files/2016/11/23107749152_bd1d95a0b2_z-150x150.jpg" style="display: block; margin-bottom: 5px; clear: both;" width="150" /><p><strong>By Lizanne Schweren</strong></p>
<p>When planning my SfN itinerary, the amazing <a href="http://www.abstractsonline.com/pp8/index.html#!/4071" target="_blank">meeting planner</a> helped me identify plenty of sessions and presentations that sound really interesting. Here, I’d like to share some of my favorites with you. If you, like me, are interested in psychiatry, neuroimaging, developmental disorders, adolescent development, or early stress and adversity, the following presentations may be worth attending:</p>
<p><em>388.05. <strong>Rewarded approach of threatening spiders engages areas of the mesolimbic dopamine system</strong> (F. Ahs) Monday 2-2.15pm @SDCC2</em></p>
<p>Professionally, I’d love to learn more about dopaminergic modulation of fear; personally, however, I’m terribly afraid of spiders, to put it mildly. My ambivalence is probably very similar to what the brave arachnophobic volunteers in Ahs’ study felt while in the MRI scanner, as they were invited to view spider pictures for money. To be totally honest: at the moment of writing, I haven’t yet decided whether I’ll go see the spider presentation or not. Follow my blog over the next few days to see which was stronger: fear or curiosity.</p>
<p><em>662. <strong>The social brain in human adolescence</strong> (S-J. Blakemore). Wednesday 11.30am-12.40pm @SDCC Ballroom 20</em></p>
<p>It’s intriguing how children inevitably grow up, change, struggle, learn, adapt, experiment, get confused and then refocus. The majority of mental illnesses surface before the age of 24, with adolescence as a major high-risk period. I’m looking forward to the presentation of professor Blakemore, arguably a leading expert in the field and a great speaker.</p>
<p><em> </em><em>772.06. <strong>Early adversity affects amygdala-cortical functional connectivity: links to adversity and gut microbial community structure</strong>. (B.L. Callaghan) Wednesday 2.15-2.30pm @SDCC5B</em></p>
<p>The brain is pretty cool, but luckily it’s not the only organ we have. The more I learn about neuroscience, the more I realize that all organs should be treated with equal respect. Seeing work such as that of Callaghan et al., I can’t help but think that the current neuroscience craze may simply be another symptom of society’s irrational belief in the rationality of human behaviors. Are we, neuroscientists, guilty of tunnel vision? Or worse, have we been staring at the wrong organ? You’ll definitely find me attending this presentation!</p>
<p><em>PDW13. <strong>How to Present Science Using Visual Tools</strong> (workshop). Monday 9-11am @SDCC30C</em></p>
<p>“A picture is worth a thousand words”. That is, a good picture. A thousand words! Imagine having one thousand <em>extra</em> words for that paper you’ve been trying to shorten in order to meet the journal’s word count, and you’ll understand my excitement about this workshop. In addition, good visuals are very helpful when explaining our findings to audiences that have not read our papers, and are not necessarily planning to do so. Sleek visuals will make you stand out from the crowd. In this workshop on Monday morning, experienced speakers will share their tips, tricks, and tools to create attractive visuals. I’m looking forward to learning about new tools to communicate my science and engage my audience!</p>
<p><em>Image credit https://www.flickr.com/photos/joshuatreenp</em></p>
<hr />
<p><em>Any views expressed are those of the author, and do not necessarily reflect those of PLOS.</em></p>
<p><strong><a href="http://blogs.plos.org/neuro/files/2016/10/LizanneSchweren.jpg"><img alt="LizanneSchweren" class="alignright size-thumbnail wp-image-18936" height="150" src="http://blogs.plos.org/neuro/files/2016/10/LizanneSchweren-150x150.jpg" width="150" /></a>Lizanne Schweren</strong> is a postdoctoral research associate at the University of Cambridge in the Department of Psychiatry, where she studies what makes the adolescent brain so highly vulnerable to developing depression and other psychiatric problems.</p>
<img alt="" height="1" src="http://feeds.feedburner.com/~r/plos/blogs/neuro/~4/yML-WQ1x0Lk" width="1" />
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://feeds.plos.org/~r/plos/blogs/neuro/~3/cPKaLg-WkPk/">#SfN16 Preview: Artful Strokes + Soulful Sounds = Healthier Brains? By Patricia Izbicki</a></h2></div>
            <p class="text-muted">by <a href="http://blogs.plos.org/neuro">PLOS Neuroscience Community</a> on November 11, 2016 07:17 PM.</p>
          </div>
          <div class="panel-body">

            <img alt="brainphonesx" class="attachment-thumbnail size-thumbnail wp-post-image" height="150" src="http://blogs.plos.org/neuro/files/2016/11/brainphonesx-150x150.jpg" style="display: block; margin-bottom: 5px; clear: both;" width="150" /><p><strong>By Patricia Izbicki</strong></p>
<p>In the recent past, there has been a great divide between the sciences and arts. However, recent studies are uncovering the connections between science and art and their importance to healthy and productive lives. It seems the Renaissance women and men were onto something! With the rise of STEAM (Science, Technology, Engineering, Art, and Mathematics) as well as art and music therapy, scientists, clinicians, educators, and society are beginning to realize the importance of both disciplines working together to improve health and education. As someone who is both a musician and neuroscientist in training, I am thrilled that both disciplines are gaining national attention and being represented on such a high-level platform such as Society for Neuroscience!</p>
<p>There are two opportunities to learn about and discuss neuroscience and the arts:</p>
<p>On <strong>Sunday, November 13</strong> from 8:30 A.M. to 11:00 A.M., a symposium titled <strong><a href="http://www.abstractsonline.com/pp8/#!/4071/session/111" target="_blank"><em>Neuroscience of Music: Novel Discoveries and Their Implications in the Understanding of Music and the Brain</em></a></strong> will discuss the implications and importance of the neuroscience of music for the discussion of new, thought-provoking ideas. Experts in the areas of neuroscience and music include Dr. John Iversen, Dr. Nina Kraus, Dr. Daniel Levitin, and Dr. Elizabeth Stegemöller, who will speak on topics including music and neuroplasticity, music and neurochemistry, and the biology of auditory learning.</p>
<p>On <strong>Tuesday, November 15</strong> from 3:00 P.M. to 5:00 P.M., an advocacy forum open to the public titled <strong><a href="http://www.abstractsonline.com/pp8/#!/4071/session/847" target="_blank"><em>Art, Music, and the Brain: How the Arts Influence Us from Youth to Maturity</em></a></strong> will tackle the role and influence of art and science in human creativity, productivity, and health. The panel will consist of neuroscientists, artists, and educators including Dr. Kenneth Elpus, Dr. Ping Ho, Dr. Nina Kraus, Dr. Daniel Levitin, and Dr. Bill Martin.</p>
<p>As Einstein once said: “All religions, arts, and sciences are branches of the same tree. All these aspirations are directed toward ennobling man’s life, lifting it from the sphere of mere physical existence and leading the individual towards freedom” (<em>Out of My Later Years)</em>. So, make your way to each of these sessions to learn from these leading experts about the role of the arts not only in the neurohealth and neuroeducation of society but also in the enrichment of your own life. I hope to see you there!</p>
<p><em>Image credit http://www.mediapocalypse.com/ (Brain image by <a href="http://www.flickr.com/photos/flamephoenix1991/8376271918/sizes/l/in/photolist-dLbzPm-7JSvWX-bmFXnS-d8fcf7-d8f4uE-d8faau-d8e9Pj-d8eKK1-d8eJ8Y-d8fepu-d8e8eC-7Ce28J-d8dZPU-d8dTsy-dVffRF-dVffN6-dVffPB-dVffSV-dVffQV-c3mJBo-fea2KK-bo2BFc-a9H6QM-a9KTjA-dTDfAz-9EZUdJ-9EX2hc-9EX4x2-9EX3sz-9EZV8W-9EX57D-eeTGSX-9LhWsA-9EWVo8-9EWXz6-9EZRsj-9EZSp5-9EWXbF-9EWWrH-9EZQzY-9784vT-c3mJFE-8NwJH1-94xTsH-7DhYVa-9EX1fZ-9vjPD4/" target="_blank">_DJ_</a> CC-BY-SA; headphones by <a href="http://commons.wikimedia.org/wiki/File:Headphones-Sennheiser-HD555.jpg" target="_blank">Adamantios</a> CC-BY-SA)</em></p>
<hr />
<p><em>Any views expressed are those of the author, and do not necessarily reflect those of PLOS.</em></p>
<p><strong><a href="http://blogs.plos.org/neuro/files/2016/10/Izbicki_Headshot.jpg"><img alt="Izbicki_Headshot" class="alignright size-thumbnail wp-image-18942" height="150" src="http://blogs.plos.org/neuro/files/2016/10/Izbicki_Headshot-150x150.jpg" width="150" /></a>Patricia Izbicki</strong> is a neuroscience doctoral student at Iowa State University. She is a classical pianist and harpsichordist, and is interested in understanding the effects of music on the brain and nervous system.</p>
<img alt="" height="1" src="http://feeds.feedburner.com/~r/plos/blogs/neuro/~4/cPKaLg-WkPk" width="1" />
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://blogs.biomedcentral.com/bmcseriesblog/2016/11/11/digging-gopher-evolution/">Digging into gopher evolution</a></h2></div>
            <p class="text-muted">by <a href="http://blogs.biomedcentral.com/bmcseriesblog">BMC Series blog</a> on November 11, 2016 10:23 AM.</p>
          </div>
          <div class="panel-body">

            <img alt="videodb_5501_77229_9068293_16x9_02_hd" class="attachment-thumbnail size-thumbnail wp-post-image" height="110" src="http://blogs.biomedcentral.com/bmcseriesblog/wp-content/uploads/sites/9/2016/11/videodb_5501_77229_9068293_16x9_02_HD-140x110.jpg" style="display: block; margin-bottom: 5px; clear: both;" width="140" /><p></p>
<p>The post <a href="http://blogs.biomedcentral.com/bmcseriesblog/2016/11/11/digging-gopher-evolution/" rel="nofollow">Digging into gopher evolution</a> appeared first on <a href="http://blogs.biomedcentral.com/bmcseriesblog" rel="nofollow">BMC Series blog</a>.</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://feeds.plos.org/~r/plos/blogs/neuro/~3/1H18eCB-_x4/">#SfN16 Preview: Immunotherapy for Neurodegenerative Disease</a></h2></div>
            <p class="text-muted">by <a href="http://blogs.plos.org/neuro">PLOS Neuroscience Community</a> on November 10, 2016 06:54 PM.</p>
          </div>
          <div class="panel-body">

            <img alt="28128037754_f0e61c01ff_z" class="attachment-thumbnail size-thumbnail wp-post-image" height="150" src="http://blogs.plos.org/neuro/files/2016/11/28128037754_f0e61c01ff_z-150x150.jpg" style="display: block; margin-bottom: 5px; clear: both;" width="150" /><p>Targeting the pathological processes underlying neurodegenerative disease with effective therapies remains one of the greatest yet most important challenges facing neuroscientists today. Among other conditions, Alzheimer’s disease, Parkinson’s disease, Huntington’s disease, Amyotrophic lateral sclerosis (Lou Gherig’s disease) and frontotemporal dementia ravage the cognitive and motor functions of their victims. While these diseases have unique genetic or environmental origins, they have one common neuropathological signature: aberrant accumulation of proteins – such as amyloid-β, tau, α-synuclein, huntingtin or SOD1. Because of this commonality, immunotherapy–by targeting the proteins implicated in disease onset and progression–is a promising candidate for treating a host of neurodegenerative diseases.</p>
<p>On <strong>Wednesday, November 16</strong> at the 2016 Society for Neuroscience conference, Dr. Eliezer Masliah, of the National Institutes of Health, will present the latest research on the use of immunotherapy for various neurodegenerative diseases, in his talk <strong><a href="http://www.abstractsonline.com/pp8/index.html#!/4071/session/137" target="_blank"><em>Capturing Immune Responses to Understand and Treat Neurodegenerative Disease</em></a></strong>. In this Q&amp;A, Dr Masliah explains the state of immunotherapy for neurodegenerative disease.</p>
<p><strong>ER</strong>: Why do immunotherapies hold more promise for treating neurodegenerative disease than other treatments? How have clinical trials so far supported their efficacy?</p>
<p><strong>Dr. Masliah</strong>: The advantage of immunotherapy is that it can work via several mechanisms and can be very specific. Multiple mechanisms of action include blocking propagation, targeting oligomers, modulating immune responses, reducing toxicity, reducing inflammation, stimulating clearance, lysosomal clearance autophagy pathways, etc. Recent anti-amyloid phase III trials show some promise in post-hoc analysis. Synuclein immunotherapy has been shown to be safe and early preliminary studies show promise.</p>
<p><strong>ER</strong>: What are the main challenges that immunotherapies face?</p>
<p><strong>Dr. Masliah</strong>: Most recent studies have shown that new approaches are safer and more specific. Potential challenges are cost in particular with passive immunotherapy.</p>
<p><strong>ER</strong>: Do you expect that immunotherapies would be as effective against intracellularly accumulating proteins as against extracellular proteins? For example, would a tau or α-synuclein antibody be as effective as an amyloid-β antibody?</p>
<p><strong>Dr. Masliah</strong>: Yes, there is extensive evidence that antibodies enter cells and target abnormal intracellular proteins; however, it is worth noting that most proteins such as amyloid-β, tau synuclein, are actually secreted and propagate from cell to cell. There are many opportunities and mechanisms for antibodies to target abnormal aggregated proteins. In fact, the more toxic forms might be those secreted.</p>
<p><strong>ER</strong>: There is uncertainty as to whether preventing protein accumulation can stop progression of some neurodegenerative diseases. For instance, some trials that effectively lower amyloid-β levels have failed to show cognitive effects. Are there certain diseases, which we are confident are in fact caused by toxic protein accumulation, that may be better targets for immunotherapy than others?</p>
<p><strong>Dr. Masliah</strong>: The trials you refer to were in patients with mild to moderate Alzheimer’s disease that for practical purposes represent full blown disease, not good examples. Primary and secondary prevention trials such as A4, DIAN-TU and others are underway in patients with pre-clinical Alzheimer’s disease or Mild Cognitive Impairment. Results won’t be known for a few more years.</p>
<p><em>Image credit https://www.flickr.com/photos/nihgov/</em></p>
<hr />
<p><em>Any views expressed are those of the author, and do not necessarily reflect those of PLOS.</em></p>
<p><b><a href="http://blogs.plos.org/neuro/files/2015/09/Reas_headshot-150x150.jpg"><img alt="" class="alignright size-full wp-image-17356" height="150" src="http://blogs.plos.org/neuro/files/2015/09/Reas_headshot-150x150.jpg" width="150" /></a></b><strong>Emilie Reas</strong> received her PhD in Neuroscience from UC San Diego, where she used fMRI to study memory. As a postdoc at UCSD, she currently studies how the brain changes with aging and disease. In addition to her tweets for <a href="https://twitter.com/PLOSNeuro" target="_blank">@PLOSNeuro</a> she is <a href="https://twitter.com/etreas" target="_blank">@etreas</a>.</p>
<img alt="" height="1" src="http://feeds.feedburner.com/~r/plos/blogs/neuro/~4/1H18eCB-_x4" width="1" />
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://biocomputation.herts.ac.uk/2016/11/10/neuronal-computation-dendrites-at-work.html">Neuronal computation: dendrites at work</a></h2></div>
            <p class="text-muted">by <a href="http://biocomputation.herts.ac.uk/">UH Biocomputation group</a> on November 10, 2016 10:15 AM.</p>
          </div>
          <div class="panel-body">

            <p>Brain dynamics emerge from the collective and orchestrated activity of single neurons. The main characteristics of neurons are their morphologically elaborate structures to receive and integrate inputs (i.e., the dendrites) and communicate their signal to other neurons (i.e., the axons). Because dendrites receive, integrate and transform inputs into relevant output they can be considered as the functional workhorses of the brain.</p>
<p>In this presentation, I’ll outline the problematic relation between dendrite structure and function in neurons. Then I’ll show how highly non-trivial processing can take place in neurons due to the spatial extend of dendrites. Lastly, I will present my current work on distilling the essence of dendritic computations using simplified models.</p>
<p><strong>Date:</strong> 11/11/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://blogs.biomedcentral.com/bmcseriesblog/2016/11/09/deep-space-travels-radiation-problem-cosmic-rays-brains/">Deep space travel’s radiation problem: what cosmic rays do to brains</a></h2></div>
            <p class="text-muted">by <a href="http://blogs.biomedcentral.com/bmcseriesblog">BMC Series blog</a> on November 09, 2016 04:59 PM.</p>
          </div>
          <div class="panel-body">

            <img alt="videodb_5501_77229_9067067_16x9_01_hd" class="attachment-thumbnail size-thumbnail wp-post-image" height="110" src="http://blogs.biomedcentral.com/bmcseriesblog/wp-content/uploads/sites/9/2016/11/videodb_5501_77229_9067067_16x9_01_HD-140x110.jpg" style="display: block; margin-bottom: 5px; clear: both;" width="140" /><p></p>
<p>The post <a href="http://blogs.biomedcentral.com/bmcseriesblog/2016/11/09/deep-space-travels-radiation-problem-cosmic-rays-brains/" rel="nofollow">Deep space travel’s radiation problem: what cosmic rays do to brains</a> appeared first on <a href="http://blogs.biomedcentral.com/bmcseriesblog" rel="nofollow">BMC Series blog</a>.</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://blogs.biomedcentral.com/bmcseriesblog/2016/11/08/understanding-species-demographic-history-avoid-unexpected-extinction/">Understanding a species’ demographic history to avoid an “unexpected” extinction</a></h2></div>
            <p class="text-muted">by <a href="http://blogs.biomedcentral.com/bmcseriesblog">BMC Series blog</a> on November 08, 2016 10:04 AM.</p>
          </div>
          <div class="panel-body">

            <img alt="A Turtle dove" class="attachment-thumbnail size-thumbnail wp-post-image" height="110" src="http://blogs.biomedcentral.com/bmcseriesblog/wp-content/uploads/sites/9/2016/11/Turtle-dove_Sturtur_by-Victor-Vasilev-140x110.jpg" style="display: block; margin-bottom: 5px; clear: both;" width="140" /><p>The conservation of biodiversity is a major concern for biologists. When a species shows a very small census size (e.g. <a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0099941">blue-throated macaws</a>), it is obvious that it is threatened and that urgent conservation measures are needed to preserve it. However, there are stunning examples in which a species can go from billions of individuals to vanishing, within a human lifetime.</p>
<p>Understanding how an abundant species can suddenly disappear is tricky. However, there are certain factors to watch out for. Factors that when combined at the right time and place can cause these “unexpected” extinctions. One paradigmatic example is the <a href="http://www.pnas.org/content/111/29/10636.full">passenger pigeon (<em>Ectopictes migratorious</em>)</a>. The passenger pigeon was an abundant species (2-5 billion individuals) that became extinct in blink of an eye. What caused such a drastic event? Two main identified factors were: that the species was going through the shrinking stage of its naturally oscillating demography and this coincided with a strong hunting pressures imposed by humans.</p>
<p>What can we learn from the passenger pigeon? Are the factors that led to its disappearance generalizable to other taxa? It seems that there are intrinsic factors that make certain species more sensitive to extinction, for example the tendency to undergo drastic <a href="http://www.sciencedirect.com/science/article/pii/S0960982215004005">demographic oscillations</a>. On the other hand, there are also extrinsic factors, like those imposed by humans (e.g. hunting, environmental degradation).</p>
<p>Unfortunately, when comparing the current situation of the European turtle dove with that of the passenger pigeon, there are many similarities that could push the former in the direction of its less fortunate cousin. The European turtle dove is an abundant species (6-10 millions individuals). However its numbers have been decreasing, leading to its classification as vulnerable to extinction (<a href="http://www.iucnredlist.org/details/22690419/0">IUCN red list</a>). In the United Kingdom alone it has shown a 97% decline in 40 years. The main reasons for this decline are habitat degradation and game hunting. Moreover, our genomic analysis suggests that the species has a naturally fluctuating demographic history, and that it is currently going thorough a shrinking stage…</p>
<p>Is there something we can do to prevent history from repeating itself? We can first learn from recent history, and continue to emphasize the importance of using cutting edge tools (such as genomics and niche modeling techniques) to help understand the population genetic structure and demographic history of species. This kind of research is valuable, not only because it helps understand evolutionary processes, but also because it provides useful information for researchers involved in the creation of international <a href="http://www.birdlife.org/europe-and-central-asia/project/life-eurosap">cooperation networks</a> for the protection of species and their natural environments. With this kind of research we can transform the unexpected into expected, and that is a very important first step towards conservation.</p>
<p>The post <a href="http://blogs.biomedcentral.com/bmcseriesblog/2016/11/08/understanding-species-demographic-history-avoid-unexpected-extinction/" rel="nofollow">Understanding a species’ demographic history to avoid an “unexpected” extinction</a> appeared first on <a href="http://blogs.biomedcentral.com/bmcseriesblog" rel="nofollow">BMC Series blog</a>.</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://feeds.plos.org/~r/plos/Blog/~3/czMTlm5HKMY/">A PLOS Response to Open in Action with Open Science</a></h2></div>
            <p class="text-muted">by <a href="http://blogs.plos.org/plos">The Official PLOS Blog</a> on November 04, 2016 07:31 PM.</p>
          </div>
          <div class="panel-body">

            <img alt="Open-in-Action_opt1" class="attachment-thumbnail size-thumbnail wp-post-image" height="150" src="http://blogs.plos.org/plos/files/2016/11/Open-in-Action_opt1-150x150.png" style="display: block; margin-bottom: 5px; clear: both;" width="150" /><div class="wp_orcid_field"><a href="http://orcid.org/0000-0001-7318-5892" rel="author" target="_blank">0000-0001-7318-5892</a></div><p>With the theme of <strong><a href="http://openaccessweek.org/" target="_blank">Open in Action</a></strong>, International Open Access Week 2016 served as a call for researchers, policymakers, funders and publishers around the globe to take “<strong><a href="http://www.action.openaccessweek.org/" target="_blank">concrete steps to open up research and scholarship</a></strong>.” In direct response to this call, PLOS thought carefully about Open Science and what it means for us.</p>
<h3><strong>Reflections on Open Science at PLOS</strong></h3>
<p>PLOS has proven that making quality research openly available for anyone to read, download and reuse is a viable business model. Our collaborative efforts with like-minded organizations have inspired others – from individual researchers to the larger publishing industry – to move toward a more open ethos. In this environment, Open Access is no longer constrained to free access to research, it’s also about <strong><a href="http://blogs.plos.org/speakingofmedicine/2016/02/10/zika-emergency-puts-open-data-policies-to-the-test/" target="_blank">open data and a more open way of working together</a></strong>. Examples of this at PLOS include our pioneering a <strong><a href="http://journals.plos.org/plosone/s/data-availability" target="_blank">forward-thinking data policy</a></strong> at scale and contributions to the community-developed open-standard <strong><a href="http://blogs.plos.org/plos/2016/07/author-credit-plos-and-credit-update/" target="_blank">taxonomy of contributions</a></strong> – the CRediT Project – that provides specific and comprehensive attribution on research articles for all who participate in generating a published work.</p>
<p>We are proud to be <strong><a href="http://blogs.plos.org/plos/2016/01/author-credit-plos-orcid-update/" target="_blank">Open in Action collaborators</a></strong> with other publishers including The Royal Society, <em>eLife</em>, Science journals and EMBO Press in making a <strong><a href="http://orcid.org/content/requiring-orcid-publication-workflows-open-letter" target="_blank">public commitment</a></strong> to implement persistent identifiers such as <strong><a href="https://www.plos.org/orcid" target="_blank">ORCID iDs</a></strong> by year end. These iDs enable researchers to receive credit for a wide range of research outputs in addition to publications (for example blog posts at PLOS) and we are well on the way to meeting this goal. With <strong><a href="http://blogs.plos.org/plos/2016/07/impact-factors-do-not-reflect-citation-rates/" target="_blank">many of these same collaborators</a></strong> (The Royal Society, <em>eLife</em>, <em>Science</em>, <em>EMBO Journal,</em> <em>Nature </em>and Professor of Structural Biology Stephen Curry and Associate Professor of Information Science Vincent Larivière) we committed to publish citation distributions of our journals to demonstrate a key flaw with impact factors—they simply do not reflect article citation rates. In publishing this data, PLOS hopes to “strengthen a call for action originally voiced by Stephen Curry, one of the authors, and to encourage other journals to follow suit.” The original <strong><a href="http://biorxiv.org/content/early/2016/07/05/062109" target="_blank">paper and dataset are posted on bioRxiv</a></strong> for all to access.</p>
<h3><strong>Open Policies and Open Research</strong></h3>
<p>Data sharing and Open Access are a matter of course for PLOS authors, providing open and rapid dissemination of their original research in all areas of science. PLOS supports authors who wish to share early versions of their research manuscripts to receive feedback before – or in parallel to – formal peer review, and <strong><a href="http://blogs.plos.org/plos/2016/10/the-best-of-both-worlds-preprints-and-journals/" target="_blank">encourages researchers to share via preprint servers</a></strong> either before or after submission to a PLOS journal. PLOS has a long-standing policy of accepting manuscripts previously posted to preprint servers, however we have eased the process for authors for this rapid dissemination vehicle that also brings transparency to the review process. Authors can now use bioRxiv’s <strong><a href="http://biorxiv.org/submit-a-manuscript" target="_blank">direct transfer to journal service drop-down menu</a></strong> to submit directly to PLOS.</p>
<p>We have exemplified Open in Action as the first publisher to react to the Zika outbreak with a Call for Research and <strong><a href="http://collections.plos.org/zika" target="_blank">The Zika Collection</a></strong>. This placed PLOS on the map for rapid dissemination and discovery of results during the outbreak. As a result, work of authors who published with PLOS caught the attention of legislators: The US Capitol called PLOS to ask for additional information regarding the <strong><a href="http://currents.plos.org/outbreaks/" target="_blank"><em>PLOS Currents: Outbreaks</em></a></strong> article, “<strong><a href="http://currents.plos.org/outbreaks/article/travel-volume-to-the-united-states-from-countries-and-u-s-territories-with-local-zika-virus-transmission/" target="_blank">Travel Volume to the United States from Countries and U.S. Territories with Local Zika Virus Transmission</a></strong>” as they were considering this information for use in upcoming legislation.</p>
<p>The practical impact of Open Access and open data may not always be immediate. The International Union for Conservation of Nature (<strong><a href="https://www.iucn.org/" target="_blank">IUCN</a></strong>), publishers of the <strong><a href="http://www.iucnredlist.org/" target="_blank">IUCN Red List of Threatened Species</a></strong>, voted in September 2016 to adopt the <strong><a href="https://portals.iucn.org/congress/motion/014" target="_blank">Environmental Impact Classification for Alien Taxa</a></strong> (EICAT) for classifying invasive species, work originally <strong><a href="http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1001850" target="_blank">published in <em>PLOS Biology</em></a></strong> in 2014. Author Tim Blackburn stated “IUCN has approved the motion on our method for classifying alien species impacts…The adopted text requires a consultation before EICAT becomes an IUCN standard… [but] it is an extremely positive development… Getting the paper published somewhere so high profile (and open) really made a difference, so thank you!”</p>
<p>Actionable knowledge on an international scale extends beyond conservation efforts to inform human health and disease initiatives. The <strong><a href="http://collections.plos.org/ferg2015" target="_blank">WHO Estimates of Foodborne Disease Collection</a></strong> reports the first estimates by the World Health Organization (WHO) <strong><a href="http://apps.who.int/iris/handle/10665/242847" target="_blank">Foodborne Disease Burden Epidemiology Reference Group</a></strong> of the incidence, mortality and disease burden caused by 31 foodborne hazards. Outcomes reported in the Collection – from PLOS, WHO and <strong><a href="https://f1000research.com/browse" target="_blank"><em>F1000Research</em></a></strong> authors – can contribute to improvements in food safety throughout the food chain when incorporated into policy development at regional, national and international levels.</p>
<p>If you choose to be Open in Action with PLOS, you can also have a bit of intellectual fun. The <strong><a href="http://blogs.plos.org/paleocomm/" target="_blank">PLOS Paleo Community</a></strong> held a <strong><a href="http://blogs.plos.org/paleocomm/2016/09/14/vote-for-the-top-10-open-access-fossil-vertebrates-of-2016/" target="_blank">competition</a></strong> for the paleontology research community for the <strong><a href="https://www.plos.org/paleo-top-ten" target="_blank">Top 10 Open Access Fossil Vertebrates</a></strong> of the year, to honor researchers that have thought long and worked hard to provide our community quality research that is openly available to all. Articles represent the vertebrate diversity published in Open Access journals, from <strong><a href="http://journals.plos.org/plosone/" target="_blank"><em>PLOS ONE</em></a></strong> to <strong><a href="https://peerj.com/articles/2027/" target="_blank"><em>PeerJ</em></a></strong>, <strong><a href="http://advances.sciencemag.org/content/2/5/e1501659.full" target="_blank"><em>Science Advances</em></a></strong> and <strong><a href="http://palaeo-electronica.org/content/2016/1490-new-marsupial-lion" target="_blank"><em>Paleontologia Electronica</em></a></strong>.</p>
<h3><strong>Encouraging the Next Generation of Open</strong></h3>
<p>PLOS supports the growth of <strong><a href="http://blogs.plos.org/thestudentblog/" target="_blank">Early Career Researchers</a></strong> (ECRs) as they build skills in science communication, become champions of Open Science and develop into ambassadors of change for a future where all research is freely available, all work is evaluated fairly and all members of the scientific community have opportunity to participate in the dialogue of and about science. To support the efforts of ECRs, we are continuing to offer our Early Career Researcher Travel Award (ECRTA) program, launched in 2015. For its first round in 2016, applicants were asked to describe characteristics of the optimal peer review process and how they might build this in a way that makes science more transparent and research more rapidly available. <strong><a href="http://blogs.plos.org/thestudentblog/2016/07/16/ecrawards1/" target="_blank">Winners were profiled</a></strong> and we’ve now completed a second award round asking what ECRs consider to be the value of a preprint server and how its broad adoption might benefit the scientific community and society.</p>
<p>As a participant in <strong><a href="http://www.opencon2016.org/" target="_blank">OpenCon 2016</a></strong>, a conference focused on educating and empowering the next generation in the areas of Open Access, Open Education and Open Data, PLOS will have the opportunity to hear directly from participants regarding their desires and concerns for the future of science communication. In a <strong><a href="https://www.youtube.com/watch?v=QtiyYK1U-Vs" target="_blank">video welcoming address</a></strong>, Publisher Louise Page acknowledges the inspiration provided by this annual gathering of Open Science thinkers and presents highlights of the past year at PLOS that reflect how the organization is Open in Action.</p>
<p></p>
<blockquote><p>“PLOS was founded with the researcher foremost in our minds and we want to work with you to continue our journey from Open Access to Open Data, Open Source and ultimately to Open Science,” says Page.</p></blockquote>
<p>The brief video is an introduction to an <strong><a href="https://youtu.be/hnr7Wsyz3SA" target="_blank">OpenCon Community Webcast with Peter Suber</a></strong>, Director of the Harvard Office for Scholarly Communication. You can also listen to the OpenCon 2015 video address by PLOS Executive Editor Véronique Kiermer on <strong><a href="http://blogs.plos.org/plos/2015/12/the-future-of-science-communication/" target="_blank">The Future of Science Communication</a></strong>.</p>
<h3><strong>Open Access Is Open in Action</strong></h3>
<p>In an increasingly vibrant research world where multimedia data, new types of research outputs and real-time online discussions are altering the way the community works, communicates and cooperates, Open Access is more than ever Open in Action. PLOS is proud that our <strong><a href="https://www.plos.org/core-principles" target="_blank">founding core principles</a></strong> exemplify Open in Action. What makes us notable among other publishers is that we were Open in Action <strong><a href="https://www.plos.org/history" target="_blank">from the start</a></strong>: 24/7, 52 weeks a year.</p>
<h3><strong>Our View of Open Science</strong></h3>
<h6>As a leading Open Access publisher, PLOS pursues a publishing strategy that optimizes the openness and integrity of the publication process by aiming to ensure that research outcomes are discoverable, accessible and available for discussion and that science communication is constructive, transparent and verifiable. We strive to implement policies and innovations that promote reproducibility, credit and accountability, as these priorities support establishment of an Open Science culture, with open data, early sharing of work and clear contributor recognition. We see the benefit of Open Access content in relation to future advances in machine-readable formats and text and data mining.</h6>
<p>We look forward to hearing your Open Science stories and the outcomes, large or small, that you have achieved. Leave a comment here or email to <strong><a href="mailto:communications@plos.org">communications@plos.org</a></strong>.</p>
<p> </p>
<p>Image Credit: SPARC</p>
<img alt="" height="1" src="http://feeds.feedburner.com/~r/plos/Blog/~4/czMTlm5HKMY" width="1" />
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://blogs.biomedcentral.com/bmcseriesblog/2016/11/04/highlights-bmc-series-october-2016/">Highlights of the BMC-series: October 2016</a></h2></div>
            <p class="text-muted">by <a href="http://blogs.biomedcentral.com/bmcseriesblog">BMC Series blog</a> on November 04, 2016 04:22 PM.</p>
          </div>
          <div class="panel-body">

            <img alt="BMCWordle" class="attachment-thumbnail size-thumbnail wp-post-image" height="110" src="http://blogs.biomedcentral.com/bmcseriesblog/wp-content/uploads/sites/9/2016/07/BMCWordle-140x110.png" style="display: block; margin-bottom: 5px; clear: both;" width="140" /><p><a href="http://bmcplantbiol.biomedcentral.com/articles/10.1186/s12870-016-0907-0"><strong>Plant Biology: imaging plant cell walls</strong></a></p>
<p>A new <em>BMC Plant Biology</em> article describes a valuable new tool to study plant cell walls and glycobiology. Glycans are carbohydrate molecules that attach to plant cell walls and proteins, and serve critical regulatory functions in development, cell-cell communication and immunity. The inability to directly label and image endogenous plant glycans with fluorescent tags has thus far hindered study of these molecules and their function in cellular processes. However, the copper-free click chemistry approach from Hoogenboom et al (2016) offers a novel method to fluorescently label plant glycans with high specificity and low toxicity.</p>
<p><strong><a href="https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-016-3110-7">Genomics: cosmic radiation affects the brain</a></strong></p>
<p>Galactic cosmic rays are a significant source of high-energy radiation and may pose a health hazard to those involved in deep space missions. <sup>56</sup>Fe ions, a component of such rays, have previously been shown to affect memory in juvenile mice, though the mechanisms underlying such effects were unclear. In this study published in <em>BMC Genomics</em>, the authors investigated the effects of <sup>56</sup>Fe ion radiation on the cognitive function of 6-month old mice. Radiation exposure resulted in behavioral changes that were correlated to epigenetic remodeling within the hippocampus, highlighting the need for further investigations on the different types of irradiation that astronauts will encounter.</p>
<p><strong><a href="https://bmccancer.biomedcentral.com/articles/10.1186/s12885-016-2805-0">Cancer: community sports and health promotion</a></strong></p>
<p>Physical activity is often recommended to men diagnosed with prostate cancer, in order to counteract the side effects that treatments often have on their quality of life. Whilst previous trials to promote physical activity in men have been hampered by short follow-up periods and the clinical settings, it is hoped that the study protocol published in <em>BMC Cancer</em> will provide some empirical data obtained in a real-world setting. In this trial, participation in community-based football (soccer) forms the basis in which to assess the effectiveness such activities have on health promotion and in promoting long-term physical activity. The study is expected to be completed by November 2017, so watch this space!</p>
<p><strong>Image of the month: <a href="http://bmcevolbiol.biomedcentral.com/articles/10.1186/s12862-016-0770-5">regenerating worms</a></strong></p>
<figure class="wp-caption alignnone" style="width: 427px;"><img height="589" src="https://static-content.springer.com/image/art%3A10.1186%2Fs12862-016-0770-5/MediaObjects/12862_2016_770_Fig8_HTML.gif" width="417" /><div class="attachment-image--caption">Aberrant regeneration of the stolon (organism’s reproductive unit), observed in <em>Typosyllis antoni</em> following removal of the proventricle region (Weidhase et al, 2016).</div></figure>
<p><strong><a href="http://bmcgeriatr.biomedcentral.com/articles/10.1186/s12877-016-0342-y">Geriatrics: environmental risks and dementia</a></strong></p>
<p>There is now growing evidence that there are some modifiable risk factors that affect the onset of dementia: “diabetes, midlife hypertension and obesity, smoking, depression, cognitive inactivity, and low educational attainment”. However, as yet, little is known about the effects that environmental risk factors may have on dementia. In this systematic review, it would appear that there is moderate evidence that dementia risk may be affected by air pollution, pesticides, and electromagnetic fields amongst other factors.</p>
<p><a href="https://bmczool.biomedcentral.com/articles/10.1186/s40850-016-0009-3"><strong>Zoology: dimorphism in Siberian squirrels</strong></a></p>
<p>Due to evolutionary pressures in mammals, it is a general pattern that males are often larger than their female counterparts, both in body size and mass. However, this isn’t often the case in tree and flying squirrels. New research using data collected over 22 years seems to support this idea in Siberian flying squirrels, which has shown that females were generally larger than males throughout the year.</p>
<p><a href="http://bmcplantbiol.biomedcentral.com/articles/10.1186/s12870-016-0921-2"><strong>Plant Biology: plant innate immunity</strong></a></p>
<p>DAMPs (damage-associated molecular patterns) and MAMPs (microbe-associated molecular patterns) are important molecules that can trigger innate immune responses in both plants and animals. This <em>BMC Plant Biology</em> mini-review from Hyong Woo Choi and Daniel F. Klessig of Cornell University provides an excellent overview of this ancient and highly conserved immune system, in addition to discussing the newly discovered NAMPs, which are molecules specifically associated with immune defence against nematode infection in plant species.</p>
<p><a href="http://bmcevolbiol.biomedcentral.com/articles/10.1186/s12862-016-0784-z"><strong>Evolutionary Biology: gene flow of king penguins</strong></a></p>
<p>A hurdle in species conservation that often has to be overcome is in understanding the population structure and the patterns within it. A study in the sub-Antarctic has found that there is very low level of genetic differentiation between penguin colonies, with some colonies spanning over 7000km apart. The authors suggest that any efforts in monitoring and conserving penguin populations should be done at an archipelago level, rather than at colony level.</p>
<p><a href="http://bmcinfectdis.biomedcentral.com/articles/10.1186/s12879-016-1923-2"><strong>Infectious Diseases: meningitis in Vietnam</strong></a></p>
<p>Tuberculous meningitis, caused by an infection of the meninges by Mycobacterium tuberculosis, is a serious condition that is often accompanied by high death or disability rates, particularly in developing nations. Although this disease is well characterized in Vietnamese adults, there is little data on how this disease manifests and affects children in Vietnam. This <em>BMC Infectious Diseases</em> study aimed to address this by describing the current practices in disease management, as well as presenting the predictors of poor outcome. The authors conclude that much research is still necessary in developing strategies to treat afflicted children in order improve clinical outcomes.</p>
<p>The post <a href="http://blogs.biomedcentral.com/bmcseriesblog/2016/11/04/highlights-bmc-series-october-2016/" rel="nofollow">Highlights of the BMC-series: October 2016</a> appeared first on <a href="http://blogs.biomedcentral.com/bmcseriesblog" rel="nofollow">BMC Series blog</a>.</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://blogs.biomedcentral.com/bmcseriesblog/2016/11/03/brain-goes-diving-seals-can-go-without-air-hour/">When the brain goes diving: how seals can go without air for an hour</a></h2></div>
            <p class="text-muted">by <a href="http://blogs.biomedcentral.com/bmcseriesblog">BMC Series blog</a> on November 03, 2016 10:52 AM.</p>
          </div>
          <div class="panel-body">

            <img alt="Public domain" class="attachment-thumbnail size-thumbnail wp-post-image" height="110" src="http://blogs.biomedcentral.com/bmcseriesblog/wp-content/uploads/sites/9/2016/11/seal-1718007-140x110.jpg" style="display: block; margin-bottom: 5px; clear: both;" width="140" /><p>For most land living mammals, a lack of oxygen usually results in irreversible damage to the brain within a few minutes. One of the reasons why this happens is because this highly active tissue cannot cope with the imbalance between energy production and demand under oxygen deficient conditions (also known as hypoxia). On the other hand, the brains of diving mammals, such as whales and seals, may survive recurrent and extended periods of hypoxia caused by diving without damage.</p>
<p>To some degree, this cerebral tolerance is credited to the combination of behavioural, anatomical and physiological diving adaptations, such as a lowering of the heart rate and constriction of peripheral blood vessels. Far less studied are cellular and molecular adaptations in the brains of the diving mammals that possibly contribute to their hypoxia tolerance as well.</p>
<p>Evidence supporting the idea that cellular and molecular mechanisms do play a role arose from electrophysiological studies of brain slices from the hooded seal <em>Cystophora cristata</em>. This seal is an expert diver with recorded dives of up to 1 hour and depths of more than 1000m. When challenged with hypoxia <em>in vitro</em>, the neurons of this arctic phocid seal remained active for an extended period, while mice neurons died immediately.</p>
<p>In our article, we investigated the molecular adaptations of the hooded seal using RNA-sequencing (RNA-seq). We first obtained a transcriptome of the visual cortex of the hooded seal with more than 10,000 transcripts. Then, the mRNA levels were compared with those in the cortex of a close terrestrial relative, the ferret. We found in the seal brain a general reduction of the expression levels of genes related to energy metabolism. Most importantly, we identified two potential candidate genes which have an unusually high expression level in the seal brain and thus may contribute to its unusual hypoxia tolerance.</p>
<p>The highest mRNA level in seal cortex was found for clusterin (CLU), which is a chaperone with a variety of functions. For example, CLU interferes with the BAX-mediated apoptosis pathway, thereby promoting cell survival. The high level of CLU in the seal brain can be interpreted either as a preadaptation that protects it from the damage associated with dives or as a consequence of the stressful condition during or after a dive.</p>
<p>The largest difference in the mRNA levels between the hooded seal and the ferret brain was found for S100B, which is highly expressed in the seal brain. S100B is a Ca<sup>2+</sup>-binding stress protein with functions such as regulation of cell proliferation and activation of astrocytes during brain damage and diseases. Most interestingly, further comparative analyses of the available brain transcriptomes showed that S100B mRNA levels were also high in the minke and the bowhead whale, but low in terrestrial mammals. Thus, S100B seems to be component of a common adaptation mechanism that evolved convergently in whales and seals to better survive the reduced oxygen supply during dives.</p>
<p>However, this is not the end of the story. The functions of these two candidates in dive adaptation must be further investigated since, for example, S100B may also promote cancer, and CLU is involved in several neurodegenerative diseases in humans as well as being associated with aging.</p>
<p>The post <a href="http://blogs.biomedcentral.com/bmcseriesblog/2016/11/03/brain-goes-diving-seals-can-go-without-air-hour/" rel="nofollow">When the brain goes diving: how seals can go without air for an hour</a> appeared first on <a href="http://blogs.biomedcentral.com/bmcseriesblog" rel="nofollow">BMC Series blog</a>.</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://biocomputation.herts.ac.uk/2016/11/02/self-sustained-asynchronous-irregular-states-and-up-down-states-in-thalamocortical-networks-of-nonlinear-integrate-and-fire-neurons.html">Self-sustained Asynchronous Irregular states and Up-Down states in thalamocortical networks of nonlinear integrate-and-fire neurons</a></h2></div>
            <p class="text-muted">by <a href="http://biocomputation.herts.ac.uk/">UH Biocomputation group</a> on November 02, 2016 04:18 PM.</p>
          </div>
          <div class="panel-body">

            <p>In this talk I will present a paper [1] about a thalamocortical network model I will use as part of my research. I will start by providing a brief summary of the background and the research questions.</p>
<p>Our collaborators at Erasmus Medical Center, Rotterdam, The Netherlands, found that it is possible to stop epileptic absence seizures by exciting cerebellar nucleus (CN) neurons in a closed loop system (this work was done together with a former PhD student, Parimala Alva, [2]). In my PhD work, I will try to understand the mechanisms underlying the termination of seizures by optogenetic stimulation of CN neurons. For this purpose, I will use a thalamocortical network model of adaptive exponential integrate-and-fire neurons, as described in [1].</p>
<p>In the paper [1] the occurrence of Asynchronous Irregular (AI) states in thalamocortical networks of non-linear integrate-and-fire neurons has been investigated together with the role of spike-frequency adaptation. The main findings are that the thalamocortical networks can display AI states or Up-Down state dynamics, depending on the level of adaptation in cortical cells.</p>
<p><strong>Date:</strong> 04/11/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>
<p>[1] <a class="reference external" href="https://www.ncbi.nlm.nih.gov/pubmed/19499317">Destexhe A. Self-sustained asynchronous irregular states and up-down states in thalamic, cortical and thalamocortical networks of nonlinear integrate-and-fire neurons. J Comput Neurosci 2009; 27:493-506</a> <br /></p>
<p>[2] <a class="reference external" href="https://www.ncbi.nlm.nih.gov/pubmed/25762286">Kros et al, Cerebellar Output Controls Generalised Spike-and-Wave Discharge Occurrence, Ann Neurol, 2015</a></p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://blogs.biomedcentral.com/bmcseriesblog/2016/10/28/the-effectiveness-of-community-based-football-in-care-for-men-with-prostate-cancer/">The effectiveness of community-based football in care for men with prostate cancer</a></h2></div>
            <p class="text-muted">by <a href="http://blogs.biomedcentral.com/bmcseriesblog">BMC Series blog</a> on October 28, 2016 08:17 AM.</p>
          </div>
          <div class="panel-body">

            <img alt="7289704868_410d314fdc_o" class="attachment-thumbnail size-thumbnail wp-post-image" height="110" src="http://blogs.biomedcentral.com/bmcseriesblog/wp-content/uploads/sites/9/2016/10/7289704868_410d314fdc_o-140x110.jpg" style="display: block; margin-bottom: 5px; clear: both;" width="140" /><h3><strong>Reasons for physical activity</strong></h3>
<p>The evidence for the positive effect of physical activity on the human body is indisputable. Physical activity is a key factor in preserving and restoring health. However, physical activity is more complex than movement of the body. Physical activity is a behavior contingent on motivation influenced by societal structures and cultural values.</p>
<p>Think for one minute why you (if motivated) choose to be physically active. Are you physically active <em>simply</em> to avoid disease and for the prospect of living 6-8 years longer? If you are, you may be characterized as an extremely rational person. However, if you’re like most people in the western world, whose basic needs are fulfilled, your choice to be physically active has to do also with fulfillment of more subtle intrinsic values (i.e. competence, autonomy and relatedness).</p>
<p>If you exercise regularly, you probably choose so for the excitement of achieving a personal goal, to look good, to feel good and/or to be around friends – and movement of your body is merely a means. From engagement in numerous studies of exercise behavior in different patient populations (primarily cancer and arthritis), I will argue, that this is also the case if you’re confronted with a serious disease.</p>
<h3><strong>Physical activity for individuals with a serious disease</strong></h3>
<p>Individuals who have been diagnosed with a serious disease, and who know that they have an elevated risk of dying, may choose to become more physically active as a consequence of a more conscious way of living and as a way of coping; they ride the crest of the diagnosis as a teachable moment. However, in terms of <em>adoption</em> of physical activity, patients are not that different from the average healthy person. Therefore, simple exercise recommendations, let alone warnings against sedentary behavior, are most likely to be insufficient in the long run.</p>
<p>Patients may experience more barriers towards physical activity (e.g. fatigue, pain, deteriorated body image and lack of self-efficacy); but at the same time strive for normality and distraction from their illness. Therefore, promotion of physical activity in health care including prevention of co-morbidity and development of secondary diseases, requires interventions, that will ensure safety and physiological efficacy without compromising the intrinsic values imperative for sustainment of the behavior. Moreover, the intervention must be easily accessible and possible to implement at low costs.</p>
<h3><strong>Community based football</strong></h3>
<p>One such novel intervention could be community-based football (soccer), which is currently being examined in the context of prostate cancer survivorship care in Denmark. The FC Prostate Community trial is an ongoing randomized multicenter study aiming to examine the effectiveness of community-based football in men with prostate cancer – regardless of treatment status and potential previous experience with football.</p>
<p>The study protocol recently published in <em>BMC Cancer</em> describes how the study as well as the intervention is pragmatically designed to improve generalization and implementation. Changes in bone health and body composition are secondary to changes in quality of life based on the idea that sustainment of the football training (and thus the expected health effects) is associated with a subjective improvement in quality of life.</p>
<p>In Denmark, as in many other countries around the world, football is the sport that arouses the most passion. Our previous qualitative research suggests that prostate cancer survivors’ perception of football is pivotal for their enrolment and sustainment. Football connotes male values, and is therefore especially attractive for men whose masculinity has be threatened by the prostate cancer diagnosis and anti-hormone treatment. In the context of community-based football, men with prostate cancer can exchange their worries and express mutual understanding without taking on the role as patients. As participants in the FC Prostate Community trial, they can feel safe knowing that their coach has undergone special training and employs an evidence-based training manual intended to prevent injuries.</p>
<p>While men with prostate cancer may be motivated to enrol in community-based football because they wish to achieve or maintain their physical health, they s<em>tay</em> motivated because of the positive relations to peers and because of the excitement of scoring a goal; they stay motivated because of what the activity enables them to feel and become. As such, their continued motivation towards physical activity may not be that different from yours or mine – although I doubt that I personally will ever feel competent playing football. Football will not be for everyone, but everyone deserves to be engaged in physical activity for other reasons than mere protection from disease.</p>
<p>The post <a href="http://blogs.biomedcentral.com/bmcseriesblog/2016/10/28/the-effectiveness-of-community-based-football-in-care-for-men-with-prostate-cancer/" rel="nofollow">The effectiveness of community-based football in care for men with prostate cancer</a> appeared first on <a href="http://blogs.biomedcentral.com/bmcseriesblog" rel="nofollow">BMC Series blog</a>.</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://biocomputation.herts.ac.uk/2016/10/27/the-pricing-of-options-and-corporate-liabilities.html">The pricing of options and corporate liabilities</a></h2></div>
            <p class="text-muted">by <a href="http://biocomputation.herts.ac.uk/">UH Biocomputation group</a> on October 27, 2016 09:09 AM.</p>
          </div>
          <div class="panel-body">

            <p><a class="reference external" href="https://www.jstor.org/stable/1831029">The pricing of options and corporate liabilities (1973)</a></p>
<p>If options are correctly priced in the market, it should not be
possible to make sure profits by creating portfolios of long and short
positions in options and their underlying stocks. Using this
principle, a theoretical valuation formula for options is derived.
Since almost all corporate liabilities can be viewed as combinations
of options, the formula and the analysis that led to it are also
applicable to corporate liabilities such as common stock, corporate
bonds, and warrants. In particular, the formula can be used to derive
the discount that should be applied to a corporate bond because of the
possibility of default.</p>
<hr class="docutils" />
<p>The objectives of this talk are as follows:</p>
<ul class="simple">
<li>provide a general overview of the arguments provided by Black,
Merton and Scholes to a non-financial audience;</li>
<li>convey the importance of the <a class="reference external" href="https://en.wikipedia.org/wiki/Black%E2%80%93Scholes_model">Option Pricing formula</a> derived in
this paper to the financial markets today;</li>
<li>cover some of its shortcomings and subsequent changes done by the
financial markets.</li>
</ul>
<div class="line-block">
<div class="line"><br /></div>
</div>
<p><strong>Date:</strong> 28/10/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://feeds.plos.org/~r/plos/Blog/~3/NiuLFmuWXxM/">The Best of Both Worlds: Preprints and Journals</a></h2></div>
            <p class="text-muted">by <a href="http://blogs.plos.org/plos">The Official PLOS Blog</a> on October 25, 2016 09:01 PM.</p>
          </div>
          <div class="panel-body">

            <img alt="Image Credit: Lisa Ann Yount" class="attachment-thumbnail size-thumbnail wp-post-image" height="150" src="http://blogs.plos.org/plos/files/2016/10/bioRxiv_wooden-ripples-150x150.jpg" style="display: block; margin-bottom: 5px; clear: both;" width="150" /><div class="wp_orcid_field"><a href="http://orcid.org/0000-0001-7318-5892" rel="author" target="_blank">0000-0001-7318-5892</a></div><p>For some time now PLOS has discussed new initiatives designed to accelerate research communication, from development of Aperta™, <strong><a href="http://blogs.plos.org/tech/a-tech-framework-for-innovations-in-open-science/" target="_blank">our streamlined manuscript submission system</a></strong> that facilitates a faster time to first decision to our <strong><a href="http://blogs.plos.org/tech/collections-behind-the-scenes/" target="_blank">Content Management System</a></strong> that allows for rapid creation of curated PLOS Collections. These efforts span the range of ways we are accelerating access to discovery of not just the final publication but the <strong><a href="https://www.plos.org/innovation/#loc-our-progress" target="_blank">entire research life cycle</a></strong>.</p>
<p><strong>Stake a Claim</strong></p>
<p>An additional strategy – early posting of articles before formal peer review through the use of preprints – can also advance science faster, more openly and with broader participation. In posting preprints, authors are able to make their findings immediately available to the scientific community and to <strong><a href="http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1001563" target="_blank">receive feedback on draft manuscripts</a></strong> before they are submitted to journals. The benefit extends beyond making early work openly and freely available prior to or during consideration at a journal; in posting a preprint, an author or author group stakes an intellectual claim to methods, results and ideas contained within that paper. This can be especially important for scientists looking to change the focus of their research and connect with engaged colleagues in new fields; for those on the job market needing to show the status of their current research, their collaborative nature and their ability to embrace change for a more open way of doing science; and for early career researchers who may find opportunity to interact with new contacts interested in their work.</p>
<p>PLOS supports authors who wish to share early versions of their research manuscripts to receive feedback before – or in parallel to – formal peer review, and <strong><a href="http://www.ascb.org/consensus-grows-preprints-biology-2/" target="_blank">encourages researchers to share via preprint servers</a></strong> either before or after submission to a PLOS journal. Preprints are an excellent way to:</p>
<ul>
<li>Establish intellectual precedence for ideas, methods, results</li>
<li>Receive early feedback from engaged colleagues</li>
<li>Obtain and document citations to a work before publication in a peer-reviewed journal</li>
<li>Contribute to accelerating scientific discovery and increasing research efficiency</li>
</ul>
<p>PLOS has a long-standing policy of accepting manuscripts previously posted to preprint servers, however we recently collaborated with bioRxiv to ease the process as a reflection of the importance we assign to this rapid dissemination vehicle for authors that also brings transparency to the review process. Authors can now use bioRxiv’s <strong><a href="http://biorxiv.org/submit-a-manuscript" target="_blank">direct transfer to journal service drop-down menu</a></strong> to submit directly to PLOS. While authors posting to bioRxiv can choose the reuse options under which to make their article available (various CC BY options or no reuse), licensing terms of PLOS content <strong><a href="https://www.plos.org/open-access" target="_blank">has not changed</a></strong>. To inform authors and the public of the current and more seamless arrangement with bioRxiv we have updated our preprint policy on all journal <strong><a href="http://journals.plos.org/plosone/s/ethical-publishing-practice#loc-preprint-servers" target="_blank">ethical publishing practice</a></strong> and <strong><a href="http://journals.plos.org/plosone/s/submission-guidelines" target="_blank">related manuscript</a></strong> sections as well as the Wikipedia page that describes the <strong><a href="https://en.wikipedia.org/wiki/List_of_academic_journals_by_preprint_policy" target="_blank">landscape of publisher’s preprint policies</a></strong>.</p>
<p><strong>Researchers First</strong></p>
<p>With preprints, authors – not publishers – are in control of when they publicly timestamp their intellectual property as well as when they want it to go for review. They <strong><a href="http://www.nytimes.com/2016/03/16/science/asap-bio-biologists-published-to-the-internet.html" target="_blank">decide when their research paper is ready to post</a></strong> and when they’re ready to submit their paper for formal peer review. In an open environment, the community can evaluate what any individual scientist’s standards are for their work and their online interaction with colleagues. By posting work and commenting on the posted work of others, authors are more in control of their own reputations. In essence, the use of preprints is analogous, in a very public and large-scale version, to the more intimate practice of sending a complete manuscript draft to a colleague to get their opinion with potential to improve the manuscript before submitting to a journal. Some have likened it to going public with a <strong><a href="http://blogs.plos.org/paleo/2015/09/07/on-preprints-in-paleontology/" target="_blank">conference abstract or presentation</a></strong>.</p>
<p><strong>How it Works</strong></p>
<p>In the same way that not all Open Access is created equal, not all preprint servers work the same way. Launched in 2013 by <strong><a href="http://www.cshl.edu/" target="_blank">Cold Spring Harbor Laboratory</a></strong>, bioRxiv is now in its third year with more than 5,000 preprints posted to the site and more than 1 million article views each month. At bioRxiv, all posted research papers receive a digital object identifier (DOI) that remains associated with the original preprint. When a manuscript is transferred to PLOS from bioRxiv, PLOS stores the preprint DOI; if that manuscript is accepted for publication it then receives a PLOS DOI and we deposit both the preprint and the final article DOI to CrossRef so the <strong><a href="http://blog.crossref.org/2016/05/members-will-soon-be-able-to-assign-crossref-dois-to-preprints.html" target="_blank">two works can be associated with each other</a></strong>.</p>
<h4>Importantly, whether posting a preprint or submitting to a journal, authors can help themselves ensure full recognition for both the preprint and the final article by <strong><a href="https://www.plos.org/orcid" target="_blank">including their ORCID iD</a></strong> at all times.</h4>
<p>At PLOS, preprints are acceptable resources for inclusion in the reference section of an article. Should anyone follow a link from an article citation to a preprint that has subsequently been peer reviewed and published, they would be directed from the preprint to the article on the PLOS journal website.</p>
<p><a href="http://blogs.plos.org/plos/files/2016/10/Blogs-image_bioRxiv_38.png"><img alt="Blogs-image_bioRxiv_38" class="size-full wp-image-7196 aligncenter" height="156" src="http://blogs.plos.org/plos/files/2016/10/Blogs-image_bioRxiv_38.png" width="900" /></a></p>
<p style="text-align: center;">DOI: <a href="http://dx.doi.org/10.1371/journal.pone.0164504" target="_blank">10.1371/journal.pone.0164504</a></p>
<p><a href="http://blogs.plos.org/plos/files/2016/10/Blogs-image_bioRxiv_gen-article.png"><img alt="Blogs-image_bioRxiv_gen-article" class="size-full wp-image-7195 aligncenter" height="292" src="http://blogs.plos.org/plos/files/2016/10/Blogs-image_bioRxiv_gen-article.png" width="900" /></a></p>
<p> </p>
<p><strong>Value Perspective</strong></p>
<p>Preprints <strong><a href="http://www.chronicle.com/article/Zika-Moves-Quickly-and/237419/" target="_blank">do not diminish the need for reputable peer-reviewed journals</a></strong>. In fact, the combination provides scientists the best of both worlds; preprints accelerate making work public and provide an opportunity for early feedback for those willing to share their work whereas journals provide a mechanism for formal assessment, curation and dissemination. Journals reinforce standards for ethical and reporting guidelines, plagiarism checks, conflicts of interest and work with organizations such as CrossRef to ensure seamless and complete metadata transfer. Publishing in journals has the added benefits of validating the quality of work through rigorous peer review; placing work in context through perspectives, editorials and incorporation into collections; providing opportunities for online dialogue with authors through <strong><a href="http://plos.io/1Jz2DfN" target="_blank">PLOS Science Wednesday AMAs</a></strong> and tracking article influence through <strong><a href="http://blogs.plos.org/plospodcasts/2016/09/19/understanding-altmetrics-an-interview-with-stacy-konkiel/" target="_blank">Article-Level Metrics</a></strong>. Our current work with bioRxiv is one more example of how we are putting researchers at the center of science communication and placing authors in control of their manuscripts. In the future, expansion of Aperta to the full suite of PLOS journals and <strong><a href="http://plos.io/2dreNOY" target="_blank">incorporating aspects of community review</a></strong> to our processes will place PLOS in the space necessary to <strong><a href="http://blogs.plos.org/plos/2016/04/placing-authors-at-the-center-of-the-scientific-endeavor/" target="_blank">accelerate dissemination</a> </strong>of research results and conversation surrounding a scholarly work.</p>
<p>Those wanting an objective look at the value of preprints might find <strong><a href="http://blogs.plos.org/absolutely-maybe/2016/05/01/breaking-down-pros-and-cons-of-preprints-in-biomedicine/" target="_blank">Breaking Down Pros and Cons of Preprints in Biomedicine</a></strong> of interest; for a detailed discussion of preprints by one active participant listen to the <strong><a href="http://blogs.plos.org/plospodcasts/2016/10/24/the-power-of-preprints-an-interview-with-james-fraser/" target="_blank">PLOScast with James Fraser</a></strong>, Associate Professor at UCSF and a founding member of <strong><a href="http://asapbio.org/" target="_blank">ASAPbio</a>,</strong> an initiative of the biology community to encourage use of preprints. When you’re ready, go ahead, post that paper, place your results and ideas in the mix and we’ll advance science forward faster, together.</p>
<p> </p>
<p>Image Credit:<a href="https://www.flickr.com/photos/136594255@N06/24345993501" target="_blank"> Lisa Ann Yount</a></p>
<img alt="" height="1" src="http://feeds.feedburner.com/~r/plos/Blog/~4/NiuLFmuWXxM" width="1" />
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://feeds.plos.org/~r/plos/Blog/~3/uJV0E045F7Q/">Jenny Machida Appointed to PLOS Board of Directors</a></h2></div>
            <p class="text-muted">by <a href="http://blogs.plos.org/plos">The Official PLOS Blog</a> on October 25, 2016 03:59 PM.</p>
          </div>
          <div class="panel-body">

            <p style="line-height: 16.5pt; background: white; vertical-align: baseline; margin: 0in 0in 15.0pt 0in;"><span style="font-size: 11.0pt; font-family: 'Calibri',sans-serif;">PLOS is pleased to announce that Jenny Machida has joined the PLOS Board of Directors, effective October 21, 2016. “Jenny’s deep business knowledge with a focus on strategy, growth and organization performance will greatly contribute to PLOS as we strive to build a better publishing experience for authors in 2017 and beyond,” said Board Chairman Gary Ward.  “We are delighted that she is joining our Board of Directors and look forward to benefiting from her depth and breadth of experience.” </span></p>
<p style="line-height: 16.5pt; background: white; vertical-align: baseline; margin: 0in 0in 15.0pt 0in;"><span style="font-size: 11.0pt; font-family: 'Calibri',sans-serif; color: black;">Machida received her BA summa cum laude from Yale University and earned an MBA from the University of California at Berkeley. Machida is currently a Managing Director at IMB Development Corporation, a private equity investment and operating firm. Prior to IMB, she co-founded and led business development at a medical technology start-up company called Sevident and helped to build out an academic research and advisory center at Columbia</span><span class="apple-converted-space"><span style="color: black;"> </span></span><span style="font-size: 11.0pt; font-family: 'Calibri',sans-serif; color: black;">University focused on advancing diversity in higher education. Machida was also a Principal at Booz &amp; Co. and a Principal and Co-founder of the Healthcare and Diversity &amp; Inclusion practice areas at Katzenbach Partners.</span></p>
<img alt="" height="1" src="http://feeds.feedburner.com/~r/plos/Blog/~4/uJV0E045F7Q" width="1" />
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://feeds.plos.org/~r/plos/blogs/neuro/~3/cX1Gg8gCBGQ/">Meet the #PLOS #SfN16 Contributors</a></h2></div>
            <p class="text-muted">by <a href="http://blogs.plos.org/neuro">PLOS Neuroscience Community</a> on October 24, 2016 10:13 PM.</p>
          </div>
          <div class="panel-body">

            <img alt="IMG_1365" class="attachment-thumbnail size-thumbnail wp-post-image" height="150" src="http://blogs.plos.org/neuro/files/2015/10/IMG_1365-150x150.png" style="display: block; margin-bottom: 5px; clear: both;" width="150" /><p>The PLOS Neuroscience Community will be returning for a third year to the <a href="https://www.sfn.org/annual-meeting/neuroscience-2016" target="_blank">Society for Neuroscience conference</a>, to be held November 12-16, in San Diego, CA. We’re thrilled to introduce our phenomenal team of students, postdocs and faculty who will be live-tweeting and blogging the meeting. Read on to meet the contributors and learn about the fascinating neuroscience, outreach issues and social events they’re planning to cover.</p>
<p> </p>
<p><a href="http://blogs.plos.org/neuro/files/2015/09/emilie.png"><img alt="" height="141" src="http://blogs.plos.org/neuro/files/2015/09/emilie.png" width="125" /></a> <strong>Emilie Reas</strong> (<a href="https://twitter.com/etreas" target="_blank">@etreas</a>): I’m a postdoctoral fellow at UC San Diego and editor for the PLOS Neuroscience Community. I’m fascinated by how the brain creates and retrieves memories, and how neural changes during aging and disease cause the loss of memory and other cognitive functions. Outside of lab, I love to indulge in long runs, travel and writing. Follow me at #SfN16 where I’ll be tweeting and blogging about memory, aging and beyond!</p>
<p> </p>
<p><a href="http://blogs.plos.org/neuro/files/2016/10/headshot-Elena-BlancoSuarez.jpg"><img alt="headshot Elena BlancoSuarez" height="150" src="http://blogs.plos.org/neuro/files/2016/10/headshot-Elena-BlancoSuarez-150x150.jpg" width="150" /></a> <strong>Elena Blanco-Suárez</strong>: I am a postdoc in the Salk Institute in the molecular neurobiology lab of Nicola Allen. I study novel astrocyte-secreted factors that are involved in synaptic plasticity in the developing brain. I use in vitro and in vivo techniques to dissect the mechanisms of these newly discovered factors. I will be blogging my favorite sessions from #SfN16.</p>
<p> </p>
<p><a href="http://blogs.plos.org/neuro/files/2016/10/Nipun-Chopra.jpg"><img alt="Nipun Chopra" height="150" src="http://blogs.plos.org/neuro/files/2016/10/Nipun-Chopra-150x150.jpg" width="150" /></a> <strong>Nipun Chopra </strong>(<a href="https://twitter.com/NipunChopra7" target="_blank">@NipunChopra7</a>): I am about to defend my PhD dissertation at IU School of Medicine. My research examines the microRNA regulation of proteins implicated in the pathogenesis of Alzheimer’s disease.</p>
<p> </p>
<p><img alt="Kurt" height="150" src="http://blogs.plos.org/neuro/files/2016/10/Kurt-150x150.jpg" width="150" /> <strong>Kurt Fraser</strong> (<a href="https://twitter.com/Kurt_Fraser" target="_blank">@Kurt_Fraser</a>) is a second year graduate student in biopsychology at The Johns Hopkins University where he works with Dr. Patricia Janak. His research interests lie in understanding individual differences in motivation and how dopamine functions within the amygdala complex during reward-related learning. At #SfN16 he’ll be tweeting all things reward, motivation, addiction, dopamine, and recent advances in understanding the link between neural circuits and behavior.</p>
<p> </p>
<p><a href="http://blogs.plos.org/neuro/files/2016/10/GulatiTanuj.jpg"><img alt="Gulati,Tanuj" height="150" src="http://blogs.plos.org/neuro/files/2016/10/GulatiTanuj-150x150.jpg" width="150" /></a> <strong>Tanuj Gulati</strong> (<a href="https://twitter.com/tanuj_gulati" target="_blank">@tanuj_gulati</a>): I am a postdoctoral fellow at UC San Francisco. I am working in the areas of procedural learning, especially its sleep-related processing. Skill learning is a special case, as unlike the memory of a fact/ episode, it takes time and practice to assimilate. And it is also sub served by different neural structures (e.g. striatum, cerebellum). In my work, I have used brain-machine interfaces (BMIs) as a proxy for skill learning. Modern systems neuroscience approaches of high-density electrophysiological recordings, and causal neural manipulations are making it possible to elucidate the neural basis of procedural learning and I will be covering this area at #SfN16. Additionally, I will also cover research on memory functions of sleep, as well as novel neurotechnology geared towards movement disorders.</p>
<p> </p>
<p><a href="http://blogs.plos.org/neuro/files/2016/10/Anahita_Hamidi-300x200.jpg"><img alt="Anahita_Hamidi-300x200" height="150" src="http://blogs.plos.org/neuro/files/2016/10/Anahita_Hamidi-300x200-150x150.jpg" width="150" /></a> <strong>Anahita Hamidi</strong> is currently a PhD Candidate in the <a href="http://neuroscience.ucdavis.edu/" target="_blank">UC Davis Neuroscience</a> program. She works with mouse models to study the neural basis of memory formation and retrieval. In addition to research, she is an active freelance science writer and maintains a blog at: <a href="http://www.genetic-expressions.com" target="_blank">www.genetic-expressions.com</a>. She is also a core team member of <a href="http://www.neuroeditor.com/" target="_blank">NeuroEditor</a> – an initiative aimed at improving the way neuroscience is communicated both within and outside of academia. She is committed to open and clear communication of science for all. Also, she can’t seem to stop asking questions and drinking coffee.</p>
<p> </p>
<p><a href="http://blogs.plos.org/neuro/files/2016/10/Izbicki_Headshot.jpg"><img alt="Izbicki_Headshot" height="150" src="http://blogs.plos.org/neuro/files/2016/10/Izbicki_Headshot-150x150.jpg" width="150" /></a> <strong>Patricia Izbicki</strong>: I am a second-year neuroscience doctoral student at Iowa State University As a classical pianist and harpsichordist, I have experienced the physical and psychological effects of music. However, the neural mechanisms, clinical implications, and educational benefits of these effects have not been completely determined. My main research interest is to understand more about the effects of music on the brain and nervous system along with the clinical and educational implications.</p>
<p> </p>
<p><a href="http://blogs.plos.org/neuro/files/2015/10/clantz.jpg"><img alt="clantz" height="150" src="http://blogs.plos.org/neuro/files/2015/10/clantz-150x150.jpg" width="150" /></a> <strong>Crystal Lantz</strong> is a post-doctoral researcher at the University of Maryland in College Park, where she uses in vivo electrophysiology to study the primary visual cortex. She is interested in the regulation of experience-dependent plasticity, and how it can be rejuvenated to treat amblyopia. When she’s not in the lab, she enjoys backpacking, fly fishing, and sewing. This year at SFN she will be tweeting about inhibitory neuron function, development, and circuitry, as well striate cortex plasticity.</p>
<p> </p>
<p><a href="http://blogs.plos.org/neuro/files/2016/10/Marthe-Ludtmann.jpg"><img alt="Marthe Ludtmann" height="150" src="http://blogs.plos.org/neuro/files/2016/10/Marthe-Ludtmann-150x150.jpg" width="150" /></a> <strong>Marthe Ludtmann</strong>: I am postdoctoral scientist at the Institute of Neurology (UCL, UK). Most of my research centres around the use of live cell imaging technologies to unravel cellular changes in Parkinson’s disease. I am particularly interested in mitochondria and changes in the bioenergetics status of the cell. This is my first SfN meeting and I will be tweeting about my conference experience, Parkinson’s and Alzheimer’s disease research.</p>
<p><a href="http://blogs.plos.org/neuro/files/2015/10/DanLurie.jpg"><img alt="DanLurie" height="150" src="http://blogs.plos.org/neuro/files/2015/10/DanLurie-150x150.jpg" width="150" /></a> <strong>Dan Lurie</strong>: I am a 3rd year PhD student in Cognitive Neuroscience at UC Berkeley. My work uses fMRI to grow our understanding of the large-scale functional architecture of the human brain, and how whole-brain activity and connectivity dynamics relate to ongoing cognition. I am particularly interested in identifying the mechanisms underlying the control of brain dynamics, and working to integrate existing knowledge about the neural basis of cognitive control and working memory with emerging insights from complex systems, network science, and machine learning.</p>
<p> </p>
<p><a href="http://blogs.plos.org/neuro/files/2015/10/ChrisMadan.jpg"><img alt="ChrisMadan" height="150" src="http://blogs.plos.org/neuro/files/2015/10/ChrisMadan-150x150.jpg" width="150" /></a> <strong>Christopher Madan</strong> (<a href="https://twitter.com/cMadan" target="_blank">@cMadan</a>) is currently a postdoc at Boston College. Chris studies memory and decision making, and is particularly interested in what factors makes some experiences more memorable than others and how these influences can manifest in decision making. Recently Chris has also been investigating inter-individual differences in brain morphology.</p>
<p> </p>
<p><a href="http://blogs.plos.org/neuro/files/2016/10/Aaron-Sathyanesan-photo.jpg"><img alt="Aaron Sathyanesan photo" height="150" src="http://blogs.plos.org/neuro/files/2016/10/Aaron-Sathyanesan-photo-150x150.jpg" width="150" /></a> <strong>Aaron Sathyanesan</strong> (<a href="https://twitter.com/UnctionFunction" target="_blank">@UnctionFunction</a>): I’m a postdoctoral fellow at the Children’s National Medical Center in Washington DC. My current research is focused on understanding how the brain computes adaptive motor behavior, and how this behavior is altered in developmental disorders. I’m ever curious about emerging neurotech to visualize neurons and glia in action. At SfN16 I will be tweeting and blogging about all things locomotion, cerebellar disorders, brain miniscopes and much more!</p>
<p> </p>
<p><a href="http://blogs.plos.org/neuro/files/2016/10/LizanneSchweren.jpg"><img alt="LizanneSchweren" height="150" src="http://blogs.plos.org/neuro/files/2016/10/LizanneSchweren-150x150.jpg" width="150" /></a> <strong>Lizanne Schweren</strong>: I’m a postdoctoral research associate at the University of Cambridge (UK), in the Department of Developmental Psychiatry. I’m trying to work out what makes the adolescent brain so highly vulnerable to developing depression and other psychiatric problems. I’m also wrapping up my PhD work on the long-term effects of stimulant treatment on the developing brain in ADHD. I’ll be tweeting and blogging about everything with the slightest relation to psychiatry and mental health, and in particular developmental psychiatry. Please do send me a tweet if you’re seeing/doing/presenting anything along these lines! When I’m not in the lab, I enjoy running and writing.</p>
<p> </p>
<p><a href="http://blogs.plos.org/neuro/files/2016/10/Marieke.jpg"><img alt="Marieke" height="135" src="http://blogs.plos.org/neuro/files/2016/10/Marieke.jpg" width="109" /></a> <strong>Marieke van Vugt</strong>: I am an assistant professor in the Department of Artificial Intelligence of the University of Groningen. My lab does research in the domain of computational cognitive neuroscience, with a focus on decision making, mind-wandering and mindfulness. I am particularly interested in how these cognitive functions are implemented by brain oscillations, so I will be tweeting about these topics and more.</p>
<img alt="" height="1" src="http://feeds.feedburner.com/~r/plos/blogs/neuro/~4/cX1Gg8gCBGQ" width="1" />
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://feeds.plos.org/~r/plos/Blog/~3/injO7e6CToA/">Open Access Week 2016 – Open in Action</a></h2></div>
            <p class="text-muted">by <a href="http://blogs.plos.org/plos">The Official PLOS Blog</a> on October 24, 2016 03:20 PM.</p>
          </div>
          <div class="panel-body">

            <img alt="OA sunrise_690x320" class="attachment-thumbnail size-thumbnail wp-post-image" height="150" src="http://blogs.plos.org/plos/files/2016/10/OA-sunrise_690x320-150x150.jpg" style="display: block; margin-bottom: 5px; clear: both;" width="150" /><p><strong>Now in its ninth year, Open Access Week celebrates progress and promotes awareness to help make Open Access – the founding principle of PLOS – the new norm in scholarship and research globally.</strong> Join PLOS in celebrating Open Access Week by being <a href="http://plos.io/2dCEpO0">Open in Action</a>.</p>
<p> </p>
<ul>
<li><strong>Register for an <a href="https://www.plos.org/orcid?utm_source=plos&amp;utm_medium=opb&amp;utm_campaign=plos-1610-oaw">ORCiD ID</a></strong> – distinguish yourself and create a record of your scholarly contributions.</li>
</ul>
<ul>
<li><strong>Join the conversation about Open Access Tools</strong> with PLOS authors Lenny Teytelman and Hilda Bastian on 10/26 10am PT for a special OA week edition of <a href="http://plos.io/AMAnext">PLOS Science Wednesday</a> – the Ask Me Anything (AMA) series on redditscience.</li>
</ul>
<ul>
<li><strong>Explore <a href="http://researchnews.plos.org/?utm_source=plos&amp;utm_medium=opb&amp;utm_campaign=plos-1610-oaw">PLOS Research News</a></strong>, featuring <a href="http://researchnews.plos.org/category/author-interview/?utm_source=plos&amp;utm_medium=opb&amp;utm_campaign=plos-1610-oaw">author interviews</a>, <a href="http://researchnews.plos.org/category/video-highlights/?utm_source=plos&amp;utm_medium=opb&amp;utm_campaign=plos-1610-oaw">video highlights</a>, <a href="http://researchnews.plos.org/category/new-research/?utm_source=plos&amp;utm_medium=opb&amp;utm_campaign=plos-1610-oaw">new research</a> and <a href="http://researchnews.plos.org/category/news-summaries/?utm_source=plos&amp;utm_medium=opb&amp;utm_campaign=plos-1610-oaw">summaries</a> of newly published PLOS articles.</li>
</ul>
<ul>
<li><strong>Get a sneak peak of PLOS’ upcoming projects</strong> with PLOS Publisher Louise Page in this OpenCon 2016 Community <a href="http://plos.io/2e3YkBf">Webcast</a>.</li>
</ul>
<ul>
<li><strong>Listen to a special episode of <a href="http://blogs.plos.org/plospodcasts/2016/10/24/the-power-of-preprints-an-interview-with-james-fraser/?utm_source=plos&amp;utm_medium=opb&amp;utm_campaign=plos-1610-oaw">PLOScast</a></strong> – a podcast focused on science, academia and the future of scholarship – featuring UCSF’s James Fraser discussing the use of preprints in the life sciences.</li>
</ul>
<ul>
<li><strong>Learn more about posting articles before formal peer review</strong> in The Official PLOS Blog’s <a href="http://blogs.plos.org/plos/2016/10/the-best-of-both-worlds-preprints-and-journals/?utm_source=plos&amp;utm_medium=opb&amp;utm_campaign=plos-1610-oaw">The Best of Both Worlds: Preprints and Journals</a>.</li>
</ul>
<ul>
<li><strong>Meet PLOS staff and editors at <a href="https://www.plos.org/svp-2016?utm_source=plos&amp;utm_medium=opb&amp;utm_campaign=plos-1610-oaw">SVP</a> or <a href="https://www.plos.org/igem-2016?utm_source=plos&amp;utm_medium=opb&amp;utm_campaign=plos-1610-oaw">iGEM</a></strong> – stop by the booth, learn more about Open Access publishing and pick up a giveaway.</li>
</ul>
<ul>
<li><strong>Browse the <a href="http://collections.plos.org/s/open-highlights?utm_source=plos&amp;utm_medium=opb&amp;utm_campaign=plos-1610-oaw">Open Highlights Collection</a></strong>, with research from across PLOS journals and the wider Open Access literature curated by staff editors to provide depth of coverage on select topics.</li>
</ul>
<ul>
<li><strong>Share your work with the world by publishing with PLOS</strong> – see <a href="https://www.plos.org/which-journal-is-right-for-me?utm_source=plos&amp;utm_medium=opb&amp;utm_campaign=plos-1610-oaw">which journal</a> is the right fit for your work or <a href="https://www.plos.org/search?utm_source=plos&amp;utm_medium=opb&amp;utm_campaign=plos-1610-oaw">search PLOS articles</a> to see where your colleagues are publishing. Some special calls for submission include: <a href="http://collections.plos.org/bridging-communities?utm_source=plos&amp;utm_medium=opb&amp;utm_campaign=plos-1610-oaw">Co- and Polymicrobial Infections</a>, <a href="http://blogs.plos.org/speakingofmedicine/2016/10/18/trauma-a-neglected-global-disease-a-call-for-papers-on-prevention-management-and-the-acute-response-to-injury/?utm_source=plos&amp;utm_medium=opb&amp;utm_campaign=plos-1610-oaw">Trauma—Prevention, Management and the Acute Response to Injury</a> and <a href="https://www.plos.org/microbiology?utm_source=plos&amp;utm_medium=opb&amp;utm_campaign=plos-1610-oaw">Microbiology</a>.</li>
</ul>
<ul>
<li><strong>Stay in touch with PLOS</strong> – Get <a href="http://plos.io/2dCDFbu">updates</a>, <a href="http://plos.io/2egJuZV">eTOCs</a> and follow PLOS on <a href="http://plos.io/1M7V3Ok">Twitter</a> and <a href="http://plos.io/2eBVrtP">Facebook</a>.</li>
</ul>
<p>Have a great Open Access Week!</p>
<img alt="" height="1" src="http://feeds.feedburner.com/~r/plos/Blog/~4/injO7e6CToA" width="1" />
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://biocomputation.herts.ac.uk/2016/10/20/principal-component-analysis.html">Principal component analysis</a></h2></div>
            <p class="text-muted">by <a href="http://biocomputation.herts.ac.uk/">UH Biocomputation group</a> on October 20, 2016 12:30 PM.</p>
          </div>
          <div class="panel-body">

            <p>Principle Component Analysis (PCA) is used by many but understood by few.</p>
<p>In this talk I hope to explain some of the math behind the tool, to raise awareness for its potential (and pitfalls) and to discuss the relationship between PCA and cluster analysis.
In addition I will present some examples of its use in neuro-science, from my own work in robotics and an application in economics.</p>
<p><strong>Date:</strong> 21/10/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://ankursinha.in/blog/2016/10/17/on-jargon.html">On jargon</a></h2></div>
            <p class="text-muted">by <a href="http://ankursinha.in/blog/">Ankur Sinha</a> on October 17, 2016 07:26 AM.</p>
          </div>
          <div class="panel-body">

            <p>Jargon is more often than not looked at unfavourably. Jargon is just the "language of a trade" and so, by itself, I don't see why I should denounce it. Rather, to me, it is the usage of jargon that is the issue. If you think of a workplace where people are aware of the context and meaning of certain jargon, I see no reason why it isn't appropriate usage. In fact, in such scenarios, jargon makes conversation efficient since the parties must not needlessly simplify their communications. So, when I go over to my lab mate's desk and say "<em>well, the STDP rule doesn't seem to result in an AI state</em>", he knows exactly what I mean. I'd find it quite difficult to rephrase that sentence to make it any simpler. The same applies for most professions if not all of them. Whether it's farming or mechanics; IT or medicine; cooking or sewing; designing or the media; they will all have some specialised terminology. It is just normal evolution of language in the same way that "selfie" is now a word. Jargon is simply a set of words that encapsulate concepts that are frequently used in a context.</p>
<p>So why are we up in arms about jargon, then? Why is everyone continuously talking about how we need to cut it out? Quite simply, because when jargon is used in the wrong scenario, it hampers transfer of information. If work related terminology is used in a social setting where other listeners are not privy to it, for example, the conversation does not serve to pass on any material. Furthermore, it usually has the effect of making the audience feel out of place. It is quite similar to speaking to a single member of a group in a language that the others do not comprehend. It is considered impolite.</p>
<p>To take it a step further, jargon seems to be used frequently with the malintent to obfuscate - especially in sales and marketing. The idea seems to be to coin and use fancy wording to trick consumers into buying products. The billboards and slogans that we see on a daily basis while not untrue, are not always created with aim to elucidate facts.</p>
<p>Another use of jargon is straightforward snobbery. It makes the snob feel like part of an exclusive club. There isn't much to say about this other than that one should simply not engage with such individuals.</p>
<p>Scenarios where the use of jargon is unintentional are more complex to deal with. Most research falls in this category. Consider people like me who spend a majority of their time in an environment that requires the use of an uncommon vocabulary. So, I read research papers that contain specific words, I write papers using these same words, the discussions I partake in utilise these too - this jargon is quite unavoidable to a large extent in work life. I'm only 2 years into my Ph.D. and I find it hard to speak about the same subject matter without employing the same dialect already. While this does not affect my daily activities as they are limited to colleagues who are well versed in our diction, it greatly limits my ability to spread the science I work in to a wider audience. This, in contrast, does effect me, and you too. If we're not working similar areas, we have very little understanding of each other's work.</p>
<p>While I can't speak for types of work, this, in general, is an issue in research and academia - the lack of ability in us researchers to disseminate our work to people in other streams, especially non research careers, is an accepted weakness.</p>
<p>Computational neuroscience, for example, is extremely multidisciplinary. At my lab alone, we have biologists, physicist, mathematicians, and us computer scientists, all working under the same roof on similar research questions. The dialect each of us speak is different. Yet, we read and publish in the same channels. When I read a paper that is heavy on biological detail, I find it much harder because the text utilises biological terminology that I'm not well aware of. In our case, though, there's only the one solution of learning what we need to know. It is how we manage to collaborate across disciplines, and it takes work - the difference in jargon ever so slightly increasing the required exertions.</p>
<p>Extend this scenario to someone who isn't working in computational neuroscience at all. Of course, it'll be even harder for them to understand the same text. Given how important research is for all life in general, it is imperative that people who do not conduct research be made aware of progress that is continuously made. If you don't understand why research is important, let me point out to you that <em>every</em> manufactured product you use in your home is the end result of some research somewhere. Take a moment to wonder how it all came about - it isn't magic; it is years of hard work and failure.</p>
<p>To insure the future of research, it is important that young students are exposed to it at an early age. It is the simplest way of arousing enough interest in them to guarantee that research receives a constant stream of capable bearers to build on past innovations. It really doesn't matter what they take up - contributions to each field count.</p>
<p>It is also helpful for consumers to have some idea of how things are manufactured and the amount of work that goes into it. It helps them pick between brands and decide what price they should pay for a product. A general awareness helps build immunity to the different tricks in use today that gently nudge consumers into buying products - creating demand for a product that wasn't required some time before.</p>
<p>A last but important note is that most research makes use of public funds that are obtained via government grants. If the tax payer is funding some research, the tax payer should know how the money is being utilised.</p>
<p>So, yes, making research information easily accessible to everyone is of great value. This is where jargon stands out as quite a bottle neck. Individuals that are not aware of the context, or those that do not have the required background knowledge cannot be expected to read research papers to understand the state of knowledge. Rather, academics have to work towards simplifying the data to an extent that it can be consumed by individuals from all walks of life. This isn't easy, and simplification usually goes hand in hand with omission of lesser important details but it is certainly possible to synthesise an overall picture of a concept.</p>
<p>What I've written isn't new by any standards. The problem is well known, and communities are working towards making knowledge more understandable. If you watch the stuff the BBC puts up, for example, you'll see a lot of work by individuals like <a class="reference external" href="https://en.wikipedia.org/wiki/Brian_Cox_(physicist)">Professor Brian Cox</a> that is aimed at explaining complex physical phenomena in simpler terms. A start has certainly been made.</p>
<p>The point of this post was to give myself some time to think about the issue. After writing about a thousand words on the subject, I have a better understanding of it myself. I also have a better handle on what I should do to do my bit. It simply takes practice and some feedback. That's all it is. So, as I blog frequently about my Fedora related activities, I am going to make more of an attempt to write about my research too. A target is always helpful. Since it takes some effort at the moment, I'm going to set myself a target of one research related post every two to three weeks to begin with. Today being the 16th of October, I'll publish the first one before the 7th of November. Let's see how that goes.</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://feeds.plos.org/~r/plos/blogs/neuro/~3/Zz4MYy-SqFU/">When Arts meet Neuroscience… (by Naureen Ghani)</a></h2></div>
            <p class="text-muted">by <a href="http://blogs.plos.org/neuro">PLOS Neuroscience Community</a> on October 16, 2016 09:26 AM.</p>
          </div>
          <div class="panel-body">

            <img alt="Raw1" class="attachment-thumbnail size-thumbnail wp-post-image" height="150" src="http://blogs.plos.org/neuro/files/2016/10/Raw1-1-150x150.jpg" style="display: block; margin-bottom: 5px; clear: both;" width="150" /><blockquote>
<p style="text-align: justify;">“<em>Why do humans do science? Why do they do art? The things that are least important for our survival are the very things that make us human</em>“.<br />
<strong>Savas Dimopoulos</strong></p>
</blockquote>
<p style="text-align: justify;">For every scientific issue, there is a cultural equivalent. Art creates metaphors that make science more transparent for the non-scientists. This subject is particularly timely now, as images and ideas in neuroscience are widely circulated among the public. The brain is seen as the last frontier in research. <a href="http://www.nature.com/nrn/journal/v10/n11/full/nrn2736.html">Questions in neuroscience, if answered, address aspects of our individuality</a>. We may learn how neural networks enable us to think, act, and even love. In this post, I interview two visual artists working at the intersection of Arts and Neuroscience. The first is <a href="http://suzanneanker.com">Suzanne Anker</a>, a pioneer of bio-art and the chair of the Fine Arts Department at the <a href="https://www.sva.edu">School of Visual Arts (SVA)</a> in Manhattan. The second is <a href="http://lukemaninov.com">Luke Maninov Hammond</a>, a contemporary jeweler and neuroscience imaging specialist who manages the Advanced Microscopy Facility at the Brain Institute at the <a href="http://www.qbi.uq.edu.au">University of Queensland (QBI)</a> in Australia.</p>
<p style="text-align: justify;"><a href="https://en.wikipedia.org/wiki/Santiago_Ram%C3%B3n_y_Cajal">Santiago Ramón y Cajal</a> is considered by many to be the father of modern neuroscience. He provided the first detailed analysis of the nervous system through visual art. His body of work is a defining example of art in neuroscience. In the 19<sup>th</sup> century, microscopy was in its infancy. Neuroscientists relied on drawings of what they observed under the microscope to communicate their work to others. In this way, Cajal generated beautiful drawings of neurons in meticulous details. His art facilitated his understanding of neuronal theory, which states that the connection between neurons is contiguous rather than continuous. From static drawings of neurons, Cajal was able to infer properties of the dynamics of these cells. The legendary neuroscientist received the Nobel Prize in Physiology for his work alongside Camille Golgi and has said, “There can be no doubt, only artists are attracted to science.”</p>
<p style="text-align: justify;">As Cajal began his studies of the cerebral cortex, he writes the following paragraph in his book <a href="https://archive.org/details/recuerdosdemivid02ramuoft"><em>Recuerdos de Mi Vida</em></a> (Recollections of My Life):</p>
<blockquote><p><em>I felt at that time the liveliest curiosity—somehow romantic—for the enigmatic organization of the organ of the soul. Humans—I said to myself—reign over Nature through the architectural perfection of their brains []. To know the brain—we said to ourselves in our idealistic enthusiasm—is equivalent to discovering the material course of thought and will. [] Like the entomologist hunting for brightly colored butterflies, my attention was drawn to the flower garden of the grey matter, which contained cells with delicate and elegant forms, the mysterious butterflies of the soul, the beating of whose wings may some day (who knows?) clarify the secret of mental life. [] Even from the aesthetic point of view, the nervous tissue contains the most charming attractions. In our parks are there any trees more elegant and luxurious than the Purkinje cells from the cerebellum or the psychic cell that is the famous cerebral pyramid?</em><br />
<strong><em>Ramón y Cajal, 1917</em></strong></p></blockquote>
<p style="text-align: justify;">Visual artists such as Suzanne Anker and Luke Maninov Hammond continue the tradition begun by Cajal and create pieces inspired by images in neuroscience. For Anker, iconic images in neuroscience are “the brain, anything symmetrical, the enteric nervous system (which is like Cajal’s butterflies of the soul transformed into butterflies of your stomach), and dendritic trees.” Hammond is inspired by the research that surrounds him at the Queensland Brain Institute. He explains how “<em>We have gone from this era of single snapshots to comprehensive imaging of entire organs and organisms. The Advanced Microscopy Facility at QBI caters to a wide range of light microscopy applications, from super-resolution of single molecules in neurons to two-photon microscopy of living organisms. Groups study a diverse range of organisms such as C. elgans, Drosophila, and </em><i>mouse.” </i>Both Anker and Hammond translate advances in neuroscience research to unique works of art.</p>
<figure class="wp-caption aligncenter" id="attachment_18907" style="width: 314px;"><a href="http://blogs.plos.org/neuro/files/2016/10/Susan.jpg"><img alt="Credit: Suzanne Anker" class=" wp-image-18907" height="464" src="http://blogs.plos.org/neuro/files/2016/10/Susan-203x300.jpg" width="314" /></a><em>Credit: Suzanne Anker</em></figure>
<p style="text-align: justify;">Anker has curated a number of neuroscience exhibitions nationally and internally. She spoke of one titled <a href="http://www.suzanneanker.com/wp-content/uploads/2011-Anker-Suzanne-Fundamentally-Human-Catalogue.pdf">“Fundamentally Human: Visual Art and Neuroscience”</a> done at the Paro Museum in Istanbul. She explains that she was asked to have an exhibit that would “<em>exchange ideas not from a scientific point of view but from something that was more poetic, literary, or cultural.</em>” One of her pieces is of a series of MRI scans with a butterfly superimposed on each image. She explains this work as “<em>a way to picture a thought… Behind each butterfly is a Rorschach test, some are real and some are not. Because of the figure-ground relationship, it appears to be a different butterfly in your perception. You see all these different shapes… and the butterfly is not true.</em>” Anker has also done a piece involving 3-D Rorschach tests. “<em>If you take one and pick it up, it is like picking up a fantasy</em>” she says wide-eyed. Anker’s fascination between the ethereal and the material is apparent her work.</p>
<p style="text-align: justify;">Hammond creates fine jewelry and silver sculptures and has exhibited his work in Australia as well as internationally, including USA. In a recent group exhibition titled <a href="http://lukemaninov.com/aboveandbelow/">“Above and Below,”</a> he contributed jewelry and sculpture inspired by neuroscience. He describes the exhibition as “<em>a celebration and reflection of the past ten years I’ve dedicated to improving my understanding of microscopy and how to use glowing proteins from the sea to reconstruct the forms of living.</em>” Each piece is made in solid sterling silver or rose gold and some are complimented by precious stones. As I viewed rings patterned as dendrites scintillate in the light, I thought of how exciting neuroscience is for so many. Hammond is uniquely positioned as a scientist-artist who has expertise in neuroimaging. Although he finds technology such as 3-D printing exciting, he avoids using it in his practice, as “<em>we are making incredible breakthroughs with digital techniques for imaging and analysis for neuroscience but for my practice I prefer the analogue approach of working with my hands, which ensures uniqueness.</em>“</p>
<figure class="wp-caption aligncenter" id="attachment_18914" style="width: 539px;"><a href="http://blogs.plos.org/neuro/files/2016/10/3.jpg"><img alt="Credit: Luke Maninov Hammond" class="wp-image-18914" height="359" src="http://blogs.plos.org/neuro/files/2016/10/3-300x200.jpg" width="539" /></a>Credit: Luke Maninov Hammond</figure>
<p> </p>
<p style="text-align: justify;">The process of curating an exhibit is not dissimilar from the way neuroscientists conduct research. Anker describes the process by stating “<em>An exhibit is like a proposition. If you are taking on an experiment, you are proposing X, Y, and Z. You research what has been done in that area before. You figure out what would be another angle… something that has not been proposed before and you work on that. Every curator and artist does it a different way.</em>” I nodded in agreement as I thought of how I plan and perform experiments in the laboratory. For Hammond, curating an exhibit begins by bringing pieces to a space and seeing how people can engage with those works. “<em>An exhibit bridges the gap between the university, the institute, and the general public</em>” says Hammond. Anker adds, “<em>The scientific method is more structured but many scientific discoveries have been by accident. What scientists and artists share is that during this process of making something or producing knowledge that even if you’re not there yet, you know which way to go. All the cases of serendipity are so critical in the way in which a person can perceive a situation. Everyone’s vision is not the same.</em>” That last line struck me as I thought of how we impose our memories and experiences as we witness the world.</p>
<p style="text-align: justify;">In a visit to the <a href="http://bioart.sva.edu">SVA Bio-Art lab</a> led by Suzanne Anker, I was stunned by the vast array of objects. I was a greeted by a display of specimen and slide collections. As I navigated my way through the lab, I came across a herbarium exploding with plant life and an aquarium filled with coral reefs. Mason jars filled with stained marine life lined the windows. In my final question to Anker, I asked of the role of art in facilitating understanding of science. Anker concluded by saying “<em>Art is the pulse of the cultural imagination. It wraps the hopes and fears of the general public.</em>”</p>
<hr />
<p><span style="color: #000000;"><strong>References </strong></span></p>
<ol>
<li>De Felipe, J. (2010). Cajal’s butterflies of the soul: science and art.</li>
<li>Frazzetto, G., &amp; Anker, S. (2009). Neuroculture. <em>Nature Reviews Neuroscience</em>, <em>10</em>(11), 815-821.</li>
<li>Ramón, S. (1995). <em>Recuerdos de mi vida: Historia de mi labor científica</em>. Alianza Editorial.</li>
</ol>
<hr />
<p style="text-align: justify;"><span style="color: #000000;"><b> </b></span></p>
<p><strong><a href="http://blogs.plos.org/neuro/files/2016/10/Naureen.jpg"><img alt="Naureen" class="wp-image-18902 alignright" height="124" src="http://blogs.plos.org/neuro/files/2016/10/Naureen-300x300.jpg" width="124" /></a>Maureen Ghani</strong> currently works at Columbia University Medical Center. She received her BS in biomedical engineering at Columbia University. In her spare time, she enjoys reading and painting.</p>
<img alt="" height="1" src="http://feeds.feedburner.com/~r/plos/blogs/neuro/~4/Zz4MYy-SqFU" width="1" />
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://biocomputation.herts.ac.uk/2016/10/13/optimising-hierarchical-load-balancing-for-the-cloud.html">Optimising hierarchical load balancing for the Cloud</a></h2></div>
            <p class="text-muted">by <a href="http://biocomputation.herts.ac.uk/">UH Biocomputation group</a> on October 13, 2016 10:14 AM.</p>
          </div>
          <div class="panel-body">

            <p>In the first half of the presentation we will cover the evolution and characteristics of the cloud computing. We will look in particular at the different existing algorithms for load balancing in the cloud. In second half we will see where my research topic fits in along with the challenges and significance of my research.</p>
<p><strong>Date:</strong> 14/10/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://feeds.plos.org/~r/plos/blogs/neuro/~3/OHHT05O_RMg/">A neural code for emotion</a></h2></div>
            <p class="text-muted">by <a href="http://blogs.plos.org/neuro">PLOS Neuroscience Community</a> on October 12, 2016 11:04 PM.</p>
          </div>
          <div class="panel-body">

            <img alt="journal.pbio.2000106.g001" class="attachment-thumbnail size-thumbnail wp-post-image" height="150" src="http://blogs.plos.org/neuro/files/2016/10/journal.pbio_.2000106.g001-150x150.png" style="display: block; margin-bottom: 5px; clear: both;" width="150" /><p>Our daily experience rides along the backdrop of a dynamic stream of mental states, characterized by spontaneous changes is mood or emotion. For instance, as you take an important exam and perform above expectations, your emotions may fluctuate from anxiety to frustration, followed by surprise and finally contentment. These changes in mood are a defining feature of the human experience, but how do they arise from the underlying stream of neural activity? In their new <a href="http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2000106" target="_blank"><em>PLOS Biology</em> study</a>, researchers from Duke University used functional MRI (fMRI) to capture brain signals of emotion, discovering that patterns of brain activity during rest can decode an array of emotional experiences.</p>
<p>Earlier studies have shown that brain activation patterns measured with fMRI can accurately decode a range of stimulus-driven experiences, including <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1808230/" target="_blank">perception</a>, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2823980/" target="_blank">mental imagery</a> and performance of various <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2935493/" target="_blank">cognitive processes</a> (such as making decisions or remembering). However, it has been unclear if distinct brain states similarly map onto unique emotional experiences, like feeling anger or surprise – much fuzzier concepts than such concrete experiences as seeing a tree or hearing a dog bark. Last year, coauthors of the new <em>PLOS</em> <em>Biology</em> paper, Philip Kragel and Kevin LaBar, showed that brain activation patterns accurately <a href="https://www.ncbi.nlm.nih.gov/pubmed/25813790" target="_blank">predicted emotions</a> elicited by movies and music. However, like prior stimulus-driven studies, their experiment could not separate the effects of emotion from the external emotion-inducing sounds and images. Their new study sought to isolate emotion from its exogenous triggers, examining brain activation patterns of spontaneous emotions, in the absence of external driving input.</p>
<p><strong>Imaging the emotive brain</strong></p>
<p>To evaluate whether brain activation indices of emotion correspond with individual mood and personality traits, the researchers performed resting fMRI on 499 young adults. Using algorithms derived from their earlier study of emotional responses to movies and music, they computed how much evidence there was from whole-brain activity patterns for each of seven emotions (neutral, contentment, amusement, fear, anger, surprise, sadness). Brain activity patterns corresponding to neutral, surprise and amusement occurred most often, whereas contentment was represented least often. Over time in the scanner, brain states of fear became less frequent, in line with the common experience of “scanner anxiety” at the start of an MRI session. Time series analysis of each emotion for each subject corroborated this trend, showing more negative emotions (fear and sadness) represented early, and more neutral or positive emotions (neutral and surprise) arising later.</p>
<p><strong>Mapping brain signals onto mood</strong></p>
<p>Perhaps more importantly, they found that the prevalence of certain brain states mapped well onto self-reported mood and personality ratings (Figure 1). For instance, individuals who were more likely to later report having felt depressed or anxious during the scan showed higher frequencies of brain activity patterns corresponding with sadness or fear, respectively. Furthermore, those with higher anxious personality ratings showed more common fear and less common anger brain states, those with higher anger ratings had frequent anger brain states, and those with high depression ratings often showed fear and sadness brain states.</p>
<figure class="wp-caption aligncenter" id="attachment_18891" style="width: 253px;"><a href="http://blogs.plos.org/neuro/files/2016/10/journal.pbio_.2000106.g004.png"><img alt="Brain-based classifications correspond with mood (A) and personality traits (B). Kragel et al., 2016." class="wp-image-18891 size-medium" height="300" src="http://blogs.plos.org/neuro/files/2016/10/journal.pbio_.2000106.g004-253x300.png" width="253" /></a>Figure 1. Brain-based classifications correspond with mood (A) and personality traits (B). Kragel et al., 2016.</figure>
<p>Critically, however, these mood and personality ratings are at best a proxy for the participants’ true emotional states <em>during</em> the MRI scan. To test the accuracy of the brain decoding algorithms on real-time measures of emotion, another group of 21 young adults underwent fMRI while self-reporting their current feeling at periodic intervals. The brain activity models predicted the self-reported emotional states better than chance, and the frequency of the reported emotions correlated with the frequency of emotions predicted by the brain classification (Figure 2). Thus, while the first study could only indirectly associate brain states with general differences in individual emotion and personality, this second study confirmed sensitivity to real-time fluctuations in emotion.</p>
<figure class="wp-caption aligncenter" id="attachment_18892" style="width: 300px;"><a href="http://blogs.plos.org/neuro/files/2016/10/journal.pbio_.2000106.g005.png"><img alt="The frequency of brain-based classifications correlates with self-reported emotions. Kragel et al., 2016" class="wp-image-18892 size-medium" height="289" src="http://blogs.plos.org/neuro/files/2016/10/journal.pbio_.2000106.g005-300x289.png" width="300" /></a>Figure 2. The frequency of brain-based classifications correlates with self-reported emotions. Kragel et al., 2016</figure>
<p><strong>A clinical window onto the affective brain?</strong></p>
<p>In contrast to past “brain decoding” studies, which used brain activity patterns to predict externally-driven sensory or cognitive experiences, Kragel and colleagues showed for the first time that brain signals can accurately identify spontaneously arising emotional states. These brain patterns not only map onto mood and personality traits, but also track rapid, real-time emotional fluctuations. This study helps push the limits of the rapidly growing cognitive applications of neuroimaging, demonstrating its power to characterize the dynamic neural events underlying the landscape of human mood and affect. However, just how well fMRI could distinguish more nuanced differences in emotion remains to be seen. As Dr. LaBar notes, “<em>We don’t yet know the limit to the ability of pattern classification tools to discriminate at finer levels of distinction in affect representations (e.g., fear vs. anxiety vs. apprehension) or emotion blends (e.g., do fear and sadness combine to elicit feelings of despair?), but these issues will be interesting to test in future work. Of course, there are limits in the spatial resolution of the dependent measures themselves (the BOLD signal in fMRI). Despite these challenges, we believe that more fine-grained distinctions are likely, as long as the emotions under investigation can be reliably induced across subjects in the MRI scanner</em>.”</p>
<p>Despite these open questions, this study holds important clinical implications; for example, with refinement, fMRI could potentially be useful for diagnosing personality or mood disorders, or for tracking therapeutic outcomes. Such applications could prove particularly valuable in identifying emotional experiences in individuals with impaired awareness or compromised ability to communicate. According to Dr. La Bar,</p>
<blockquote><p>“Some of the most interesting applications would be in situations where people are unaware that a specific emotion is being elicited yet their behavior indicates an affective bias. If we can show elevated activation in our brain-based emotion models under these circumstances, we can begin to unpack unconscious emotional influences in a way that was previously unimaginable.”</p></blockquote>
<p><strong>References</strong></p>
<p>Kamitani Y, Tong F. (2005). Decoding the visual and subjective contents of the human brain. <em>Nat Neurosci</em>. 8(5):679-85. doi: 10.1038/nn1444</p>
<p>Kragel PA, LaBar KS. (2015). Multivariate neural biomarkers of emotional states are categorically distinct. <em>Soc Cogn Affect Neurosci</em>. 10(11):1437-48. doi: 10.1093/scan/nsv032</p>
<p>Kragel PA, Knodt AR, Haririr AR, LaBar KS. (2016). Decoding Spontaneous Emotional States in the Human Brain. <em>PLOS Biol</em>. 14(9): e2000106. doi: 10.1371/journal.pbio.2000106</p>
<p>Poldrack RA, Halchenko Y, Hanson SJ. (2009). Decoding the Large-Scale Structure of Brain Function by Classifying Mental States Across Individuals. <em>Psychol Sci</em>. 20(11):1364-72. doi: 10.1111/j.1467-9280.2009.02460.x</p>
<p>Reddy L, Tsuchiya N, Serre T. (2010). Reading the mind’s eye: decoding category information during mental imagery. <em>Neuroimage</em>. 50(2):818-25. doi: 10.1016/j.neuroimage.2009.11.084</p>
<hr />
<p><em>Any views expressed are those of the author, and do not necessarily reflect those of PLOS.</em></p>
<p><b><a href="http://blogs.plos.org/neuro/files/2015/09/Reas_headshot-150x150.jpg"><img alt="" class="alignright size-full wp-image-17356" height="150" src="http://blogs.plos.org/neuro/files/2015/09/Reas_headshot-150x150.jpg" width="150" /></a></b><strong>Emilie Reas</strong> received her PhD in Neuroscience from UC San Diego, where she used fMRI to study memory. As a postdoc at UCSD, she currently studies how the brain changes with aging and disease. In addition to her tweets for <a href="https://twitter.com/PLOSNeuro" target="_blank">@PLOSNeuro</a> she is <a href="https://twitter.com/etreas" target="_blank">@etreas</a>.</p>
<img alt="" height="1" src="http://feeds.feedburner.com/~r/plos/blogs/neuro/~4/OHHT05O_RMg" width="1" />
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://feeds.plos.org/~r/plos/blogs/neuro/~3/Tn5JtaTGkWI/">Does Junk Food Steal Memories?</a></h2></div>
            <p class="text-muted">by <a href="http://blogs.plos.org/neuro">PLOS Neuroscience Community</a> on October 11, 2016 07:43 PM.</p>
          </div>
          <div class="panel-body">

            <img alt="Burger" class="attachment-thumbnail size-thumbnail wp-post-image" height="150" src="http://blogs.plos.org/neuro/files/2016/10/Burger-150x150.jpg" style="display: block; margin-bottom: 5px; clear: both;" width="150" /><p style="text-align: justify;">Obesity, a multifactorial metabolic disorder, is rapidly increasing in western and developing countries. Nearly 35% of adults over the age of 20 and 50% of adults over the age of 60 have a metabolic syndrome, which may lead to serious health problems. In fact, we consume more food than necessary and this food is usually far from being healthy. Indeed, life style and education shape the direction in which humanity is going globally.</p>
<p style="text-align: justify;">Interestingly, factors associated with metabolic syndromes negatively impact cognition and thus represent serious risk factors for dementia and intellectual disabilities (Yaffe K et al., 2004). In fact, “junk food”, which is food mostly enriched in sugar and fat (I know, we often crave it), strongly disrupts learning and memory functions in both humans and rodents. Given that obesity is epidemic and tied to impaired cognition, understanding the long-term impact of a high-fat diet (HFD) on the hippocampus –a key brain structure involved in learning and memory processes– is of paramount importance, especially in children and adolescents.</p>
<p style="text-align: justify;">In a recent <a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0163883">PLOS ONE article</a>, Catrina Sims-Robinson and colleagues from the Medical University of South Carolina decided to investigate the impact of HFD hippocampal functions and whether dietary reversal may rescue short- and long-term alterations (Sims-Robinson et al., 2016). As part of this study, mice were exposed either to normal food or to high-fat food for several days –just imagine something like a diet based on tasty, saucy, fat burgers for weeks and weeks. Using hippocampus-dependent behavioral paradigms, such as the Novel Object Recognition (NOR) and the Morris Water Maze (MWM) tests, the authors observed that obese mice exhibited severe memory loss. Obese mice were indeed unable to discriminate between objects or to simply recall spatial references; basically, they were lost. Interestingly –and luckily– such deleterious effects of a high-fat diet on memory processes were entirely abolished once mice were re-exposed (dietary reversal) to a normal and healthy diet, which strongly indicates that cognitive dysfunctions induced by “junk food” may be somehow reversible.</p>
<p style="text-align: justify;">In order to go a bit further in dissecting the cellular and molecular mechanisms possibly underlying “junk food”-induced cognitive decline, the authors focused on the insulin signaling pathway and its cerebral receptors. The notion that insulin, a hormonal peptide secreted by the pancreas, could act on the brain might come as a surprise; as such, this study constitutes a fascinating piece of science. In fact, insulin, like many other peripheral peptides (leptin, ghrelin, GLP-1, etc), can send a plethora of information to our brain, thus influencing our behavior.</p>
<p style="text-align: justify;">HFD is associated with peripheral insulin resistance, which occurs following hyperinsulinemia and InsR (Insulin Receptor) desensitization (Draznin, 2006). At the central level, HFD is associated with insulin resistance in various critical brain regions, including the hypothalamus, cortex and hippocampus; however, whether these dramatic changes are reversible remains elusive. In fact, “<em>this is the first study, to our knowledge, that reports an improvement in impaired hippocampal insulin signaling and an irreversible decrease InsR expression in the hippocampus with dietary intervention</em>”, said the authors. “<em>It is possible that the reduction in InsR expression in the hippocampus following a HFD is a protective mechanism to prevent over activation of insulin signaling and subsequent desensitization</em>”, concluded Catrina Sims-Robinson, the leading author of the study. Hence, it could be possible that HFD may lead to an acceleration of age-related decrease in InsR expression. Although further studies are definitely warranted, this may represent a factor in the increased risk of age-related neurodegenerative diseases (<em>i.e.</em> Alzheimer’s disease and dementia) in metabolic syndromes.</p>
<p style="text-align: justify;">It is likely that several molecular pathways are involved in the mechanisms underlying diet-induced changes on cognition and among them insulin may play a critical role. In this study, Dr. Sims-Robinson and colleagues demonstrate that dietary intervention (dietary reversal) improves impaired glucose tolerance, impaired hippocampal insulin signaling, and cognitive deficits, even though the reduction in the levels of the InsRs was irreversible. It must be mentioned that hippocampal-dependent cognitive deficits induced by HFD have been attributed also to leptin, calcium dysregulation, inflammation, cellular stress, and impaired insulin signaling. It is therefore difficult to point to a single factor entirely responsible for such a mess within the hippocampus. Nonetheless the authors added that “<em>enhancing insulin signaling</em> <em>has promising therapeutic benefits for improving cognition; however, more research is needed to understand its impact on endoplasmic reticulum stress and inflammation</em>”.</p>
<p style="text-align: justify;">In conclusion, this research should encourage a more detailed investigation of the secrets of our brain, as well as to strive for a deeper understanding of what food does to our mental functions. In the meantime, a healthy lunch may be the easiest solution to please and protect our brain.</p>
<hr />
<p><span style="color: #000000;"><strong>References </strong></span></p>
<ol>
<li><span style="color: #000000;">Sims-Robinson C, Bateman A, Bruno E, Jackson S, Glasser R, Murphy GG, Feldman EL. Dietary Reversal Ameliorates Short- and Long-Term Memory Deficits Induced by High-fat Diet Early in Life. <span class="jrnl" title="PloS one">PLoS One</span>. 2016 Sep 27;11(9):e0163883. doi: 10.1371/journal.pone.0163883. eCollection 2016.</span></li>
<li>Draznin B. Molecular mechanisms of insulin resistance: serine phosphorylation of insulin receptor substrate-1 and increased expression of p85alpha: the two sides of a coin. <span class="jrnl" title="Diabetes">Diabetes</span>. 2006 Aug;55(8):2392-7. Review.</li>
</ol>
<hr />
<p style="text-align: justify;"><span style="color: #000000;"><em>Any views expressed are those of the author, and do not necessarily reflect those of PLOS. </em></span></p>
<p style="text-align: justify;"><span style="color: #000000;"><b><img alt="Peppe-BW" class="wp-image-17882 alignleft" height="148" src="http://blogs.plos.org/neuro/files/2015/10/Peppe-BW-238x300.jpg" width="117" />Giuseppe Gangarossa </b>received his PhD in Biomedical Sciences, specialty Neuroscience, from the University of Bologna. He has been a visiting fellow at the Karolinska Institutet (Sotckholm, Sweden), the French Inserm (Montpellier, France) and the Collège de France (Paris, France). Giuseppe is currently Assistant Professor of Physiology at the University Paris Diderot. His main research topic is dopamine-related brain disorders. You can follow him on twitter <a href="https://twitter.com/peppeganga?lang=en">@PeppeGanga</a></span></p>
<p> </p>
<img alt="" height="1" src="http://feeds.feedburner.com/~r/plos/blogs/neuro/~4/Tn5JtaTGkWI" width="1" />
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://biocomputation.herts.ac.uk/2016/10/08/open-position-lecturer-senior-lecturer-in-computer-science-machine-learning-biocomputation.html">Open Position: Lecturer/Senior Lecturer in Computer Science (Machine learning / Biocomputation)</a></h2></div>
            <p class="text-muted">by <a href="http://biocomputation.herts.ac.uk/">UH Biocomputation group</a> on October 08, 2016 04:06 PM.</p>
          </div>
          <div class="panel-body">

            <p>Salary: £32,004 to £48,327 per annum depending on qualifications and experience <br />
FTE: Full time position working 37 hours per week (1.0 FTE) <br />
Closing date: 21 October 2016</p>
<p>Applications are invited for a Lecturer or Senior Lecturer in the School of Computer Science, University of Hertfordshire. The successful candidate will be expected to contribute to the School's teaching and curriculum development activities, and to strengthen its research activities. We are looking to recruit specifically a computer scientist with background in machine learning or data science related to biocomputation (including computational neuroscience). By Data Science we broadly mean the extraction of meaning from large quantities of data. The successful candidate will also have the flexibility to teach across mainstream topics in computer science. The School has an international reputation for teaching and research, with 58 academic staff, 20 adjunct lecturer staff, and 65 research students and postdoctoral research staff. With a history going back to 1958, the School teaches one of the largest cohorts of undergraduate students in the UK, and also delivers a thriving online computer science degree programme.</p>
<p>The person appointed will be expected to contribute to learning and teaching relevant to core computer science topics, participate in curriculum review and development, design and develop new modules, and supervise student projects at all levels. The appointee will strengthen the research culture in the School by pursuing research as part of a larger research team, seeking external funding, publishing papers, supervising research students, and participating in commercial activity as appropriate. Preference will be given to candidates who can contribute to teaching and research in databases as outlined above.</p>
<p>Applicants must hold a PhD (or equivalent) in a relevant subject, possess excellent communication skills in English and the ability to teach at undergraduate and postgraduate level. It is desirable that candidates have a track record of publication, external research funding, collaboration across disciplines, experience of different types of assessment and higher education quality assurance. They should also have the ability to play a role in the routine running of the School of Computer Science.</p>
<p>Applications should be made through <a class="reference external" href="http://www.herts.ac.uk/contact-us/jobs-and-vacancies/academic-vacancies">http://www.herts.ac.uk/contact-us/jobs-and-vacancies/academic-vacancies</a> (reference 014050). Informal enquiries may be addressed to Dr Volker Steuber (Head of the Biocomputation Research Group, v.steuber at herts.ac.uk) or Professor William Clocksin (Dean of School, w.clocksin at herts.ac.uk). Please note that applications sent directly to these email addresses will not be accepted.</p>
<p>We are committed to providing a supportive environment. The university also provides an onsite childcare facility and child-centred holiday clubs. The University is required to meet UKVI visa regulations. Applicants who do not currently have the right to work in the UK will have to satisfy UKVI regulations before they can be appointed.</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://biocomputation.herts.ac.uk/2016/10/04/computational-models-of-synaptic-plasticity-and-information-processing-in-the-cerebellum.html">Computational models of synaptic plasticity and information processing in the cerebellum</a></h2></div>
            <p class="text-muted">by <a href="http://biocomputation.herts.ac.uk/">UH Biocomputation group</a> on October 04, 2016 07:21 AM.</p>
          </div>
          <div class="panel-body">

            <p>A central theme of the computational neuroscience research in the Biocomputation Research Group is synaptic plasticity, the activity-dependent strengthening and weakening of connections between neurons in the brain. In this talk, I will describe a number of previous PhD projects in the group that have studied computational functions, and the underlying mechanisms, of synaptic plasticity. I will focus on the functional roles and mechanisms of synaptic plasticity in the cerebellum, a brain structure that is important for the control of movements, motor learning and many higher cognitive functions. Our results suggest that different forms of synaptic plasticity at different  time scales can implement many diverse functions such as associative memory, noise resistance, multiplicative operations and the transformation  between different types of neural code. Moreover, I will discuss the relation between cerebellar synaptic plasticity and movement disorders that are based on cerebellar dysfunction, and I will describe the application of machine learning algorithms to analyse neuronal activity during epileptic seizures.</p>
<p><strong>Date:</strong> 07/10/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://biocomputation.herts.ac.uk/2016/09/28/opposing-effects-of-neuronal-activity-on-structural-plasticity.html">Opposing effects of neuronal activity on structural plasticity</a></h2></div>
            <p class="text-muted">by <a href="http://biocomputation.herts.ac.uk/">UH Biocomputation group</a> on September 28, 2016 08:40 PM.</p>
          </div>
          <div class="panel-body">

            <p>The connectivity of the brain is continuously adjusted to new environmental
influences by several activity-dependent adaptive processes. The most
investigated adaptive mechanism is activity-dependent functional or synaptic
plasticity regulating the transmission efficacy of existing synapses. Another
important but less prominently discussed adaptive process is structural
plasticity, which changes the connectivity by the formation and deletion of
synapses. In this review, we show, based on experimental evidence, that
structural plasticity can be classified similar to synaptic plasticity into two
categories: (i) Hebbian structural plasticity, which leads to an increase
(decrease) of the number of synapses during phases of high (low) neuronal
activity and (ii) homeostatic structural plasticity, which balances these
changes by removing and adding synapses.  Furthermore, based on experimental
and theoretical insights, we argue that each type of structural plasticity
fulfills a different function. While Hebbian structural changes enhance memory
lifetime, storage capacity, and memory robustness, homeostatic structural
plasticity self-organizes the connectivity of the neural network to assure
stability. However, the link between functional synaptic and structural
plasticity as well as the detailed interactions between Hebbian and homeostatic
structural plasticity are more complex. This implies even richer dynamics
requiring further experimental and theoretical investigations.</p>
<p>The complete paper can be found here: <a class="reference external" href="http://journal.frontiersin.org/article/10.3389/fnana.2016.00075/full">http://journal.frontiersin.org/article/10.3389/fnana.2016.00075/full</a></p>
<p><strong>Date:</strong> 30/09/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location:</strong> LB252</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://feeds.plos.org/~r/plos/Blog/~3/jyXczmzCv-8/">Influential Work from PLOS Authors Garners Lasker Awards</a></h2></div>
            <p class="text-muted">by <a href="http://blogs.plos.org/plos">The Official PLOS Blog</a> on September 21, 2016 06:17 PM.</p>
          </div>
          <div class="panel-body">

            <img alt="Lasker-Award---blog-image" class="attachment-thumbnail size-thumbnail wp-post-image" height="150" src="http://blogs.plos.org/plos/files/2016/09/Lasker-Award-blog-image-150x150.png" style="display: block; margin-bottom: 5px; clear: both;" width="150" /><div class="wp_orcid_field"><a href="http://orcid.org/0000-0001-7318-5892" rel="author" target="_blank">0000-0001-7318-5892</a></div><p>The <strong><a href="http://www.laskerfoundation.org/awards/" target="_blank">Lasker Awards</a></strong> recognize the contributions of scientists, physicians and public servants who have made major advances in the understanding, diagnosis, treatment and prevention of human disease. Each year since 1945, dedicated scientists benefit from the mission of the Albert and Mary Lasker Foundation to recognize research excellence, public education and advocacy.</p>
<p>As a champion of biomedical research, Mary Lasker worked to increase public appreciation for and government funding of medical sciences. As a result of her advocacy efforts, several <strong><a href="https://profiles.nlm.nih.gov/ps/retrieve/Narrative/TL/p-nid/200" target="_blank">NIH Institutes were newly created</a></strong>, including the National Heart Institute, the National Institute of Mental Health and the (originally named) National Institute of Neurological Diseases and Blindness. Lasker helped change the biomedical research landscape in the United States and the scientific community to this day benefits from her dedication.</p>
<p>PLOS is proud that six of this year’s seven Lasker awardees have published research or an interview with PLOS, and we are fortunate to benefit from the expertise of Charles M. Rice of The Rockefeller University in his role as an Academic Editor for <strong><a href="http://journals.plos.org/plospathogens/" target="_blank"><em>PLOS Pathogens</em></a></strong>.</p>
<h4>Here are the 2016 Lasker Award honorees with a summary of their PLOS research and interviews, spanning five journals and <strong><a href="http://blogs.plos.org/plos/" target="_blank">The PLOS Blog Network</a></strong>, for a collective total of 38 articles and two interviews.</h4>
<h3><strong>Oxygen sensing—an essential process for survival:</strong></h3>
<p><strong><a href="http://plos.io/2d6I99p" target="_blank">Gregg L. Semenza’s</a></strong> three<em> PLOS ONE</em> articles cover the role of<strong> <a href="http://plos.io/2czynvc" target="_blank">NADPH oxidase in Hypoxia Inducible Factor-1α (HIF-1α) activation</a></strong>, the <strong><a href="http://plos.io/2cSO5EK" target="_blank">dependency on tumor suppressor p53</a></strong> for macrophage migration inhibitory factor’s effect on HIF-1 activation, and the ability of HIF-1α to <strong><a href="http://plos.io/2d4wyDS" target="_blank">regulate the expression of cell adhesion molecule CD44</a></strong>.</p>
<p><strong><a href="http://plos.io/2dq4IpM" target="_blank">Peter J. Ratcliffe</a></strong> published two <em>PLOS ONE</em> articles and one each in <em>PLOS Biology</em> and <em>PLOS Medicine</em>. Some of this work examines the relationship between the <strong><a href="http://plos.io/2cNxr5Y" target="_blank">von Hippel-Lindau (VHL) tumor suppressor gene, HIF-1 and extracellular matrix</a></strong> in <em>C. elegans</em>, the role of VHL-HIF pathway in human <strong><a href="http://plos.io/2d6vamu" target="_blank">cardiopulmonary physiology and function</a></strong> at standard and high altitudes, and most recently the investigation of <strong><a href="http://plos.io/2d6tFEI" target="_blank">compounds that inhibit the hypoxia sensors of the HIF system</a></strong>, the HIF prolyl-hydroxylases, with implications for therapeutic treatment of stroke or other diseases of cerebral ischemia.</p>
<figure class="wp-caption alignleft" id="attachment_7119" style="width: 331px;"><a href="http://blogs.plos.org/plos/files/2016/09/celegans_PR.jpg"><img alt="celegans_PR" class="wp-image-7119 " height="149" src="http://blogs.plos.org/plos/files/2016/09/celegans_PR-300x135.jpg" title="DOI: 10.1371/journal.pbio.0020289" width="331" /></a>DOI: 10.1371/journal.pbio.0020289</figure>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p><strong><a href="http://plos.io/2dq2AOS" target="_blank">William G. Kaelin’s</a></strong> <em>PLOS Biology</em> article – published in the journal’s inaugural year – explores the relationship between inactivation of the VHL gene, <strong><a href="http://plos.io/2cJwgCx" target="_blank">subsequent HIF2α activity and renal carcinoma tumor formation</a></strong>.</p>
<h3><strong>Hepatitis C replicon system and drug development:</strong></h3>
<p><strong><a href="http://plos.io/2d6Of9H" target="_blank">Charles M. Rice</a></strong> has eight articles with PLOS; three in <em>PLOS ONE</em> and five with <em>PLOS Pathogens</em>. His virology research – while primarily focused on hepatitis C virus (HCV) – also addresses <strong><a href="http://plos.io/2d6wm96" target="_blank">arthropod-transmitted viruses in the <em>Flaviviridae </em>family</a></strong>, such as yellow fever virus, and <strong><a href="http://plos.io/2crjDve" target="_blank">natural inhibitors of HIV identified from simulation screening</a></strong> of the pan-African Natural Product Library followed by cell-based testing. A subset of Rice’s HCV work published in <em>PLOS Pathogens </em>covers <strong><a href="http://plos.io/2cXxRb0" target="_blank">direct deregulation of the cell cycle in HCV infection</a></strong> as a contributor to liver disease, <strong><a href="http://plos.io/2dq3A5C" target="_blank">host cell protein and lipid mapping</a></strong> to uncover temporal and global changes as a result of HCV infection and a mutational structural analysis of the p7 protein revealing <strong><a href="http://plos.io/2czzew5" target="_blank">positions important for particle assembly and infectivity</a></strong>.</p>
<figure class="wp-caption alignleft" id="attachment_7120" style="width: 286px;"><a href="http://blogs.plos.org/plos/files/2016/09/mapping_CR.jpg"><img alt="mapping_CR" class="wp-image-7120" height="144" src="http://blogs.plos.org/plos/files/2016/09/mapping_CR-300x151.jpg" width="286" /></a>DOI: 10.1371/journal.ppat.1000719</figure>
<figure class="wp-caption alignright" id="attachment_7121" style="width: 280px;"><a href="http://blogs.plos.org/plos/files/2016/09/p7_CR.jpg"><img alt="p7_CR" class="wp-image-7121" height="128" src="http://blogs.plos.org/plos/files/2016/09/p7_CR-300x136.jpg" width="280" /></a>DOI: 10.1371/journal.ppat.1005297</figure>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p><strong><a href="http://plos.io/2cXTre3" target="_blank">Ralf Bartenschlager</a></strong> tops the PLOS list with 27 articles; 20 in <em>PLOS Pathogens</em> and seven in <em>PLOS ONE</em>. Select key early work on HCV includes the role of <strong><a href="http://plos.io/2d6tObe" target="_blank">cyclophilin A in HCV replication</a></strong> and polyprotein processing, the role of HCV p7 protein as a membrane pore involved in <strong><a href="http://plos.io/2cXU332" target="_blank">production and release of infectious virions</a></strong> and the dependence of HCV envelope glycoprotein secretion on <strong><a href="http://plos.io/2cNvW8a" target="_blank">assembly of triglyceride rich lipoproteins</a></strong>.</p>
<p>Bartenschlager’s team also determined the nonstructural protein 5A (NS5A), a component of the viral RNA replication machinery, as a key factor for the formation of infectious HCV particles through an <strong><a href="http://plos.io/2cXy65K" target="_blank">assembly determinant domain and lipid droplets</a></strong>. Bartenschlager’s seminal microscopy work on the <strong><a href="http://plos.io/2dgSlxy" target="_blank">intracellular membranes of HCV infected cells</a></strong> is visually stunning and included in the <strong><a href="http://collections.plos.org/pathogens-10th-anniversary" target="_blank"><em>PLOS Pathogens</em> 10th Anniversary Collection</a>.</strong></p>
<p>More recent articles describe use of a yeast two-hybrid screening strategy to generate an <strong><a href="http://plos.io/2cXz8ig" target="_blank">interactome of cellular proteins</a></strong> that may function with influenza virus non-structural proteins NS1 and NS2, potentially informing therapeutic interventions, and work on Dengue virus that provides a <strong><a href="http://plos.io/2dnPJdd" target="_blank">genetic map of determinants involved in viral RNA replication</a></strong> and extends the list of functions ascribed to the enigmatic nonstructural protein 1.</p>
<figure class="wp-caption alignright" id="attachment_7125" style="width: 285px;"><a href="http://blogs.plos.org/plos/files/2016/09/Dengue_RB.jpg"><img alt="Dengue_RB" class="wp-image-7125" height="130" src="http://blogs.plos.org/plos/files/2016/09/Dengue_RB-300x137.jpg" width="285" /></a>DOI: 10.1371/journal.ppat.1005277</figure>
<figure class="wp-caption alignleft" id="attachment_7124" style="width: 300px;"><a href="http://blogs.plos.org/plos/files/2016/09/morphology_RB.jpg"><img alt="morphology_RB" class="wp-image-7124 size-medium" height="137" src="http://blogs.plos.org/plos/files/2016/09/morphology_RB-300x137.jpg" width="300" /></a>DOI: 10.1371/journal.ppat.1003056</figure>
<p> </p>
<p> </p>
<p> </p>
<h3></h3>
<h3><strong>Discoveries in DNA replication and leadership in science and education:</strong></h3>
<p>In 2012, <em>PLOS Genetics</em>’ <strong><a href="http://collections.plos.org/jane-gitschier-interviews?intcampaign=opb-1609-opbjc" target="_blank">Jane Gitschier Interviews</a></strong> turned to this year’s Lasker-Koshland Special Achievement Award in Medical Science awardee Bruce Alberts for his memories of how he got into science and his thoughts on <strong><a href="http://plos.io/2cPfPGm" target="_blank">learning from failure and getting committees to reach consensus</a></strong>. More recently Alberts shared with PLOS his insights into issues facing scientists today, such as journal impact factors, new forms of recognition for contributions to the scientific publication process and the <strong><a href="http://plos.io/2crjsjm" target="_blank">role of senior as well as junior researchers in changing the culture of science</a></strong>.</p>
<p>For those wanting more information on the significance of the work of this year’s winners and the award in general, <strong><a href="http://www.laskerfoundation.org/awards/" target="_blank">The Lasker Foundation</a></strong> and <strong><em><a href="http://www.cell.com/cell/lasker-2016/home" target="_blank">Cell</a></em></strong> provide coverage.  <em>Cell</em> has also curated Collections dedicated to <strong><a href="http://www.cell.com/cell/collections/hif" target="_blank">Hypoxia-Inducible Factors</a></strong> and <strong><a href="http://www.cell.com/cell/collections/hcv" target="_blank">virus infections</a></strong>. Much, but not all, of the content is Open Access.</p>
<p>PLOS has previously profiled author recipients of the <strong><a href="http://plos.io/2cXxSf0" target="_blank">2016 Breakthrough Prize in Life Sciences</a>, </strong>so bookmark <strong><a href="http://blogs.plos.org/plos/" target="_blank">The Official PLOS Blog</a></strong> and visit this site as future scientific prizes are awarded.</p>
<p> </p>
<p>Image credit: The Lasker Foundation</p>
<img alt="" height="1" src="http://feeds.feedburner.com/~r/plos/Blog/~4/jyXczmzCv-8" width="1" />
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://feeds.plos.org/~r/plos/blogs/neuro/~3/1rE5Jw9uL9U/">“As simple as random can be” by Jasmine Reggiani</a></h2></div>
            <p class="text-muted">by <a href="http://blogs.plos.org/neuro">PLOS Neuroscience Community</a> on September 16, 2016 10:28 PM.</p>
          </div>
          <div class="panel-body">

            <img alt="The Drosophila mushroom body, shown in the MB010B-GAL4 line. Courtesy of Katrin Vogt." class="attachment-thumbnail size-thumbnail wp-post-image" height="150" src="http://blogs.plos.org/neuro/files/2016/09/Droso-150x150.jpg" style="display: block; margin-bottom: 5px; clear: both;" width="150" /><p style="text-align: justify;">A few weeks ago I was having a discussion about mathematical models for the prediction of the movements of the stock market. The question was whether there was any use to developing complex algorithms trying to predict these fluctuations. My friend (an economist) argued that while he admits the market value isn’t truly random, incorporating random variables may be the best model we have for it. It turns out that many mathematicians (and quants, economists who analyze market fluctuations using algorithms) have been using “random” models for their predictions. These range from sequences randomly drawn from log-normal distributions, to chaotic systems that may allow for the prediction of market crashes and other rare large movements. I was fascinated by the idea of randomness as a model for complex systems. It seemed particularly interesting to explore this in the context of biological processes, especially when the laws of thermodynamics have described that all physical phenomena drift towards the chaotic state of maximum entropy. Could randomness be a model for circuit wiring and function in the brain?</p>
<figure class="wp-caption aligncenter" id="attachment_18839" style="width: 543px;"><a href="http://blogs.plos.org/neuro/files/2016/09/Droso.jpg"><img alt="The Drosophila mushroom body, shown in the MB010B-GAL4 line. Courtesy of Katrin Vogt." class=" wp-image-18839" height="290" src="http://blogs.plos.org/neuro/files/2016/09/Droso-300x160.jpg" width="543" /></a>The Drosophila mushroom body, shown in the MB010B-GAL4 line. Courtesy of Katrin Vogt.</figure>
<p style="text-align: justify;">At his plenary lecture at the FENS (Federation of European Neuroscience Societies) Forum of Neuroscience last month, Larry Abbott talked about two distinct but very similar systems in which randomness may play a critical role in shaping the circuit and allowing for its complexity. The work he presented focused on detangling the role of the Kenyon cells in the olfactory learning center of the Drosophila brain, called the mushroom body. He compared these cells to the granule cells of the mammalian cerebellum – a fair comparison because unlike most other known neuronal cell types, both these cell types receive a surprisingly low number of inputs: an average of 4 for granule cells, and up to 6 for Kenyon cells.</p>
<p style="text-align: justify;">The two systems, that granule cells and Kenyon cells are part of, are very similar in their organization. They both comprise three layers: a first input layer that is highly organized and contains a limited number of sensory cells (the olfactory glomeruli in <em>Drosophila</em>, and mossy fibers in the cerebellum), an output layer that is equally organized and is linked to behavioral commands (the mushroom body output neurons in <em>Drosophila</em>, and the Purkinje cells in the cerebellum), and finally a middle layer with a high number of cells that at first glance appear randomly wired (the Kenyon cells in <em>Drosophila</em>, and the granule cells in cerebellum). In a brain where the vast majority of cells are joined at various locations by thousands of synapses of varying strengths, finding a population of cells that only has a handful of synaptic inputs should be a relief for the computational neuroscientist trying to model its behavior. As it turns out, these cells provided quite the head-scratcher. Abbott compared the organization of these neural circuits to the workings of machine learning algorithms, where the input and output are understood and structured, but the connecting layers are complex and hidden.</p>
<p style="text-align: justify;">Abbott, in collaboration with Rubin and Axel, has attempted to decipher this middle layer of Kenyon cells, and understand the network of their inputs and their role in the process of odor learning. In a 2012 paper they used careful tracing and functional mapping of the olfactory glomeruli to the dendrites of Kenyon cells to reveal a random set of connections (Caron et al., 2012). Random connections means that the mapping of projection neurons onto Kenyon cells is no more organized than shuffled combinations. It also means that knowing the input onto one Kenyon cell dendrite gives no predictive power as to which other cells also synapse onto it (Aso et al., 2014). Interestingly, Abbott suggests that the randomness of the antennal lobe to Kenyon cell connectivity patterns might be the key to the mushroom body’s ability to match sensory inputs to meaning and a variety of behavioral outputs. This matching occurs at the axonal projection targets of the Kenyon cells: the mushroom body’s output neurons. This synaptic layer is highly plastic, and combines inputs from dopaminergic neurons as well.</p>
<p style="text-align: justify;">How does the wiring of Kenyon cells allow for olfactory learning? Abbott suggests that the key is increasing dimensionality. The olfactory glomeruli represent odors in a 50-dimensional space. The Kenyon cells, as a large population of cells that each mix inputs from a small number of olfactory glomeruli, amplify odor representation by at least one order of magnitude (Aso et al., 2014). This more complex and varied representation allows for an easier categorization of odors at the level of behavioral output. Reexamining the connectivity in this light, Abbott and his colleagues found that the Kenyon cell innervation appeared more diverse than a random connectivity: the number of cells with the same combinations of inputs was below chance. Especially when considering that the number of synaptic inputs ranges from 1 to 6, a truly random system would have a higher probability of duplicated input combinations. Abbott and colleagues suggested that the system actually favored diversity over randomness! Is randomness then a too simple model to understand the dendritic innervations of Kenyon cells?</p>
<p style="text-align: justify;">In many ways, elementary biological processes are all random: molecules bumping into one another, and neurons finding synaptic partners. Peters and Feldman had suggested in 1976 that axons randomly innervated the dendritic targets in the area. The findings from Abbott’s lab, and much other work in recent years, suggest that further rules restrict or diversify synaptic connection patterns, taking random processes and optimizing their functional potential.</p>
<hr />
<p style="text-align: justify;"><strong>Bibliography</strong></p>
<ol>
<li style="text-align: justify;">Caron S.J.C., Ruta V., Abbott L.F., Axel R. (2012) Random convergence of olfactory inputs in the Drosophila mushroom body, <em>Nature</em>, 497, p. 113-117.</li>
<li style="text-align: justify;">Aso Y., Hattori D., Yu Y., Johnston R.M., Iyer N.A., Ngo T.T., Dionne H., Abbott L.F., Axel R., Tanimoto H., Rubin G.M. (2014) The neuronal architecture of the mushroom body provides a logic for associative learning, <em>eLife</em>, 3e04577.</li>
<li style="text-align: justify;">Davis M. (2001) Mathematics of Financial Markets <em>in Mathematics Unlimited: 2001 and beyond (ed. Engquist and Schmid). </em></li>
<li style="text-align: justify;">Peters A. and Feldman M.L. (1976) The projection of the lateral geniculate nucleus to area 17 of the rat cerebral cortex. I. General description, <em>J Neurocytol</em>, 5(1), p. 63-84.</li>
</ol>
<hr />
<p style="padding-left: 30px;"><a href="http://blogs.plos.org/neuro/files/2016/09/Jasmine.jpg"><img alt="Jasmine" class="wp-image-18840 alignleft" height="168" src="http://blogs.plos.org/neuro/files/2016/09/Jasmine-e1474064260314.jpg" width="145" /></a></p>
<p style="padding-left: 30px;"><strong>Jasmine Reggiani</strong> recently completed a masters at the University of Utrecht (The Netherlands), and currently she studies the function and the molecular identity of retinal ganglion cell types in mice in the lab of <a href="http://saneslab.mcb.harvard.edu/home" target="_blank">Josh Sanes</a>. She is excited about mountains and modern art as much as about science. Jasmine is a contributor of <a href="https://harvardneuro.wordpress.com">Harvard Neuro Blog</a>. You can follow her blog <a class="ProfileHeaderCard-screennameLink u-linkComplex js-nav" href="https://twitter.com/harvardneurosci">@<span class="u-linkComplex-target">harvardneurosci</span></a></p>
<img alt="" height="1" src="http://feeds.feedburner.com/~r/plos/blogs/neuro/~4/1rE5Jw9uL9U" width="1" />
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://feeds.plos.org/~r/plos/Blog/~3/1NUeGyzmqg0/">PLOS appoints Dr. Joerg Heber Editor-in-Chief of PLOS ONE</a></h2></div>
            <p class="text-muted">by <a href="http://blogs.plos.org/plos">The Official PLOS Blog</a> on September 16, 2016 09:01 AM.</p>
          </div>
          <div class="panel-body">

            <img alt="45c6cd5668839d0af93a0a0fc89e4368_400x400" class="attachment-thumbnail size-thumbnail wp-post-image" height="150" src="http://blogs.plos.org/plos/files/2016/09/45c6cd5668839d0af93a0a0fc89e4368_400x400-150x150.png" style="display: block; margin-bottom: 5px; clear: both;" width="150" /><p>PLOS announced today that after an extensive search, Dr. Joerg Heber has been appointed Editor-in-Chief of <em>PLOS ONE</em>. Heber will be responsible for setting the editorial course of the journal and continue its mission of improving scholarly communication. His appointment is effective November 21, 2016.</p>
<p>“Joerg’s deep understanding of scholarly publishing and his passion for Open Access will be tremendous assets to me and our editorial staff, and most importantly to <em>PLOS ONE</em>’s 6,000 Academic Editors and our authors,” said Veronique Kiermer, Executive Editor of PLOS. “<em>PLOS ONE</em> has been a driver of changes in scientific communication since its launch ten years ago. It is an enormous responsibility and I am entirely confident in Joerg’s ability to lead the journal through its next phase, to further develop its mission and meet the needs of the scientific community.”</p>
<p>“I am delighted to be joining PLOS” said Heber. “PLOS’ commitment to Open Access and to innovation has been transformative, and <em>PLOS ONE</em> is ideally placed to support Open Access and open science with continued advancements in scholarly communication. I’m excited to work with the <em>PLOS ONE</em> team to serve science as a whole.”</p>
<p>Prior to joining PLOS, Heber was Executive Editor of <em>Nature Communications</em>. In this role Heber had responsibility for the journal’s overall editorial strategy. He was instrumental in <em>Nature Communications</em> transparent peer review initiative, implementing its Data Availability Statements and contributed to the journal’s move to full Open Access publishing. Heber also worked as a Senior Editor for <em>Nature Materials</em> and his previous experience includes a visiting professorship at the University of Tokyo and lecturer at Philipps-University Marburg, Germany.</p>
<p>Heber obtained his PhD in semiconductor physics at Imperial College London, UK, and did post-doctoral work at Bell Labs, New Jersey.</p>
<img alt="" height="1" src="http://feeds.feedburner.com/~r/plos/Blog/~4/1NUeGyzmqg0" width="1" />
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://biocomputation.herts.ac.uk/2016/09/14/next-generation-sequencing-ngs.html">Next generation sequencing (NGS)</a></h2></div>
            <p class="text-muted">by <a href="http://biocomputation.herts.ac.uk/">UH Biocomputation group</a> on September 14, 2016 04:01 PM.</p>
          </div>
          <div class="panel-body">

            <p>My talk will be a summary of my research so far in investigating the effects of
artefacts which occur during the library preparation stage of Next generation
sequencing.</p>
<p>Next generation sequencing (NGS) of DNA has dramatically transformed approaches
to genomic and genetic research. DNA sequencing refers to a laboratory method
used to determine the sequence of a DNA molecule. Some of the well-known
technologies that are applied in this process include the Roche GS-FLX 454
Genome Sequencer (originally 454 sequencing), the Illumina Genome Analyser
(originally Solexa technology), the ABI SOLiD analyser, Polonator G.007 and the
Helicos HeliScope platforms. These technologies (also referred to as massively
parallel sequencing technologies) have enabled the sequencing of DNA at
unprecedented speeds compared to the "original" sequencing methodology known as
the Sanger method.</p>
<p>Although NGS has revolutionised biology by increasing current understanding of
many genes and genomic regions involved in the pathogenesis of human diseases,
there are challenges associated with the use of these new technologies. For
example, the sequencing of parts of a genome characterized by extremely biased
base composition is still a great challenge to the currently available NGS
platforms. The genomes of certain important pathogenic organisms like
Plasmodium falciparum and Escherichia coli display extremes of base
composition, high AT content and high GC content respectively. The sequencing
"coverage" of these genomes can be affected by artefacts that may be introduced
at various stages of the sequencing process, thus affecting final sequencing
output.</p>
<p>My project studies the effects of artefacts that occur during the initial stage
of the sequencing work flow referred to as library preparation. The purpose of
this research is to identify known artefacts that can occur during the library
preparation stage from existing literature, and to analyse the extent to which
sequencing coverage may be affected by these artefacts. In other words, a study
of problems that can arise from the library preparation stage of the sequencing
work flow and how they affect final sequencing output forms the basis of my
work.</p>
<ul class="simple">
<li><a class="reference external" href="http://www.biomedcentral.com/1471-2164/13/1">Oyola, S.O., Otto, T.D., Gu, Y., Maslen, G., et al. (2012) Optimizing Illumina
next-generation sequencing library preparation for extremely AT-biased genomes.
BMC genomics.</a></li>
<li><a class="reference external" href="http://www.pnas.org/content/74/12/5463.short">Sanger, F., Nicklen, S. &amp; Coulson, A.R. (1977) DNA sequencing with
chain-terminating inhibitors. Proceedings of the National Academy of Sciences
of the United States of America.</a></li>
<li><a class="reference external" href="http://www.sciencedirect.com/science/article/pii/S1673852711000300">Zhang, J., Chiodini, R., Badr, A. &amp; Zhang, G. (2011) The impact of
next-generation sequencing on genomics. Journal of genetics and genomics = Yi
chuan xue bao.</a></li>
</ul>
<p><strong>Date:</strong> 16/09/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://biocomputation.herts.ac.uk/2016/09/08/removing-noisy-features-via-feature-weight-preliminary-results-in-mixed-model-gaussian-distribution.html">Removing noisy features via feature weights: preliminary results in mixed-model Gaussian distributions</a></h2></div>
            <p class="text-muted">by <a href="http://biocomputation.herts.ac.uk/">UH Biocomputation group</a> on September 08, 2016 10:12 AM.</p>
          </div>
          <div class="panel-body">

            <p>In this article, we purpose an unsupervised feature selection algorithm that removes uniform noisy features encapsulated
in the mixed model Gaussian distribution. The method is based on feature weighting principle and assumes that the noisy
features have least feature weight and therefore have less or no contribution to cluster recovery. Experiments show that the proposed feature selection algorithm is more efficient in identifying noisy features compare to other similar algorithms like feature selection based on feature similarity (FSFS) or the intelligent K-Means feature selection(iKFS).</p>
<p><strong>Date:</strong> 09/09/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://feeds.plos.org/~r/plos/Blog/~3/4j_Ot9fFqPU/">Riding A Wave Towards Improved Truth in Science Communication</a></h2></div>
            <p class="text-muted">by <a href="http://blogs.plos.org/plos">The Official PLOS Blog</a> on September 06, 2016 04:35 PM.</p>
          </div>
          <div class="panel-body">

            <img alt="Archaic Waves_Hero" class="attachment-thumbnail size-thumbnail wp-post-image" height="150" src="http://blogs.plos.org/plos/files/2016/09/Archaic-Waves_Hero-150x150.jpg" style="display: block; margin-bottom: 5px; clear: both;" width="150" /><div class="wp_orcid_field"><a href="http://orcid.org/0000-0001-7318-5892" rel="author" target="_blank">0000-0001-7318-5892</a></div><p>It is an exciting time in scientific publishing. Initiatives such as <strong><a href="http://blogs.plos.org/plos/2016/01/author-credit-plos-orcid-update/" target="_blank">digital identifiers for authors through ORCID</a></strong>, more <strong><a href="http://blogs.plos.org/plos/2016/07/author-credit-plos-and-credit-update/" target="_blank">granular recognition of collaborative work</a></strong> with standardized language for specific roles with CRedIT, and more competition in the Open Access publishing world benefit researchers and move the scientific endeavor toward a more transparent and accountable future.</p>
<p>Yet, the write up and publication of results is one of the most challenging aspects of the endeavor, with peer review and reproducibility at the heart of this stage of the research lifecycle. We have previously acknowledged on The Official PLOS Blog that the public</p>
<blockquote><p>“relies on the belief that <strong><a href="http://blogs.plos.org/plos/2016/04/where-next-for-plos-working-together-to-make-waves-in-scientific-communication/" target="_blank">content published in peer-reviewed journals is trustworthy</a></strong>, despite the fact that this is too often not the case.”</p></blockquote>
<p>We have also acknowledged that we must do better: all stakeholders, including publishers, are accountable. Although the overall concept of peer review is an accepted form of quality control and valued by the scientific community, in practice it suffers from imperfections that prevent it from achieving that one great thing: advancing research communication.</p>
<h4>In a thoughtful consideration of <strong><a href="http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1002547" target="_blank">Truth in Science Publishing: A Personal Perspective</a></strong>, Thomas Sudhof eloquently describes peer review and reproducibility as flawed checkpoints that impair the “validity of published scientific results” and impede trust in science.</h4>
<p>As a recipient of both the Nobel Prize and the Lasker Award for his work on synaptic transmission, Sudhof brings perspective and integrity to his thought leadership. Highlighting hidden conflicts of interest, too little accountability for journals and reviewers, and lack of competition between journals as three problems with peer review that have “corrupted the process, decreasing its value,” Sudhof endorses more transparency in the peer review process to reduce bias.</p>
<p>At PLOS there are a range of ways to improve the process without diminishing those aspects that the community values. Current tools and systems that address these limitations include the <strong><a href="http://www.ariessys.com/views-press/press-releases/deployment-editorial-manager-ingest-service-biorxiv-preprint-server-simplifies-author-submission-journals-plos-one/" target="_blank">posting of research to preprint servers</a></strong> before formal publication, to enable researchers to <strong><a href="http://blogs.plos.org/absolutely-maybe/2016/05/01/breaking-down-pros-and-cons-of-preprints-in-biomedicine/" target="_blank">improve their work and share it earlier</a></strong>. There is an opportunity to improve review forms that may be cumbersome or insufficient to provide thoughtful and constructive feedback to authors. Appropriate and rigorous reviewer and editor training can help to mitigate potential reviewer bias and mentor early career researchers. With improved technologies and processes, publishers have an opportunity to improve efficiencies, quality, trustworthiness and authenticity of the process.</p>
<h4>As for reproducibility, Sudhof outlines increasingly complex experiments that are impossible to reproduce, “tweaked or selected” results that do not hold up with repetition, lack of validation of reagents and methods, and the “near impossibility” of publishing negative results as contributors to the problem.</h4>
<p>Providing opportunity to showcase peer-reviewed articles that address the reproducibility issue is an important value of PLOS and <strong><a href="http://journals.plos.org/plosone/static/publish" target="_blank"><em>PLOS ONE</em></a></strong>; the journal welcomes submission of <strong><a href="http://collections.plos.org/missing-pieces" target="_blank">negative, null and inconclusive results</a></strong>. <em>PLOS Biology</em>’s <strong><a href="http://collections.plos.org/meta-research" target="_blank">Meta-Research section</a></strong> welcomes experimental, observational, modeling and meta-analyses that address research design, methods, reporting, verification or evaluation.</p>
<p><em>PLOS Biology</em> and <em>PLOS Genetics</em> authors can contribute to the reproducibility effort by <strong><a href="http://journals.plos.org/plosgenetics/s/submission-guidelines#loc-research-resource-identifiers" target="_blank">identifying model organisms, antibodies or tools</a></strong> with a unique Research Resource Identifier (RRID). PLOS is a part of the <strong><a href="https://www.force11.org/node/4463" target="_blank">Research Resource Identification Initiative</a></strong>, a cross-publisher effort to promote reproducibility in science and enable effective tracking of the use of particular research resources across the biomedical literature.</p>
<p>PLOS works toward a future where research is published without unnecessary delays, and continual assessment and commentary is provided by a robust and ethical system of visible, engaged pre- and post-publication peer review. We strive to engage a global editorial and reviewer contributor community, appropriately trained, recognized and incentivized. With regard to journal-facilitated peer review, rigorous input from experts in a relevant field of research is highly valued by both authors and readers, and contributes to trust of research results for working scientists, clinicians, patient advocates, policymakers and educators.</p>
<p>Addressing the issues and challenges that perversely incentivize unreliable research or prevent peer review from achieving its scholarly ideal will not be easy or quick. The <strong><a href="http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1002165" target="_blank">challenges are substantial</a></strong> and the solutions must be as well, and satisfy a diverse researcher and stakeholder community. Broader adoption of <strong><a href="http://blogs.plos.org/thestudentblog/2016/08/05/the-irreproducibility-crisis-an-opportunity-to-make-science-better/" target="_blank">reproducibility efforts</a></strong> and better recognition for the range of contributions made by researchers and reviewers will not be enough without the engagement of <strong><a href="http://blogs.plos.org/thestudentblog/2016/07/16/ecrawards1/" target="_blank">early career researchers</a></strong>, junior investigators and <strong><a href="http://rescuingbiomedicalresearch.org/the-problem/" target="_blank">senior leadership</a></strong> with the power to influence change.</p>
<p> </p>
<p>Image credit: one-vibe, pixabay.com</p>
<img alt="" height="1" src="http://feeds.feedburner.com/~r/plos/Blog/~4/4j_Ot9fFqPU" width="1" />
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://ankursinha.in/blog/2016/09/02/using-neuron-part-ii.html">Using NEURON - Part II</a></h2></div>
            <p class="text-muted">by <a href="http://ankursinha.in/blog/">Ankur Sinha</a> on September 02, 2016 12:39 PM.</p>
          </div>
          <div class="panel-body">

            <p><a class="reference external" href="https://senselab.med.yale.edu/ModelDB/ModelList.cshtml?id=1882">ModelDB</a> is a popular resource where the computational neuroscience community puts up models that were used in various publications. Since I'm quite new to <a class="reference external" href="http://www.neuron.yale.edu/neuron/">NEURON</a>, I thought I'd play with some existing models to get a hang of things. Here I document how to run an existing model.</p>
<p><a class="reference external" href="https://senselab.med.yale.edu/ModelDB/ModelList.cshtml?id=1882">ModelDB</a> has quite a few models that use <a class="reference external" href="http://www.neuron.yale.edu/neuron/">NEURON</a>. Find one that suits you. I'll pick <a class="reference external" href="https://senselab.med.yale.edu/ModelDB/ShowModel.cshtml?model=139653">L5b PC model constrained for BAC firing and perisomatic current step firing (Hay et al., 2011)</a> for now.</p>
<div class="section" id="download-the-model">
<h2>Download the model</h2>
<p><a class="reference external" href="https://senselab.med.yale.edu/modeldb/eavBinDown.cshtml?o=139653&amp;a=23&amp;mime=application/zip">Download the zip</a> file from the model page to a convenient location. There's a link right on the top of the page. Extract it.</p>
<pre class="code bash literal-block">$ unzip L5bPCmodelsEH.zip
$ lash
total 668K
4.0K drwxr-xr-x. <span class="m">7</span> asinha asinha 4.0K Mar <span class="m">30</span>  <span class="m">2013</span> L5bPCmodelsEH
664K -rw-r-----. <span class="m">1</span> asinha asinha 662K Sep  <span class="m">2</span> 13:55 L5bPCmodelsEH.zip
</pre>
</div>
<div class="section" id="building-and-running-the-model">
<h2>Building and running the model</h2>
<p>Enter the directory:</p>
<pre class="code bash literal-block"><span class="nb">cd</span> L5bPCmodelsEH/
</pre>
<p><a class="reference external" href="http://www.neuron.yale.edu/neuron/">NEURON</a> code comprises of two sets of code files. You have the HOC files, and the NMODL files. NMODL files need to be compiled before the model can be run.</p>
<pre class="code bash literal-block">$ ~/dump/neuron-installation/x86_64/bin/nrnivmodl mod
Creating x86_64 directory <span class="k">for</span> .o files.

/home/asinha/dump/neuron-blog/L5bPCmodelsEH
mod/CaDynamics_E2.mod mod/Ca_HVA.mod mod/Ca_LVAst.mod mod/epsp.mod mod/Ih.mod mod/Im.mod mod/K_Pst.mod mod/K_Tst.mod mod/Nap_Et2.mod mod/NaTa_t.mod mod/NaTs2_t.mod mod/SK_E2.mod mod/SKv3_1.mod
CaDynamics_E2.mod Ca_HVA.mod Ca_LVAst.mod epsp.mod Ih.mod Im.mod K_Pst.mod K_Tst.mod Nap_Et2.mod NaTa_t.mod NaTs2_t.mod SK_E2.mod SKv3_1.mod
<span class="s2">"/home/asinha/dump/neuron-installation/x86_64/bin/nocmodl"</span> CaDynamics_E2
Translating CaDynamics_E2.mod into CaDynamics_E2.c
Thread Safe
<span class="s2">"/home/asinha/dump/neuron-installation/share/nrn/libtool"</span> --tag<span class="o">=</span>CC --mode<span class="o">=</span>compile mpicc -DHAVE_CONFIG_H  -I. -I.. -I<span class="s2">"/home/asinha/dump/neuron-installation/include/nrn"</span> -I<span class="s2">"/home/asinha/dump/neuron-installation/x86_64/lib"</span>      -O2 -g -pipe -Wall -Werror<span class="o">=</span>format-security -Wp,-D_FORTIFY_SOURCE<span class="o">=</span><span class="m">2</span> -fexceptions -fstack-protector-strong --param<span class="o">=</span>ssp-buffer-size<span class="o">=</span><span class="m">4</span> -grecord-gcc-switches -specs<span class="o">=</span>/usr/lib/rpm/redhat/redhat-hardened-cc1 -m64 -mtune<span class="o">=</span>generic -c -o CaDynamics_E2.lo CaDynamics_E2.c
libtool: compile:  mpicc -DHAVE_CONFIG_H -I. -I.. -I/home/asinha/dump/neuron-installation/include/nrn -I/home/asinha/dump/neuron-installation/x86_64/lib -O2 -g -pipe -Wall -Werror<span class="o">=</span>format-security -Wp,-D_FORTIFY_SOURCE<span class="o">=</span><span class="m">2</span> -fexceptions -fstack-protector-strong --param<span class="o">=</span>ssp-buffer-size<span class="o">=</span><span class="m">4</span> -grecord-gcc-switches -specs<span class="o">=</span>/usr/lib/rpm/redhat/redhat-hardened-cc1 -m64 -mtune<span class="o">=</span>generic -c CaDynamics_E2.c  -fPIC -DPIC -o .libs/CaDynamics_E2.o
CaDynamics_E2.c:94:34: warning: missing braces around initializer <span class="o">[</span>-Wmissing-braces<span class="o">]</span>
  static VoidFunc hoc_intfunc<span class="o">[]</span> <span class="o">=</span> <span class="o">{</span>
  ...
  ....
  ...
  ...
</pre>
<p>You'll see a new <code>x86_64</code> directory which contains the compiled code. Now, simply run <a class="reference external" href="http://www.neuron.yale.edu/neuron/">NEURON</a> as usual. If everything went well, the simulation will run:</p>
<pre class="code bash literal-block">$ ~/dump/neuron-installation/x86_64/bin/nrngui mosinit.hoc
</pre>
<p>Remember that you must run <code>nrngui</code> in the directory where the <code>x86_64</code> directory resides for <a class="reference external" href="http://www.neuron.yale.edu/neuron/">NEURON</a> to find it.</p>
<p>That's it!</p>
</div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://biocomputation.herts.ac.uk/2016/09/02/open-positions-early-career-research-fellowships-in-systems-biology-machine-learning-for-food-and-disease.html">Open Positions: Early Career Research Fellowships in systems biology/machine learning for food and disease</a></h2></div>
            <p class="text-muted">by <a href="http://biocomputation.herts.ac.uk/">UH Biocomputation group</a> on September 02, 2016 09:58 AM.</p>
          </div>
          <div class="panel-body">

            <p>Salary: £31,656 - £37,768 per annum depending on skills and experience <br />
Closing Date: 27th Oct 2016 <br />
Full time position working 37 hours per week. <br />
Fixed term contract for a period of five years. <br /></p>
<p>The postdoctoral fellowship will focus on emerging methods in biocomputation to improve food and health or combat plant, animal or human diseases. A first degree in biology, computer science or a relevant subject and a doctoral degree in bioinformatics, machine learning, quantitative biology or related subjects is required. Experience in systems biology, big data science or genomics will be useful. The fellowship is offered for a period of 5 years with the expectation that the fellow will obtain a permanent academic post supported.</p>
<div class="section" id="qualifications-required">
<h2>Qualifications required</h2>
<p>You must have a first degree in a science, such as biology, computer science, mathematics or a relevant subject, and a doctoral degree in areas such as bioinformatics, machine learning, quantitative biology or a related subject area.  Experience in systems biology, big data science or genomics will be useful.</p>
</div>
<div class="section" id="research-focus-and-environment">
<h2>Research focus and environment</h2>
<p>The Fellow is expected to develop her/his own line of research. This should include a focus on emerging methods in biocomputation that generate and exploit large data sets of biological information to better understand mechanisms such as those underlying host resistance/immunity and/or resistance breakdown.  The Fellow will generate an improved understanding of relevant biological systems to develop specific strategies to improve food and health or combat plant, animal or human diseases.  This Fellowship will be supported by existing collaborations between colleagues in Schools of Life &amp; Medical Sciences (Kukol, Stotz, Barling, Fitt) and Computer Science (Steuber).  The Fellow is expected to use the University’s high performance computer cluster.</p>
</div>
<div class="section" id="experience-and-skills-required-for-the-post">
<h2>Experience and skills required for the post</h2>
<ul class="simple">
<li>Ability to develop and apply computational methods to biological problems;</li>
<li>Experience with techniques such as machine learning or mathematical modelling of biological datasets, for example in genomics or proteomics;</li>
<li>Evidence of original research and ability to publish in high impact journals.</li>
</ul>
</div>
<div class="section" id="research-expectations">
<h2>Research expectations</h2>
<p>The Fellow is expected to develop a collaborative research program with our academic partners.  We envisage that the Research Fellow will become a permanent staff member, supported by funding from successful research grant applications and developing new areas of teaching, especially at the post-graduate level. To ensure this, the two Schools will provide career training for the Fellow. The Fellow will have established collaborations with companies and successfully obtained co-funded industry-government projects. The Fellow will publish high-impact papers and be building a research team.</p>
</div>
<div class="section" id="description-of-the-school-s">
<h2>Description of the School(s)</h2>
<p>This Early Career Research Fellow will work with and receive support from the School of Life and Medical Sciences and the School of Computer Science.  The successful candidate can build on the strengths of both Schools and may combine experiment-based empirical research with data-based analysis.</p>
<p>Within the <a class="reference external" href="http://www.herts.ac.uk/apply/schools-of-study/life-and-medical-sciences/research">School of Life and Medical Sciences</a>, the Centre for Agriculture, Food and Environmental Management (CAFEM) is a research and teaching collaboration with the Royal Veterinary College, Rothamsted Research and Oaklands College.  The Fellow will work with researchers in CAFEM who have experience with systems biology applicable to crop protection, combining experimental field and lab research with computational modelling.  Within the School of Computer Science, research in the <a class="reference external" href="http://biocomputation.herts.ac.uk/">Biocomputation Research Group</a> involves development of computational models to study biological systems and application of biologically-inspired machine learning algorithms for the analysis of "real-world" data.  Members of the Biocomputation Group analyse and simulate computational models at different levels of complexity and collaborate closely with leading experimentalists in the UK and abroad.</p>
<hr class="docutils" />
<p>Informal enquiries are encouraged and should be made to: <br />
Professor Bruce Fitt, <br />
Professor of Plant Pathology, <br />
email: <a class="reference external" href="mailto:b.fitt@herts.ac.uk">b.fitt@herts.ac.uk</a>  <br />
Tel + 44 (0)1707 284751</p>
<p>or</p>
<p>Dr. Volker Steuber, <br />
Reader in Biocomputation and Head of the Biocomputation Research Group, <br />
email:  <a class="reference external" href="mailto:v.steuber@herts.ac.uk">v.steuber@herts.ac.uk</a> <br />
Tel: +44 (0)1707 284350.</p>
<p>Applications should be made through <a class="reference external" href="http://www.herts.ac.uk/contact-us/jobs-and-vacancies/research-vacancies">http://www.herts.ac.uk/contact-us/jobs-and-vacancies/research-vacancies</a></p>
</div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://ankursinha.in/blog/2016/08/27/quickly-scripting-a-grid-search-for-parameter-tuning.html">Quickly scripting a grid-search for parameter tuning</a></h2></div>
            <p class="text-muted">by <a href="http://ankursinha.in/blog/">Ankur Sinha</a> on August 27, 2016 09:10 AM.</p>
          </div>
          <div class="panel-body">

            <p>A lot of models rely on different parameters. In my cortical models, these are usually variables like conductances of different sets of synapses, the sparsity of different synapse sets, learning rates of spike time dependent plasticity learning rules and so on. Given how finely tuned neuronal networks sometimes are, models don't depict the expected behaviours for the entire domain of parameter values. Instead, we often must find the right ranges of these parameters.</p>
<p>In my simulations, I have some sets of synapses, and in my recent investigations, I needed to find the right "balance" between them. The standard way of going about this is to carry out an organised parameter search, what I think is referred to as a "grid search". In a grid search, each point in the parameter space is tested to find the ranges where the required behaviour is simulated - really just simple brute force at play here. Now, since I have three parameters to test, my parameter space would be a three dimensional grid - the Cartesian product of the domains of the three parameters - <code>p1 x p2 x p3</code>. For all possible ordered sets of p1, p2, and p3, I need to run my simulation - the number of possible combinations being <code>n(p1) x n(p2) x n(p3)</code>, where <code>n</code> is the cardinality of each set.</p>
<p>Of course, I wrote myself a script. Modifying the parameters by hand and then queuing up all these simulations manually on the cluster would just take too much time.</p>
<div class="section" id="the-idea">
<h2>The idea</h2>
<p>It's a simple Python script, and this fits well with my <a class="reference external" href="http://ankursinha.in/blog/feeds/categories/20160531-some-tips-and-tricks-for-running-simulations-on-a-cluster.rst">workflow</a> (which intensively uses Git and scripts to queue jobs on the cluster). The idea is:</p>
<ul class="simple">
<li>create a new Git branch for the grid search (so we keep things organised!)</li>
<li>use a simple scripting language to iterate over the parameter space</li>
<li>modify the parameters in the simulation source code</li>
<li>create a new commit for each point in the parameter space</li>
<li>queue up all these commits on the cluster</li>
</ul>
</div>
<div class="section" id="the-script">
<h2>The script</h2>
<p>I've used Python - you can use another scripting language that you prefer. I wouldn't recommend a shell script - even though it's powerful, handling arrays and floats and the sort is quite tedious in bash.</p>
<pre class="code Python literal-block"><span class="ch">#!/usr/bin/env python3</span>
<span class="sd">"""
Copyright 2016 Ankur Sinha
Author: Ankur Sinha &lt;sanjay DOT ankur AT gmail DOT com&gt;

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.
"""</span>

<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">subprocess</span>
<span class="kn">import</span> <span class="nn">datetime</span>


<span class="k">class</span> <span class="nc">GridSearch</span><span class="p">:</span>

    <span class="sd">"""Set up your simulations for a grid search.


    This will modify the source in a branch, make changes, commit
    and then you can set these commits up on the cluster.
    """</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">"""Initialise."""</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">source</span> <span class="o">=</span> <span class="s2">"/path/to/source/file/"</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">branch</span> <span class="o">=</span> <span class="s2">"master"</span>

    <span class="k">def</span> <span class="nf">usage</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">"""Print usage."""</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">"Usage:"</span><span class="p">,</span> <span class="nb">file</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">"python3 grid_search.py &lt;branch&gt;"</span><span class="p">,</span> <span class="nb">file</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">"Branch MUST be specified."</span><span class="p">,</span> <span class="nb">file</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">branch</span><span class="p">,</span> <span class="n">range_dict</span><span class="p">):</span>
        <span class="sd">"""Set it up."""</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">branch</span> <span class="o">=</span> <span class="n">branch</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">range_dict</span><span class="p">[</span><span class="s1">'param1'</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param1_increment</span> <span class="o">=</span> <span class="mf">0.5</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param1_min</span> <span class="o">=</span> <span class="n">range_dict</span><span class="p">[</span><span class="s1">'param1'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param1_max</span> <span class="o">=</span> <span class="n">range_dict</span><span class="p">[</span><span class="s1">'param1'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">param1_increment</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">range_dict</span><span class="p">[</span><span class="s1">'param1'</span><span class="p">])</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param1_increment</span> <span class="o">=</span> <span class="n">range_dict</span><span class="p">[</span><span class="s1">'param1'</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param1_min</span> <span class="o">=</span> <span class="n">range_dict</span><span class="p">[</span><span class="s1">'param1'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param1_max</span> <span class="o">=</span> <span class="n">range_dict</span><span class="p">[</span><span class="s1">'param1'</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">param1_increment</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s2">"param1 not found in dict. Exiting."</span><span class="p">,</span> <span class="nb">file</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">False</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">range_dict</span><span class="p">[</span><span class="s1">'param2'</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param2_increment</span> <span class="o">=</span> <span class="mf">0.5</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param2_min</span> <span class="o">=</span> <span class="n">range_dict</span><span class="p">[</span><span class="s1">'param2'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param2_max</span> <span class="o">=</span> <span class="n">range_dict</span><span class="p">[</span><span class="s1">'param2'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">param2_increment</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">range_dict</span><span class="p">[</span><span class="s1">'param2'</span><span class="p">])</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param2_increment</span> <span class="o">=</span> <span class="n">range_dict</span><span class="p">[</span><span class="s1">'param2'</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param2_min</span> <span class="o">=</span> <span class="n">range_dict</span><span class="p">[</span><span class="s1">'param2'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param2_max</span> <span class="o">=</span> <span class="n">range_dict</span><span class="p">[</span><span class="s1">'param2'</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">param2_increment</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s2">"param2 not found in dict. Exiting."</span><span class="p">,</span> <span class="nb">file</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">False</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">range_dict</span><span class="p">[</span><span class="s1">'param3'</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param3_increment</span> <span class="o">=</span> <span class="mf">0.5</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param3_min</span> <span class="o">=</span> <span class="n">range_dict</span><span class="p">[</span><span class="s1">'param3'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param3_max</span> <span class="o">=</span> <span class="n">range_dict</span><span class="p">[</span><span class="s1">'param3'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">param3_increment</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">range_dict</span><span class="p">[</span><span class="s1">'param3'</span><span class="p">])</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param3_increment</span> <span class="o">=</span> <span class="n">range_dict</span><span class="p">[</span><span class="s1">'param3'</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param3_min</span> <span class="o">=</span> <span class="n">range_dict</span><span class="p">[</span><span class="s1">'param3'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param3_max</span> <span class="o">=</span> <span class="n">range_dict</span><span class="p">[</span><span class="s1">'param3'</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">param3_increment</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s2">"param3 not found in dict. Exiting."</span><span class="p">,</span> <span class="nb">file</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">False</span>

        <span class="k">return</span> <span class="bp">True</span>

    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">"""Run."""</span>
        <span class="c1"># checkout the branch</span>
        <span class="n">git_args</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"checkout"</span><span class="p">,</span> <span class="s2">"-b"</span><span class="p">,</span> <span class="s2">"grid_search-{}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="nb">str</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">date</span><span class="o">.</span><span class="n">today</span><span class="p">())),</span> <span class="bp">self</span><span class="o">.</span><span class="n">branch</span><span class="p">]</span>
        <span class="n">subprocess</span><span class="o">.</span><span class="n">call</span><span class="p">([</span><span class="s1">'git'</span><span class="p">]</span> <span class="o">+</span> <span class="n">git_args</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">param1</span> <span class="ow">in</span> <span class="n">numpy</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param1_min</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">param1_max</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">param1_increment</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">param2</span> <span class="ow">in</span> <span class="n">numpy</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param2_min</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">param2_max</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">param2_increment</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">param3</span> <span class="ow">in</span> <span class="n">numpy</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param3_min</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">param3_max</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">param3_increment</span><span class="p">):</span>

                    <span class="n">sed_args_param1</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'sed'</span><span class="p">,</span> <span class="s1">'-i'</span><span class="p">,</span>
                                <span class="s2">"s/param1 = .*$/param1 = {}/"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">param1</span><span class="p">),</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">source</span><span class="p">]</span>
                    <span class="n">subprocess</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">sed_args_param1</span><span class="p">)</span>

                    <span class="n">sed_args_param2</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'sed'</span><span class="p">,</span> <span class="s1">'-i'</span><span class="p">,</span>
                                <span class="s2">"s/param2 = .*$/param2 = {}/"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">param2</span><span class="p">),</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">source</span><span class="p">]</span>
                    <span class="n">subprocess</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">sed_args_param2</span><span class="p">)</span>

                    <span class="n">sed_args_param3</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'sed'</span><span class="p">,</span> <span class="s1">'-i'</span><span class="p">,</span>
                                <span class="s2">"s/param3 = .*$/param3 = {}/"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">param3</span><span class="p">),</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">source</span><span class="p">]</span>
                    <span class="n">subprocess</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">sed_args_param3</span><span class="p">)</span>

                    <span class="n">git_args</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"add"</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">source</span><span class="p">]</span>
                    <span class="n">subprocess</span><span class="o">.</span><span class="n">call</span><span class="p">([</span><span class="s1">'git'</span><span class="p">]</span> <span class="o">+</span> <span class="n">git_args</span><span class="p">)</span>

                    <span class="n">commit_msg</span> <span class="o">=</span> <span class="s2">"""{} {} {} {}"""</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="nb">str</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">date</span><span class="o">.</span><span class="n">today</span><span class="p">()),</span> <span class="n">param1</span><span class="p">,</span>
                        <span class="n">param2</span><span class="p">,</span> <span class="n">param3</span><span class="p">)</span>

                    <span class="n">git_args</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"commit"</span><span class="p">,</span> <span class="s2">"-m"</span><span class="p">,</span> <span class="n">commit_msg</span><span class="p">]</span>
                    <span class="n">subprocess</span><span class="o">.</span><span class="n">call</span><span class="p">([</span><span class="s1">'git'</span><span class="p">]</span> <span class="o">+</span> <span class="n">git_args</span><span class="p">)</span>

        <span class="n">git_args</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"checkout"</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">branch</span><span class="p">]</span>
        <span class="n">subprocess</span><span class="o">.</span><span class="n">call</span><span class="p">([</span><span class="s1">'git'</span><span class="p">]</span> <span class="o">+</span> <span class="n">git_args</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s2">"__main__"</span><span class="p">:</span>
    <span class="n">search</span> <span class="o">=</span> <span class="n">GridSearch</span><span class="p">()</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">search</span><span class="o">.</span><span class="n">usage</span><span class="p">()</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">branch</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1"># dictionary that holds the required grid ranges</span>
        <span class="c1"># specify min, max if want a grid search, else specify only one value</span>
        <span class="c1"># if you specify max, min, you must specify increment</span>
        <span class="n">setup_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">'param1'</span><span class="p">:</span> <span class="p">[</span><span class="mf">3.</span><span class="p">],</span>
            <span class="s1">'param2'</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>
            <span class="s1">'param3'</span><span class="p">:</span> <span class="p">[</span><span class="o">-</span><span class="mf">5.</span><span class="p">,</span> <span class="o">-</span><span class="mf">30.</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.</span><span class="p">],</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="n">search</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">branch</span><span class="p">,</span> <span class="n">setup_dict</span><span class="p">):</span>
            <span class="n">search</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
</pre>
<p>Since I'm calling <code>sed</code> to modify my source and replace the parameter values, the only requirement here is that my source code needs to have the three lines (look at the regular expressions):</p>
<pre class="code Python literal-block"><span class="n">param1</span> <span class="o">=</span> <span class="o">..</span>
<span class="n">param2</span> <span class="o">=</span> <span class="o">..</span>
<span class="n">param3</span> <span class="o">=</span> <span class="o">..</span>
</pre>
<p>If all goes well, you should have a new branch:</p>
<pre class="code console literal-block"><span class="go">* 74866b6 - (3 months ago) Bugfix - neurons first, synapses later — Ankur Sinha (Ankur Sinha Gmail)
| * fd6a7fa - (5 days ago) 2016-08-22 3.0 3.0 -30.0 — Ankur Sinha (Ankur Sinha Gmail) (origin/grid_search-2016-08-22, grid_search-2016-08-22)
| * 33c95be - (5 days ago) 2016-08-22 3.0 3.0 -25.0 — Ankur Sinha (Ankur Sinha Gmail)
| * 51f96c1 - (5 days ago) 2016-08-22 3.0 3.0 -20.0 — Ankur Sinha (Ankur Sinha Gmail)
| * e8c106e - (5 days ago) 2016-08-22 3.0 3.0 -15.0 — Ankur Sinha (Ankur Sinha Gmail)
| * eaa7341 - (5 days ago) 2016-08-22 3.0 3.0 -10.0 — Ankur Sinha (Ankur Sinha Gmail)
| * 4597114 - (5 days ago) 2016-08-22 3.0 3.0 -5.0 — Ankur Sinha (Ankur Sinha Gmail)
| * a111e00 - (5 days ago) 2016-08-22 3.0 2.5 -30.0 — Ankur Sinha (Ankur Sinha Gmail)
| * 5261f4b - (5 days ago) 2016-08-22 3.0 2.5 -25.0 — Ankur Sinha (Ankur Sinha Gmail)
| * d10a686 - (5 days ago) 2016-08-22 3.0 2.5 -20.0 — Ankur Sinha (Ankur Sinha Gmail)
| * 91bc10e - (5 days ago) 2016-08-22 3.0 2.5 -15.0 — Ankur Sinha (Ankur Sinha Gmail)
| * add5188 - (5 days ago) 2016-08-22 3.0 2.5 -10.0 — Ankur Sinha (Ankur Sinha Gmail)
| * c93c817 - (5 days ago) 2016-08-22 3.0 2.5 -5.0 — Ankur Sinha (Ankur Sinha Gmail)
| * 8e779b9 - (5 days ago) 2016-08-22 3.0 2.0 -30.0 — Ankur Sinha (Ankur Sinha Gmail)
| * 9f67e1c - (5 days ago) 2016-08-22 3.0 2.0 -25.0 — Ankur Sinha (Ankur Sinha Gmail)
.....</span>
</pre>
<p>Now, with the help of some bash hacking I get a list of all the commits I need to queue up in a single line:</p>
<pre class="code bash literal-block"><span class="c1"># list all commits reachable from grid_search.. branch but not from the base_branch
</span>$ git log base_branch..grid_search-2016-08-22  --oneline <span class="p">|</span> cut -f1 -d<span class="s2">" "</span> <span class="p">|</span> tr <span class="s2">"\n"</span> <span class="s2">" "</span>
fd6a7fa 33c95be 51f96c1 .. e8c106e eaa7341
</pre>
<p>Then, I use the bash <code>for</code> construct to queue them all up as before:</p>
<pre class="code bash literal-block">$ <span class="k">for</span> commit in fd6a7fa 33c95be 51f96c1 .. e8c106e eaa7341<span class="p">;</span> <span class="k">do</span> ./start-job.sh <span class="s2">"</span><span class="nv">$commit</span><span class="s2">"</span> 32<span class="p">;</span> sleep 1m<span class="p">;</span> <span class="k">done</span>
</pre>
<p>Note - I used the <code>sleep</code> command to space out each job by a minute. This is because my workflow uses folder names which are timestamps of when the job was queued up, like this: <code>201608121234</code> (YYYYMMDDHHMM). So, I can't have two commits starting at the same minute.</p>
<p>There are many ways of carrying out the same method. This is what I quickly came up with. <a class="reference external" href="http://scikit-learn.org">Scikit</a>, for example has <a class="reference external" href="http://scikit-learn.org/stable/modules/grid_search.html">methods for grid search</a>, but they don't gel well with my simulations.</p>
</div>
<div class="section" id="postprocessing-all-this-data">
<h2>Postprocessing all this data</h2>
<p>I have a bunch of scripts for post processing too - this grid search had 36 simulations, the postprocessing is still trudging along. The bigger question is: is there a good way of visualising all these results? I've had to resort to a spreadsheet - but if you have any suggestions, please do let me know. I really haven't found a nice front-end that would let me log results to a database and visualise them - over time, over parameters and so on - does anyone know one? What do people use to keep track of all their data?</p>
<p>Anyway, it's a long weekend here with Monday being a bank holiday. Enjoy the weekend, everyone!</p>
</div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://ankursinha.in/blog/2016/08/05/using-neuron-part-i.html">Using NEURON - Part I</a></h2></div>
            <p class="text-muted">by <a href="http://ankursinha.in/blog/">Ankur Sinha</a> on August 05, 2016 12:24 PM.</p>
          </div>
          <div class="panel-body">

            <div class="section" id="what-is-neuron">
<h2>What is NEURON</h2>
<p>From the <a class="reference external" href="http://www.neuron.yale.edu/neuron/what_is_neuron">website</a>:</p>
<p><em>NEURON is a simulation environment for modeling individual neurons and networks of neurons. It provides tools for conveniently building, managing, and using models in a way that is numerically sound and computationally efficient. It is particularly well-suited to problems that are closely linked to experimental data, especially those that involve cells with complex anatomical and biophysical properties.</em></p>
</div>
<div class="section" id="installing-neuron-on-fedora-24">
<h2>Installing NEURON on Fedora 24</h2>
<p>The first thing you do is install the simulator. I've been trying to build <a class="reference external" href="https://copr.fedorainfracloud.org/coprs/ankursinha/neuroscience-research/">copr</a> packages but they're not as simple as I'd have liked - the configurations that upstream uses for iv and neuron are outdated and require quite a bit of patching.</p>
<div class="section" id="download-the-sources">
<h3>Download the sources</h3>
<p>First, download the source files:</p>
<pre class="code bash literal-block"><span class="c1"># Make sure we're in the /home/&lt;user&gt; directory
</span><span class="nb">cd</span>
<span class="c1"># Make a new directory - use what you want but be consistent
</span>mkdir -p dump/neuron

<span class="c1"># Another one for the installed files
# You can use /opt or /usr/local or any other directory
# Using a directory in your home folder doesn't require root access
</span>mkdir -p dump/neuron-installation

<span class="c1"># Keep the sources here
</span><span class="nb">cd</span> ~/dump/neuron

<span class="c1"># Install mercurial to checkout the neuron source code
</span>sudo dnf install hg
<span class="c1"># Download the source code
# Can't build from the latest tar somehow.
# http://www.neuron.yale.edu/neuron/download/getdevel
</span>hg clone http://www.neuron.yale.edu/hg/neuron/nrn

<span class="c1"># Check http://www.neuron.yale.edu/neuron/download/getstd for correct links
</span>wget http://www.neuron.yale.edu/ftp/neuron/versions/v7.4/iv-19.tar.gz

<span class="c1"># Untar the source for iv - this seems to work
</span>tar -xvf iv-19.tar.gz
</pre>
</div>
<div class="section" id="prep">
<h3>Prep</h3>
<p>We need to build iv first. On Fedora 24, the default gcc flags include <code>-Wformat-security</code> so a quick patch needs to be applied to iv to get it to build. The patch <a class="reference external" href="https://www.neuron.yale.edu/phpBB/viewtopic.php?f=20&amp;t=3536">has been reported here</a>:</p>
<pre class="code diff literal-block"><span class="gh">diff -ur ../iv-18.orig/src/lib/IV-2_6/matcheditor.cpp ./src/lib/IV-2_6/matcheditor.cpp
</span><span class="gd">--- ../iv-18.orig/src/lib/IV-2_6/matcheditor.cpp   2014-01-08 19:10:44.895487120 +1100
</span><span class="gi">+++ ./src/lib/IV-2_6/matcheditor.cpp   2014-01-08 19:11:05.949315579 +1100
</span><span class="gu">@@ -82,7 +82,7 @@
</span>         strncpy(buf, text-&gt;Text(), length);
         while (length &gt; 0) {
             buf[length] = '\0';
<span class="gd">-            if (sscanf(buf, pattern) == EOF) {
</span><span class="gi">+            if (sscanf(buf, "%s", pattern) == EOF) {
</span>                 break;
             }
             --length;
</pre>
<p>Copy the diff into a file and call it <code>iv-format-security.patch</code>. Place this in the directory where you have the neuron sources (<code>~/dump/neuron</code>).
To apply the patch, enter the uncompressed iv directory:</p>
<pre class="code bash literal-block"><span class="nb">cd</span> iv
patch -p1 &lt; ../iv-format-security.patch
<span class="c1"># On success, it'll say:
# patching file src/lib/IV-2_6/matcheditor.cpp</span>
</pre>
<p>Before we build either iv or neuron, we need to install the build dependencies:</p>
<pre class="code bash literal-block"><span class="c1"># Install dependencies from the standard repositories
</span>sudo dnf install xorg-x11-server-devel chrpath libtiff-devel imake libX11-devel automake autoconf libtool libXext-devel ncurses-devel readline-devel Random123-devel Cython openmpi-devel
</pre>
<p>I've left out Java - I have no intention of using the Java support. Instead of openmpi, you can also use mpich - that's up to you - replace <code>openmpi-devel</code> with <code>mpich-devel</code>.</p>
</div>
<div class="section" id="build">
<h3>Build</h3>
<p>Follow the instructions <a class="reference external" href="http://www.neuron.yale.edu/neuron/download/compile_linux">here</a>.
First we build iv:</p>
<pre class="code bash literal-block"><span class="c1"># we're already in the iv source directory
# ./configure --help for all available options
# I use the default Fedora CFLAGS and CXXFLAGS
# You needn't use these
# rpm -E %optflags will tell you what the default ones on your system are
# echo $CFLAGS
# -O2 -g -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -m64 -mtune=generic
# echo $CXXFLAGS
# -O2 -g -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -m64 -mtune=generic
</span>
<span class="c1"># iv doesn't build with -Wnarrowing which is also default, so we disable it
</span><span class="nb">export</span> <span class="nv">CFLAGS</span><span class="o">=</span><span class="s2">"</span><span class="nv">$CFLAGS</span><span class="s2"> -Wno-narrowing"</span>
<span class="nb">export</span> <span class="nv">CXXFLAGS</span><span class="o">=</span><span class="s2">"</span><span class="nv">$CXXFLAGS</span><span class="s2"> -Wno-narrowing"</span>

<span class="c1"># configure, make, make install
</span>./configure --prefix<span class="o">=</span>/home/asinha/dump/neuron-installation/ --with-x
<span class="c1"># I have 24 processors, check to see how many you do
</span>make -j24
make install
</pre>
<p>Then, we build neuron</p>
<pre class="code bash literal-block"><span class="nb">cd</span> ../nrn
<span class="c1"># configure --help to see all options
# Enable MPI
</span>module load mpi/openmpi-x86_64
<span class="c1"># More change to flags to get the thing to build
</span><span class="nb">export</span> <span class="nv">CFLAGS</span><span class="o">=</span><span class="s2">"</span><span class="nv">$CFLAGS</span><span class="s2"> -Wno-narrowing -std=c99 -D_POSIX_C_SOURCE=200809L"</span>
<span class="nb">export</span> <span class="nv">CXXFLAGS</span><span class="o">=</span><span class="s2">"</span><span class="nv">$CXXFLAGS</span><span class="s2"> -Wno-narrowing -D_POSIX_C_SOURCE=200809L"</span>
./build.sh
./configure --prefix<span class="o">=</span>/home/asinha/dump/neuron-installation/ --with-x --with-paranrn --with-mpi --with-multisend --with-nrniv --with-iv<span class="o">=</span>/home/asinha/dump/neuron-installation
<span class="c1"># I have 24 processors, check to see how many you do
</span>make -j24
make install
</pre>
</div>
<div class="section" id="check">
<h3>Check</h3>
<p>Follow the instructions <a class="reference external" href="http://www.neuron.yale.edu/neuron/download/compile_linux">here</a>.</p>
<pre class="code bash literal-block"><span class="nb">cd</span>
<span class="nb">cd</span> dump/neuron-installation/
find . -name <span class="s2">"neurondemo"</span>
<span class="c1"># You'll get something like: ./x86_64/bin/neurondemo
</span>./86_64/bin/neurondemo
<span class="c1"># Will give out something like:
# NEURON -- VERSION 7.5 (1454:2350fc838a79) 2016-08-01
# Duke, Yale, and the BlueBrain Project -- Copyright 1984-2016
# See http://neuron.yale.edu/neuron/credits
#
# loading membrane mechanisms from /home/asinha/dump/neuron-installation/share/nrn/demo/release/x86_64/.libs/libnrnmech.so
# Additional mechanisms from files
#  cabpump.mod cachan1.mod camchan.mod capump.mod invlfire.mod khhchan.mod mcna.mod nacaex.mod nachan.mod release.mod
# first instance of j
# first instance of itmp
# first instance of using_cvode_
# first instance of movie_frame_dur_
# first instance of realtime
# first instance of running_
# first instance of rtstart
# first instance of stdrun_quiet
# first instance of screen_update_invl
# first instance of tstop
# first instance of steps_per_ms
# first instance of nstep_steprun
# first instance of runStopAt
# first instance of runStopIn
# first instance of global_ra
# first instance of mapped_nrnmainmenu_
# first instance of v_init
# first instance of n_graph_lists
# first instance of i
# first instance of eventslow
# first instance of eventcount
# first instance of cnt
# oc&gt;
#</span>
</pre>
</div>
<div class="section" id="post">
<h3>Post</h3>
<p>Last, we update the PATH and things so that everything works smoothly in the future. The docs suggest an <code>nrnenv</code> file that can be sourced in the <code>.bashrc</code> file. We'll just follow the suggested method.</p>
<pre class="code bash literal-block">cat &gt;&gt; ~/dump/neuron-installation/x86_64/bin/nrnenv <span class="s">&lt;&lt; EOF
export NRNINSTALLATION="\$HOME/dump/neuron-installation"
export NRNCPU="x86_64"
export PATH="\$PATH:\$NRNINSTALLATION/\$NRNCPU/bin"

EOF</span>
</pre>
<p>and modify <code>.bashrc</code> to source it:</p>
<pre class="code bash literal-block"><span class="nb">echo</span> <span class="s2">"source /home/asinha/dump/neuron-installation/x86_64/bin/nrnenv"</span> &gt;&gt; ~/.bashrc
</pre>
<p>Log out and back in, or source the file again: <code>source ~/.bashrc</code>.  All the binaries for neuron should then be available to you:</p>
<pre class="code bash literal-block">$ ls ~/dump/neuron-installation/x86_64/bin/
bbswork.sh   iclass  idraw  memacs        modlunit  mos2nrn2.sh  nocmodl  nrngui  nrniv_makefile  nrnmech_makefile  nrnoc_makefile  nrnpyenv.sh  set_nrnpyenv.sh
hel2mos1.sh  idemo   ivoc   mkthreadsafe  mos2nrn   neurondemo   nrnenv   nrniv   nrnivmodl       nrnoc             nrnocmodl       oc           sortspike

$ which idraw
~/dump/neuron-installation/x86_64/bin/idraw
$ which nrniv
~/dump/neuron-installation/x86_64/bin/nrniv
$ which nrnoc
~/dump/neuron-installation/x86_64/bin/nrnoc
$ which oc
~/dump/neuron-installation/x86_64/bin/oc
</pre>
<p>I think that should be it! I've tested the instructions on my Fedora 24 machine but if you run into issues, drop a comment and I'll look into it.</p>
</div>
</div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://ankursinha.in/blog/2016/08/04/tinkering-with-openlayers-and-js-cajal-a-hacked-up-neuroscience-research-map.html">Tinkering with OpenLayers and JS - Cajal - a hacked up neuroscience research map</a></h2></div>
            <p class="text-muted">by <a href="http://ankursinha.in/blog/">Ankur Sinha</a> on August 04, 2016 05:49 PM.</p>
          </div>
          <div class="panel-body">

            <p>I was a bit fed up with the various minute issues my simulations kept throwing at me and decided I needed a distraction to keep me from completely burning out. Research is hard work, and sometimes we hit solid walls where no progress seems possible. I haven't hit one yet, but I was beginning to see that my performance had begun to drop. The simplest answer to this situation is to take a holiday - a change of scenery. Unfortunately, I haven't any plans to take one at the moment. I've never understood the appeal of wandering around crowded cities with throngs of tourists anyway. Instead, I decided to set my simulations aside for a few days and tinker with other things for a bit.</p>
<p>I decided to take up a short "passion project". It needed to be something that would keep me occupied for a few days at the most. I'd tinkered with <a class="reference external" href="http://openlayers.org/">OpenLayers</a> before and I'd been meaning to brush up on my <a class="reference external" href="https://www.javascript.com/">JavaScript</a> recently seeing as how it's become quite a dominant scripting language. So I thought up a simple web application that would use the two to do something useful.</p>
<div class="section" id="cajal">
<h2>Cajal</h2>
<p>To start with, the app needs to have a name. I've come up with some unique ones before (<a class="reference external" href="http://ankursinha.in/blog/tag/zaphod/">Zaphod</a>, <a class="reference external" href="http://ankursinha.in/blog/tag/calliope/">Calliope</a>). This time I decided to pay homage to <a class="reference external" href="https://en.wikipedia.org/wiki/Santiago_Ram%C3%B3n_y_Cajal">Santiago Ramón y Cajal</a> who is considered the father of modern neuroscience. There are multiple applications called Cajal already, but not too many of them seem to be related to neuroscience. Unique enough, then.</p>
<p>Cajal is a simple web page that shows a world map. On this map are markers that denote different neuroscience laboratories. The markers are clickable, so when you click one of these, some information about the laboratory is displayed below the map - the principal investigator, the website address, and the sort. I've only managed to add a few laboratories to it now, but I've hosted a working demo <a class="reference external" href="http://ankursinha.in/cajal-map/">here</a>. The screenshot below shows what it looks like.</p>
<a class="reference external image-reference" href="http://ankursinha.in/blog/images/20160804-cajal.png"><img alt="Screenshot of Cajal web application" class="align-center" src="http://ankursinha.in/blog/images/20160804-cajal.png" style="height: 400.0px;" /></a>
<p>The code is quite simple. The data is stored in a <code>yaml</code> file at <code>data/groups.yaml</code>. The Python script <code>bin/populate_map.py</code> takes this file and generates a <a class="reference external" href="https://www.javascript.com/">JavaScript</a> file with functions to set up the map, overlay the markers, and assign them all <code>singleclick</code> events that display information - <code>js/cajal.js</code>. The main <code>index.html</code> file uses this JavaScript file to show a map and the markers with their associated information.</p>
<p>Maybe there is a better, less hacky, way of going about it, but this works for a quick two day project. In the future, maybe I can use a server side database and so on - it depends on how much it needs to scale. I know my shared hosting account can't handle all that!</p>
<p>The <a class="reference external" href="https://github.com/sanjayankur31/cajal/">source code is available on Github</a>. To add more laboratories, entries need to be added to the <code>data/groups.yaml</code> file - that's all. If you're a neuroscience researcher and want to add to the map, please open pull requests and I can then periodically regenerate the page as required.</p>
</div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://biocomputation.herts.ac.uk/2016/07/19/sloping-the-interview-and-career-development-playing-fields-in-your-favour.html">Sloping the interview and career development playing fields in your favour</a></h2></div>
            <p class="text-muted">by <a href="http://biocomputation.herts.ac.uk/">UH Biocomputation group</a> on July 19, 2016 01:30 PM.</p>
          </div>
          <div class="panel-body">

            <p>Organisations have to ensure that they recruit the best candidates at every level and develop their staff in paths closely aligned with their corporate styles, missions and objectives.  This not only ensures a positive and integrated work force and organisation, it also allows protection against maverick interviewers and managers promoting or overlooking staff randomly (or worse). To achieve this, most professional organisations have clearly defined processes which guide and regulate interviewers and which formalise staff development.  Understanding these formal processes and methods will give candidates and staff a substantial advantage over those who don't.  My talk will give attendees a comprehensive view of real examples of interview questions and crucially the real assessment criteria that the interviewer is looking to document evidence of suitability against.  In respect of career development my talk will give you a comprehensive example of how career paths in a professional services organisation are defined and the success criteria for progression.  In both cases I will give you the insider's view and my own rules and  tips for success, accumulated over many years in blue chip international corporations.</p>
<p><strong>Date:</strong> 22/07/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://biocomputation.herts.ac.uk/2016/07/14/automated-morphological-classification-of-galaxies-using-machine-learning-techniques.html">Automated morphological classification of galaxies using machine learning techniques</a></h2></div>
            <p class="text-muted">by <a href="http://biocomputation.herts.ac.uk/">UH Biocomputation group</a> on July 14, 2016 10:42 AM.</p>
          </div>
          <div class="panel-body">

            <p>The predominant method to analyse the morphology of galaxies is to use human visual inspection. <a class="reference external" href="https://www.galaxyzoo.org/">The Galaxy Zoo project</a> has successfully scaled this process to incorporate crowd sourced inspection and has released detailed classifications of hundreds of thousands of galaxies. However, the next generation of telescopes are now being designed and built. An optical telescope called the <a class="reference external" href="https://www.lsst.org/">Large Synoptic Sky Telescope</a>, for example, is due to come online in 2019 and will image half the sky every few days to catalogue ~40 billion objects. This is beyond the capability of even the significant crowd sourced resources of Galaxy Zoo. Therefore, astronomers are now investigating automated solutions using machine learning. In this talk I outline the key issues that need to be resolved in order to automate galaxy morphological analysis in large surveys. I describe existing automated systems that analyse galaxies, and I describe the results of my work using unsupervised machine learning approaches to characterize galaxies.</p>
<p><strong>Date:</strong> 15/07/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://feeds.plos.org/~r/plos/Blog/~3/FiBBzSyGfIU/">Author Credit: PLOS and CRediT Update</a></h2></div>
            <p class="text-muted">by <a href="http://blogs.plos.org/plos">The Official PLOS Blog</a> on July 08, 2016 11:25 PM.</p>
          </div>
          <div class="panel-body">

            <img alt="CRediT-blog-post_690x320" class="attachment-thumbnail size-thumbnail wp-post-image" height="150" src="http://blogs.plos.org/plos/files/2016/07/CRediT-blog-post_690x320-150x150.png" style="display: block; margin-bottom: 5px; clear: both;" width="150" /><div class="wp_orcid_field"><a href="http://orcid.org/0000-0002-4565-0280" rel="author" target="_blank">0000-0002-4565-0280</a></div><p>Our January <strong><a href="http://plos.io/29p9j59" target="_blank">update on author credit</a></strong> focused on how PLOS was moving forward with the use of ORCID identifiers (iDs) for researcher identification. Starting with authors, that effort allows us to know and unambiguously credit <strong>who</strong> participated in the work being published and forms the base for plans to eventually provide credit to all participants in the research outputs ecosystem. Today’s update is about providing authors attribution for <strong>what</strong> they contributed. <strong>Specific and comprehensive attribution moves the needle for institutions’ and funders’ abilities to evaluate researchers based on the roles they play in published works, rather than on the journals in which their articles appear or their placement within the byline.</strong></p>
<h3>Collaborative Development</h3>
<p>PLOS has for many years required that authors state what contributions they made to their work, as have many other publishers. The author contributions statements published in articles provide transparency in credit and accountability for all authors. What’s new is that there is now a community-developed open-standard <strong><a href="http://plos.io/29CRcig" target="_blank">taxonomy of contributions</a></strong> intended to replace over time the many disparate lists currently in use.</p>
<p>PLOS participated along with many other publishers and stakeholders (including funders, researchers and university administrators) in the development of this taxonomy, under the auspices of CASRAI (Consortia Advancing Standards in Research Administration Information) and with the participation of NISO (National Information Standards Organization). Articles in <strong><a href="http://openscholar.mit.edu/sites/default/files/dept/files/lpub28-2_151-155.pdf" target="_blank"><em>Learned Publishing</em></a></strong> and <strong><a href="http://www.nature.com/news/publishing-credit-where-credit-is-due-1.15033" target="_blank"><em>Nature</em></a></strong> – and related documents on the <strong><a href="http://casrai.org/CRediT" target="_blank">CASRAI site</a></strong> – provide background about the work that led to this open standard.</p>
<h3>Author Benefit</h3>
<p>For a given published work, the CRediT taxonomy makes transparent who participated and the roles they played. It remains simple by design but offers more granularity than previous lists used by PLOS and other publishers. <strong>More finely-grained information will help make the ordering of authors less important and will facilitate a shift in focus for tenure and promotion committees – and other evaluators – away from how many times an individual is a first-or last-named author and toward their specific contributions to the scholarly record.</strong></p>
<p>Importantly, the CRediT taxonomy is not meant to determine who qualifies as an author. Each author on a paper may have one or more CRediT contribution roles, yet having a role described by the taxonomy does not automatically qualify someone as an author. Authorship is determined by following <strong><a href="http://plos.io/29CRJAN" target="_blank">PLOS guidelines</a></strong>, which are based on the ICMJE (International Committee of Medical Journal Editors) requirements.</p>
<p>As PLOS continues to implement its <strong><a href="http://plos.io/1rfutwn" target="_blank">new submission system</a></strong>, Aperta™, we will make author contributions machine readable, with each individual’s contributions coded into the article’s XML. This is already in place for <em>PLOS Biology</em>, the first journal to <strong><a href="http://plos.io/29s5Qna" target="_blank">launch in Aperta</a></strong>. For every article (identified by a <strong><a href="http://crossref.org/" target="_blank">Crossref DOI</a></strong>) and every author (all to be identified – eventually – by an <strong><a href="http://orcid.org/" target="_blank">ORCID iD</a></strong>), there will be one or more associated contributions (identified by <strong><a href="http://casrai.org/CRediT" target="_blank">CRediT</a></strong>). <strong>It is the confluence of these persistent identifier systems that will underlie future applications to increase transparency and allow discovery of individual contributions. </strong></p>
<h3>Future Functionality</h3>
<p>Eventually, the coding of individual contributions in article metadata will allow contributions to be surfaced in CVs and researcher profiles. In the short term, it will improve the display of contributions within PLOS articles, currently presented in paragraph form within the article—whether PDF or HTML. The mock-up images here illustrate the approach PLOS is exploring for presentation in the author tab and for roll-over display in the author byline.</p>
<p><a href="http://blogs.plos.org/plos/files/2016/07/Author-Tab_070816-1.jpg"><img alt="Author Tab_070816" class="wp-image-7018 alignnone" height="284" src="http://blogs.plos.org/plos/files/2016/07/Author-Tab_070816-1.jpg" width="353" /></a><a href="http://blogs.plos.org/plos/files/2016/07/Author-Detail_070816v2.jpg"><img alt="Author Detail_070816v2" class="wp-image-7023 alignnone" height="280" src="http://blogs.plos.org/plos/files/2016/07/Author-Detail_070816v2.jpg" width="351" /></a></p>
<h3>Process and Policy</h3>
<p>The corresponding (or submitting) author will be required to provide the relevant contributions for their co-authors, just as they do now, when submitting a manuscript (see our <strong><a href="http://plos.io/29nTVGL" target="_blank">Authorship Guidelines</a></strong>). We strongly encourage each group of researchers to think about, discuss and decide on their various contributions during the course of manuscript preparation. The task of assigning contributions to individuals should be collegial, and the corresponding author should ensure that contributions are agreed on amongst authors before submission, in the same way that the ordering of authors should be agreed on before submission. The CRediT taxonomy offers a framework for discussion to reach this agreement.</p>
<p>It’s worth repeating—before submission, decide and get agreement on:</p>
<ul>
<li>Who will be included in the author list</li>
<li>What contributions each author has made</li>
<li>In what order the authors will appear</li>
</ul>
<p>And if there are contributors whose input does not rise to the level of authorship, ensure that proper acknowledgements are included. Every person named – authors and those acknowledged – must be aware of and agree to their inclusion. When preparing your next manuscript, take some time to discuss author contributions using CRediT as a common language. Don’t have an ORCID iD yet? <strong><a href="http://www.orcid.org/register" target="_blank">Get one here</a></strong> and log in to the PLOS manuscript submission system with it—when your next article is published with PLOS we’ll automatically update your ORCID record. In the future, that update will also include your contributions.</p>
<p> </p>
<p> </p>
<p>Image Credit: Fabricio Rosa Marques</p>
<img alt="" height="1" src="http://feeds.feedburner.com/~r/plos/Blog/~4/FiBBzSyGfIU" width="1" />
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://biocomputation.herts.ac.uk/2016/07/07/detecting-road-surface-wetness-from-audio-a-deep-learning-approach.html">Detecting road surface wetness from audio: a deep learning approach</a></h2></div>
            <p class="text-muted">by <a href="http://biocomputation.herts.ac.uk/">UH Biocomputation group</a> on July 07, 2016 03:26 PM.</p>
          </div>
          <div class="panel-body">

            <p>We introduce a recurrent neural network architecture for automated road surface wetness detection from audio of tire-surface interaction. The robustness of our approach is evaluated on 785,826 bins of audio that span an extensive range of vehicle speeds, noises from the environment, road surface types, and pavement conditions including international roughness index (IRI) values from 25 in/mi to 1400 in/mi. The training and evaluation of the model are performed on different roads to minimize the impact of environmental and other external factors on the accuracy of the classification. We achieve an unweighted average recall (UAR) of 93.2% across all vehicle speeds including 0 mph. The classifier still works at 0 mph because the discriminating signal is present in the sound of other vehicles driving by.</p>
<p>The complete paper can be found here: <a class="reference external" href="http://arxiv.org/abs/1511.07035">http://arxiv.org/abs/1511.07035</a></p>
<p><strong>Date:</strong> 08/07/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://feeds.plos.org/~r/plos/Blog/~3/27P7Jghr38k/">Measuring Up: Impact Factors Do Not Reflect Article Citation Rates</a></h2></div>
            <p class="text-muted">by <a href="http://blogs.plos.org/plos">The Official PLOS Blog</a> on July 05, 2016 09:07 PM.</p>
          </div>
          <div class="panel-body">

            <img alt="interference-728421_1280" class="attachment-thumbnail size-thumbnail wp-post-image" height="150" src="http://blogs.plos.org/plos/files/2016/07/interference-728421_1280-150x150.jpg" style="display: block; margin-bottom: 5px; clear: both;" width="150" /><div class="wp_orcid_field"><a href="http://orcid.org/orcid.org/0000-0001-8771-7239" rel="author" target="_blank">orcid.org/0000-0001-8771-7239</a></div><p><strong><em>This special blog post is co-authored by PLOS Executive Editor Véronique Kiermer, Université de Montréal Associate Professor of Information Science Vincent Larivière and PLOS Advocacy Director Catriona MacCallum. It accompanies the posting on BioRxiv of a research paper on citation distributions.</em></strong></p>
<p>Journal-level metrics, the Journal Impact Factor (JIF) being chief among them, do not appropriately reflect the impact or influence of individual articles—a truism perennially repeated by bibliometricians, journal editors and research administrators alike. Yet, many researchers and research assessment panels continue to rely on this erroneous proxy of research – and researcher – quality to inform funding, hiring and promotion decisions.</p>
<p>In strong support for the shedding of this misguided habit, seven journal representatives and two independent researchers – including the three authors of this post – came together to add voice to the rising opposition to journal-level metrics as a measure of an individual’s scientific worth. The result is a collaborative article from Université de Montréal, Imperial College London, <strong><a href="http://plos.io/29yBba8" target="_blank">PLOS</a></strong>, <strong><a href="https://elifesciences.org/" target="_blank"><em>eLife</em></a></strong>, <a href="http://emboj.embopress.org/" target="_blank"><em><strong>EMBO</strong> <strong>Journal</strong></em></a><em>, </em><strong><a href="https://royalsociety.org/journals/" target="_blank">The Royal Society</a></strong>, <strong><a href="http://www.nature.com/index.html" target="_blank"><em>Nature</em></a> </strong>and <strong><a href="http://www.sciencemag.org/" target="_blank"><em>Science</em></a></strong>, <strong><a href="http://biorxiv.org/content/early/2016/07/05/062109" target="_blank">posted on BioRxiv</a></strong> this week. Using a diverse selection of our own journals, we provide data illustrating why no article can be judged on the basis of the Impact Factor of the journal in which it is published.</p>
<p>The article presents frequency plots – citation distributions – of 11 journals (including <strong><a href="http://journals.plos.org/plosbiology/" target="_blank"><em>PLOS Biology</em></a></strong>, <strong><a href="http://journals.plos.org/plosgenetics/" target="_blank"><em>PLOS Genetics</em></a></strong> and <strong><a href="http://journals.plos.org/plosone/" target="_blank"><em>PLOS ONE</em></a></strong>) that range in their Impact Factor from less than three to more than 30 (the analysis covers the same period as the 2015 Impact Factor calculation.) Despite the differences in Impact Factors, the similarities between distributions are striking: all distributions are left-skewed (a majority of articles with fewer citations than indicated by the JIF) and span several orders of magnitude. The most important observation, however, is the substantial overlap between the journal distributions. Essentially, two articles published in journals with widely divergent Impact Factors may very well have the same number of citations.</p>
<h3><strong>Share and share alike</strong></h3>
<p>By publishing this data, we hope to strengthen a <strong><a href="http://occamstypewriter.org/scurry/2015/06/23/data-not-shown-time-to-distribute-some-common-sense-about-impact-factors/" target="_blank">call for action</a></strong> originally voiced by Stephen Curry, one of the authors, and to encourage other journals to follow suit. In the spirit of this call we present below the plots for all seven PLOS journals <strong>[see Fig. 1]</strong>. Needless to say, there are no surprises. Despite widely different volumes, all distributions show a marked skew to the left (low citations) with a long tail expanding to the right (high citations)—a pattern obscured by use of the JIF.</p>
<p> </p>
<p><a href="http://blogs.plos.org/plos/files/2016/07/PLOS-distributions.jpg"><img alt="PLOS distributions" class="alignleft wp-image-6973 size-medium" height="300" src="http://blogs.plos.org/plos/files/2016/07/PLOS-distributions-293x300.jpg" width="293" /></a><strong>Fig. 1:</strong> Citation Distributions of the PLOS Journals. Citations are to ‘citable documents’ (<strong><a href="http://wokinfo.com/essays/impact-factor/" target="_blank">as classified by Thomson Reuters</a></strong>), which include standard research articles and reviews; distributions contain citations accumulated in 2015 to citable documents published in 2013 and 2014. Data was extracted using the “Purchased Database Method” detailed in the V. Larivière <em>et. al</em>. <strong><a href="http://biorxiv.org/content/early/2016/07/05/062109" target="_blank">BioRxiv article</a></strong>. To facilitate direct comparison, distributions are plotted with the same range of citations (0-100) in each plot; articles with more than 100 citations are shown as a single bar at the right of each plot. Copyright held by Thomson Reuters prohibits publication of the raw data but aggregated data behind the graphs is available on <strong><a href="https://dx.doi.org/10.6084/m9.figshare.3471521" target="_blank">Figshare</a></strong>.</p>
<p> </p>
<p>We do not deny there are differences among journals, which reflect the different article types, editorial criteria, scope and volume of each publication. These effects are notable, for instance, when considering <em>PLOS ONE</em>—where articles are selected on the basis of being technically sound and robustly reported rather than on perceived impact or general interest. Such criteria enable the publication of small studies or those with <strong><a href="http://plos.io/29wRw1X" target="_blank">negative, null or inconclusive results</a></strong>, which might not garner many citations but are crucial in mitigating against publication bias. The journal scope comprises <strong><a href="https://works.bepress.com/ted_bergstrom/79/" target="_blank">disciplines with different citation habits</a></strong> and niche areas of research as well as social sciences, where citation rates are typically lower. And since volume of publication is not artificially limited, these factors provide an explanation for the relatively higher number of articles with few or zero citations (a similar explanation can account for the distribution of citations in <em>Scientific Reports</em>). This does not mean that <em>PLOS ONE</em> (or <em>Scientific Reports</em>) does not publish many highly-cited articles. To the contrary, a 2013 study indicated that <strong><a href="https://arxiv.org/abs/1304.6460" target="_blank"><em>PLOS ONE</em> publishes its fair share of the top cited papers in the literature</a></strong> (relative to the number of papers it publishes). In the 2015 distributions, the volume of papers making up the high-citation tail of the <em>PLOS ONE</em> distribution is again substantial.</p>
<h3><strong>The sway of influence</strong></h3>
<p><strong>What motivates our initiative to raise awareness is that despite calls to the contrary, the JIF remains a prevalent tool in evaluating scientists. Often it comes down to convenience, lack of time and appropriate alternatives, but it is also a question of culture. The misuse of the Impact Factor has become institutionalized in the research assessment methods of many universities and national evaluation panels, leading to a perverse incentive system.</strong></p>
<p>For researchers, the career advancement and reputational reward of ‘aiming high’ when choosing a journal is too great to ignore, even when the consequences are to work one’s way down the Impact Factor ladder one step at a time, rejection after rejection. This sequential submission pattern not only puts an enormous burden on journal editors and reviewers, it also causes unnecessary and unacceptable delays in making results available to the wider scientific community and the public. Worse are the stories of researchers who feel compelled to alter their experimental or analytical approach to make the manuscript more attractive to one journal or another. The profound consequences are manifest in other ways—a strong disincentive to pursue risky and lengthy research programs, to publish negative results or to pursue multidisciplinary research. They also provide a potent motive to flood fields that are already over-crowded and entrench <strong><a href="http://www.pnas.org/content/111/16/5773" target="_blank">a hypercompetitive system</a></strong> that increasingly disadvantages graduate students and early career researchers.</p>
<h3><strong>Action in process</strong></h3>
<p>There is no escaping the fact that a paper can only be properly evaluated by reading it. However, there are tools to help filter the scientific literature for reach and impact that an article might have, and not just within the scholarly research community. Several platforms offer article-level metrics, including <strong><a href="http://plos.io/29nTSyD" target="_blank">PLOS’ own ALM service</a></strong>, which provides citations and other indicators of readership and social attention. The open source software <a href="http://www.lagotto.io/" target="_blank">Lagotto</a> powering PLOS ALMs underpins <strong><a href="http://eventdata.crossref.org/" target="_blank">Crossref’s Event Tracker</a></strong> to capture a range of usage activity linked to any digital object identifier, including datasets.</p>
<p>No single metric, however, can accurately reflect the diverse impact of different research outputs (as clearly laid out in the <strong><a href="http://www.hefce.ac.uk/pubs/rereports/Year/2015/metrictide/Title,104463,en.html" target="_blank">Metric Tide report</a></strong> and the <strong><a href="http://www.nature.com/news/bibliometrics-the-leiden-manifesto-for-research-metrics-1.17351" target="_blank">Leiden Manifesto for research metrics</a></strong>). Ultimately, the scientific community needs a better means of capturing and communicating the assessment of validity, reliability, significance and quality that takes place over time, when experts engage deeply with and build upon the results of their peers.</p>
<p>We also need more granular and robust ways of describing and assigning credit to the myriad different contributions of individual researchers to articles, data, software, research projects, peer review and mentoring students. Towards this aim, <strong><a href="https://orcid.org/content/requiring-orcid-publication-workflows-open-letter" target="_blank">PLOS and other publishers</a></strong> are starting to require that <strong><a href="http://plos.io/29hITT9" target="_blank">authors register for an ORCID ID</a></strong>, and are introducing the <strong><a href="http://casrai.org/credit" target="_blank">CRediT taxonomy</a></strong> to recognize the individual contributions of authors to an article. In the EU, Science Europe has just issued a report on <strong><a href="http://www.scienceeurope.org/uploads/PublicDocumentsAndSpeeches/SCsPublicDocs/SE_LEGS_Careerpaths_Workshop_Report.PDF" target="_blank">how to evaluate multidisciplinary research</a></strong> that includes a recommendation for funders to evaluate applicants on a range of outputs, rather than just on publication record.</p>
<p><strong>These are all welcome steps but ultimately, the culture will only change when the institutions responsible for overseeing the assessment of researchers and those who constitute the evaluation panels take active steps to change how they assess scientists</strong><em>.</em></p>
<p>Meanwhile, the message from journal editors and publishers that show their citation distributions is clear: we select and publish diverse articles that attract a wide range of citations, and no article can be adequately judged by the single value of the Impact Factor of the journal in which it is published.</p>
<p> </p>
<p>Image Credit: Gerd Altman, Pixabay.com</p>
<p> </p>
<img alt="" height="1" src="http://feeds.feedburner.com/~r/plos/Blog/~4/27P7Jghr38k" width="1" />
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://biocomputation.herts.ac.uk/2016/06/22/research-team-from-unesp-brazil-reports-its-works-on-genomics-from-basic-science-to-biotechnology.html">Research team from UNESP-Brazil reports its works on Genomics: from basic science to biotechnology</a></h2></div>
            <p class="text-muted">by <a href="http://biocomputation.herts.ac.uk/">UH Biocomputation group</a> on June 22, 2016 09:37 AM.</p>
          </div>
          <div class="panel-body">

            <p><a class="reference external" href="https://scholar.google.co.in/citations?user=zJtKwFsAAAAJ&amp;hl=en&amp;oi=sra">Gui Valente</a> joins us for a special journal club session.</p>
<hr class="docutils" />
<p>This lecture is made possible through an international partnership between <a class="reference external" href="http://researchprofiles.herts.ac.uk/portal/en/persons/bruce-fitt(1cc9437f-0d99-46b2-9266-caac2a320501).html">Prof. Fitt</a> and <a class="reference external" href="http://researchprofiles.herts.ac.uk/portal/en/persons/henrik-stotz(ba09c915-8b5e-47a4-a658-e079174637d4)">Dr. Stotz</a> (University of Hertfordshire) with Dr. Valente (São Paulo State University, UNESP-Brazil) with funding from the Santander Bank. The aim of this meeting it to report what Valente's team has been doing in science to establish future international cooperation between both universities as a result of Santander funding.</p>
<p>Dr. Valente leads the Systems Biology and Genomics Lab. at the São Paulo State University, Brazil (UNESP). Despite being a quite new group (2015), they have worked on several biological topics, including biofuel, health science, plant research and basic sciences (genome organization and evolution). They focus on using bioinformatics as an important "toolbox" for better understanding biological questions. This, the presentation will therefore introduce Valente's research group, showing projects they are working on right now. He will show results on ncRNAs, HIV+HCV/HBV evolution, B chromosome science, genomic entropies, enzyme discoveries in plants and <em>S. cerevisiae</em> ethanol tolerance.</p>
<p><strong>Date:</strong> 24/06/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://mcraveiro.blogspot.com/2016/06/nerd-food-interesting.html">Nerd Food: Interesting...</a></h2></div>
            <p class="text-muted">by <a href="http://mcraveiro.blogspot.com/">Marco Craveiro</a> on June 17, 2016 09:58 AM.</p>
          </div>
          <div class="panel-body">

            Nerd Food: Interesting…<div id="content"><p>Time to flush all those tabs again. Some interesting stuff I bumped into recently-ish. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">Finance, Economics, Politics</h2><div class="outline-text-2" id="text-1"><ul class="org-ul"><li><a href="http://www.strongtowns.org/journal/2016/3/20/dbuidkmm60m63enun84oqs07mktdwq">Understanding Growth, part 1</a>: looks very promising although I've only started parsing it. Also pointed me to - Tomas Sedlacek and the <a href="http://www.amazon.co.uk/Economics-Good-Evil-Economic-Gilgamesh/dp/019932218X">Economics of Good and Evil</a>. Bought the book, but still reading it. Seems very thoughtful. </li><li><a href="http://www.bloomberg.com/features/2016-ev-oil-crisis/">Here’s How Electric Cars Will Cause the Next Oil Crisis</a>: Extremely interesting take on the relationship between electric cars and the oil price. Its along the lines of articles posted in the past, to be fair, but still. Basically, it won't take a huge number of sales of electric cars to start knocking down the oil price. And with Model 3 <a href="http://www.bloomberg.com/news/features/2016-03-22/how-tesla-model-3-can-complete-its-take-over-of-the-u-s-luxury-market">coming out</a>, this all seems quite ominous to the oil producing countries. Here we go again, Angola. </li><li><a href="http://www.zdnet.com/article/red-hat-becomes-first-2b-open-source-company/">Red Hat becomes first $2b open-source company</a>: I may not use their wares any more but RedHat will always be one of my favourite companies. Really happy to see they are growing nicely and hopefully continuing all of their incredible investment on Linux. </li><li><a href="https://stratechery.com/2016/the-amazon-tax/">The Amazon Tax</a>: Really, <b>really</b> good article about Amazon and their strategy. If you read only one, read this. Amazon is amazing - and its dominance is very worrying because they are so good at executing! See also Bezos letter. </li><li><a href="https://stratechery.com/2016/its-a-tesla/">It’s a Tesla</a>: Great article about Tesla. Some of the usual Fanboyism we all know and love, of course, but still a lot of very good points. The core of the article is a interesting comparison between Tesla and Apple. By the by, not at all convinced about that dashboard and the launch ceremony itself was a bit sparse too! But, Model 3 looks great. I'm officially a Stratechery fanboy now. </li><li><a href="http://www.wired.com/2016/04/googles-alphabet-transition-tougher-b-c/">Google’s Alphabet Transition Has Been Tougher Than A-B-C</a>: Great article on the pains of moving to a single monolithic structure to something more distributed. In truth, what would one expect with such a seismic change? And, also, how come it took Google so long to make this shift? After all, programmers are supposedly taught how important separation of concerns is. The other very interesting point is the CED difficulties. These guys were able founders (at least able enough to get bought out by Google) but seem to fail badly at the CEO'ing malarky. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">Startups et al.</h2><div class="outline-text-2" id="text-2"><ul class="org-ul"><li><a href="https://stratechery.com/2015/venture-capital-and-the-internets-impact/">Venture capital and the internet’s impact</a>: From the same guys as the Amazon post, this is also a very interesting take on VCs and the internet. Highly recommended. </li><li><a href="http://news.efinancialcareers.com/uk-en/240115/believe-not-want-quit-banking-job-tech-unicorn/">Believe me, you do not want to quit your banking job for a tech unicorn</a>: Stories from the trenches on how Unicorns are not always rosy. Of course, given it comes from "eFinacialCareers", one must assume they are talking their book. Cautionary tale, nonetheless. </li><li><a href="http://obscurehandhelds.com/2016/02/sir-clive-sinclair-revives-the-zx-spectrum/">Sir Clive Sinclair Revives the ZX Spectrum</a>: so the Spectrum is back! I know I shouldn't - there isn't a single logical reason to back it up - but I just feel like I need to get me one of these… </li></ul></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">General Coding</h2><div class="outline-text-2" id="text-3"><ul class="org-ul"><li><a href="http://www.theregister.co.uk/2016/03/24/water_utility_hacked/">Water treatment plant hacked, chemical mix changed for tap supplies</a>: this is a tad worrying. Can you imagine the amount of systems out there with vulnerabilities, etc - many of which are connected to the internet. </li><li><a href="http://www.metzdowd.com/pipermail/cryptography/2016-March/028824.html">On the Impending Crypto Monoculture</a>: Talking about security, very worrying news from the crypto front. It seems our foundations are much less solid than expected - and after all the OpenSSL bugs, this is a surprising statement indeed. Very interesting email on the subject. The LWN article is a must read too. </li><li><a href="http://lumiverse.io/video/part-1-data-and-architecture">Neural Networks Demystified - Part 1: Data and Architecture</a>: just started browsing this in my spare time, but it looks very promising. For the layperson. </li><li><a href="http://www.telegraph.co.uk/technology/2016/03/24/microsofts-teen-girl-ai-turns-into-a-hitler-loving-sex-robot-wit/">Microsoft deletes 'teen girl' AI after it became a Hitler-loving sex robot within 24 hours</a>: friggin' hilarious in a <i>funny-not-funny</i>sort of way. This tweet said it best: "Tay" went from "humans are super cool" to full nazi in &lt;24 hrs and I'm not at all concerned about the future of AI. – Gerry </li><li><a href="http://www.beepsend.com/2016/04/05/abandoning-gitflow-github-favour-gerrit/">Abandoning Gitflow and GitHub in favour of Gerrit</a>: I've always wanted to know more about Gerrit but never seem to find the time. The article explains it to my required extent, contrasting it with the model I'm more familiar with - GitHub, forks and pull requests. I must say, still not convinced about Gerrit, but having said that, it seems there is definitely scope for some kind of hybrid between the two. A lot of the issues they mention in the article are definitely pain points for GitHub users. </li><li><a href="http://githubengineering.com/introducing-dgit/">Introducing DGit</a>: OK this one is a puzzling post, from our friends at GitHub engineering. I'm not sure I get it at all, but seems amazing. Basically, they talk about all the hard work they've made to make git distributed. Fine, I'm jesting - but not totally. The part that leaves no doubts is that GitHub as a whole is a lot more reliable after this work and can handle a lot more traffic - <b>without</b>increasing its hardware requirements. Amazing stuff. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-4"><h2 id="sec-4">Databases</h2><div class="outline-text-2" id="text-4"><ul class="org-ul"><li><a href="https://www.citusdata.com/blog/17-ozgun-erdogan/403-citus-unforks-postgresql-goes-open-source">Citus Unforks From PostgreSQL, Goes Open Source</a>: Great news everyone! Sharding in Postgres just became easier with the open sourcing of Citus! Also worth watching / reading: <a href="https://www.citusdata.com/blog/15-marco-slot/402-interactive-analytics-github-data-using-postgresql-citus">Interactive Analytics on GitHub Data using PostgreSQL with Citus</a>. This explains in a very understandable way how you will use Citus to shard. </li><li><a href="http://blog.2ndquadrant.com/parallel-aggregate/">Parallel Aggregate – Getting the most out of your CPUs</a>: The elephant just keeps getting better and better. Improved scaling on multi-CPU for a few scenarios is coming on 9.6. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-5"><h2 id="sec-5">C++</h2><div class="outline-text-2" id="text-5"><ul class="org-ul"><li><a href="https://randomascii.wordpress.com/2016/03/24/compiler-bugs-found-when-porting-chromium-to-vc-2015/">Compiler Bugs Found When Porting Chromium to VC++ 2015</a>: great tales form the frontline. Also good to hear that MS is really responsive to bug reports. Can't wait to be able to build my C++ 14 code on Windows… </li><li><a href="https://github.com/haptork/easylambda">EasyLambda</a>: C++ 14 library for data processing. Based on MPI though. Still, seems like an interesting find. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-6"><h2 id="sec-6">Layperson Science</h2><div class="outline-text-2" id="text-6"><ul class="org-ul"><li><a href="http://www.fastcompany.com/3042443/mendeley-elsevier-and-the-future-of-scholarly-publishing">The Open Publishing Revolution, Now Behind A Billion-Dollar Paywall</a>: this is very sad news. How science has regressed yet again, now that Mendeley has been bought out. This saga gets worse and worse. On the slightly more positive side: <a href="http://techcrunch.com/2014/03/03/from-crowdfunding-to-open-access-startups-are-experimenting-with-academic-research/">From Crowdfunding To Open Access, Startups Are Experimenting With Academic Research</a>. But will they succeed? </li><li><a href="https://www.edge.org/conversation/stephen_wolfram-ai-the-future-of-civilization">AI &amp; The Future Of Civilization</a>: Very interesting chat with Wolfram. Absurdly long but worth a read. </li><li><a href="https://www.quora.com/What-is-the-best-way-to-explain-the-concept-of-manifold-to-a-novice">What is the best way to explain the concept of manifold to a novice?</a>: Bumped into this in Quora. If only we had more of these. We need an entire book of "mathematics for lay people". </li><li><a href="http://kernelmag.dailydot.com/issue-sections/staff-editorials/16335/neuroskeptic-neurohype-brain-training-apps/?utm_content=buffer874e9&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer">Why we’re living in an era of neuroscience hype</a>: One that everyone interested on the field should read. Interesting take on the wave of progress on the neuroscience front. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-7"><h2 id="sec-7">Other</h2><div class="outline-text-2" id="text-7"><ul class="org-ul"><li><a href="https://medium.com/@thatdavidhopkins/how-a-tv-sitcom-triggered-the-downfall-of-western-civilization-336e8ccf7dd0#.gjnifjo0k">How a TV Sitcom Triggered the Downfall of Western Civilization</a>: OK, I got to say that with a click bait title as bad as this, I almost immediately ignored this article. Somehow I went back to it. Its very long and a bit crazy but its actually very interesting. Friends (the sitcom) as the signal of the end. </li></ul></div></div></div><div class="status" id="postamble"><p class="date">Created: 2016-06-17 Fri 10:56</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://mcraveiro.blogspot.com/2016/06/nerd-food-strange-case-of-undefined.html">Nerd Food: The Strange Case of the Undefined References</a></h2></div>
            <p class="text-muted">by <a href="http://mcraveiro.blogspot.com/">Marco Craveiro</a> on June 17, 2016 09:49 AM.</p>
          </div>
          <div class="panel-body">

            Nerd Food: The Strange Case of the Undefined References<div id="content"><p>As a kid, I loved reading Sherlock Holmes and Poirot novels. Each book got me completely spellbound, totally immersed and pretty much unable to do anything else until I finally found out <i>whodunnit</i>. Somehow, the culprits were never the characters I suspected of. Debugging and troubleshooting difficult software engineering problems is a lot like the plot of a crime novel: in both cases you are trying to form a mental picture of something that happened, with very incomplete information - the <i>clues</i>; in both cases, experience and attention to detail is crucial, with many a wrong path taken before the final eureka moment; and, in both cases too, there is this overwhelming sense of urgency in figuring out <i>whodunnit</i>. Of course, unlike a crime novel, we'd all prefer not having to deal with these kinds of "interesting" issues, but you don't choose the problems - they choose you. </p> <p>I recently had to deal with one such problem, which annoyed me to no end until I finally fixed it. It was so annoying I decided it was worth blogging about - if nothing else, it may save other people from the same level of pain and misery. </p> <p>A bit of context for those that are new here. <a href="https://github.com/DomainDrivenConsulting/dogen">Dogen</a> is a pet project that I've been maintaining for a few years now. Like many other C++ projects, it relies on the foundational <a href="http://www.boost.org/">Boost libraries</a>. To be fair, we rely on other stuff as well - libraries such as <a href="http://xmlsoft.org/">LibXML2</a> and so on - but Boost is our core C++ dependency and the only one where latest is greatest, so it tends to cause us the most problems. I've covered my past woes in terms of <a href="https://mcraveiro.blogspot.co.uk/2015/12/nerd-food-dogen-package-management-saga.html">dependency management</a> and how happy I was to find <a href="https://www.conan.io/">Conan</a>. And so it was that life was bliss for a number of builds, until one day… </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">It All Started With a Warning</h2><div class="outline-text-2" id="text-1"><p>It was a rainy day and I must have been bored because I noticed a rather innocuous-looking warning on my Travis build, related to Conan: </p> <pre class="example"><br />CMake Warning (dev) in build/output/conanbuildinfo.cmake:<br />  Syntax Warning in cmake code at<br />    /home/travis/build/DomainDrivenConsulting/dogen/build/output/conanbuildinfo.cmake:142:88<br />  Argument not separated from preceding token by whitespace.<br />Call Stack (most recent call first):<br />  CMakeLists.txt:30 (include)<br />This warning is for project developers.  Use -Wno-dev to suppress it.<br /></pre> <p>Little did I know that this simple discovery would lead to a sequence of troublesome events and to many a broken build. I decided to <a href="https://github.com/conan-io/conan/issues/138">report</a>the problem to the Conan developers who, with their usual promptness, rolled up their sleeves, quickly bounced ideas back and forth and then did a sterling job in spinning fixes until we got to the bottom of the issue. Some of the fixes were to Conan itself, whereas some others were related to rebuilding <a href="https://www.conan.io/source/Boost/1.60.0/lasote/testing">Boost</a>. In the heat of the investigation, I bumped into some very troubling - and apparently unrelated - linking errors: </p> <pre class="example"><br />/home/travis/.conan/data/Boost/1.60.0/lasote/stable/package/ebdc9c0c0164b54c29125127c75297f6607946c5/lib/libboost_log.so: undefined reference to `std::invalid_argument::invalid_argument(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;)@GLIBCXX_3.4.21'<br />/home/travis/.conan/data/Boost/1.60.0/lasote/stable/package/ebdc9c0c0164b54c29125127c75297f6607946c5/lib/libboost_log.so: undefined reference to `std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;::find(char const*, unsigned long, unsigned long) const@GLIBCXX_3.4.21'<br /></pre> <p>The build was littered with errors such as these. But the most puzzling thing was that I had changed nothing of consequence on my side and the Conan guys changed very little at their end too! What on earth was going on? </p> <p>After quite a lot of thinking, Conan's <i><a href="https://github.com/memsharded">memsharded</a></i> came up a startling conclusion: we've been hit by one of those rare-but-dreadful ABI-transitions! His comment is worth <a href="https://github.com/conan-io/conan/issues/138#issuecomment-185163060">reading in full</a>, but the crux of his findings is as follows (copied <i>verbatim</i>): </p> <blockquote><ul class="org-ul"><li>Boost packages, generated with travis use docker to manage different versions of gcc, as gcc 5.2 or gcc 5.3 </li><li>Those docker images are using modern linux distros, e.g. &gt; Ubuntu 15.10 </li><li>By default, new modern linux distros have switched to the gcc &gt; 5.1 new C++11 ABI, that is libstdc++ is built with gcc &gt; 5.1, usually named libcxx11, as well as the rest of the system. The libcxx11 ABI is incompatible with the old gcc &lt; 5.1 libcxx98 ABI. </li><li>Building in such environment links with the new libcxx11 by default. </li><li>Now, we move to our user, package consumer environment, which could be an Ubuntu 14.04, or a travis VM (12.04). Those distros use a libcxx98 libstdc++, as a lot of programs of those distros depends on the old libcxx98 ABI. It is not simple to replace it for the new one, requiring to rebuild or reinstall large part of the system and applications. Maybe it could be installed for dev only, and specified in the build, but I have not been able yet. </li></ul></blockquote> <p>Reading the above may have given you that sad, sinking feeling: "what on earth is he on about, I just want to compile my code!", "Why oh why is C++ so damn complicated!" and so forth. So, for the benefit of those not in the know, let me try to provide the required background to fully grok <i>memsharded</i>'s comment. </p></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">What's this ABI Malarkey Again?</h2><div class="outline-text-2" id="text-2"><p>This topic may sound oddly familiar to the faithful reader of Nerd Food and with good reason: we did cover ABIs in the distant past, at a slightly lower level. The post in question was <a href="https://mcraveiro.blogspot.co.uk/2012/05/nerd-food-mingw-cygwin-and-wine-up-home.html">On MinGW, Cygwin and Wine</a> and it does provide some useful context to this discussion, but, if you want a TL;DR, it basically dealt with kernel space and user space and with things such as the C library. This time round we will turn our attention to the C++ Standard Library. </p> <p>In addition to specifying the C++ language, the <a href="https://en.wikipedia.org/wiki/C%252B%252B#Standardization">C++ Standard</a> also defines the <a href="http://en.wikipedia.org/wiki/Application_programming_interface">API</a> of the C++ Standard Library - the classes and their methods, the functions and so on. The C++ Standard Library is responsible for providing a set of services for applications compiled with a C++ compiler. So far, so similar to the C Standard Library. Where things begin to differ is in the crucial matter of the <a href="http://en.wikipedia.org/wiki/Application_binary_interface">ABI</a>. But first, lets get a working definition for ABI, just so we are all on the same page. For this, we can do worse than using <a href="https://www.amazon.co.uk/Linux-System-Programming-Talking-Directly/dp/1449339530">Linux System Programming</a>: </p> <blockquote><p>Whereas an API defines a source interface, an ABI defines the low-level binary interface between two or more pieces of software on a particular architecture. It defines how an application interacts with itself, how an application interacts with the kernel, and how an application interacts with libraries. An ABI ensures binary compatibility, guaranteeing that a piece of object code will function on any system with the same ABI, without requiring recompilation. </p> <p>ABIs are concerned with issues such as calling conventions, byte ordering, register use, system call invocation, linking, library behavior, and the binary object format. The calling convention, for example, defines how functions are invoked, how arguments are passed to functions, which registers are preserved and which are mangled, and how the caller retrieves the return value. </p></blockquote> <p>The second paragraph is especially crucial. You see, although both the C and the C++ Standards are somewhat silent on the matter of specifying an ABI, C tends to have a <i>de facto</i> standard for <i>a given OS on a given architecture</i>. This may not sound like much and you may be saying: "what, wait: the same OS on a different architecture has a different ABI?" Yep, that is indeed the case. If you think about it, it makes perfect sense; after all, C was carefully designed to be equivalent to "portable assembler"; in order to achieve maximum performance, one must not create artificial layers of indirection on top of the hardware but instead expose it as is. So, by the same token, two different C compilers working on the same architecture and OS will tend to agree on the ABI. The reason why is because the OS will also follow the hardware where it must, for performance reasons; and where the OS can make choices, it more or less makes the choice for everybody else. For example, until recently, if you were on Windows, it did you no good to compile code into an <a href="https://en.wikipedia.org/wiki/Executable_and_Linkable_Format">ELF</a> binary because the law of the land was <a href="https://en.wikipedia.org/wiki/Portable_Executable">PE</a>. Things have now <a href="https://blogs.msdn.microsoft.com/wsl/2016/04/22/windows-subsystem-for-linux-overview/">changed dramatically</a>, but the general point remains: the OS and the hardware rule. </p> <p>C++ inherits much of C's approach to efficiency, so at first blush you may be fooled into thinking it too would have a <i>de facto</i> ABI standard ("for a given OS, " etc. etc.). However, there are a few crucial differences that have grave consequences. Let me point out a few: </p> <ul class="org-ul"><li>C++'s support for genericity - such as function overloading, templates, etc - is implemented by using <a href="https://en.wikipedia.org/wiki/Name_mangling">name mangling</a>; however, each compiler tends to have their own mangling scheme. </li><li>implementation details such as the memory layout of objects in the C++ Standard Library - in particular, as we shall see, <code>std::string</code> - are important. </li></ul> <p>In the past, compiler vendors tended exacerbate differences such as these; as it was with the <a href="https://en.wikipedia.org/wiki/Unix_wars">UNIX wars</a>, so too during the "C++ wars" did it make sense to be as incompatible as possible in the never ending hunt for monetisation. Thus, ABI specifications were kept internal and were closely guarded secrets. But since then the world has changed. To a large extent, C++ lost the huge amounts of funding it once had during the nineties and part of the naughties, and many vendors either went under or greatly reduced their efforts in this space. Two compilers emerged as victors: <a href="https://en.wikipedia.org/wiki/Visual_C%252B%252B">MSVC</a> on the Windows platform and - once the dust of the <a href="http://www.h-online.com/open/features/GCC-We-make-free-software-affordable-1066831.html%253Fpage=3">EGCS fork</a> finally settled - GCC everywhere else. The excellent quality of GCC across a vast array of platforms and its strict standards adherence - coupled with a quick response to the standardisation efforts - resulted in total domination outside of Windows. So much so that only recently did it meet a true challenger in <a href="https://en.wikipedia.org/wiki/Clang">Clang</a>. The brave new world in which we now find ourselves in is one where C++ ABI standardisation is a real possibility - see <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4028.pdf">Defining a Portable C++ ABI</a>. </p> <p>But pray forgive the old hand, I digress again. The main point is that, for a given OS on a given architecture, you normally had to compile all your code with a single compiler; if you did that, you were good to go. Granted, GCC never made any official promises to keep its releases ABI-compatible, but in practice we came to rely on the fact that new and old releases interoperated just fine since the days of 3.x. And so did Clang, respecting GCC's ABI so carefully it made us think of them as one happy family. Then, C++-11 arrived. </p></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">Mixing and Matching</h2><div class="outline-text-2" id="text-3"><p>As described in <a href="http://developers.redhat.com/blog/2015/02/05/gcc5-and-the-c11-abi/">GCC5 and the C++11 ABI</a>, this pleasant state of affairs was too idyllic to last forever: </p> <blockquote><p>[…] [S]ome new complexity requirements in the C++11 standard require ABI changes to several standard library classes to satisfy, most notably to <code>std::basic_string</code> and <code>std::list</code>. And since <code>std::basic_string</code> is used widely, much of the standard library is affected. </p></blockquote> <p>On hindsight, the improvements in the <code>std::string</code> implementation are great; as a grasshopper, I recall spending hours on end debugging my code in the long forgotten days of EGGS 2.91, only to find out there was a weird bug in the <a href="https://en.wikipedia.org/wiki/Copy-on-write">COW</a> implementation for my architecture. That was the first time - and as it happens, the last time too - I found a library bug, and it made a strong impression on me, at that young age. These people were not infallible. </p> <p>These days I sit much higher up in the C++ stack. Like many, I didn't read that carefully the GCC 5 release notes when it came out, relying as usual on my distro to do the right thing. And, as usual, the distros largely did, even though, unbeknown to many, a stir was happening in their world <sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.1" id="fnr.1" name="fnr.1">1</a></sup>. But hey, who reads distro blogs, right?  Hidden comfortably under my Debian Testing lean-to, I was blissfully unaware of this transition since my code continued to compile just fine. Also, where things start to get hairy is when you need to mix and match compiler versions and build settings - and who on their right mind does that, right? </p> <p>As it happens, this is a situation in which modern C++ users of Travis may easily find themselves in, stuck as they are on either on Ubuntu 12.04 (2012) or Ubuntu 14.04 (2014). Nick Sarten's <a href="http://genbattle.bitbucket.org/blog/2016/01/17/c++-travis-ci/">blog post</a> rams the point home in inimitable fashion: </p> <blockquote><p>Hold on, did I say GCC 4.6? Clang 3.4? WHAT YEAR IS IT? </p></blockquote> <p>Yes, what year is it indeed. So it is that most of us rely on PPA's to bring the C++ environment on Travis up to date, such as the Ubuntu Toolchain: </p> <pre class="example"><br />sudo add-apt-repository -y ppa:ubuntu-toolchain-r/test<br /></pre> <p>This always seemed like an innocent thing to do but after my linking errors and <i>memsharded</i> discoveries, one suddenly started to question everything: what settings did the PPA use to build? What settings were used to build the Boost Conan packages? With what compiler? In what distro? The nightmare was endless. It was clear this was going to lead to tears before bedtime. </p></div></div> <div class="outline-2" id="outline-container-sec-4"><h2 id="sec-4">The Long Road to a Solution</h2><div class="outline-text-2" id="text-4"><p>Whilst <i>memsharded</i> honed into the problem pretty quickly - less than a couple of weeks - a complete solution to my woes was a lot more elusive. In truth, this is the kind of situation where you need long spells of concentrated effort, so working in your copious spare time does not help at all. I first tried the easiest approach: to pray that it would all go away by itself, given enough time. And, lo and behold, things did work again, for a little while! And then started to fail again; the Boost package in Conan got rebuilt and the build broke. And that way it stayed. </p> <p>Once waiting was no longer an option, I had to take it seriously and started investigating in earnest. Trouble is, when you lose trust in the compilation settings you then need to methodically validate absolutely <i>everything</i>, until you bottom out the problem. And that takes time. Many things were tried, including: </p> <ul class="org-ul"><li>rebuilding Boost locally, attempting to reproduce the issue - to no avail. </li><li>rebuilding the Conan Boost packages with the old ABI; a fail (<a href="https://github.com/lasote/conan-boost/issues/12">#12</a>). </li><li>reading up a variety of articles on the subject, most of them linked in this post. </li><li>building the Boost packages locally and exporting them into Travis using DropBox's public folders. Another fail, but DropBox was a win. </li><li>obtaining the exact same Ubuntu 14.04 image as Travis is using, use the compiler from the PPA and export Boost to Travis using DropBox and replicating the problem locally in a VM. This worked. </li></ul> <p>Predictably, the final step is the one I should have tried first, but one is always lazy. Still, all of this got me wondering why had things been so complicated. Normally one would be able to <code>ldd</code> or <code>nm -C</code>the binary and figure out the dependencies, but in this case I seemed to always be pointing to <code>libstdc++.so.6</code> regardless. Most puzzling. And then I found the Debian wiki page on <a href="https://wiki.debian.org/GCC5">GCC5</a>, which states: </p> <blockquote><p>The good news is, that GCC 5 now provides a stable libcxx11 ABI, and stable support for C++11 (GCC version before 5 called this supported experimental). This required some changes in the libstdc++ ABI, and now libstdc++6 provides a dual ABI, the classic libcxx98 ABI, and the new libcxx11 (GCC 5 (&lt;&lt; 5.1.1-20) only provides the classic libcxx98 ABI). The bad news is that the (experimental) C++11 support in the classic libcxx98 ABI and the new stable libcxx11 ABIs are not compatible, and upstream doesn't provide an upgrade path except for rebuilding. Note that even in the past there were incompatibilities between g++ versions, but not as fundamental ones as found in the g++-5 update to stable C++11 support. </p> <p>Using different libstdc++ ABIs in the same object or in the same library is allowed, as long as you don't try to pass std::list to something expecting <code>std::__cxx11::list</code> or vice versa. We should rebuild everything with g++-5 (once it is the default). Using g++-4.9 as a fallback won't be possible in many cases. </p> <p>libstdc++ (&gt;= 5.1.1-20) doesn't change the soname, provides a dual ABI. Existing C++98 binary packages will continue to work. Building these packages using g++-5 is expected to work after build failures are fixed. </p></blockquote> <p>The crux is, of course, all the stuff about a <i>dual ABI</i>. I had never bumped into the <i>dual ABI</i> beast before, and now that I did I'm not sure I am entirely pleased. It's probably great when it just works, but it's tricky to troubleshoot when it doesn't: are you linking against a <code>libstdc++</code> with dual ABI disabled/unsupported? Or is it some other error you've introduced? Personally, having a completely different SO name like <i>memsharded</i> had suggested seems like a less surprising approach - e.g. call it <code>libcxx11</code> instead of <code>libstdc++</code>. But, as always, one has to play with the cards that were dealt so there is no point in complaining. </p></div></div> <div class="outline-2" id="outline-container-sec-5"><h2 id="sec-5">Conclusion</h2><div class="outline-text-2" id="text-5"><p>The Ubuntu 14.04 build of Boost did get us a <a href="https://travis-ci.org/DomainDrivenConsulting/dogen/builds/137848143">green build again</a>, but for all the joyous celebrations, there is still a grey cloud hovering above since the mop-up exercise is not completed. I now need to figure out how to build Boost with Conan on 14.04 and upload this version into the package manager's repo. However, for now <i>carpe diem</i>. After so much unproductive time, there is a real need for a few weeks (months!)  of proper coding - the reason why I have a spare time project in the first place. But some lessons were learned. </p> <p>Firstly, one cannot but feel truly annoyed at <code>${COSMIC_DEITY}</code> for having to deal with issues such as this. After all, one of the reasons I prefer C++ to the languages I use at work (C# and Java) is that it is usually very transparent; normally I can very quickly reproduce, diagnose and fix a problem in my code. Of course, lord knows this statement is not true of <i>all</i> C++ code, but at least it tends to be valid for most Modern C++ - and over the last five years that's all the C++ I dealt with in anger. It was indeed rather irritating to find out that the pain has not yet been removed from the language, and on occasion, even experienced developers get bitten. Hard. </p> <p>A second point worth of note is that in C++ - more so than in any other language - one cannot just blindly trust the package manager. There are just so many configuration knobs and buttons for that to be possible, and one can easily get bitten by assumptions. The sad truth is that even when using Conan, one should probably upload one's own packages built with a well understood configuration. True, this may cost time - but on the other hand, it will avoid wild goose chases such as this one. </p> <p>Finally, its also important to note that this whole episode illustrates the sterling job that package maintainers do in distributions. Paradoxically, their work is often so good that we tend to be blissfully unaware of its importance. Articles such as <a href="http://kmkeen.com/maintainers-matter/">Maintainers Matter</a> take a heightened sense of urgency after an experience like this. </p> <p>The road was narrow, long and troublesome. But, as with all Poirot novels, there is always that satisfying feeling of finally finding out <i>whodunnit</i> in the end. </p></div></div> <div class="outline-2" id="outline-container-sec-6"><h2 id="sec-6">Post Script</h2><div class="outline-text-2" id="text-6"><p>There is one final twist to this story, which adds insult to injury and further illustrates <code>${COSMIC_DEITY}</code>'s sense of humour. When I finally attempted to restore our <a href="https://travis-ci.org/DomainDrivenConsulting/dogen/jobs/137859606">clang builds</a>, I found out that LLVM has <a href="http://lists.llvm.org/pipermail/llvm-dev/2016-June/100400.html">disabled their APT repo</a> for an unspecified length of time: </p> <blockquote><p>&gt; TL;DR: APT repo switched off due to excessive load / traffic </p></blockquote> <p>There are no alternatives at present to build with a recent clang. Sometimes one has the feeling that the universe does not want to play ball. Stiff upper lip and all that; mustn't grumble. </p></div></div><div id="footnotes"><h2 class="footnotes">Footnotes: </h2><div id="text-footnotes"> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.1" id="fn.1" name="fn.1">1</a></sup> <p class="footpara">For example, see <a href="http://allanmcrae.com/2015/06/the-case-of-gcc-5-1-and-the-two-c-abis/">The Case of GCC-5.1 and the Two C++ ABIs</a> to understand Arch's pains. </p></div>  </div></div></div><div class="status" id="postamble"><p class="date">Created: 2016-06-16 Thu 14:12</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://biocomputation.herts.ac.uk/2016/06/11/from-morphology-to-network-level-activity-patterns-dendritic-arrangement-and-clustering-among-inferior-olive-neurons.html">From morphology to network-level activity patterns: dendritic arrangement and clustering among inferior olive neurons</a></h2></div>
            <p class="text-muted">by <a href="http://biocomputation.herts.ac.uk/">UH Biocomputation group</a> on June 11, 2016 09:21 AM.</p>
          </div>
          <div class="panel-body">

            <p><a class="reference external" href="https://scholar.google.co.in/citations?hl=en&amp;user=Nadz-doAAAAJ&amp;view_op=list_works&amp;sortby=pubdate">Marylka Uusisaari</a> from the Erasmus Medical Centre, Rotterdam joins us for a special journal club session.</p>
<hr class="docutils" />
<p>Anatomical understanding of the neuronal circuitry, comparable to electronic chip blueprint underlies theories and models of computational capabilities of various brain structures. The fundamental and essential nature of this knowledge is recently gaining visibility in the form of large-scale connectomic mapping initiatives. Their work aims (among others) to define the communication pathways between neurons, most commonly delineated in terms of axonal termination spaces and their overlaps with the target neurons’ dendritic fields.</p>
<p>The axo-dendritic or axo-somatic chemical synaptic connection is not, however, the only mechanism for fast interneuronal communication, as gap junctions linking neighbouring neurons provide the means for electrical signal propagation and synchronisation of spiking activity. A prime example of a structure where this mechanism plays a key role in shaping network activity is the inferior olive (IO), a nucleus in the brainstem integrating multimodal sensorimotor input and providing the climbing fibre input to the cerebellum. Intriguingly, there seem to be no local chemical synapses within the IO; instead, the coherence of inter-olivary network relies entirely on gap junctional communication. Thus, it is of key interest to define the anatomical arrangement of IO cells in respect to each other, as the amount of electrical coupling between individual IO cells - defining the emerging spatio-temporal patterns of olivo-cerebellar activity - must depend on the extent of dendritic overlap.</p>
<p>It is generally assumed that the IO cells are spherical neurons interspersed homogeneously throughout the nucleus, with the strength of electrical coupling decreasing with increasing inter-somata distance. However, this assumption has not been rigorously examined until now; and indeed, early anatomical works (Sotelo et al., 1974) described the olive as formed of segregated clusters of olivary cells.</p>
<p>To gain insight into the possible inhomogeneity and anisotropy present on anatomical level in the IO, we employed a novel “sparse viral labelling” technique that preserves the flexibility of genetically targetable staining but results in a sparse, Golgi-stain-like labelling of neurons. This method allows detailed reconstruction of large number of neurons in thick brain sections and thereby quantitative assessment of their dendritic morphology in respect to the boundaries of the IO as well as to the neighbouring cohort of IO cells.</p>
<p>Examining a large number of reconstructed cells as well as the overall arrangement of thousands of IO cell bodies revealed that while closely positioned IO cells’ dendritic fields may overlap to a great extent, the inter-somatic distance is not necessarily indicative of overlap. In contrast, IO cells can show strong avoidance regarding their neighbouring cells’ dendritic fields, suggesting that the functional clustering of IO as well as their axonal activity (i.e., the climbing fibre) is defined by the IO cell dendrite arrangement. Such non-uniform neuronal arrangement calls for re-evaluation of our hypotheses regarding the origins of cerebellar complex spike synchrony.</p>
<p><strong>Date:</strong> 17/06/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://biocomputation.herts.ac.uk/2016/06/09/could-a-neuroscientist-understand-a-microprocessor.html">Could a neuroscientist understand a microprocessor?</a></h2></div>
            <p class="text-muted">by <a href="http://biocomputation.herts.ac.uk/">UH Biocomputation group</a> on June 09, 2016 04:20 PM.</p>
          </div>
          <div class="panel-body">

            <p>There is a popular belief in neuroscience that we are primarily data
limited, that producing large, multimodal, and complex datasets will,
enabled by data analysis algorithms, lead to fundamental insights into
the way the brain processes information. Microprocessors are among
those artificial information processing systems that are both complex
and that we understand at all levels, from the overall logical flow,
via logical gates, to the dynamics of transistors. Here we take a
simulated classical microprocessor as a model organism, and use our
ability to perform arbitrary experiments on it to see if popular data
analysis methods from neuroscience can elucidate the way it processes
information. We show that the approaches reveal interesting structure
in the data but do not meaningfully describe the hierarchy of
information processing in the processor. This suggests that current
approaches in neuroscience may fall short of producing meaningful
models of the brain.</p>
<p>The complete paper can be found here: <a class="reference external" href="http://www.biorxiv.org/content/early/2016/05/26/055624.abstract">http://www.biorxiv.org/content/early/2016/05/26/055624.abstract</a></p>
<p><strong>Date:</strong> 10/06/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://ankursinha.in/blog/2016/06/02/checking-your-latex-sources-for-spelling-errors-with-hunspell.html">Checking your LaTeX sources for spelling errors with Hunspell</a></h2></div>
            <p class="text-muted">by <a href="http://ankursinha.in/blog/">Ankur Sinha</a> on June 02, 2016 10:42 AM.</p>
          </div>
          <div class="panel-body">

            <p>I usually use <a class="reference external" href="http://www.vim.org/">Vim</a> and a <a class="reference external" href="https://en.wikipedia.org/wiki/Makefile">Makefile</a> when writing LaTeX documents. Even though <a class="reference external" href="http://vimdoc.sourceforge.net/htmldoc/spell.html">Vim does permit you to check your spellings</a>, it's always nice to run the entire text through a standalone spell checker before passing your documents on to others.</p>
<p>The workflow is quite simple. Once you've written your text, you commit your changes, and then you can use one of either <a class="reference external" href="http://aspell.net/">Aspell</a> or <a class="reference external" href="http://hunspell.github.io/">Hunspell</a> to check your text for spelling errors. Both provide an interactive interface that makes them easy to use.</p>
<p>On <a class="reference external" href="http://getfedora.org">Fedora</a>, you can install them using <code>dnf</code>:</p>
<pre class="code bash literal-block">sudo dnf install aspell hunspell
</pre>
<p>You'll also need to make sure you have the language files installed:</p>
<pre class="code bash literal-block">sudo dnf install aspell-en hunspell-en
</pre>
<p>Then, to check all your <code>.tex</code> files, you can use something like this:</p>
<pre class="code bash literal-block">find . -name <span class="s2">"*.tex"</span> -exec aspell --lang<span class="o">=</span>en --mode<span class="o">=</span>tex check <span class="s2">"{}"</span> <span class="se">\;</span> <span class="c1"># Aspell
</span>find . -name <span class="s2">"*.tex"</span> -exec hunspell -t -i utf-8 <span class="s1">'{}'</span> <span class="se">\;</span> <span class="c1"># Hunspell</span>
</pre>
<p>I looked around a bit, and decided to use <a class="reference external" href="http://hunspell.github.io/">Hunspell</a>. It's used by LibreOffice, Firefox, and other applications. I commit my work first and then run the above command which opens a window like this:</p>
<a class="reference external image-reference" href="http://ankursinha.in/blog/images/hunspell-example.png"><img alt="Hunspell screenshot" src="http://ankursinha.in/blog/images/hunspell-example.png" style="width: 750px;" /></a>
<p>Once you've gone through it and made your changes, you can then use <code>git diff --word-diff</code> to review your changes. If you'd like to undo some of them, use <code>git add -i</code> and so on:</p>
<a class="reference external image-reference" href="http://ankursinha.in/blog/images/git-word-diff.png"><img alt="Git diff screenshot" src="http://ankursinha.in/blog/images/git-word-diff.png" style="width: 750px;" /></a>
<p>That's it! Happy writing!</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://biocomputation.herts.ac.uk/2016/06/01/convolutional-neural-networks.html">Convolutional neural networks</a></h2></div>
            <p class="text-muted">by <a href="http://biocomputation.herts.ac.uk/">UH Biocomputation group</a> on June 01, 2016 10:33 AM.</p>
          </div>
          <div class="panel-body">

            <p><a class="reference external" href="http://papers.nips.cc/paper/4824-imagenet-classification-w">In 2012, Krishevsky et al, submitted an entry to the ImageNet competition that smashed the previous error rate record</a>. Krishevsky’s solution won the competition using deep convolutional nets (conv nets) and GPUs. From 2012 the ImageNet competition error rate has continued to plummet from ~15% to just over 3%, with all winning entries using deep conv nets and GPUs. In this talk I review the history of deep conv nets, the key points from Khrishevsky’s paper, conv nets strengths and weaknesses and briefly show how easy it is to create your own deep conv net using Google’s new machine learning library <a class="reference external" href="https://www.tensorflow.org/">TensorFlow</a>.</p>
<p><strong>Date:</strong> 03/06/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://ankursinha.in/blog/2016/05/31/some-tips-and-tricks-for-running-simulations-on-a-cluster.html">Some tips and tricks for running simulations on a cluster</a></h2></div>
            <p class="text-muted">by <a href="http://ankursinha.in/blog/">Ankur Sinha</a> on May 31, 2016 06:17 PM.</p>
          </div>
          <div class="panel-body">

            <p>To begin with, you must use a terminal multiplexer! I use <a class="reference external" href="http://byobu.org/">Byobu with tmux</a> to multiplex a single SSH session. I use it on all my machines. It's an excellent tool.</p>
<div class="section" id="monitoring-your-jobs">
<h2>Monitoring your jobs</h2>
<p>Three of my Byobu screens run these commands to monitor the queue and my jobs:</p>
<pre class="code bash literal-block">watch -n <span class="m">30</span> qstat main
watch -n <span class="m">30</span> qstat -B
watch -n <span class="m">30</span> /usr/local/maui/bin/showq -u asinha
</pre>
<p><code>showq</code> may be installed elsewhere. Use <code>which showq</code> to locate it. More information on the commands can be found in their manuals:</p>
<pre class="code bash literal-block">man watch
man qstat
</pre>
<p>Remember, to find a man page, you can use the <code>apropos</code> command.</p>
<p>I run all my simulations in a specific directory on the shared data disk. I usually also monitor this folder. It gives me an idea of how much my simulations have progressed. Something like this works:</p>
<pre class="code bash literal-block">watch -n <span class="m">30</span> <span class="s1">'du -sch *'</span> <span class="c1"># in the directory that stores simulation results*</span>
</pre>
</div>
<div class="section" id="use-git">
<h2>Use Git</h2>
<p>Of course. If you make frequent changes, you must use a version control system. I stick to <code>git</code> myself. You can use <code>svn</code> or <code>hg</code> if you wish - whatever floats your boat.</p>
<p>An issue I've stumbled upon while working with the cluster is that the program you want it to run is not loaded into memory until your job begins to run. So, if you want to run a certain version of your program on the cluster, say some version_1, you must not make any changes to this version until the queued job has begun to run. This is extremely inconvenient, especially if you make frequent changes to your simulations, as is often the case in research. I would, for example, like to queue separate jobs in parallel for a myriad of tiny changes and then compare results.</p>
<p>Enter <a class="reference external" href="https://git-scm.com/docs/git-worktree">git work-tree</a>! The simplest solution to the aforementioned issue is to checkout different work-trees for commits you want to test and queue up jobs for each individually. This would work really well. Once the simulation finishes, you can remove the work-tree.</p>
<p>Unfortunately, clusters usually run stable long term support oriented versions of Linux distributions - EL/CentOS/Scientific. As a result, it's quite probable that the version of git on the cluster doesn't support work-trees - as is the case with the cluster I use. I came up with a workaround which works somewhat like work-trees - I manually clone my source repository to a temporary location, checkout the commit I want to run (which is what work-trees sort of are), and set up a job that runs this particular simulation version. It uses two scripts:</p>
<ul class="simple">
<li>A template PBS script for the simulation run. This will be passed to <code>qsub</code>.</li>
<li>A script that clones my repo, checks out the required commit, completes the template script, and calls <code>qsub</code> to queue up the job.</li>
</ul>
<p>The first is a simple PBS script:</p>
<pre class="code bash literal-block"><span class="c1"># File: run-sim.sh
</span>
<span class="c1">#PBS -l walltime=48:00:00
#PBS -l nodes=50
#PBS -m abe
#PBS -N nest_v_s
</span>
module unload mpi/mpich-x86_64
module load mvapich2-1.7

<span class="nv">SIM_PATH</span><span class="o">=</span><span class="s2">"/stri-data/asinha/simulations-nest/"</span>
<span class="nv">SIM_TIME</span><span class="o">=</span><span class="s2">""</span>
<span class="nv">PROGRAM_PATH</span><span class="o">=</span><span class="s2">"</span><span class="nv">$SIM_PATH</span><span class="s2">""</span><span class="nv">$SIM_TIME</span><span class="s2">""/Sinha2016/src/Sinha2016.py"</span>
<span class="nv">RESULT_PATH</span><span class="o">=</span><span class="s2">"</span><span class="nv">$SIM_PATH</span><span class="s2">""</span><span class="nv">$SIM_TIME</span><span class="s2">""/result/"</span>
<span class="nv">NUM_NODES</span><span class="o">=</span>50

<span class="nb">echo</span> ------------------------------------------------------
<span class="nb">echo</span> <span class="s1">'Job is running on nodes'</span><span class="p">;</span> cat <span class="nv">$PBS_NODEFILE</span>
<span class="nb">echo</span> ------------------------------------------------------
<span class="nb">echo</span> PBS: qsub is running on <span class="nv">$PBS_O_HOST</span>
<span class="nb">echo</span> PBS: originating queue is <span class="nv">$PBS_O_QUEUE</span>
<span class="nb">echo</span> PBS: executing queue is <span class="nv">$PBS_QUEUE</span>
<span class="nb">echo</span> PBS: working directory is <span class="nv">$PBS_O_WORKDIR</span>
<span class="nb">echo</span> PBS: execution mode is <span class="nv">$PBS_ENVIRONMENT</span>
<span class="nb">echo</span> PBS: job identifier is <span class="nv">$PBS_JOBID</span>
<span class="nb">echo</span> PBS: job name is <span class="nv">$PBS_JOBNAME</span>
<span class="nb">echo</span> PBS: node file is <span class="nv">$PBS_NODEFILE</span>
<span class="nb">echo</span> PBS: current home directory is <span class="nv">$PBS_O_HOME</span>
<span class="nb">echo</span> PBS: <span class="nv">PATH</span> <span class="o">=</span> <span class="nv">$PBS_O_PATH</span>
<span class="nb">echo</span> ------------------------------------------------------

<span class="nb">echo</span> <span class="s2">"ANKUR&gt;&gt; Begun at </span><span class="nv">$SIM_TIME</span><span class="s2">"</span>
<span class="nb">echo</span> <span class="s2">"ANKUR&gt;&gt; Script: </span><span class="si">${</span><span class="nv">0</span><span class="si">}</span><span class="s2">"</span>

mkdir -pv <span class="nv">$RESULT_PATH</span>
<span class="nb">cd</span> <span class="nv">$RESULT_PATH</span>

/usr/local/bin/mpiexec -n <span class="nv">$NUM_NODES</span> python <span class="nv">$PROGRAM_PATH</span>

<span class="nv">END_TIME</span><span class="o">=</span><span class="k">$(</span>date +%Y%m%d%H%M<span class="k">)</span>
<span class="nb">echo</span> <span class="s2">"ANKUR&gt;&gt; Ended at </span><span class="nv">$END_TIME</span><span class="s2">"</span>
</pre>
<p>It sets up the required PBS options, then loads the MPI module I wish to use. It creates a directory where my simulation's results will be stored, enters it, and then uses <code>mpiexec</code> to run my Python program.</p>
<p>The second script is a wrapper that clones the required commit, sets up the correct paths in the above script and the calls <code>qsub</code>:</p>
<pre class="code bash literal-block"><span class="c1"># File: setup-job.sh
</span>
<span class="nv">SOURCE_PATH</span><span class="o">=</span><span class="s2">"/home/asinha/Documents/02_Code/00_repos/00_mine/Sinha2016/"</span>
<span class="nv">GIT_COMMIT</span><span class="o">=</span><span class="s2">""</span>
<span class="nv">SIM_PATH</span><span class="o">=</span><span class="s2">"/stri-data/asinha/simulations-nest/"</span>
<span class="nv">SIM_TIME</span><span class="o">=</span><span class="k">$(</span>date +%Y%m%d%H%M<span class="k">)</span>
<span class="nv">RUN_SCRIPT</span><span class="o">=</span><span class="s2">"scripts/cluster/nest-runsim.sh"</span>
<span class="nv">RUN_NEW</span><span class="o">=</span><span class="s2">""</span>
<span class="nv">ERROR</span><span class="o">=</span><span class="s2">"no"</span>
<span class="nv">NUM_NODES</span><span class="o">=</span>50
<span class="nv">CUR_SIM_PATH</span><span class="o">=</span><span class="s2">""</span>

<span class="k">function</span> queue_task
<span class="o">{</span>
    <span class="nb">pushd</span> <span class="s2">"</span><span class="nv">$CUR_SIM_PATH</span><span class="s2">"</span>
        qsub <span class="s2">"</span><span class="nv">$RUN_NEW</span><span class="s2">"</span>
    <span class="nb">popd</span>
<span class="o">}</span>

<span class="k">function</span> setup_env
<span class="o">{</span>
    <span class="nv">CUR_SIM_PATH</span><span class="o">=</span><span class="s2">"</span><span class="nv">$SIM_PATH</span><span class="s2">""</span><span class="nv">$SIM_TIME</span><span class="s2">"</span>
    <span class="nb">echo</span> <span class="s2">"This simulation will run in: </span><span class="nv">$CUR_SIM_PATH</span><span class="s2">"</span>
    mkdir -pv <span class="s2">"</span><span class="nv">$CUR_SIM_PATH</span><span class="s2">"</span>

    <span class="nb">pushd</span> <span class="s2">"</span><span class="nv">$CUR_SIM_PATH</span><span class="s2">"</span>
        <span class="nb">echo</span> <span class="s2">"Cloning source repository..."</span>
        git clone <span class="s2">"</span><span class="nv">$SOURCE_PATH</span><span class="s2">"</span> <span class="s2">"Sinha2016"</span>

        <span class="nb">pushd</span> <span class="s2">"Sinha2016"</span>
            <span class="nb">echo</span> <span class="s2">"Checking out commit </span><span class="nv">$GIT_COMMIT</span><span class="s2">..."</span>
            git checkout -b this_sim <span class="s2">"</span><span class="nv">$GIT_COMMIT</span><span class="s2">"</span>
            <span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="nv">$?</span><span class="s2">"</span> -ne <span class="m">0</span> <span class="o">]</span>
            <span class="k">then</span>
                <span class="nb">echo</span> <span class="s2">"Error occured. Could not checkout </span><span class="nv">$GIT_COMMIT</span><span class="s2">. Exiting..."</span>
                <span class="nv">ERROR</span><span class="o">=</span><span class="s2">"yes"</span>
            <span class="k">fi</span>
        <span class="nb">popd</span>

        <span class="k">if</span> <span class="o">[</span> <span class="s2">"xyes"</span> <span class="o">==</span>  x<span class="s2">"</span><span class="nv">$ERROR</span><span class="s2">"</span> <span class="o">]</span>
        <span class="k">then</span>
            <span class="nb">exit</span> -1
        <span class="k">fi</span>

        <span class="nv">RUN_NEW</span><span class="o">=</span><span class="s2">"nest_""</span><span class="nv">$GIT_COMMIT</span><span class="s2">"".sh"</span>
        <span class="nb">echo</span> <span class="s2">"Setting up </span><span class="nv">$RUN_NEW</span><span class="s2">..."</span>
        cp <span class="s2">"</span><span class="nv">$SOURCE_PATH</span><span class="s2">""</span><span class="nv">$RUN_SCRIPT</span><span class="s2">"</span> <span class="s2">"</span><span class="nv">$RUN_NEW</span><span class="s2">"</span> -v
        sed -i <span class="s2">"s|nest_v_s|nest_</span><span class="nv">$GIT_COMMIT</span><span class="s2">|"</span> <span class="s2">"</span><span class="nv">$RUN_NEW</span><span class="s2">"</span>
        sed -i <span class="s2">"s|nodes=.*|nodes=</span><span class="nv">$NUM_NODES</span><span class="s2">|"</span> <span class="s2">"</span><span class="nv">$RUN_NEW</span><span class="s2">"</span>
        sed -i <span class="s2">"s|NUM_NODES=.*|NUM_NODES=</span><span class="nv">$NUM_NODES</span><span class="s2">|"</span> <span class="s2">"</span><span class="nv">$RUN_NEW</span><span class="s2">"</span>
        sed -i <span class="s2">"s|SIM_TIME=.*|SIM_TIME=</span><span class="nv">$SIM_TIME</span><span class="s2">|"</span> <span class="s2">"</span><span class="nv">$RUN_NEW</span><span class="s2">"</span>
    <span class="nb">popd</span>
<span class="o">}</span>

<span class="k">function</span> usage
<span class="o">{</span>
    <span class="nb">echo</span> <span class="s2">"Usage: </span><span class="nv">$0</span><span class="s2">"</span>
    <span class="nb">echo</span> <span class="s2">"Queue up a job to run a particular git commit"</span>
    <span class="nb">echo</span> <span class="s2">"</span><span class="nv">$0</span><span class="s2"> &lt;git_commit&gt; &lt;number_nodes&gt;"</span>
<span class="o">}</span>

<span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="nv">$#</span><span class="s2">"</span> -ne <span class="m">2</span> <span class="o">]</span><span class="p">;</span>
<span class="k">then</span>
    <span class="nb">echo</span> <span class="s2">"Error occurred. Exiting..."</span>
    <span class="nb">echo</span> <span class="s2">"Received </span><span class="nv">$#</span><span class="s2"> arguments. Expected: 3"</span>
    usage
    <span class="nb">exit</span> -1
<span class="k">fi</span>

<span class="nv">GIT_COMMIT</span><span class="o">=</span><span class="s2">"</span><span class="nv">$1</span><span class="s2">"</span>
<span class="nv">NUM_NODES</span><span class="o">=</span><span class="s2">"</span><span class="nv">$2</span><span class="s2">"</span>
setup_env
queue_task

<span class="nb">exit</span> 0
</pre>
<p>This takes two arguments, as the <code>usage</code> function will tell you. The first argument is the commit you want to run the simulation for, and the second is the number of nodes you want to use. It'll clone your repository to a temporary location and checkout this specified commit. Then, it'll modify the first script <code>run-sim.sh</code> to set up the correct path to the code and also correctly specify the number of nodes you'd want to request. Finally, once all this is done, it'll call <code>qsub run-sim.sh</code> to queue up your job. I use unique date stamps as directory names to distinguish between simulation runs, but you can use another unique identifier.</p>
<p>Now, this copy of your code, at the specified commit will be used for the job you've queued. You can merrily go about tinkering with the main source repo without affecting queued up jobs. Yay!</p>
<p>Even though I've used Python here, you can use similar scripts for compiled languages. You'll simply have to compile your executable after you checkout the required commit.</p>
</div>
<div class="section" id="other-miscellaneous-stuff">
<h2>Other miscellaneous stuff</h2>
<p>My lab mate, Alex, recently introduced me to <a class="reference external" href="https://www.continuum.io/downloads">Anaconda</a>. It's a great tool for that lets you install packages in your user specific directory. It contains quite a few python and other related packages. No need to use <code>sudo</code> with it, and you can use <code>pip</code> etc. with it too. It even lets you set up virtual environments and things.</p>
<p>I think that's it for today. I'll update the post with other things I find/learn as I continue my adventures with the cluster.</p>
</div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://biocomputation.herts.ac.uk/2016/05/25/the-jinx-on-the-nasa-software-defect-data-sets.html">The Jinx on the NASA software defect data sets</a></h2></div>
            <p class="text-muted">by <a href="http://biocomputation.herts.ac.uk/">UH Biocomputation group</a> on May 25, 2016 09:27 AM.</p>
          </div>
          <div class="panel-body">

            <p>Jean Petrić is scheduled to present two papers at the <a class="reference external" href="http://ease2016.lero.ie/">20th International Conference on Evaluation and Assessment in Software Engineering in Limerick, Ireland</a>:</p>
<ul class="simple">
<li>Using different characteristics of machine learners to identify different defect families (doctoral symposium paper)</li>
<li>The Jinx on the NASA Software Defect Data Sets (short paper)</li>
</ul>
<p>In this journal club session, he presents the papers to the research group to gather additional feedback.</p>
<p><strong>Date:</strong> 27/05/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://feeds.plos.org/~r/plos/Blog/~3/msgNOclLtYI/">Easing Discovery: A New Website for PLOS</a></h2></div>
            <p class="text-muted">by <a href="http://blogs.plos.org/plos">The Official PLOS Blog</a> on May 25, 2016 08:00 AM.</p>
          </div>
          <div class="panel-body">

            <img alt="Home-page" class="attachment-thumbnail size-thumbnail wp-post-image" height="150" src="http://blogs.plos.org/plos/files/2016/05/Home-page-150x150.png" style="display: block; margin-bottom: 5px; clear: both;" width="150" /><div class="wp_orcid_field"><a href="http://orcid.org/0000-0001-7318-5892" rel="author" target="_blank">0000-0001-7318-5892</a></div><p>PLOS has a history of moving forward on initiatives designed to benefit diverse stakeholders, from authors, reviewers, editors and librarians to policy makers, educators and the general public. Delivering the best content to the appropriate audience is challenging and our previous website was simply not up to the task. PLOS is excited to announce that the clean design and user-friendly experience recently brought to <strong><a href="http://plos.io/1NJMvAE" target="_blank">PLOS Journals</a></strong>, <strong><a href="http://plos.io/1RnGGDR" target="_blank">PLOS Collections</a></strong> and PLOS’ new <strong><a href="http://plos.io/1YVYlIJ" target="_blank">submission system</a></strong> for <strong><a href="http://plos.io/1XRwOKf" target="_blank"><em>PLOS Biology</em></a></strong> authors, <strong><a href="http://plos.io/1RnGYdR" target="_blank">Aperta™</a></strong>, is in place on the organization’s umbrella website and homepage, <strong><a href="http://plos.io/1Tv9q50" target="_blank">www.plos.org</a></strong>.</p>
<p>In all of these endeavors, the PLOS Product and Technology teams provide tools that allow quick and easy content updates, enabling PLOS Communications to be as agile as PLOS Journals in delivering fresh content to visitors of PLOS.org on a weekly basis. Read “<strong><a href="http://blogs.plos.org/tech/a-new-front-door-for-plos" target="_blank">A New Front Door for PLOS</a></strong>” by PLOS Senior Product Manager Molly Sharp to learn more about development of the organization’s new website, truly designed to be a front door to PLOS—from <strong><a href="http://plos.io/1WfTapa" target="_blank">Who We Are</a></strong> and <strong><a href="http://plos.io/1Xuklf1" target="_blank">Core Principles</a></strong> to <strong><a href="http://plos.io/1RnHclf" target="_blank">PLOS Publications</a></strong>, <strong><a href="http://plos.io/27RmuWJ" target="_blank">Tracking Impact</a></strong> and tips for a <strong><a href="http://plos.io/1sOgX3z" target="_blank">Successful Submission</a></strong>.</p>
<p>Advanced search technology provides visitors to PLOS.org easy search across all PLOS content with one click, and from the PLOS homepage Publications menu, readers can easily browse the thousands of articles in PLOS Journals, PLOS Collections and <strong><a href="http://plos.io/1qHfXw8" target="_blank">PLOS Currents</a></strong>.</p>
<p>Those interested in learning about <strong><a href="http://plos.io/1qHg9LU" target="_blank">PLOS Innovations</a></strong> – past, current and future – can look to <strong><a href="http://plos.io/1Tv9q50" target="_blank">Learn Where We’re Headed</a></strong> from the new iconography on the homepage that runs throughout the website, and those wanting a bit more detail on how PLOS works with the broader community to improve the <strong><a href="http://plos.io/1s7vir9" target="_blank">author experience</a></strong>, <strong><a href="http://plos.io/1OLlA2i" target="_blank">researcher recognition</a></strong> or <strong><a href="http://plos.io/1YVZi3F" target="_blank">data sharing</a></strong> can jump directly from the Blog menu item to <strong><a href="http://plos.io/27RmW7q" target="_blank">The Official PLOS Blog</a></strong>. The PLOS Blog Network has been given more prominence on the publication page; with more than 2 million readers PLOS BLOGS provides a forum for authors, scientific leaders and early career researchers to articulate and communicate their thoughts on current research and issues of interest to the broad scientific community.</p>
<p>To understand the discovery, enrichment and educational benefits of Open Access journals, the <strong><a href="http://plos.io/1s7vtCH" target="_blank">Why Open Access</a></strong> page provides a jumping off point to information on the <strong><a href="http://plos.io/1qHgLBf" target="_blank">HowOpenIsIt?</a></strong>® Open Access Spectrum guide, downloadable resources, general license and <strong><a href="http://plos.io/1s7v6bn" target="_blank">Research Councils UK policy</a></strong> information related to publishing in Open Access journals. New <strong><a href="http://plos.io/1Tvay8P" target="_blank">Get Involved!</a></strong> and <strong><a href="http://plos.io/1YW07td" target="_blank">Advocacy</a></strong> pages provide a range of opportunities and information on how researchers can help move Open Access forward and what PLOS itself is doing in this area.</p>
<p>While publishing more than 165,000 articles (2003-2015) PLOS continues to <strong><a href="http://plos.io/1OUgYMO" target="_blank">transform research communication</a></strong> as we accelerate the time from discovery to publication, expand the means by which scientist share their ideas, use <strong><a href="http://plos.io/1WMwyMV" target="_blank">technology and the Internet to empower researchers</a></strong> and work to open the restrictions on credit to authors, reviewers and editors. The PLOS homepage Spotlight section is a place where readers can look to stay informed on these and other developments and the Featured Articles section offers quick access to the week’s article of interest from each journal’s homepage. Visit <strong><a href="http://plos.io/1Tv9q50" target="_blank">PLOS.org</a></strong> regularly to stay up to date on the latest research and the ongoing dialogue around the work, learn about opportunities to meet PLOS editors and gain a breadth of perspective on topics related to advancing science communication and the ongoing <strong><a href="http://plos.io/1s7vYN6" target="_blank">ripples of new initiatives</a></strong> at PLOS.</p>
<img alt="" height="1" src="http://feeds.feedburner.com/~r/plos/Blog/~4/msgNOclLtYI" width="1" />
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://biocomputation.herts.ac.uk/2016/05/13/what-does-the-nose-know-and-how-does-it-know-it.html">What does the nose know and how does it know it</a></h2></div>
            <p class="text-muted">by <a href="http://biocomputation.herts.ac.uk/">UH Biocomputation group</a> on May 13, 2016 09:48 AM.</p>
          </div>
          <div class="panel-body">

            <p><a class="reference external" href="http://bower-lab.org/">James Bower</a> joins us for a special journal club session where he discusses olfactory processing.</p>
<hr class="docutils" />
<p>Since Lucretius published his epic poem, De rerum natura (On the Nature of Things) in 66 BC, philosophical and scientific thinking about the sense of smell has been built on the assumption that the olfactory system detects odours through a process of classification based on analytical chemical structures.  Somewhat similarly, starting with Linnaeus in the mid 18th century, various efforts have been made to regularize odour perception by identifying different scales or perceptual groupings.  For the last 100 years many attempts have been made to correlate chemical characteristics believed important to detection to these classification schemes for perception.  All have failed.  This talk will describe the origins and implications of the alternative view that the olfactory system, both detection and perception is organized around the biological significance of an odorant molecule rather than its strict chemical form.  Evidence in support will be presented from a range of approaches from human psychophysics to receptor ligand binding studies to neuronal modelling.  The talk will also consider the possible implications for the function of cerebral cortex as a whole, given the likely olfactory origin of the cerebral cortical processing algorithm.</p>
<p><strong>Date:</strong> 20/05/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://biocomputation.herts.ac.uk/2016/04/28/open-position-phd-studentship-in-computational-neuroscience.html">Open Position: PhD studentship in Computational Neuroscience</a></h2></div>
            <p class="text-muted">by <a href="http://biocomputation.herts.ac.uk/">UH Biocomputation group</a> on April 28, 2016 10:57 PM.</p>
          </div>
          <div class="panel-body">

            <hr class="docutils" />
<p>We welcome applications for a funded PhD position in the Biocomputation Research Group at the University of Hertfordshire.</p>
<p>The successful applicant will work on a project related to the detailed modelling of neuronal dynamics arising through dendritic processing and/or the analysis of morphological and circuit data. Potential projects in the fields of neuroinformatics and computational neuroscience include (but are not limited to):</p>
<ul class="simple">
<li>Analysis of neuronal morphology and micro-circuitry.</li>
<li>Simulation of development of neuronal morphologies and tissues.</li>
<li>Simulation of dendritic processing on hardware.</li>
<li>Sensory processing and behaviour generation in individual invertebrate neurons.</li>
<li>Development of experimental robot controllers based on dendritic computation.</li>
<li>Structural plasticity at the single neuron and micro-circuitry level.</li>
</ul>
<p>More project ideas can be found here: <a class="reference external" href="http://www.dendrites.club/Positions.html">http://www.dendrites.club/Positions.html</a></p>
<p>The successful candidate will have extensive programming experience, preferably in Python (and/or other programming languages depending on the precise project). Depending on the project, experience with parallel programming (MPI, ZMQ), meshing software (VTK, CGAL, ITK, ...), or statistical analysis in R or Python are an advantage. In addition, we greatly value curiosity and a personal motivation to find out how things work.</p>
<p>We collaborate closely with leading experimentalists and theoreticians all over the world, such as Prof. Adrian Moore (RIKEN, Japan), Prof. Erik De Schutter (OIST, Japan) and Dr. Marylka Uusisaari (Erasmus Medical Center Rotterdam, The Netherlands).</p>
<p>The student will be based in the <a class="reference external" href="http://biocomputation.herts.ac.uk">Biocomputation Group</a> at the University of Hertfordshire and will be supervised by Drs. Ben Torben-Nielsen (b.torben-nielsen at herts.ac.uk) and Volker Steuber (v.steuber at herts.ac.uk) to whom informal enquiries can be sent.</p>
<p>Successful candidates are eligible for a research studentship award from the University (approximately GBP 14,250 per annum bursary plus the payment of the student fees). Application forms can be obtained from:</p>
<p>Mrs Lorraine Nicholls, <br />
Research Student Administrator, <br />
STRI, <br />
University of Hertfordshire, <br />
College Lane, <br />
Hatfield, Herts, <br />
AL10 9AB, <br />
Tel: +44 01707 286083, <br />
l.nicholls @ herts.ac.uk.</p>
<p>The short-listing process will begin on 30 May, 2016.</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://biocomputation.herts.ac.uk/2016/04/28/open-position-phd-studentship-in-olfactory-biocomputation.html">Open Position: PhD studentship in Olfactory Biocomputation</a></h2></div>
            <p class="text-muted">by <a href="http://biocomputation.herts.ac.uk/">UH Biocomputation group</a> on April 28, 2016 04:32 PM.</p>
          </div>
          <div class="panel-body">

            <hr class="docutils" />
<p>Applications are invited for a fully funded PhD position in the Biocomputation Research group at the University of Hertfordshire. Our research on Olfactory Biocomputation encompasses the following topics:</p>
<ul class="simple">
<li>Olfactory computing in insects and vertebrates</li>
<li>The role of stimulus dynamics in olfaction</li>
<li>Chemical “receptive fields” of odorant receptors</li>
<li>Neuromorphic computing and bio-inspired signal processing for chemical sensing</li>
</ul>
<p>Our spectrum of methods covers data science and machine learning, simulation of spiking networks, cheminformatics, and brain-like computing on neuromorphic hardware. The successful candidate should ideally have previous experience in one or more of these methods, but a keen interest in our research topics and enthusiasm for interdisciplinary research is considered essential. Excellent programming skills are required and should be documented upon application. Most of our code is written in Python.</p>
<p>Depending on the area of work, the successful candidate will join our collaborative research efforts with excellent experimental research groups, as e.g. led by Prof. Andreas Schaefer (Francis Crick Institute, London), Dr. Markus Knaden and Dr. Silke Sachse (Max-Planck Institute for Chemical Ecology, Jena, Germany). For a list of recent projects and publications please refer to the web pages of the <a class="reference external" href="http://biomachinelearning.net">BioMachineLearning Project</a> and the <a class="reference external" href="http://biocomputation.herts.ac.uk/">Biocomputation Group</a>.</p>
<p>The student will be supervised by Drs. Michael Schmuker (m.schmuker @ biomachinelearning.net) and Volker Steuber (v.steuber @ herts.ac.uk). Informal enquiries by email prior to application are encouraged and very welcome.</p>
<p>Successful candidates are eligible for a research studentship award from the University (approximately GBP 14,250 per annum bursary plus payment of the student fees).</p>
<p>Research in Computer Science at the University of Hertfordshire has been recognized as excellent by the latest Research Excellence Framework Assessment, with 50% of the research submitted being rated as world leading or internationally excellent. The Science and Technology Research Institute provides a very stimulating environment, offering a large number of specialized and interdisciplinary seminars as well as general training and researcher development opportunities. The University of Hertfordshire is situated in Hatfield, in the green belt just north of London.</p>
<p>Application forms can be obtained from:</p>
<p>Mrs Lorraine Nicholls, <br />
Research Student Administrator, <br />
STRI, <br />
University of Hertfordshire, <br />
College Lane, <br />
Hatfield, Herts, <br />
AL10 9AB, <br />
Tel: +44 01707 286083, <br />
l.nicholls @ herts.ac.uk.</p>
<p>The short-listing process will begin on 30 May, 2016.</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://biocomputation.herts.ac.uk/2016/04/28/open-position-phd-studentship-in-data-clustering.html">Open Position: PhD studentship in Data Clustering</a></h2></div>
            <p class="text-muted">by <a href="http://biocomputation.herts.ac.uk/">UH Biocomputation group</a> on April 28, 2016 03:41 AM.</p>
          </div>
          <div class="panel-body">

            <hr class="docutils" />
<p>Applications are invited for a fully funded PhD position in the Machine Learning team, under the Biocomputation Research Group, at the University of Hertfordshire. Our research in data clustering encompasses the following topics:</p>
<ul class="simple">
<li>Unsupervised feature weighting.</li>
<li>Metric learning.</li>
<li>Recovering the number of clusters in data sets.</li>
<li>Applications of the above in security and natural language processing.</li>
</ul>
<p>The successful candidate should ideally have previous experience in at least one of the above topics; those without experience must be able to demonstrate a keen interest in our research. Excellent programming skills are required and should be documented upon application.</p>
<p>The student will be supervised by Dr. Renato Cordeiro de Amorim (r dot amorim at herts dot ac dot uk). Informal enquires by email prior to application are encouraged and very welcome.</p>
<p>We collaborate closely with leading scientists from all over the world, including Prof. Boris Mirkin (National Research University Higher School of Economics and Birkbeck University of London), Prof. Vladimir Makarenkov (University of Quebec at Montreal), Dr. Christian Hennig (University College London), and Dr. Marcos Zampieri (Saarland University). For a list of recent publications please refer to <a class="reference external" href="http://homepages.herts.ac.uk/~comqra">http://homepages.herts.ac.uk/~comqra</a>.</p>
<p>Successful candidates are eligible for a research studentship award from the University (approximately GBP 14,250 per annum bursary plus payment of the student fees).</p>
<p>Research in Computer Science at the University of Hertfordshire has been recognized as excellent by the latest Research Excellence Framework Assessment, with 50% of the research submitted being rated as world leading or internationally excellent. The Science and Technology Research Institute provides a very stimulating environment, offering a large number of specialized and interdisciplinary seminars as well as general training and researcher development opportunities. The University of Hertfordshire is situated in Hatfield, in the green belt just north of London.
Application forms can be obtained from:</p>
<p>Mrs Lorraine Nicholls, <br />
Research Student Administrator, <br />
STRI, <br />
University of Hertfordshire, <br />
College Lane, <br />
Hatfield, Herts, <br />
AL10 9AB, <br />
Tel: +44 01707 286083, <br />
l.nicholls @ herts.ac.uk.</p>
<p>The short-listing process will begin on 30 May, 2016.</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://biocomputation.herts.ac.uk/2016/04/27/using-watertight-polygon-meshes-for-neuronal-morphology-representation.html">Using watertight polygon meshes for neuronal morphology representation</a></h2></div>
            <p class="text-muted">by <a href="http://biocomputation.herts.ac.uk/">UH Biocomputation group</a> on April 27, 2016 05:11 PM.</p>
          </div>
          <div class="panel-body">

            <p>I will report on the progress of my work to use polygon meshes as
a way to represent neuronal morphologies. The presentation is
composed of two parts. The first part discusses the acquisition
of neuronal morphology data from microscopy and the generation of
computer representations using the SWC format. It is intended to
provide a background on the second part of the presentation,
which focuses on using watertight polygon meshes as a way to
represent neuronal morphology. We shall cover the advantages of
this approach and the difficulties faced. In this context shall
discuss the paper by McDougal et al. [1]</p>
<p>[1] McDougal, Robert A., Michael L. Hines, and William
W. Lytton. "Water-tight membranes from neuronal morphology
files." Journal of neuroscience methods 220.2 (2013): 167-178.</p>
<p><strong>Date:</strong> 29/04/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://biocomputation.herts.ac.uk/2016/04/19/forests-are-trees-2-dendritic-tree-topology-revisited.html">Forests are TREES 2 - Dendritic tree topology revisited</a></h2></div>
            <p class="text-muted">by <a href="http://biocomputation.herts.ac.uk/">UH Biocomputation group</a> on April 19, 2016 09:45 AM.</p>
          </div>
          <div class="panel-body">

            <p><a class="reference external" href="https://scholar.google.com/citations?user=IpKlv7kAAAAJ">Felix Effenberger</a> joins us for a special journal club session where he discusses preliminary results on the statistics of the branching structure of dendritic trees.</p>
<hr class="docutils" />
<p>We report on preliminary results on the statistics of the branching structure of dendritic trees. Such trees can be considered to be binary trees since exactly two branches emerge from each branch point. Previous work has compared dendritic topology with random branching processes. Here we investigate a number of statistics over the topology (i.e. branching structure) of dendritic trees using a large sample of reconstructions of real dendritic trees from the NeuroMorpho.org database. First results indicate that real dendritic morphologies span the entire space of possible binary trees. This result indicates that precise dendritic topology might not be a relevant factor determining dendritic computation.</p>
<p>The reconstructions were accessed directly through the TREES toolbox in Matlab using a newly developed software interface that allows easy access to the database from third party applications. The API supports a rich query language enabling the user to conveniently perform sophisticated queries and obtain the reconstructions matching the query parameters. This is harnessed by a first client implemented as part of a forthcoming version of the TREES toolbox that handles populations of reconstructions. In cooperation with the NeuroMorpho.org team we plan to soon make the API available to other parties.</p>
<p><strong>Date:</strong> 22/04/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://biocomputation.herts.ac.uk/2016/04/13/open-position-early-career-research-fellowships-in-systems-biology-machine-learning-for-food-and-disease.html">Open Positions: Early Career Research Fellowships in systems biology/machine learning for food and disease</a></h2></div>
            <p class="text-muted">by <a href="http://biocomputation.herts.ac.uk/">UH Biocomputation group</a> on April 13, 2016 12:27 PM.</p>
          </div>
          <div class="panel-body">

            <hr class="docutils" />
<p>Salary: £31,656 - £37,768 per annum depending on skills and experience. <br />
Closing date: 17 May 2016 <br /></p>
<p>The University of Hertfordshire is investing in its future research staff and infrastructure, and is in the process of transitioning the delivery of its research under six Themes: Food; Global Economy; Health and Wellbeing; Heritage, Cultures and Communities; Information and Security; Space. These will assist in the further development of research excellence and provide both increased external profile and internal focus for Hertfordshire’s research activities.</p>
<p>Six new Research Fellow posts are each offered for a five year term in the first instance. It is our expectation, however, that successful appointees will grow their research activities to become permanent academic staff members by the end of that period.</p>
<div class="section" id="qualifications-required">
<h2>Qualifications required</h2>
<p>You must have a first degree in a science, such as biology, computer science, mathematics or a relevant subject, and a doctoral degree in bioinformatics, machine learning, quantitative genetics or a related subject area.  Experience in systems biology, big data science or genomics will be particularly relevant.</p>
</div>
<div class="section" id="research-focus-and-environment">
<h2>Research focus and environment</h2>
<p>This Fellowship will focus on emerging methods in biocomputation that generate and exploit large data sets of biological information available from genomics, transcriptomics, proteomics and metabolomics to better understand mechanisms of host resistance/immunity and/or resistance breakdown.  The Fellow will generate an improved understanding of relevant biological systems to develop specific strategies to combat infectious diseases caused by plant, animal or human pathogens.  This Fellowship will be supported by existing collaborations between colleagues in Schools of Life &amp; Medical Sciences (Kukol, Stotz, Barling, Fitt) and Computer Science (Steuber).  The Fellow is expected to use the University’s high performance computer cluster.</p>
</div>
<div class="section" id="experience-and-skills-required-for-the-post">
<h2>Experience and skills required for the post</h2>
<ul class="simple">
<li>Considerable experience with big data analysis and machine learning, including working knowledge of scripting languages like Perl, Python and/or R;</li>
<li>Knowledge of genomic research techniques, such as next-generation sequencing, proteomics and/or metabolic profiling;</li>
<li>Practical experience with the application of numerical analysis and/or mathematical models to biological datasets, for example in genomics or quantitative genetics;</li>
<li>Evidence of original research published in high impact journals.</li>
</ul>
</div>
<div class="section" id="research-expectations">
<h2>Research expectations</h2>
<p>The Fellow is expected to develop a collaborative research program with our academic partners.  We envisage that the Research Fellow will become a permanent staff member, supported by funding from successful research grant applications and developing new areas of teaching, especially at the post-graduate level. To ensure this, the two Schools will provide career training for the Fellow. The Fellow will have established collaborations with companies and successfully obtained co-funded industry-government projects. The Fellow will continue to publish high-impact papers and be leading an internationally recognised research team.</p>
</div>
<div class="section" id="description-of-schools">
<h2>Description of Schools</h2>
<p>The Early Career Research Fellow will work with and receive support from the School of Life and Medical Sciences and the School of Computer Science.  The successful candidate can build on the strengths of both Schools and may combine experiment-based empirical research with data-based analysis.</p>
<p>Within the <a class="reference external" href="http://www.herts.ac.uk/apply/schools-of-study/life-and-medical-sciences/research">School of Life and Medical Sciences</a>, the Centre for Agriculture, Food and Environmental Management (CAFEM) is a research and teaching collaboration with the Royal Veterinary College, Rothamsted Research and Oaklands College.  The Fellow will work with researchers in CAFEM who have experience with systems biology applicable to crop protection, combining experimental field and lab research with computational modelling.  Within the School of Computer Science, research in the <a class="reference external" href="http://biocomputation.herts.ac.uk/">Biocomputation Research Group</a> involves development of computational models to study biological systems and application of biologically-inspired machine learning algorithms for the analysis of "real-world" data.  Members of the Biocomputation Group analyse and simulate computational models at different levels of complexity and collaborate closely with leading experimentalists in the UK and abroad.</p>
<hr class="docutils" />
<p>Informal enquiries are encouraged and should be made to: <br />
Professor Bruce Fitt, <br />
Professor of Plant Pathology, <br />
email: <a class="reference external" href="mailto:b.fitt@herts.ac.uk">b.fitt@herts.ac.uk</a>  <br />
Tel + 44 (0)1707 284751</p>
<p>or</p>
<p>Dr. Volker Steuber, <br />
Reader in Biocomputation and Head of the Biocomputation Research Group, <br />
email:  <a class="reference external" href="mailto:v.steuber@herts.ac.uk">v.steuber@herts.ac.uk</a> <br />
Tel: +44 (0)1707 284350.</p>
<p>Applications should be made through <a class="reference external" href="http://www.herts.ac.uk/contact-us/jobs-and-vacancies/research-vacancies">http://www.herts.ac.uk/contact-us/jobs-and-vacancies/research-vacancies</a>, job reference 013457.</p>
</div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://biocomputation.herts.ac.uk/2016/04/06/the-potential-for-using-artificial-intelligence-techniques-to-improve-e-learning-systems.html">The potential for using artificial intelligence techniques to improve e-Learning systems</a></h2></div>
            <p class="text-muted">by <a href="http://biocomputation.herts.ac.uk/">UH Biocomputation group</a> on April 06, 2016 04:40 PM.</p>
          </div>
          <div class="panel-body">

            <p>There has been significant progress in the development of techniques to deliver more effective e-Learning systems in both education and commerce but there are very few examples of comprehensive learning systems that exploit contemporary artificial intelligence (AI) techniques.  We have surveyed existing intelligent learning/training systems and explored the contemporary AI techniques which appear to offer the most promising contributions to e-Learning.  With the convergence of several of the required components for success increasingly in place the opportunity to make progress now appears to be much stronger.</p>
<p>In the field of education, the mining, extraction and exploitation of useful information and patterns from student data provides lecturers, trainers and organisations with the potential to tailor learning paths and materials to maximize teaching efficiency and to predict and influence student success rates. Progress in the area of student data analytics can provide useful techniques for exploitation in the development of adaptive learning systems. Student data often includes a combination of nominal and numeric data. A large variety of techniques are available to analyse numeric data, however there are fewer techniques applicable to nominal data.  We have explored potential correlations between student attributes in a freely available data set, including the application of what we believe to be a novel technique to analyse nominal data, providing the opportunity to focus on promising correlations for deeper analysis.</p>
<p><strong>Date:</strong> 8/04/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://biocomputation.herts.ac.uk/2016/03/30/dendritic-computation.html">Dendritic Computation</a></h2></div>
            <p class="text-muted">by <a href="http://biocomputation.herts.ac.uk/">UH Biocomputation group</a> on March 30, 2016 05:54 PM.</p>
          </div>
          <div class="panel-body">

            <p>Ankur Sinha's journal club session where he speaks about dendritic computation.</p>
<p><strong>Date:</strong> 01/04/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://ankursinha.in/blog/2016/03/05/calliope-helping-you-keep-a-diary-in-latex.html">Calliope - helping you keep a diary - in LaTeX!</a></h2></div>
            <p class="text-muted">by <a href="http://ankursinha.in/blog/">Ankur Sinha</a> on March 05, 2016 02:07 PM.</p>
          </div>
          <div class="panel-body">

            <p>Quite a few people write personal diaries - researchers tend to also keep research diaries where we note our generally brilliant ideas. I've used <a class="reference external" href="http://lifeograph.sourceforge.net/wiki/Main_Page">Lifeograph</a> for a number of years now. It's a great application with all the right features that a diary needs - chapters, tags, and  metrics. It doesn't quite work for a <em>research diary</em>, though - it doesn't support maths notation for a start, and we really do write a lot of very complicated maths from time to time. (The kinds with lots of symbols you see in the films? Think "<a class="reference external" href="http://www.imdb.com/title/tt0268978/">A beautiful mind</a>".)</p>
<p>The simple solution, of course, is <a class="reference external" href="http://lifeograph.sourceforge.net/wiki/Main_Page">LaTeX</a>. <a class="reference external" href="http://lifeograph.sourceforge.net/wiki/Main_Page">LaTeX</a> is used extensively in academic writing. While it does have a reputation for being complex and complicated (<a class="reference external" href="http://english.stackexchange.com/questions/10459/what-is-the-difference-between-complicated-and-complex">YES! There's a difference in the two words - they're not interchangeable!</a>) at times, it is by far the best tool for academic writing. It has everything a researcher needs - citation support, can be customised to fit multiple format, and if you pair it with <a class="reference external" href="https://git-scm.com/">Git</a> you even have versioning and <a class="reference external" href="http://ankursinha.in/blog/tag/zaphod/">change tracking</a>.</p>
<div class="section" id="calliope">
<h2>Calliope</h2>
<p>I went looking for packages that may provide this functionality in <a class="reference external" href="http://lifeograph.sourceforge.net/wiki/Main_Page">LaTeX</a> but didn't quite find any that had a convenient workflow and so on. I ran into a <a class="reference external" href="https://github.com/mikhailklassen/research-diary-project">this Github project</a> instead, which is a set of templates and scripts that does quite a good job. I've forked it and made some improvements. There's now a single script that takes arguments, for example. I've also added support for indexing - which works similar to tagging - it'll generate a nice clickable index at the end of the document. Of course, I've given it a fancy name, <a class="reference external" href="https://github.com/sanjayankur31/calliope">Calliope, and put it up on Github</a>.</p>
<p>Usage is quite straightforward:</p>
<pre class="code bash literal-block"><span class="o">[</span>asinha@cs-as14aho-2-herts-ac-uk  00_research_diary<span class="o">(</span>master %<span class="o">=)]</span>$ ./calliope.sh -h
    usage: ./calliope.sh options

    Master script file that provides functions to maintain a journal using LaTeX.

    OPTIONS:
    -h  Show this message and quit

    -t  Add new entry <span class="k">for</span> today

    -c  Compile today<span class="err">'</span>s entry

    -a  &lt;year&gt;
        Year to generate anthology of

    -p  &lt;year&gt;
        Compile all entries in this year

    -s  &lt;entry&gt; <span class="o">(</span>yyyy-mm-dd<span class="o">)</span>
        Compile specific entry
</pre>
<p>This is what the directory structure looks like:</p>
<pre class="code bash literal-block"><span class="o">[</span>asinha@cs-as14aho-2-herts-ac-uk  00_research_diary<span class="o">(</span>master %<span class="o">=)]</span>$ tree
.
├── calliope.sh
├── diary
│   ├── 2016
│   │   ├── 2016-03-04.tex
│   │   ├── 2016-03-05.tex
│   │   ├── images
│   │   ├── research_diary.sty -&gt; ../../templates/research_diary.sty
│   │   └── stdp_connection_symmetric.h
│   └── research_diary.sty -&gt; ../templates/research_diary.sty
├── pdfs
│   └── 2016
│       ├── 2016-03-04.pdf
│       └── 2016-03-05.pdf
├── README.rst
└── templates
    ├── entry.tex
    └── research_diary.sty

        <span class="m">6</span> directories, <span class="m">11</span> files
</pre>
<p>The script generates your source <a class="reference external" href="http://lifeograph.sourceforge.net/wiki/Main_Page">LaTeX</a> files and puts them in the folders in <tt class="docutils literal">diary/</tt>. Then you write up and use the script to compile it - the generated pdfs are collected in the <tt class="docutils literal">pdfs/</tt> folder. The script can also generate an anthology for a year you pick. The resultant pdf for a daily entry will look like this:</p>
<a class="reference external image-reference" href="http://ankursinha.in/blog/images/20160305-Calliope.png"><img alt="Screenshot showing pdf generated by Calliope" class="align-center" src="http://ankursinha.in/blog/images/20160305-Calliope.png" style="width: 500px;" /></a>
<p>That's pretty much it. Commit your entry to Git and you're done.</p>
<p>So, give it a go and please <a class="reference external" href="https://github.com/sanjayankur31/calliope/issues/">file issues</a> if you have any suggestions that would improve it.</p>
</div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://ankursinha.in/blog/2016/03/02/sli-vim-syntax-file-for-the-nest-simulators-sli-language.html">sli.vim - syntax file for the NEST simulator's SLI language</a></h2></div>
            <p class="text-muted">by <a href="http://ankursinha.in/blog/">Ankur Sinha</a> on March 02, 2016 10:53 AM.</p>
          </div>
          <div class="panel-body">

            <p>I've been reading some of <a class="reference external" href="http://nest-simulator.org">NEST</a>'s <a class="reference external" href="http://www.nest-simulator.org/quickref/">SLI</a> examples to understand the simulation better. I noticed that these files had no syntax highlighting at all which made the code difficult to read. I couldn't find a syntax highlighting file for Vim anywhere so I've begun writing my own. It isn't complete, and I'm sure it's buggy, but it already seems to make reading and writing SLI easier. Here's what it makes an SLI file look like:</p>
<a class="reference external image-reference" href="http://ankursinha.in/blog/images/20160302-sli-vim.png"><img alt="Screenshot showing SLI syntax highlighting in Vim" class="align-center" src="http://ankursinha.in/blog/images/20160302-sli-vim.png" style="width: 500px;" /></a>
<div class="section" id="installation">
<h2>Installation</h2>
<p>It's just a syntax file. You can drop it in <tt class="docutils literal"><span class="pre">~/.vim/syntax/</span></tt> directory (on Linux) or you can use <a class="reference external" href="https://github.com/tpope/vim-pathogen">pathogen</a> and just clone the repository and so on. Once done, add this to your <tt class="docutils literal">vimrc</tt> file:</p>
<pre class="code vim literal-block"><span class="k">au</span> <span class="nb">BufRead</span><span class="p">,</span><span class="nb">BufNewFile</span> *.sli <span class="k">set</span> <span class="k">filetype</span><span class="p">=</span>sli
<span class="k">au</span> <span class="nb">FileType</span> sli <span class="k">setl</span> <span class="nb">foldenable</span> <span class="nb">foldmethod</span><span class="p">=</span><span class="nb">syntax</span>
</pre>
<p>The file is <a class="reference external" href="https://github.com/sanjayankur31/sli.vim">hosted on Github</a>. Feel free to open issues, or even better, pull requests ;)</p>
</div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://ankursinha.in/blog/2016/02/28/new-zaphod-release-v0-5-7.html">New Zaphod release - v0.5.7</a></h2></div>
            <p class="text-muted">by <a href="http://ankursinha.in/blog/">Ankur Sinha</a> on February 28, 2016 04:52 PM.</p>
          </div>
          <div class="panel-body">

            <p><a class="reference external" href="http://ankursinha.in/blog/2016/02/13/zaphod-a-latex-change-tracking-tool.html">I'd written about Zaphod recently</a>. I've been making some tweaks to it - just some enhancements to the revision bit which will make it easier to use. The diff bit is still the same - I didn't see the need to make too many improvements there.</p>
<div class="section" id="new-revision-bits">
<h2>New revision bits</h2>
<p>Now, it looks like this when you start it up:</p>
<pre class="code bash literal-block"><span class="o">[</span>asinha@cs-as14aho-2-herts-ac-uk  latex-changes<span class="o">(</span>201602281328-latexdiff-annotated<span class="o">)]</span>$ python3 ../zaphod/zaphod.py revise -m paper.tex -s src
<span class="o">[</span>Zaphod<span class="o">]</span> LaTeX files with annotations:
<span class="o">[</span>1<span class="o">]</span> src/discussion.tex
<span class="o">[</span>2<span class="o">]</span> src/introduction.tex
<span class="o">[</span>3<span class="o">]</span> src/paper.tex
<span class="o">[</span>4<span class="o">]</span> src/methods.tex

Pick file to revise? 1-4/Q/q:
</pre>
<p>The idea here is that the user should be able to pick what file they want to edit. Previously, Zaphod just went file after file.</p>
<p>Once you pick a file, it'll look like this:</p>
<pre class="code bash literal-block">....
Pick file to revise? 1-4/Q/q: <span class="nv">1</span>

<span class="o">======</span> src/discussion.tex <span class="o">======</span>
+++ Addition found +++
<span class="se">\s</span>ection<span class="o">{</span>Discussion<span class="o">}</span>

Add a new file.

+++ Addition found +++
Accept addition? Y/N/Q/y/n/q: y
<span class="o">[</span>Zaphod<span class="o">]</span> Addition accepted.

<span class="o">[</span>Zaphod<span class="o">]</span> File src/discussion.tex revised and saved.
<span class="o">[</span>Zaphod<span class="o">]</span> LaTeX files with annotations:
<span class="o">[</span>1<span class="o">]</span> src/introduction.tex
<span class="o">[</span>2<span class="o">]</span> src/paper.tex
<span class="o">[</span>3<span class="o">]</span> src/methods.tex

Pick file to revise? 1-3/Q/q:
</pre>
<p>But, you can also make partial revisions. This is handy in situations where you have a long file and do not have the time to go over all of it at once. So, here's an example. I go over some changes, but I need to stop there for the moment:</p>
<pre class="code bash literal-block">...
<span class="o">[</span>Zaphod<span class="o">]</span> LaTeX files with annotations:
<span class="o">[</span>1<span class="o">]</span> src/introduction.tex
<span class="o">[</span>2<span class="o">]</span> src/paper.tex
<span class="o">[</span>3<span class="o">]</span> src/methods.tex

Pick file to revise? 1-3/Q/q: <span class="nv">2</span>

<span class="o">======</span> src/paper.tex <span class="o">======</span>
--- Deletion found ---
Tracking
--- Deletion found ---
Accept deletion? Y/N/Q/y/n/q: y
<span class="o">[</span>Zaphod<span class="o">]</span> Deletion accepted.

<span class="o">======</span> src/paper.tex <span class="o">======</span>
+++ Addition found +++
Visualising
+++ Addition found +++
Accept addition? Y/N/Q/y/n/q: y
<span class="o">[</span>Zaphod<span class="o">]</span> Addition accepted.

<span class="o">======</span> src/paper.tex <span class="o">======</span>
+++ Addition found +++
<span class="se">\i</span>nput<span class="o">{</span>discussion<span class="o">}</span>

+++ Addition found +++
Accept addition? Y/N/Q/y/n/q: q
Save partial file? Y/N/y/n: y
<span class="o">[</span>Zaphod<span class="o">]</span> Some files still have latexdiff annotations:
<span class="o">[</span>1<span class="o">]</span> src/introduction.tex
<span class="o">[</span>2<span class="o">]</span> src/methods.tex

Generate pdf? Y/y/N/n: n
<span class="o">[</span>Zaphod<span class="o">]</span> Not generating pdf.
<span class="o">[</span>Zaphod<span class="o">]</span> Following files have been revised <span class="o">(</span>maybe partially<span class="o">)</span>:
<span class="o">[</span>1<span class="o">]</span> src/discussion.tex
<span class="o">[</span>2<span class="o">]</span> src/paper.tex

Commit current changes? Y/y/N/n: n
<span class="o">[</span>Zaphod<span class="o">]</span> Exiting without committing.
</pre>
<p>There's one catch here, though. Because I want to make absolutely sure that Zaphod doesn't make any changes "by mistake", you'll have to either stash or commit these changes before you can run Zaphod again. This is just to be on the safer side. A better way would probably be for Zaphod to remember what files were partially revised, but I haven't implemented it at the moment. I'd actually just commit the changes - I mean, that's why we've got Git, right?</p>
<pre class="code bash literal-block"><span class="o">[</span>asinha@cs-as14aho-2-herts-ac-uk  latex-changes<span class="o">(</span>201602281328-latexdiff-annotated *<span class="o">)]</span>$ python3 ../zaphod/zaphod.py revise -m paper.tex -s src
Modifed or untracked files found.
git status output:
 M src/discussion.tex
 M src/paper.tex

Please stash or commit and rerun Zaphod.
</pre>
<p>That's it. I think it's a lot easier to use now, and in this design addresses a lot more use cases than it did before.</p>
<p><a class="reference external" href="https://github.com/sanjayankur31/zaphod/releases">Give it a go</a> and <a class="reference external" href="https://github.com/sanjayankur31/zaphod/issues/new">let me know</a> if things break - I've tested it myself, but only on a mock document.</p>
</div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://mcraveiro.blogspot.com/2016/02/nerd-food-interesting.html">Nerd Food: Interesting...</a></h2></div>
            <p class="text-muted">by <a href="http://mcraveiro.blogspot.com/">Marco Craveiro</a> on February 10, 2016 09:14 AM.</p>
          </div>
          <div class="panel-body">

            Nerd Food: Interesting…<div id="content"><p>Time to flush all those tabs again. Some interesting stuff I bumped into recently-ish. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">Finance, Economics, Politics</h2><div class="outline-text-2" id="text-1"><ul class="org-ul"><li><a href="http://www.ted.com/talks/yanis_varoufakis_capitalism_will_eat_democracy_unless_we_speak_up?utm_campaign=social&amp;utm_medium=referral&amp;utm_source=t.co&amp;utm_content=talk&amp;utm_term=global-social%2520issues#t-874630">Yanis Varoufakis: Capitalism will eat democracy – unless we speak up</a>: Very interesting Ted talk by Varoufakis. </li><li><a href="http://www.salon.com/2016/02/04/naomi_klein_there_are_no_non_radical_options_left_before_us_partner/">Naomi Klein: “There are no non-radical options left before us"</a>: I always have time for Naomi Klein even if I don't always agree with her. Very interesting post on market failures (predictably). </li><li><a href="http://www.theguardian.com/technology/2016/jan/28/apple-quarterly-results-iphone-silicon-valley-developers">Apple – losing out on talent and in need of a killer new device</a>: Very interesting post on Apple, and how it is not cool with the cool developers any longer. Good read and worrying one for Apple. </li><li><a href="http://www.spectator.co.uk/2016/01/the-low-tricks-of-high-finance-how-greedy-bankers-weak-politicians-and-timid-journalists-could-cause-a-new-crash/">The low tricks of high finance: how greedy bankers, weak politicians and timid journalists could cause a new crash</a>. Always have time for Michael Lewis. While waiting for the Big Short, this article kept me entertained. </li><li><a href="http://bottlerocketscience.blogspot.co.uk/2016/01/startup-geometry-ep-016-emanuel-derman.html">Startup Geometry EP 016 Emanuel Derman</a>: Podcast with uber nerd, quintessential Quant and fellow African Emanuel Derman. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">Startups et al.</h2><div class="outline-text-2" id="text-2"><ul class="org-ul"><li>Spotify engineering culture: <a href="https://labs.spotify.com/2014/03/27/spotify-engineering-culture-part-1/">Part I</a>, <a href="https://labs.spotify.com/2014/09/20/spotify-engineering-culture-part-2/">Part II</a>. "Oldie" but goodie. How a modern company is organised for raw efficiency. </li><li><a href="http://www.themacro.com/articles/2016/01/advice-startups-running-out-of-money/">Advice for Companies With Less Than 1 Year of Runway</a>: Lots of useful bits of advice for how to manage your runway. Source: Hacker News (twitter). </li><li><a href="http://dealbook.nytimes.com/2014/10/20/the-truth-hidden-by-ibms-buybacks/">The Truth Hidden by IBM’s Buybacks</a>: Something slightly dodgy seems to be going on in IBM, very strange financial transactions! </li><li><a href="http://www.wired.com/2016/02/ai-is-changing-the-technology-behind-google-searches/">AI Is Transforming Google Search. The Rest of the Web Is Next</a>: Google is moving from a "human algo" approach to AI in search. Very interesting. </li><li><a href="http://gavinandresen.ninja/a-guided-tour-of-the-2mb-fork">A Guided Tour of the 2mb Fork</a>: The BTC main man Gavin takes us on a detailed tour of one of the BTC forks. Source: Hacker News (twitter) </li><li><a href="http://www.coindesk.com/state-of-bitcoin-blockchain-2016/?utm_content=bufferccc2b&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer">State of Bitcoin and Blockchain 2016</a>: Blockchain Hits Critical Mass: A very detailed - some say <i>too detailed</i> - look at BTC in 2016. Source: CoinDesk (twitter). </li><li><a href="http://www.wired.com/2016/02/why-bitcoin-will-thrive-first-in-the-developing-world/?utm_content=buffer9ce0d&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer">Why Bitcoin Will Thrive First in the Developing World</a>: Most interesting hypothesis - that BTC will first gain lots of traction in the developing world - but to me, it fails slightly to provide enough evidence. It reminds me how I always thought that Linux would explode in the developing world, but in the end it was the developed world that took the lead, whereas the poorer nations simply pirated windows. I want to believe them, but unfortunately reality does not tend to be that linear. Source: CoinDesk (twitter) </li><li><a href="http://blog.nootch.net/2016/02/02/on-motivation-and-shipping/">On motivation, shipping and startups</a>: Great post on life in the start-up trenches. Source: Bruno Antunes (twitter) </li><li><a href="http://techcrunch.com/2016/01/18/why-big-companies-keep-failing-the-stack-fallacy/#.xiisrb:9sQZ">Why Big Companies Keep Failing: The Stack Fallacy</a>: Interesting hypothesis but not sure if totally buy it: "Stack fallacy is the mistaken belief that it is trivial to build the layer above yours.". Does seem to explain some behaviour that appears to be pretty irrational otherwise though. </li><li><a href="https://backchannel.com/the-next-social-media-we-want-and-need-2d03a7e0551c#.a07nlopz1">The Next Social Media We Want and Need!</a>: The next social media revolution, apparently. Some good ideas but as always, I fear they overestimate people's demand for privacy - unfortunately. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">General Coding</h2><div class="outline-text-2" id="text-3"><ul class="org-ul"><li><a href="http://www.nytimes.com/2016/01/26/business/marvin-minsky-pioneer-in-artificial-intelligence-dies-at-88.html">Marvin Minsky, Pioneer in Artificial Intelligence, Dies at 88</a>: Minsky is no more. Sad day for our field. </li><li><a href="https://medium.com/backchannel/marvin-minsky-s-marvelous-meat-machine-f436aec02fdf#.qcarjjdif">Marvin Minsky’s Marvelous Meat Machine</a>: Levy's eulogy to Minsky. I met Minsky through <a href="http://www.amazon.co.uk/Hackers-Heroes-Computer-Revolution-Anniversary/dp/1449388396/ref=sr_1_3?ie=UTF8&amp;qid=1453930109&amp;sr=8-3&amp;keywords=hackers">Hackers</a> so this is particularly poignant. </li><li><a href="http://blog.stephenwolfram.com/2016/01/farewell-marvin-minsky-19272016/">Farewell, Marvin Minsky (1927–2016)</a>: Wolfram's eulogy to Minsky. Most excellent and, dare I say, almost humble. </li><li><a href="https://github.com/blog/2042-git-2-5-including-multiple-worktrees-and-triangular-workflows">Git 2.5, including multiple worktrees and triangular workflows</a>: I seemed to have missed this extremely useful new feature in Git. If you have too, check it out. </li><li><a href="http://sealedabstract.com/rants/nanomsg-postmortem-and-other-stories/">nanomsg postmortem and other stories</a>: Extremely interesting post on FOSS projects, project governance and personalities. Hat tip: Bruno Antunes (twitter) </li><li><a href="http://www.iron.io/blog/2016/01/microcontainers-tiny-portable-containers.html">Microcontainers – Tiny, Portable Docker Containers</a>: <a href="http://www.iron.io/">iron.io</a> has a repo of Dockerfiles with really small images. Source: Hacker News (twitter) </li><li><a href="https://www.brianchristner.io/docker-is-moving-to-alpine-linux/">Docker Official Images are Moving to Alpine Linux</a>: After the whole excitement around <a href="http://www.iron.io/">iron.io</a>, we all started to pay attention to Alpine and it seems so did docker. It certainly would be great to have sensible sized base images, but not quite sure about using a different libc. Lets see how this plays out! Source: Hacker News (twitter) </li><li><a href="http://www.eweek.com/virtualization/coreos-launches-docker-rival-rkt-1.0.html">CoreOS Launches Docker Rival Rkt 1.0</a>: Rocket reaches 1.0. Still haven't used it, but still rooting on the sidelines - docker needs competition. Source: Hacker News (twitter) </li><li><a href="https://vimeo.com/56748054">Kevlin Henney - It Is Possible to Do Object-Oriented Programming in Java</a>: haven't seen it yet, but being a Kevlin presentation I recommend it without hesitation. Can't wait to watch it. </li><li><a href="https://yow.eventer.com/yow-2013-1080/the-solid-design-principles-deconstructed-by-kevlin-henney-1386">The SOLID Design Principles Deconstructed</a>: Another Henney special, next on the play list. </li><li><a href="http://web.media.mit.edu/~minsky/papers/sciam.inherit.html">Will Robots Inherit the Earth?</a>: As we morn Minsky, we start to rediscover his papers. Oldie but goodie. The man was a true genius. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-4"><h2 id="sec-4">Databases</h2><div class="outline-text-2" id="text-4"><ul class="org-ul"><li><a href="http://dailytechvideo.com/video-435-simon-riggs-databases-the-long-view/">Databases - the Long View</a>: good presentation on databases and Postgres in particular, giving you a perspective of how things changed over time. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-5"><h2 id="sec-5">C++</h2><div class="outline-text-2" id="text-5"><ul class="org-ul"><li><a href="https://github.com/ipkn/crow">Crow</a>: New find. Simple library to write web services in C++. If you need to quickly expose some code as a web service, this may be easier than using <a href="https://github.com/Microsoft/cpprestsdk">Casablanca</a>. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-6"><h2 id="sec-6">Layperson Science</h2><div class="outline-text-2" id="text-6"><ul class="org-ul"><li><a href="http://www.sciencefriday.com/segments/when-water-flows-uphill/">When Water Flows Uphill</a>: How science can be great fun. Dying to try this with my kids. Source: Hacker News (twitter) </li><li><a href="http://gizmodo.com/heres-why-finding-gravitational-waves-would-be-such-a-b-1752286165">Why Finding Gravitational Waves Would Be Such a Big Deal</a>: Layperson introduction to gravitational waves and why they are important. </li><li><a href="https://tincman.wordpress.com/2011/01/04/research-paper-management-with-emacs-org-mode-and-reftex/">Research Paper Management with Emacs, org-mode and RefTeX</a>: I personally have been using <a href="https://github.com/mcraveiro/referencer">Gnome Referencer</a> for my reference management, but I should have known there would be an Emacs solution. Will move over to this when I have the time. </li><li><a href="https://github.com/emacsmirror">Emacs Mirror</a>: Lots and lots of emacs packages. I am currently using this as an inspiration to find new packages such as <a href="https://github.com/emacsmirror/wsd-mode">wsd-mode</a>, a WebSequenceDiagrams mode - pretty nifty. Its all in ELPA/MELPA etc but somehow the GitHub interface seems to make it more discoverable? </li></ul></div></div> <div class="outline-2" id="outline-container-sec-7"><h2 id="sec-7">Other</h2><div class="outline-text-2" id="text-7"><ul class="org-ul"><li><a href="http://www.bbc.co.uk/iplayer/episode/b06vm9qp/empire-of-the-tsars-romanov-russia-with-lucy-worsley-1-reinventing-russia">Empire of the Tsars: Romanov Russia</a>: Great BBC documentary about Russian history. </li><li><a href="http://www.bbc.co.uk/iplayer/episode/b06y8hyr/the-brain-with-david-eagleman-1-what-is-reality">The Brain with David Eagleman</a>: BBC documentary about the brain. </li><li><a href="http://www.openculture.com/2012/08/bob_dylan_and_the_grateful_dead_rehearse_together_in_summer_1987_listen_to_74_tracks.html">Bob Dylan &amp; The Grateful Dead Rehearse Together in Summer 1987: Hear 74 Tracks</a>: The name says it all. Deeply personal tracks. </li><li><a href="http://www.neilgaiman.com/Cool_Stuff/Short_Stories/The_Return_of_the_Thin_White_Duke">The return of the Thin White Duke</a>: Gaiman on Bowie. Great read. </li></ul></div></div></div><div class="status" id="postamble"><p class="date">Created: 2016-02-08 Mon 22:29</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://mcraveiro.blogspot.com/2016/02/nerd-food-tooling-in-computational.html">Nerd Food: Tooling in Computational Neuroscience - Part III: Data</a></h2></div>
            <p class="text-muted">by <a href="http://mcraveiro.blogspot.com/">Marco Craveiro</a> on February 08, 2016 09:41 PM.</p>
          </div>
          <div class="panel-body">

            Nerd Food: Tooling in Computational Neuroscience - Part III: Data<div id="content"><table border="0"><tbody><tr><td width="50%"></td><td width="50%"><p class="verse" style="text-align: left;"><small>In God we trust; all others must bring data. <i>-- <a href="https://en.wikipedia.org/wiki/W._Edwards_Deming">W. Edwards Deming</a></i></small></p></td></tr></tbody></table> <p>Welcome to yet another instalment in our series of posts about tooling in Computational Neuroscience. Previously, we have discussed <a href="http://mcraveiro.blogspot.co.uk/2015/11/nerd-food-tooling-in-computational.html">simulators</a> - a <a href="https://en.wikipedia.org/wiki/Neuron_(software)">popular one</a>, in particular - and <a href="http://mcraveiro.blogspot.co.uk/2015/11/nerd-food-tooling-in-computational_30.html">microscopes</a>. We shall now talk about <i>data</i> in Computational Neuroscience, a seemingly broad and somewhat mundane topic but one which is central to any attempt in understanding the <i>status quo</i> of the discipline. The target audience remains as it was - the lay person - but I'm afraid things are getting increasingly technical. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">More Data! We Need More Data!</h2><div class="outline-text-2" id="text-1"><p>Computational Neuroscience by itself is not particularly interesting if there are no inputs to the models we carefully craft nor detailed outputs to allow us to know what the models are doing. Similarly, one needs to be able to use experimental data to inform our modeling choices and in order to baseline expectations; if this data is not available, one cannot tell how close or how far models are from the real thing. As everywhere else, data is of crucial importance here; we need lots of it and of many different kinds. </p> <p>Once you need data, you soon need to worry about data representation: how should information be encoded? Clearly, in order for the data to be useful in a general sense, it must be accompanied by a formal or informal specification or else users will not know how to interpret it. Furthermore, given the highly technical nature of the data in question, the specification must be very precise or the data becomes useless or even dangerous; "Was that in microns or nanometres?" is not the sort of question you want to be asking. In a world where producers and consumers of data can be anywhere geographically, the specification assumes an ever larger degree of importance. </p> <p>In summary, it is just not practical to allow everyone to come up with their own data formats: </p> <ul class="org-ul"><li>writing a clear and concise specification for data interchange is hard work, and requires a lot of experience in both the domain and the specification process in general. The first attempts would probably prove to be incomplete, inconsistent or impractical. </li><li>writing code to read and write files according to a specification and in multiple programming languages is also demanding engineering work. </li><li>writing code to convert from one data specification to another is even more complicated because it requires intimate knowledge of both. </li><li>some data is generated directly by hardware, making it impractical to adapt to different requirements. </li></ul> <p>Another aspect worth highlighting is the "big data" nature of a lot of the data sets used in this field. Anything to do with the brain gets pretty complex pretty quickly, and this manifests itself in the data dimension by having ever larger data sets with greater levels of detail. On the plus side, thanks to Moore's Law <a href="https://en.wikipedia.org/wiki/Sigmoid_function">sigmoid</a>, detailed information at all levels is allowing us to answer questions that were unanswerable not so long ago. The flip side is that all those details come at a cost: the data sets are becoming <i>huge</i>. For example, the resolution of the data coming out of microscopy is now so high that a single data set can take as much as 500 TB. And of course, not only are individual data sets getting larger and larger, but we are able to generate more of them at an ever increasing pace because the processes are more streamlined. It is a fire-hose of data. </p> <p>All of these difficulties are not unique to Computational Neuroscience or even to Neuroscience as a whole, but the complexity of the domain has the effect of greatly exacerbating an already thorny problem. </p></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">Neuroinformatics to the Rescue</h2><div class="outline-text-2" id="text-2"><p>If you think we're exaggerating then think again. The management of data in Neuroscience is so complex <i>it is a field on its own right</i>, with the cool-sounding name of <a href="https://en.wikipedia.org/wiki/Neuroinformatics">Neuroinformatics</a>. Wikipedia tells us that: </p> <blockquote><p>Neuroinformatics is a research field concerned with the organization of neuroscience data by the application of computational models and analytical tools. These areas of research are important for the integration and analysis of increasingly large-volume, high-dimensional, and fine-grain experimental data. Neuroinformaticians provide computational tools, mathematical models, and create interoperable databases for clinicians and research scientists. </p></blockquote> <p>In layman's terms, Neuroinformatics concerns itself with Neuroscience data and the places where said data is to be stored. It is also implied that one has to deal with a variety of <i>types</i> of data, e.g.: data from experiments (of which there can be many kinds), model inputs, model outputs, the models themselves when viewed as data, etc. The classification of this data is in itself a Neuroinformatics task.  Finally, Neuroinformatics also is responsible for the tooling necessary to acquire the data, manipulate it, analyse it, visualise it and so on. Given such a broad definition, one is forced to conclude that there is a big overlap between Computational Neuroscience - the modeling activity - and Neuroinformatics - the management of the data required by it. This lack of clarity is common in science, particularly as new fields develop; take for example Mathematics and Computer Science at its inception. </p> <p>In truth, such definitions and demarcations are only as useful as the tangible benefits they provide. It is perhaps more fruitful to think of Neuroinformatics as a hat you don on as and when your Computational Science work requires; the definition is there then to allow one to be aware of the separation between the analytic work in modeling and the data storage / retrieval work. For the purposes of this article, we'll continue to refer to the "Neuroinformatics Scientist" and the Computational Neuroscientist personas, but bear in mind they may resolve to the same person in practice.<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.1" id="fnr.1" name="fnr.1">1</a></sup></p> <p>Before we move on, I'd like to point out another interesting challenge Neuroinformatics has to address, and one that is common to all Medical Sciences: the need to handle human-derived data very carefully. After all, making data sets available widely must not have implications for the original patients, so its often a requirement that the data is <i>de-identified</i>; in the cases where the data is patient sensitive, additional requirements may be made to users of the data to avoid leaking this information, such as requiring a registration, etc. This illustrates the peculiar nature of Neuroinformatics, with the constant tension between making data as widely available as possible but at the same time having to ensure there are no side-effects of doing so. Presumably, <i>Primum non nocere</i> - first, do no harm. </p></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">Databases, Repositories and Archives</h2><div class="outline-text-2" id="text-3"><p>Thanks to the efforts of Neuroinformatics, there is now a wealth of Neuroscience data available to all on the Internet. The roots of this growth were sowed in the nineties when labs started sharing research results online. Sharing always existed in one way or another, of course, but the rise of the Internet simply changed the magnitude of the process. It soon became apparent that there was a need to organise central repositories of data, and to ensure the consistency of the shared data. Papers with a distinct Neuroinformatics tone were written, such as <a href="http://www.ncbi.nlm.nih.gov/pubmed/9821633">An on-line archive of reconstructed hippocampal neurons</a> (1999). Repositories grew, multiplied, morphed and in many cases died, as these things do, and the evolutionary process left us with the survivors. I'd like to highlight some of the ones I have bumped into so far are (with descriptions in their own words): </p> <ul class="org-ul"><li><a href="https://senselab.med.yale.edu/modeldb/">ModelDB</a>: "ModelDB provides an accessible location for storing and efficiently retrieving computational neuroscience models. ModelDB is tightly coupled with NeuronDB. Models can be coded in any language for any environment. Model code can be viewed before downloading and browsers can be set to auto-launch the models." </li><li><a href="https://senselab.med.yale.edu/neurondb/">NeuronDB</a>: "NeuronDB provides a dynamically searchable database of three types of neuronal properties: voltage gated conductances, neurotransmitter receptors, and neurotransmitter substances. It contains tools that provide for integration of these properties in a given type of neuron and compartment, and for comparison of properties across different types of neurons and compartments." </li><li><a href="http://neuromorpho.org/">NeuroMorpho</a>: "NeuroMorpho.Org is a centrally curated inventory of digitally reconstructed neurons associated with peer-reviewed publications. It contains contributions from over 100 laboratories worldwide and is continuously updated as new morphological reconstructions are collected, published, and shared. To date, NeuroMorpho.Org is the largest collection of publicly accessible 3D neuronal reconstructions and associated metadata." </li><li><a href="http://fcon_1000.projects.nitrc.org/">Functional Connectomes Project</a>: "Following the precedent of full unrestricted data sharing, which has become the norm in molecular genetics, the FCP entailed the aggregation and public release (via www.nitrc.org) of over 1200 resting state fMRI (R-fMRI) datasets collected from 33 sites around the world." </li><li><a href="https://openfmri.org/">OpenfMRI</a>: "[…] project dedicated to the free and open sharing of functional magnetic resonance imaging (fMRI) datasets, including raw data." </li><li><a href="http://www.opensourcebrain.org/projects">Open Source Brain</a>: "resource for sharing and collaboratively developing computational models of neural systems." </li></ul> <p>As you can see from this small list - rather incomplete, I'm sure - there is a wealth of information out there, covering all sorts of aspects of the brain. We never had so much data as we do today. And, in many ways, this is fast becoming a problem. As an example, data from each of Neuroscience's plethora of divisions and sub-fields is not designed to talk to each other: Electron Microscopy (EM) data is disconnected from data obtained by Magnetic Resonance Imaging (MRI), which is also totally separate from connectome information<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.2" id="fnr.2" name="fnr.2">2</a></sup> and so forth. In many cases, these sub-fields have evolved in fairly separate paths, and developed their own technical vocabulary in isolation and over long periods of time - an approach perfectly suitable for a "disconnected" world but less than ideal for a world where multiple sources of data are required to make sense of complex phenomena. If one can't even agree on what to call things, how can one be able to explain them? </p> <p>Thus, the early Neuroinformatics approach is best described as "evolutionary". It is not as if someone sat down and generated a well defined set of file formats for data interchange, covering all different aspects of the areas under study. Instead, what has been emerging is a multitude of file formats in each sub-field, all calling out for attention, and all of them designed for the immediate goal at hand rather than the greater good of Neuroscience. </p></div></div> <div class="outline-2" id="outline-container-sec-4"><h2 id="sec-4">Taming the Sea of Data</h2><div class="outline-text-2" id="text-4"><p>From a Software Engineering perspective, an evolutionary approach makes perfect sense; after all, the <a href="http://c2.com/cgi/wiki?MakeItWorkMakeItRightMakeItFast">Real Programmers had said</a>: "first make it work, then make it right, and, finally, make it fast." In many ways, we are reaching the "make it right" phase, with an increasing interest in efforts towards the creation of broad standards. There have been several papers and initiatives on the subject, such as the Neuroscience Information Framework, or NIF, described in a paper: <a href="http://www.neuinfo.org/about/publications/nif_knowledge_environment.pdf">The Neuroscience Information Framework: A Data and Knowledge Environment for Neuroscience</a>. The paper outlined a lot of the problems that are hampering research, such as: </p> <ul class="org-ul"><li>the need for specialised search engines that are domain aware, and advanced query tools too; </li><li>the need to aid integration and to provide connectivity across related data and findings; </li><li>a requirement to provide new and enhanced forms of analysing existing data, as data reuse is extremely important - new insights can be obtained on already existing data, often long after the data was generated, and by using it in ways that were not at all envisioned by the original authors; </li><li>the need to make contribution to online repositories easier; lowering the "contribution barrier" is important to increase data availability but must be done in ways that do not compromise the quality of the data; </li><li>a requirement to make all code open source such that any lab can make use of it, and the community as a whole can share the maintenance load; </li><li>a need for an online repository for all tooling, to avoid reinventing the wheel; </li><li>the need to create a multi-domain standard vocabulary. </li></ul> <p>There are many worthwhile points in this paper, and it is highly recommended to anyone interested in the subject matter. For instance, the section discussing the design of the NIF also covers the requirements for any specification that wishes to solve the problems outlined above. They are worth highlighting as - in my humble and lay opinion - they are very well thought out. </p> <ul class="org-ul"><li>The design of such a framework must combine technical specifications choices and broad community support; "open data, access and exchange, via open source and platform, aid Framework-enabled open discover for Neuroscience." </li><li>A common framework would reduce costs and enhance benefits of data sharing and knowledge sharing; it would "reduce the cost/benefit ration for data acquisition and utilization." </li><li>The framework must be designed by the broader community and with the needs of this broader community in mind, and it must build upon prior development in Neuroinformatics. </li><li>A focus on interoperability is crucial, and it is not a static target but one that must be looked after over time. In addition, there is also a need to keep in mind that different resources have very different interoperability potential. In order to maximise interoperability, we should aim to standardise as much as possible all aspects of the process such as user interfaces, terminologies, formats, etc. </li></ul> <p>To the untrained eye, the NIF initiative appears to be a great effort to solve fundamental problems in the field. It also seems to have spawned and/or helped popularise many useful and lasting resources such as <a href="http://neuromorpho.org/">NeuroMorpho</a>. However, the impression one gets from the outside is that the NIF didn't quite fulfil all of its potential. Having said that, I am keenly looking for up-to-date documents that describe the current status across all of its many aspects - alas, I have not yet succeeded in finding any such document. If indeed it is the case that the initiative petered out, it did highlight a few potential problems for anyone working in this space: </p> <ul class="org-ul"><li>large undertakings are hard to pull off; small, organic, incremental changes are easier to do, but of course, that is why we have the problems we currently have. </li><li>large initiatives require large amounts of funding; work is technical and very expensive. </li><li>it is not easy to understand NIFs deliverables from looking at their documentationa and website. One can clearly see it was an ambitious project, and one which took on the brunt of the problem areas highlighted above, but perhaps it needed a slightly more self-contained view of their achievements rather than a whole-or-nothing approach. This allows preserving some components even whilst others are failing to gain traction. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-5"><h2 id="sec-5">XML strikes back</h2><div class="outline-text-2" id="text-5"><p>Another interesting attempt to tackle these problems is what I call the "XML suite". These are basically a set of different XML-based standards that are able to interoperate and augment each other, a bit like a stack of building blocks. You can find more details in this paper: <a href="http://www.brains-minds-media.org/archive/228#documentContent">XML for Model Specification in Neuroscience</a>. Some of the components of the XML Suite are (with descriptions on their own words, copied from the above paper and a link for more details): </p> <ul class="org-ul"><li><a href="http://lems.github.io/LEMS/">LEMS</a>: "the Low Entropy Model Specification […] is being developed to provide a compact, minimally redundant, human-readable, human-writable, declarative way of expressing models of biological systems. It differs from other systems such as CellML or SBML in its requirement to be human writable and the inclusion of basic physical concepts such as dimensionality and physical nesting as part of the language." </li><li><a href="https://www.neuroml.org/">NeuroML</a>: "supports the use of declarative model specifications for neuroscience modeling efforts at different scales, from intracellular mechanisms to networks of reconstructed neurons." </li><li><a href="https://www.neuroml.org/">MorphML</a>: "provides a common format for exchange of neuronal morphology data. It can also be used to specify cell structure for modeling efforts as part of NeuroML." </li><li><a href="http://neurobot.bio.auth.gr/2006/brainml-a-standard-xml-metaformat-for-exchanging-neuroscience-data/">BrainML</a>: "application for representing time series data, spike trains, experimental protocols, and other data relevant to neurophysiology experiments." </li><li><a href="http://www.sbml.org/">SBML</a>: "(Systems Biology Markup Language) is an application for specifying models of biochemical reaction networks such as metabolic networks, cell-signaling pathways and gene regulatory networks." </li><li><a href="https://www.cellml.org/">CellML</a>: "is designed for the specification of biological models of cellular and sub-cellular processes such as calcium dynamics, metabolic pathways, signal transduction, and electrophysiology." </li><li><a href="https://www.w3.org/Math/">MathML</a>: "provides the means for describing the structure and content of mathematical notation in order to serve, receive, and process mathematics on the web. Other XML applications often use MathML language elements for representing mathematical equations." </li></ul> <p>A positive aspect of the XML Suite is its "discrete" nature. Each of these file formats are free to evolve in isolation, and the nature of their cooperation is very loose in most cases. For example MathML is not at all related to Neuroscience and has the support of the Maths community (to some extent). In addition, the "stacking" approach is also a very interesting one, allowing a good domain focus. For example, NeuroML is built on top of LEMS, so in theory each of these should cover different domains and there should be minimal redundancy. </p> <p>The key challenge for the XML Suite is for each of their components to find a sustainable user base and sustainable funding to go along with it. This is a broader problem of Neuroinformatics: researchers do not want to spend time on work that is not contributing directly to their research and so the developer pool to do fundamental work on the file formats is limited. Once the developer pool becomes too limited, the file format ends up with a small user base because it is not fit for purpose, and thus starts a downward spiral. This appears to have been the fate of projects such as BrainML. </p></div></div> <div class="outline-2" id="outline-container-sec-6"><h2 id="sec-6">Conclusion</h2><div class="outline-text-2" id="text-6"><p>This post provided an overview of the data landscape in Computational Neuroscience and introduced the sub-field of Neuroinformatics. We also looked at some of the available data stores and reviewed a few of the more popular initiatives to solve the fundamental data problems in the field. </p> <p>Stay tuned for the next instalment! </p></div></div><div id="footnotes"><h2 class="footnotes">Footnotes: </h2><div id="text-footnotes"> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.1" id="fn.1" name="fn.1">1</a></sup> <p class="footpara">For a bit more details on the two fields see <a href="https://www.maths.nottingham.ac.uk/personal/sc/cnn/CNN2A.pdf">What are Computational Neuroscience and Neuroinformatics?</a></p></div> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.2" id="fn.2" name="fn.2">2</a></sup> <p class="footpara">"A connectome is a comprehensive map of neural connections in the brain, and may be thought of as its "wiring diagram". From <a href="https://en.wikipedia.org/wiki/Connectome">this</a> page. </p></div>  </div></div></div><div class="status" id="postamble"><p class="date">Created: 2016-02-08 Mon 21:41</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://mcraveiro.blogspot.com/2016/01/nerd-food-interesting.html">Nerd Food: Interesting...</a></h2></div>
            <p class="text-muted">by <a href="http://mcraveiro.blogspot.com/">Marco Craveiro</a> on January 18, 2016 12:52 PM.</p>
          </div>
          <div class="panel-body">

            Nerd Food: Interesting…<div id="content"><p>Time to flush all those tabs again. Some interesting stuff I bumped into recently-ish. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">Finance, Economics, Politics</h2><div class="outline-text-2" id="text-1"><ul class="org-ul"><li><a href="https://www.project-syndicate.org/commentary/marginal-pricing-end-of-western-oil-producers-by-anatole-kaletsky-2015-12">Why Big Oil Should Kill Itself</a>: This is a really, really interesting article. The gist of it is that the entire logic around oil exploration is now a fallacy and it makes more economic sense to simply give up looking for oil because all oil that is left is just to expensive to commercialise. It also has a very interesting take on the valuation of oil companies (and sources of take overs) but I won't spoil it for you. If you are into oil (or against it), its a must read. </li><li><a href="http://krugman.blogs.nytimes.com/2016/01/16/oil-goes-nonlinear/">Oil Goes Nonlinear</a>: Short but thought provoking. I don't tend to agree with Krugman on a lot of things, but quite like this analysis. </li><li><a href="http://foreignpolicy.com/2015/12/31/africas-boom-is-over/?utm_content=bufferc093b&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer">Africa’s Boom Is Over</a>: And the bad news continue. Totally spot on analysis of what will befall us. </li><li><a href="http://startupboy.com/2016/01/15/american-spring/">American Spring</a>: interesting take on the state of affairs of American politics. Not sure I agree with everything, but definitely food for thought. "Statistically speaking, what are the odds that the two most qualified candidates to be president out of 300 million people are siblings? Or married?" Indeed. </li><li><a href="https://www.project-syndicate.org/commentary/sovereign-default-wave-emerging-markets-by-carmen-reinhart-2015-12#Z3gIvCtPUzZmf8PF.01">A Year of Sovereign Defaults?</a>: Very good and very scary. This has to be on the cards, the only question is the timing. </li><li><a href="https://www.washingtonpost.com/news/wonk/wp/2015/12/30/really-rich-people-are-suddenly-paying-quite-a-bit-more-in-taxes/">Really rich people are suddenly paying quite a bit more in taxes</a>: some good news on the equality front I guess. But not quite sure it makes much of a difference in the big scheme of US things. </li><li><a href="http://www.latimes.com/world/mexico-americas/la-fg-argentina-economy-new-president-20151230-story.html">Argentina's 'little trees' getting chopped down by new president</a>: Seems like Argentina is going to go through yet another turbulent period, with some good and bad news coming out. Interesting take on the impact to the less well off of the new policies. The chap is certainly a doer, it seems: <a href="http://linkis.com/www.economist.com/ne/HiAjy">A fast start</a>. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">Startups et al.</h2><div class="outline-text-2" id="text-2"><ul class="org-ul"><li><a href="https://www.oreilly.com/ideas/the-wtf-economy">The WTF Economy</a>: Tim O'Reilly (of publishing house fame) is setting up a conference in the future of work. Sounds extremely interesting. Hopefully, they will have a section dedicated to the developing world.  Source: Tim O'Reilly (Twitter) </li><li><a href="https://medium.com/@jgarzik/bitcoin-is-being-hot-wired-for-settlement-a5beb1df223a#.vn9b7chtk">Bitcoin is Being Hot-Wired for Settlement</a>: Garzik is at it again. Interesting news of cryptos in the settlement front. Source: Jeff Garzik (Twitter) </li><li><a href="http://www.wired.com/2015/12/elon-musks-billion-dollar-ai-plan-is-about-far-more-than-saving-the-world/?mbid=social_fb">Elon Musk’s Billion-Dollar AI Plan Is About Far More Than Saving the World</a>: So it seems Musk and Altman want to ensure AI plays nice. Not quite sure he's right on this one. Steven Levy's version is available <a href="https://medium.com/backchannel/how-elon-musk-and-y-combinator-plan-to-stop-computers-from-taking-over-17e0e27dd02a#.f3ydovlgu">here</a>, more of an interview with Musk. </li><li><a href="https://medium.com/backchannel/license-to-not-drive-6dbea84b9c45#.w9jh0xlyw">License to (Not) Drive</a>: Levy gets to try the Google self-driving cars. Very interesting. </li><li><a href="http://arches.io/2016/01/hire-literally-anyone/">Hire Literally Anyone</a>: Extremely interesting. I always thought the existing hiring practices are not very well thought out, but this article makes me realise that the flaws are deeper than I expected. While we are on this topic, this ain't too bad either: <a href="https://medium.com/swlh/how-to-hire-34f4ded5f176#.mb0pcnhda">How to Hire</a>. </li><li><a href="https://medium.com/@octskyward/the-resolution-of-the-bitcoin-experiment-dabb30201f7#.vk8lilnkk">The resolution of the Bitcoin experiment</a>: Great - nay - insanely great analysis on the state of affairs in the BTC world. Spoken with authority. </li><li><a href="https://tonyarcieri.com/on-the-dangers-of-a-blockchain-monoculture">On the dangers of a blockchain monoculture</a>: Pours more petrol in the raging BTC fire. Very interesting. Never saw BTC as a monoculture, but actually it so is. </li><li><a href="http://www.bloomberg.com/news/articles/2015-12-30/the-final-days-of-the-bitcoin-foundation-">The Final Days of the Bitcoin Foundation?</a>: And yet some more on the BTC impending doom. I just gotta stop reading about it now, the whole saga is far too depressing. Lets hope the technology survives where humans failed. </li><li><a href="http://www.coindesk.com/ibm-open-ledger-blockchain/?utm_content=buffer601ae&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer">IBM Talks Open Ledger Project, Bright Future for Blockchain</a>: Still trying to catch my breath on all the BTC articles coming out, and lo-and-behold, I missed the whole Open Ledger thing. </li><li><a href="https://www.policyalternatives.ca/publications/monitor/apploitation-city-instaserfs">Apploitation in a city of instaserfs</a>: Scary. Very scary. Reminiscent of the older Mirani article <a href="http://qz.com/312537/the-secret-to-the-uber-economy-is-wealth-inequality/">The secret to the Uber economy is wealth inequality</a>. San Francisco is becoming more like Mumbai and that is not good news. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">General Coding</h2><div class="outline-text-2" id="text-3"><ul class="org-ul"><li><a href="https://medium.com/@henrikjohansen/feeding-graph-databases-a-third-use-case-for-modern-log-management-platforms-d5dac8a80d53#.tqmmc91uy">Feeding Graph databases - a third use-case for modern log management platforms</a>: Very interesting ideas on how to use logging data in a graph database. Sounds extremely counter-intuitive, and then you start reading at which point its like "Damn, why didn't I think of that before!".  Source: Hacker News </li><li><a href="http://www.agner.org/optimize/blog/read.php?i=417">Moores law hits the roof</a>: Seems like the exponential function is revealing itself as a sigmoid, as everyone knew it would. Some of the cracks that are already present in Moore's law. Interesting to note that a transistor is now only a few silicon atoms wide - meaning we can't really make it much smaller. Source: Hacker News </li><li><a href="http://robotlolita.me/2016/01/09/no-i-dont-want-to-configure-your-app.html">No, I Don't Want To Configure Your App</a>: Call to arms to get us all thinking on just how many configuration knobs you need to use something. Source: Hacker News </li><li><a href="http://jameshunt.us/writings/your-ide-is-killing-you.html">Your IDE Is Killing You</a>: Somewhat preaching to the choir, since I am an Emacs user of old, but still a very cogent argument on why relying too much on IDEs is not a good thing. Source: Bruno Antunes (twitter) </li><li><a href="http://jlongster.com/Starters-and-Maintainers">Starters and Maintainers</a>: The different personas around an open source project. Interesting, its good to be aware of which hat you are wearing when. </li><li><a href="https://medium.com/backchannel/i-moved-to-linux-and-it-s-even-better-than-i-expected-9f2dcac3f8fb#.aakpzoln9">I Moved to Linux and It’s Even Better Than I Expected</a>: A feel good story about the Linux desktop. Given how slowly things are progressing on that front, we all need one of these some times to cheer us up. Main value of the article though. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-4"><h2 id="sec-4">Databases</h2><div class="outline-text-2" id="text-4"><ul class="org-ul"><li><a href="http://lwn.net/Articles/667946/">Encrypted databases with ZeroDB</a>: I'm not exactly impressed with the technology itself, but more with the ideas one can extract from it. Briefly: what if the database only stores encrypted data, which only each client can decrypt? This is certainly a very useful thing for certain types of information and a PostgreSQL extension would be most useful. Source: Hacker News </li><li><a href="http://rachbelaid.com/introduction-to-postgres-physical-storage/">Introduction to PostgreSQL physical storage</a>: Great article on Postgres low-level details. One to read if you want to get serious about the Elephant but are not yet in the know. </li><li><a href="http://tech.valgog.com/2012/01/schema-based-versioning-and-deployment.html">Schema based versioning and deployment for PostgreSQL</a>: Tips on how to manage versions for your stored procs, and also contains links for table management. For those of us not totally taken by NoSQL. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-5"><h2 id="sec-5">C++</h2><div class="outline-text-2" id="text-5"><ul class="org-ul"><li><a href="http://webcache.googleusercontent.com/search?q=cache:z7PWAldSxdQJ:sourceforge.net/p/sobjectizer/wiki/Lessons%252520learnt%252520from%25252010%252B%252520years%252520with%252520actors%252520in%252520C%252B%252B/+&amp;cd=1&amp;hl=en&amp;ct=clnk&amp;gl=uk">Lessons learnt from 10+ years with actors in C++</a>: The voice of experience talks about what they learned from using Actors over more than a decade. Worth reading if you are into that pattern. </li><li><a href="http://blog.scottfrees.com/automating-a-c-program-from-a-node-js-web-app">Automating a C++ program from a Node.js web app</a>: If you are considering exposing your C++ code into JS, this is a series of posts to read. </li><li><a href="https://medium.com/swlh/starting-a-tech-startup-with-c-6b5d5856e6de#.tocwuwbe8">Starting a tech startup with C++</a>: lots of libraries I never heard of and an insight on the performance differences between python and c++. </li><li><a href="https://medium.com/hacker-daily/writing-high-performance-servers-in-modern-c-7cd00926828#.hksbtpyoh">Writing modern C++ servers using Wangle:</a> The follow up to the previous post, explaining how to write servers with Facebook technologies. </li><li><a href="http://www.di.unipi.it/~nids/docs/i_want_my_pony_or_why_you_cannot_have_cpp_exceptions_with_a_stack_trace.html">I want my pony! Or why you cannot have C++ exceptions with a stack trace</a>: very interesting. Since I started using Boost.Exception I never missed the stack traces either. Source: Hacker News </li></ul></div></div> <div class="outline-2" id="outline-container-sec-6"><h2 id="sec-6">Layman Science</h2><div class="outline-text-2" id="text-6"><ul class="org-ul"><li><a href="http://www.forbes.com/sites/startswithabang/2015/12/23/why-string-theory-is-not-science/">Why String Theory Is Not A Scientific Theory</a>: Doesn't say a lot of new things, but its good to remind ourselves on what exactly do we mean when we say "Science". This would save us from a lot of grief, such as considering Economics as a Science. </li><li><a href="https://aeon.co/essays/why-do-scientists-dismiss-the-possibility-of-cold-fusion">The cold fusion horizon</a>: … talking about Science, I was surprised to find out that people are still talking seriously about cold fusion. Interesting article, because it takes the flip side of the Science coin: nothing should <i>not</i> be science unless it is <i>not</i>using the scientific method. Whilst up til now cold fusion has been more of a hoax, we should not discredit people who work on it provided they are following scientific principles. Who knows, they may be right in the end. Science is all about long-shots. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-7"><h2 id="sec-7">Other</h2><div class="outline-text-2" id="text-7"><ul class="org-ul"><li><a href="http://www.blastr.com/2015-12-23/exit-sandman-neil-gaiman-goes-depth-overture-one-2015s-best-comics">Exit Sandman: Neil Gaiman goes in-depth with Overture, one of 2015's best comics</a>: For the Sandman fans, the new (and last) Sandman book is all the rage. A great interview by the man himself. </li><li><a href="https://www.youtube.com/watch?v=MpkqfZ95jtw">Dear Zachary</a>: bumped into this via <i>Wait But Why</i>, and, as usual, great tip. Fantastic documentary. </li><li><a href="https://www.youtube.com/watch?v=GG9Anstjlro&amp;feature=youtu.be">Solaris</a>: Always wanted to watch this Tarkovsky movie and now it seems it is available online! This is part of an initiative described by Open Culture <a href="http://www.openculture.com/2010/07/tarkovksy.html">here</a>. Source: Bruno Antunes (twitter) </li><li><a href="https://www.youtube.com/watch?v=8BoKjQfMihs">Wittgenstein: A Wonderful Life</a>: Found a Wittgenstein documentary, but sadly haven't had time to watch it just yet. In my watch list though. </li><li><a href="http://therealnews.com/t2/index.php?option=com_content&amp;task=view&amp;id=31&amp;Itemid=74&amp;jumival=14293">Je ne suis pas Charlie</a>: Haven't yet watched it but seems thought-provoking. Watch listed. </li><li><a href="https://www.youtube.com/watch?v=THKCteQocns">Tulipa Ruiz - Efêmera - Album Completo</a>: New musical find in the Brazilian space (Portuguese). </li></ul></div></div></div><div class="status" id="postamble"><p class="date">Created: 2016-01-18 Mon 12:49</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://mcraveiro.blogspot.com/2016/01/nerd-food-on-product-backlogs.html">Nerd Food: On Product Backlog</a></h2></div>
            <p class="text-muted">by <a href="http://mcraveiro.blogspot.com/">Marco Craveiro</a> on January 18, 2016 12:01 AM.</p>
          </div>
          <div class="panel-body">

            Nerd Food: On Product Backlog<div id="content"><table border="0"><tbody><tr><td width="50%"></td><td width="50%"><p class="verse" style="text-align: left;"><small>Would be be good to have a better bug-tracking setup? Yes. But I think it takes man-power, and it would take something *fundamentally* better than bugzilla. <i>-- <a href="http://yarchive.net/comp/linux/bug_tracking.html">Linus</a></i></small></p></td></tr></tbody></table> <p>Many developers in large companies tend to be exposed to a strange variation of agile which I like to call "Enterprise Grade Agile", but I've also heard it called "Fragile" and, most aptly, "Cargo-Cult Agile". However you decide to name the phenomena, the gist of it is that these setups contain nearly all of the ceremony of agile - including stand-ups, sprint planning, retrospectives and so on - but none of its spirit. Tweets such as this are great at capturing the essence of the problem: </p> <blockquote class="twitter-tweet" lang="en"><p dir="ltr" lang="en">Top tip: if you need to bring a notepad to the daily stand up to tell us what you did yesterday that's too many details</p>— Fran Buontempo (@fbuontempo) <a href="https://twitter.com/fbuontempo/status/686856528696086528">January 12, 2016</a></blockquote>  <p>Once you start having that nagging feeling of doing things "because you are told to", and once your stand-ups become more of a status report to the "project manager" and/or "delivery manager" - the existence of which, in itself, is rather worrying - your Cargo Cult Agile alarm bells should start ringing. As I see it, agile is a toolbox with a number of tools, and they only start to add value once you've adapted them to your personal circumstances. The fitness function that determines if a tool should be used is how much value it adds to all (or at least most) of its users. If it does not, the tool must be further adapted or removed altogether. And, crucially, you learn about agile tools by using them and by reflecting on the lessons learned. There is no other way. </p> <p>This post is one such exercise and the tool I'd like to reflect on is the <i>Product Backlog</i>. Now, before you read through the whole rant, its probably worth saying that this post takes a slightly narrow and somewhat "advanced" view of agile, with a target audience of those already using it. If you require a more introductory approach, you are probably better off looking at other online resources such as <a href="http://zerodollarbill.blogspot.co.uk/2012/06/how-to-learn-scrum-in-10-minutes-and.html">How to learn Scrum in 10 minutes and clean your house in the process</a>. Having said that, I'll try to define terms best I can to make sure we are all on the same page. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">Working Definition</h2><div class="outline-text-2" id="text-1"><p>Once your company has grokked the basics of agile and starts to move away from those lengthy specification documents - those that no one reads properly until implementation and those that never specified anything the customer wanted, but everything we thought the customer wanted and then some - you will start to use the product backlog in anger. And that's when you will realise that it is not quite as simple as memorising text books. </p> <p>So what do the "text books" say? Let's take a fairly typical definition - this one from <a href="https://en.wikipedia.org/wiki/Scrum_(software_development)">Scrum</a>: </p> <blockquote><p>The agile product backlog in Scrum is a prioritized features list, containing short descriptions of all functionality desired in the product. When applying Scrum, it's not necessary to start a project with a lengthy, upfront effort to document all requirements. Typically, a Scrum team and its product owner begin by writing down everything they can think of for agile backlog prioritization. This agile product backlog is almost always more than enough for a first sprint. The Scrum product backlog is then allowed to grow and change as more is learned about the product and its customers.<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.1" id="fnr.1" name="fnr.1">1</a></sup></p></blockquote> <p>This is a good working definition, which will suffice for the purposes of this post. It is deceptively simple. However, as always, one must remember Yogi Berra: "In theory, there is no difference between theory and practice. But in practice, there is." </p></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">Potmenkin Product Backlogs</h2><div class="outline-text-2" id="text-2"><p>Many teams finish reading one such definition, find it amazingly inspiring, install the "agile plug-in" on their bug-tracking software of choice and then furiously start typing in those tickets. But if you look closely, you'd be hard-pressed to find any difference between the bug tickets of old versus the "stories" in the new and improved "product backlog" that apparently you are now using. </p> <p>This is a classic management disconnect, whereby a renaming exercise is applied and suddenly, <a href="https://en.wikipedia.org/wiki/Potemkin_village">Potemkin village-style</a>, we are now in with the kool kids and our company suddenly becomes a modern and desirable place to work. But much like Potemkin villages were not designed for real people to live in, so "Potmenkin Product Backlogs" are not designed to help you manage the lifecycle of a real product; they are there to give you the <i>appearance</i> of doing said management, for the purposes of reporting to the higher eschelons and so that you can tell stakeholders that "their story has been added to the product backlog for prioritisation". </p> <p>Alas, very soon you will find that the bulk of the "user stories" are nothing but glorified one-liners that no one seems to recall what exactly they're supposed to mean, and those few elaborately detailed tickets end up rotting because they keep being deprioritised and now describe a world long gone. Soon enough you will find that your sprint planning meetings will cover less and less of the product backlog - after all, who is able to prioritise this mess?  Some stories don't even make any sense! The final act is when all stories worked on are stories raised directly on the sprint backlog, and the product backlog is nothing but the dumping ground for the stories that didn't make it on a given sprint. At this stage, the product backlog is in such a terrible mess that no one looks at it, other than for the occasional historic search for valuable details on how a bug was fixed. Eventually the product backlog is zeroed - maybe a dozen or so of the most recent stories make it through the cull - and the entire process begins anew. Alas, enlightenment is never achieved, so you are condemned to repeat this cycle for all eternity. </p> <p>As expected, the Potmenkin Product Backlog adds very little value - in fact it can be argued that it detracts value - but it must be kept because "agile requires a product backlog". </p></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">Bug-Trackers: Lessons From History</h2><div class="outline-text-2" id="text-3"><p>In order to understand the difficulties with a product backlog, we turn next to their logical predecessors: bug-tracking systems such as <a href="https://www.bugzilla.org/">Bugzilla</a> or <a href="https://www.atlassian.com/software/jira">Jira</a>. This post starts with a quote from the kernel's Benevolent Dictator that illustrates the problem with these. Linus has long taken the approach that there is no need for a bug-tracker in kernel development, although he does not object if someone wants to use one for a subsystem. You may think this is a very primitive approach but in some ways it is also a <i>very</i> modern approach, very much in line with agile; if you have a bug-tracking system which is taking time away from developers without providing any value, you should <i>remove</i> the bug-tracking system. In kernel development, there simply is no space for ceremony - or, for that matter, for anything which slows things down<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.2" id="fnr.2" name="fnr.2">2</a></sup>. </p> <p>All of which begs the question: what makes bug-tracking systems so useless? From experience, there are a few factors: </p> <ul class="org-ul"><li>they are a "fire and forget" capture system. Most users only care about entering new data, rather than worrying about the lifecycle of a ticket. Very few places have some kind of "ticket quality control" which ensures that the content of the ticket is vaguely sensible, and those who do suffer from another problem: </li><li>they require dedicated teams. By this I don't just mean running the bug-tracking software - which you will most likely have to do in a proprietary shop; I also mean the entire notion of Q&amp;A and Testing as separate from development, with reams of people dedicated to setting "environments" up (and keeping them up!), organising database restores and other such activities that are incompatible with current best practices of software development. </li><li>they are temples of ceremony: a glance at the myriad of fields you need to fill in - and the rules and permutations required to get them exactly right - should be sufficient to put off even the most ardent believer in process. Most developers end up memorising some safe incantation that allows them to get on with life, without understanding the majority of the data they are entering. </li><li>as the underlying product ages, you will be faced with <a href="http://tinyletter.com/programming-beyond-practices/letters/the-sad-graph-of-software-death">the sad graph of software death</a>. The main problem is that resources get taken away from systems as they get older, a phenomena that manifests itself as a growth in the delta between the number of open tickets against the number of closed tickets. This is actually a <i>really</i> useful metric but one that is often ignored.<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.3" id="fnr.3" name="fnr.3">3</a></sup>. </li></ul> <p>And what of the newest iterations on this venerable concept such as <a href="https://guides.github.com/features/issues/">GitHub Issues</a>? Well, clearly they solve a number of the problems above - such as lowering the complexity and cost barriers - and certainly they do serve a very useful purpose: they allow the efficient management of user interactions. Every time I create an issue - such as this <a href="https://github.com/flycheck/flycheck/issues/852">one</a> - it never ceases to amaze me how easily the information flows within GitHub projects; one can initiate comms with the author(s) or other users with <i>zero setup</i> - something that previously required mailinglist membership, opening an account on a bug-tracker and so forth. We now take all of this for granted, of course, but it is important to bear in mind that many open source projects would probably not even have <i>any</i> form of user interaction support, were it not for GitHub. After all, most of them are a one-person shop with very little disposable time, and it makes no sense to spend part of that time maintaining infrastructure for the odd person or two who may drop by to chat. </p> <p>However, for all of its glory, it is also important to bear in mind that GitHub Issues is <b>not</b> a product backlog solution. What I mean by this is that the product backlog must be owned by the team that owns the product and, as we shall see, it must be carefully groomed if it is to be continually useful. This is at loggerheads with allowing free flow of information from users. Your Issues will eventually be filled up with user requests and questions which you may not want to address, or general discussions which may or may not have a story behind it. They are simply different tools for different jobs, albeit with an overlap in functionality. </p> <p>So, history tells us what does not work. But is the product backlog even worth all this hassle? </p></div></div> <div class="outline-2" id="outline-container-sec-4"><h2 id="sec-4">Voyaging Through Strange Seas of Thought</h2><div class="outline-text-2" id="text-4"><p>One of the great things about agile is how much it reflects on itself; a strange loop of sorts. Presentations such as Kevlin Henney's <a href="http://www.infoq.com/presentations/architecture-uncertainty">The Architecture of Uncertainty</a> are part of this continual process of discovery and understanding, and provide great insights about the fundamental nature of the development process. The product backlog plays - or should play - a crucial role exactly because of this uncertain nature of software development. We can explain this by way of a device. </p> <p>Imagine that you start off by admitting that you know very little about what it is that you are intending to do and that the problem domain you are about to explore is vast and complex. In this scenario, the product backlog is the sum total of the knowledge gained whilst exploring this space that has yet not been transformed into source code. Think of it like the explorer's maps in the fifteen-hundreds. In those days, "users" knew that much of it was incorrect and a great part was sketchy and ill-defined, but it was all you had. Given that the odds of success were stacked against you, you'd hold that map pretty tightly while the storms were raging about you. Those that made it back would provide corrections and amendments and, over time, the maps eventually converged with the real geography. </p> <p>The product backlog does something similar, but of course, the space you are exploring does not have a fixed geometry or topography and your knowledge of the problem domain can actively <i>change</i> the domain itself too - an unavoidable consequence of dealing with pure thought stuff. But the general principle applies. Thus, in the same way <a href="http://www.joelonsoftware.com/articles/fog0000000069.html">a code base is precious</a> because it embodies the sum total knowledge of a domain - heck, in many ways it <i>is</i> the sum total knowledge of a domain! - so the product backlog is precious because it captures all the known knowledge of these yet-to-be-explored areas. In this light, you can understand statements such as this: </p> <blockquote class="twitter-tweet" lang="en"><p dir="ltr" lang="en">When your product backlog is empty, your product is dead - <a href="https://twitter.com/KevlinHenney">@KevlinHenney</a><a href="https://twitter.com/hashtag/agileotb?src=hash">#agileotb</a></p>— Marc Johnson (@marcjohnson) <a href="https://twitter.com/marcjohnson/status/507522331900915712">September 4, 2014</a></blockquote> <p>So, if the backlog is this important, how should one manage it? </p></div></div> <div class="outline-2" id="outline-container-sec-5"><h2 id="sec-5">Works For Me, Guv!</h2><div class="outline-text-2" id="text-5"><p>Up to this point - whilst we were delving into the problem space - we have been dealing with a fairly general argument, likely applicable to many. Now, as we enter the solution space, I'm afraid I will have to move from the general to the particular and talk only about the specific circumstances of my one-man-project <a href="https://github.com/DomainDrivenConsulting/dogen">Dogen</a>. You can find Dogen's product backlog <a href="https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/product_backlog.org">here</a>. </p> <p>This may sound like a bit of a cop out, you may say, and not without reason: how on earth are you supposed to extrapolate conclusions from a one-person open source project to a team of N working on a commercial product? However, it is also important to take into account what I said at the start: agile is what you make of it. I personally think of it as a) the smallest amount of processes required to make your development process work smoothly and b) and the continual improvement of those processes. Thus, there are no one-size-fits-all solutions; all one can do is to look at others for ideas. So, lets look at my findings<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.4" id="fnr.4" name="fnr.4">4</a></sup>. </p> <p>The first and most important thing I did to help me manage my product backlog was to use a simple text file in <a href="http://orgmode.org/">Org Mode</a> notation. Clearly, this is not a setup that is workable for a development team much larger than a set of one, or one that doesn't use Emacs (or <a href="https://github.com/hsitz/VimOrganizer">Vim</a>). But for my particular circumstances it has worked <i>wonders</i>: </p> <ul class="org-ul"><li>the product backlog is close to the code, so wherever you go, you take it with you. This means you can always search the product backlog and - most importantly - add to it <i>wherever</i> you are and <i>whenever</i> an idea happens to come by. I use this flexibility frequently. </li><li>the Org Mode interface makes it really easy to move stories up and down (order is taken to mean priority here) and to create "buckets" of stories according to whatever categorisation you decide to use, up to any level of nesting. At some point you end up converging to a reasonable level of nesting, of course. It is surprising how one can manage <b>very</b> large amounts of stories thanks to this flexible tree structure. </li><li>it's trivial to move stories in and out of a sprint, keeping track of all changes to a story - they are just text that can be copy and pasted and committed. </li><li>Org Mode provides a very capable <a href="http://orgmode.org/manual/Tags.html">tagging system</a>. I first started by overusing these, but when tagging got too fine grained it became unmaintainable. Now we use too few - just <code>epic</code> and <code>story</code> - so this will have to change again in the near future. For example, it should be trivial to add tags for different components in the system or to mark stories as bugs or features, etc. <a href="http://orgmode.org/manual/Tag-searches.html#Tag-searches">Searching</a> then allows you to see a subset of the stories that match those labels. </li></ul> <p>A second decision which has proven to be a very good one has been to groom the product backlog <i>very often</i>. And by this I don't just mean a cursory look, but a deep inspection of <i>all</i> stories, fixing them where required. Again, the choice of format has proved very helpful: </p> <ul class="org-ul"><li>it is easy to mark all stories as "non-reviewed" or some other suitable tag in Org Mode, and then unmark them as one finishes the groom - thereby ensuring all stories get some attention. As the product backlog becomes larger, a full groom could take multiple sprints, but this is not an issue once you understand its value and the cost of having it rot. </li><li>because the product backlog is with the code, any downtime can be used for grooming; those idle weekends or that long wait at the airport are perfect candidates to get a few stories looked at. Time spent waiting for the build is also a good candidate. </li><li>you get an HTML representation of the Org Mode file for free in GitHub, meaning you can read your backlog from your phone. And with the new editing functionality, you can also edit stories too. </li></ul> <p>Thirdly, I decided to take a "multi-pass" approach at managing the story lifecycle. These are some of the key aspects of this lifecycle management: </p> <ul class="org-ul"><li>stories can only be captured if they are aligned with the <a href="https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/vision.org">vision</a>. This filter saves me from adding all sorts of ideas which are just too "out of the left field" to be of practical use, but keeps <a href="https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/product_backlog.org#visionary-work-and-random-ideas">those that may sound crazy</a> are but aligned with the vision. </li><li>stories can only be captured if there is no "prior art". I always perform a number of searches in the backlog to look for anything which covers similar ground. If found, I append to that. </li><li>new stories tend to start with very little content - just the minimum required to allow resetting state back to the idea I was trying to capture. Due to this, very little gets lost. At this point, we have a "proto-story". </li><li>as time progresses, I end up having more ideas on this space, and I update the story with those ideas - mainly bullet points with one liners and links. </li><li>at some point the story begins to mature; there is enough on it that we can convert the "proto-story" to a full blown story. After a number of grooms, the story becomes fully formed and is then a candidate to be moved to a sprint backlog for implementation. It may stay in this state <i>ad-infinitum</i>, with periodic updates just to make sure it does not rot. </li><li>A candidate story can still get refined: trimmed in scope, re-targeted, or even cancelled because it no longer fits with the current architecture or even the vision. Cancelled stories are important because we may came back to them - its just very unlikely that we do. </li><li>every sprint has a "sprint mission"<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.5" id="fnr.5" name="fnr.5">5</a></sup>. When we start to move stories into the sprint backlog, we look for those which resonate with the sprint mission. Not all of them are fully formed, and the work on the sprint can entail the analysis required to create a full blown story. But many will be implementable directly off of the product backlog. </li><li>some times I end up finding related threads in multiple stories and decide to merge them. Merging of related stories is done by simply copying and pasting them into a single story; over time, with the multiple passes done in the grooms, we end up again with a single consistent story. </li></ul> <p>What all of this means is that a story can evolve over time in the product backlog, only to become the exact thing you need at a given sprint; at that point you benefit from the knowledge and insight gained over that long period of time. Some stories in Dogen's backlog have been there for years, and when I finally get to them, I find them extremely useful. Remember: they are a map to the unknown space you are exploring. </p> <p>With all of this machinery in place, we've ended up with a very useful product backlog for Dogen - one that certainly adds a lot of value. Don't take me wrong, the cost of maintenance is high and I'd rather be coding instead of maintaining the product backlog, especially given the limited resources. But I keep it because I can see on a daily basis how much it improves the overall quality of the development process. It is a price I find worth paying, given what I get in return. </p></div></div> <div class="outline-2" id="outline-container-sec-6"><h2 id="sec-6">Final Thoughts</h2><div class="outline-text-2" id="text-6"><p>This post was an attempt to summarise some of the thoughts I've been having on the space of product backlogs. One of its main objectives was to try to convey the importance of this tool, and to provide ideas on how you can improve the management of your own product backlog by discussing the approach I have taken with Dogen. </p> <p>If you have any suggestions or want to share your own tips on how to manage your product backlog please reach me on the comments section - there is always space for improvement. </p></div></div><div id="footnotes"><h2 class="footnotes">Footnotes: </h2><div id="text-footnotes"> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.1" id="fn.1" name="fn.1">1</a></sup> <p class="footpara">Source: <a href="https://www.mountaingoatsoftware.com/agile/scrum/product-backlog">Scrum Product Backlog</a>, Mountain Goat Software. </p></div> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.2" id="fn.2" name="fn.2">2</a></sup> <p class="footpara">A topic which I covered some time ago here: <a href="http://mcraveiro.blogspot.co.uk/2008/06/nerd-food-on-evolutionary-methodology.html">On Evolutionary Methodology</a>. It is also interesting to see how the kernel processes are organised for speed: <a href="http://lwn.net/Articles/670209/">How 4.4's patches got to the mainline</a>. </p></div> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.3" id="fn.3" name="fn.3">3</a></sup> <p class="footpara">Another topic which I also covered here some time ago: <a href="http://mcraveiro.blogspot.co.uk/2007/05/nerd-food-on-maintenance.html">On Maintenance</a>. </p></div> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.4" id="fn.4" name="fn.4">4</a></sup> <p class="footpara">I am self-plagiarising a little bit here and rehashing some of the arguments I've used before in <a href="http://mcraveiro.blogspot.co.uk/2014/09/nerd-food-dogen-lessons-in-incremental.html">Lessons in Incremental Coding</a>, mainly from section DVCS to the Core. </p></div> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.5" id="fn.5" name="fn.5">5</a></sup> <p class="footpara">See the <a href="https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/sprint_backlog_78.org">current sprint backlog</a> for an example. </p></div>  </div></div></div><div class="status" id="postamble"><p class="date">Created: 2016-01-17 Sun 23:55</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://mcraveiro.blogspot.com/2015/12/nerd-food-dogen-package-management-saga.html">Nerd Food: Dogen: The Package Management Saga</a></h2></div>
            <p class="text-muted">by <a href="http://mcraveiro.blogspot.com/">Marco Craveiro</a> on December 22, 2015 02:01 PM.</p>
          </div>
          <div class="panel-body">

            Nerd Food: Dogen: The Package Management Saga<div id="content"><p>We've just gone past <a href="https://github.com/DomainDrivenConsulting/dogen">Dogen's</a> <a href="https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/sprint_backlog_75.org">Sprint 75</a>, so I guess it's time for one of those "reminiscing posts" - something along the lines of what we did for <a href="http://mcraveiro.blogspot.co.uk/2014/09/nerd-food-dogen-lessons-in-incremental.html">Sprint 50</a>. This one is a bit more practical though; if you are only interested in the practical side, keep scrolling until you see "Conan". </p> <p>So, package management. Like any other part-time C++ developer whose professional mainstay is C# and Java, I have keenly felt the need for a package manager when in C++-land. The problem is less visible when you are working with mature libraries and dealing with just Linux, due to the huge size of the package repositories and the great tooling built around them. However, things get messier when you start to go cross-platform, and messier still when you are coding on the bleeding edge of C++: either the package you need is not available in the distro's repos or even <a href="https://launchpad.net/ubuntu/+ppas">PPA's</a>; or, when it is, its rarely at the version you require. </p> <p>Alas, for all our sins, that's exactly where we were when <a href="https://github.com/DomainDrivenConsulting/dogen">Dogen</a> got started. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">A Spoonful of Dogen History</h2><div class="outline-text-2" id="text-1"><p>Dogen sprung to life just a tad after C++-0x became <a href="https://en.wikipedia.org/wiki/C%252B%252B11">C++-11</a>, so we experienced first hand the highs of a quasi-new-language followed by the lows of feeling the brunt of the bleeding edge pain. For starters, <i>nothing</i> we ever wanted was available out of the box, on any of the platforms we were interested in. Even Debian testing was a bit behind - probably stalled due to a compiler transition or other, but I can't quite recall the details. In those days, Real Programmers were Real Programmers and mice were mice: we had to <a href="http://mcraveiro.blogspot.co.uk/2012/06/nerd-food-c-11-with-gcc.html">build and install the C++ compilers ourselves</a> and, even then, C++-11 support was new, a bit flaky and limited. We then had to use those compilers to compile all of the dependencies in C++-11 mode. </p></div> <div class="outline-3" id="outline-container-sec-1-1"><h3 id="sec-1-1">The PFH Days</h3><div class="outline-text-3" id="text-1-1"><p>After doing this manually once or twice, it soon stopped being fun. And so we solved this problem by creating the PFH - the Private Filesystem Hierarchy - a gloriously over-ambitious name to describe a set of wrapper scripts that helped with the process of downloading tarballs, unpacking, building and finally installing them into well-defined locations. It worked well enough in the confines of its remit, but we were often outside those, having to apply out-of-tree patches, adding new dependencies and so on. We also didn't use Travis in those days - not even sure it existed, but if it did, the rigmarole of the bleeding edge experience would certainly put a stop to any ideas of using it. So we used a local install of CDash with a number of build agents on OSX, Windows (MinGW) and Linux (32-bit and 64-bit). Things worked beautifully when nothing changed and the setup was stable; but, every time a new version of a library - or god forbid, of a compiler - was released, one had that sense of dread: do I <b>really</b> need to upgrade? </p> <p>Since one of the main objectives of Dogen was to learn about C++-11, one has to say that the pain was worth it. But all of the moving parts described above were not ideal and they were certainly not the thing you want to be wasting your precious time on when it is very scarce. They were certainly not scalable. </p></div></div> <div class="outline-3" id="outline-container-sec-1-2"><h3 id="sec-1-2">The Good Days and the Bad Days</h3><div class="outline-text-3" id="text-1-2"><p>Things improved slightly for a year or two when distros started to ship C++-11 compliant compilers and recent boost versions. It was all so good we were able to move over to <a href="https://travis-ci.org/DomainDrivenConsulting/dogen">Travis</a> and ditch almost all of our private infrastructure. For a while things looked really good. However, due to Travis' <a href="https://wiki.ubuntu.com/LTS">Ubuntu LTS</a> policy, we were stuck with a rapidly ageing Boost version. At first PPAs were a good solution for this, but soon these became stale too. We also needed to get latest CMake as there are a lot of developments on that front, but we certainly could not afford (time-wise) to revert back to the bad old days of the PFH. At the same time, it made no sense to freeze dependencies in time, providing a worse development experience. So the only route left was to break Travis and hope that some solution would appear. Some alternatives were tried such as <a href="https://drone.io/github.com/DomainDrivenConsulting/dogen">Drone.io</a> but nothing was successful. </p> <p>There was nothing else for it; what was needed was a package manager to manage the development dependencies. </p></div></div> <div class="outline-3" id="outline-container-sec-1-3"><h3 id="sec-1-3">Nuget Hopes Dashed</h3><div class="outline-text-3" id="text-1-3"><p>Having used <a href="https://www.nuget.org/">Nuget</a> in anger for both C# and C++ projects, and given Microsoft's recent change of heart with regards to open source, I was secretly hoping that Nuget would get some traction in the wider C++ world. To recap, Nuget worked <a href="http://mcraveiro.blogspot.co.uk/2014/05/nerd-food-using-mono-in-anger-part-ii_3422.html">well enough in Mono</a>; in addition, C++ support for Windows was added <a href="http://blogs.msdn.com/b/vcblog/archive/2013/04/26/nuget-for-c.aspx">early on</a>. It was somewhat limited and a bit quirky at the start, but it kept on getting better, to the point of usability. Trouble was, their focus was just Visual Studio. </p> <p>Alas, nothing much ever came from my Nuget hopes. However, there have been a couple of recent announcements from Microsoft that make me think that they will eventually look into this space: </p> <ul class="org-ul"><li><a href="http://blogs.msdn.com/b/vcblog/archive/2015/12/04/introducing-clang-with-microsoft-codegen-in-vs-2015-update-1.aspx">Clang with Microsoft CodeGen in VS 2015 Update 1</a></li><li><a href="http://blogs.msdn.com/b/vcblog/archive/2015/12/15/support-for-android-cmake-projects-in-visual-studio.aspx">Support for Android CMake projects in Visual Studio</a></li></ul> <p>Surely the logical consequence is to be able to manage packages in a consistent way across platforms? We can but hope. </p></div></div> <div class="outline-3" id="outline-container-sec-1-4"><h3 id="sec-1-4">Biicode Comes to the Rescue?</h3><div class="outline-text-3" id="text-1-4"><p>Nuget did not pan out but what did happen was even more unlikely: some crazy-cool Spaniards decided to create a stand alone package manager. Being from the same peninsula, I felt compelled to use their wares, and was joyful as they went from strength to strength - including the success of their <a href="https://www.biicode.com/biicode-open-source-challenge">open source campaign</a>. And I loved the fact that it integrated really well with <a href="https://cmake.org">CMake</a>, and that <a href="https://www.jetbrains.com/clion/">CLion</a>provided Biicode integration very early on. </p> <p>However, my biggest problem with Biicode was that it was just too complicated. I don't mean to say the creators of the product didn't have very good reasons for their technical choices - lord knows creating a product is hard enough, so I have nothing but praise to anyone who tries. However, for me personally, I never had the time to understand why Biicode needed its own version of CMake, nor did I want to modify my CMake files too much in order to fit properly with Biicode and so on. Basically, I needed a solution that worked well and required minimal changes at my end. Having been brought up with Maven and Nuget, I just could not understand why there wasn't a simple "packages.xml" file that specified the dependencies and then some non-intrusive CMake support to expose those into the CMake files. As you can see from some of <a href="http://forum.biicode.com/t/building-out-of-tree-using-biicode/460">my posts</a>, it just seemed it required "getting" Biicode in order to make use of it, which for me was not an option. </p> <p>Another thing that annoyed me was the difficulty on knowing what the "real" version of a library was. I wrote, at the time: </p> <blockquote><p>One slightly confusing thing about the process of adding dependencies is that there may be more than one page for a given dependency and it is not clear which one is the "best" one. For RapidJson there are three options, presumably from three different Biicode users: </p> <ul class="org-ul"><li><a href="https://www.biicode.com/fenix/rapidjson">fenix</a>: authored on 2015-Apr-28, v1.0.1. </li><li><a href="https://www.biicode.com/hithwen/rapidjson">hithwen</a>: authored 2014-Jul-30 </li><li><a href="https://www.biicode.com/denis/rapidjson">denis</a>: authored 2014-Oct-09 </li></ul> <p>The "fenix" option appeared to be the most up-to-date so I went with that one. However, this illustrates a deeper issue: how do you know you can trust a package? In the ideal setup, the project owners would add Biicode support and that would then be the one true version. However, like any other project, Biicode faces the initial adoption conundrum: people are not going to be willing to spend time adding support for Biicode if there aren't a lot of users of Biicode out there already, but without a large library of dependencies there is nothing to draw users in. In this light, one can understand that it makes sense for Biicode to allow anyone to add new packages as a way to bootstrap their user base; but sooner or later they will face the same issues as all distributions face. </p> <p>A few features would be helpful in the mean time: </p> <ul class="org-ul"><li>popularity/number of downloads </li><li>user ratings </li></ul> <p>These metrics would help in deciding which package to depend on. </p></blockquote> <p>For all these reasons, I never found the time to get Biicode setup and these stories lingered in Dogen's backlog. And the build continued to be red. </p> <p>Sadly Biicode the company <a href="http://blog.biicode.com/biicode-just-the-company-post-mortem/">didn't make it either</a>. I feel very sad for the guys behind it, because their heart was on the right place. </p> <p>Which brings us right up to date. </p></div></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">Enter Conan</h2><div class="outline-text-2" id="text-2"><p>When I was a kid, we were all big fans of Conan. No, not <a href="https://en.wikipedia.org/wiki/Conan_the_Barbarian">the barbarian</a>, the Japanese Manga <a href="https://en.wikipedia.org/wiki/Future_Boy_Conan">Future Boy Conan</a>. For me the name Conan will always bring back great memories of this show, which we watched in the original Japanese with Portuguese subtitles. So I was secretly pleased when I found <a href="https://www.conan.io/">conan.io</a>, a new package management system for C++. The guy behind it seems to be one of the original Biicode developers, so a lot of lessons from Biicode were learned. </p> <p>To cut a short story short, the great news is I managed to add Conan support to Dogen in roughly <a href="https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/sprint_backlog_77.org#add-support-for-conanio">3 hours</a> and with very minimal knowledge about Conan. This to me was a litmus test of sorts, because I have very little interest in package management - creating my own product has proven to be challenging enough, so the last thing I need is to divert my energy further. The other interesting thing is that roughly half of that time was taken by trying to get Travis to behave, so its not quite fair to impute it to Conan. </p></div> <div class="outline-3" id="outline-container-sec-2-1"><h3 id="sec-2-1">Setting Up Dogen for Conan</h3><div class="outline-text-3" id="text-2-1"><p>So, what changes did I do to get it all working? It was a very simple 3-step process. First I installed Conan using a Debian package from <a href="https://www.conan.io/downloads">their site</a>. </p> <p>I then created a <code>conanfile.txt</code> on my top-level directory: </p> <pre class="example"><br />[requires]<br />Boost/1.60.0@lasote/stable<br /><br />[generators]<br />cmake<br /></pre> <p>Finally I modified my top-level <code>CMakeLists.txt</code>: </p> <pre class="example"><br /># conan support<br />if(EXISTS "${CMAKE_BINARY_DIR}/conanbuildinfo.cmake")<br />    message(STATUS "Setting up Conan support.")<br />    include("${CMAKE_BINARY_DIR}/conanbuildinfo.cmake")<br />    CONAN_BASIC_SETUP()<br />else()<br />    message(STATUS "Conan build file not found, skipping include")<br />endif()<br /></pre> <p>This means that it is entirely possible to build Dogen without Conan, but if it is present, it will be used. With these two changes, all that was left to do was to build: </p> <pre class="example"><br />$ cd dogen/build/output<br />$ mkdir gcc-5-conan<br />$ conan install ../../..<br />$ make -j5 run_all_specs<br /></pre> <p><i>Et voila</i>, I had a brand spanking new build of Dogen using Conan. Well, actually, <i>not quite</i>. I've omitted a couple of problems that are a bit of a distraction on the Conan success story. Let's look at them now. </p></div></div> <div class="outline-3" id="outline-container-sec-2-2"><h3 id="sec-2-2">Problems and Their Solutions</h3><div class="outline-text-3" id="text-2-2"><p>The first problem was that Boost 1.59 does not appear to have an overridden <code>FindBoost</code>, which means that I was not able to link. I moved to Boost 1.60 - which I wanted to do any way - and it worked out of the box. </p> <p>The second problem was that Conan seems to get confused with <a href="https://ninja-build.org/manual.html">Ninja</a>, my build system of choice. For whatever reason, when I use the Ninja generator, it fails like so: </p> <pre class="example"><br />$ cmake ../../../ -G Ninja<br />$ ninja -j5<br />$ ninja: error: '~/.conan/data/Boost/1.60.0/lasote/stable/package/ebdc9c0c0164b54c29125127c75297f6607946c5/lib/libboost_system.so', needed by 'stage/bin/dogen_utility_spec', missing and no known rule to make it<br /></pre> <p>This is very strange because boost system is clearly available in the Conan download folder. Using make solved this problem. I am going to open a ticket on the Conan GitHub project to investigate this. </p> <p>The third problem is more boost related than anything else. Boost Graph has not been as well maintained as it should, really. Thus users now find themselves carrying patches, and all because no one seems to be able to apply them upstream. Dogen is in this situation as we've hit the issue described here: <a href="http://stackoverflow.com/questions/25395805/compile-error-with-boost-graph-1-56-0-and-g-4-6-4">Compile error with boost.graph 1.56.0 and g++ 4.6.4.</a> Sadly this is still present on Boost 1.60; the patch exists in Trac but remains unapplied (<a href="https://svn.boost.org/trac/boost/ticket/10382">#10382</a>). This is a tad worrying as we make a lot of use of Boost Graph and intend to increase the usage in the future. </p> <p>At any rate, as you can see, none of the problems were showstoppers, nor can they all be attributed to Conan. </p></div></div> <div class="outline-3" id="outline-container-sec-2-3"><h3 id="sec-2-3">Getting Travis to Behave</h3><div class="outline-text-3" id="text-2-3"><p>Once I got Dogen building locally, I then went on a mission to convince Travis to use it. It was painful, but mainly because of the lag between commits and hitting an error. The core of the changes to my YML file were as follows: </p> <pre class="example"><br />install:<br />&lt;snip&gt;<br />  # conan<br />  - wget https://s3-eu-west-1.amazonaws.com/conanio-production/downloads/conan-ubuntu-64_0_5_0.deb -O conan.deb<br />  - sudo dpkg -i conan.deb<br />  - rm conan.deb<br />&lt;snip&gt;<br />script:<br />  - export GIT_REPO="`pwd`"<br />  - cd ${GIT_REPO}/build<br />  - mkdir output<br />  - cd output<br />  - conan install ${GIT_REPO}<br />  - hash=`ls ~/.conan/data/Boost/1.60.0/lasote/stable/package/`<br />  - cd ~/.conan/data/Boost/1.60.0/lasote/stable/package/${hash}/include/<br />  - sudo patch -p0 &lt; ${GIT_REPO}/patches/boost_1_59_graph.patch<br />  - cmake ${GIT_REPO} -DWITH_MINIMAL_PACKAGING=on<br />  - make -j2 run_all_specs<br />&lt;snip&gt;<br /></pre> <p>I probably should have a bash script by know, given the size of the YML, but hey - if it works. The changes above deal with installation of the package, applying the boost patch and using Make instead of Ninja. Quite trivial in the end, even though it required a lot of iterations to get there. </p></div></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">Conclusions</h2><div class="outline-text-2" id="text-3"><p>Having a red build is a very distressful event for a developer, so you can imagine how painful it has been to have red builds for <i>several months</i>. So it is with unmitigated pleasure that I got to see <a href="https://travis-ci.org/DomainDrivenConsulting/dogen/builds/98304957">build #628</a> in a shiny emerald green. As far as that goes, it has been an unmitigated success. </p> <p>In a broader sense though, what can we say about Conan? There are many positives to take home, even at this early stage of Dogen usage: </p> <ul class="org-ul"><li>it is a lot less intrusive than Biicode and easier to setup. Biicode was very well documented, but it was easy to stray from the beaten track and that then required reading a lot of different wiki pages. It seems easier to stay on the beaten track with Conan. </li><li>as with Biicode, it seems to provide solutions to Debug/Release and multi-platforms and compilers. We shall be testing it on Windows soon and reporting back. </li><li>hopefully, since it started Open Source from the beginning, it will form a community of developers around the source with the know-how required to maintain it. It would also be great to see if a business forms around it, since someone will have to pay the cloud bill. </li></ul> <p>In terms of negatives: </p> <ul class="org-ul"><li>I still believe the most scalable approach would have been to extend Nuget for the C++ Linux use case, since Microsoft is willing to take patches and since they foot the bill for the public repo. However, I can understand why one would prefer to have total control over the solution rather than depend on the whims of some middle-manager in order to commit. </li><li>it seems publishing packages requires getting down into Python. Haven't tried it yet, but I'm hoping it will be made as easy as importing packages with a simple text file. The more complexity around these flows the tool adds, the less likely they are to be used. </li><li>there still are no "official builds" from projects. As explained above, this is a chicken and egg problem, because people are only willing to dedicate time to it once there are enough users complaining. Having said that, since Conan is easy to setup, one hopes to see some adoption in the near future. </li><li>even when using a GitHub profile, one still has to define a Conan specific password. This was not required with Biicode. Minor pain, but still, if they want to increase traction, this is probably an unnecessary stumbling block. It was sufficient to make me think twice about setting up a login, for one. </li></ul> <p>In truth, these are all very minor negative points, but still worth making them. All and all, I am quite pleased with Conan thus far. </p></div></div></div><div class="status" id="postamble"><p class="date">Created: 2015-12-22 Tue 14:00</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://mcraveiro.blogspot.com/2015/12/nerd-food-interesting_21.html">Nerd Food: Interesting...</a></h2></div>
            <p class="text-muted">by <a href="http://mcraveiro.blogspot.com/">Marco Craveiro</a> on December 21, 2015 11:32 PM.</p>
          </div>
          <div class="panel-body">

            Nerd Food: Interesting…<div id="content"><p>Time to flush all those tabs again. Some interesting stuff I bumped into recently-ish. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">Finance, Economics, Politics</h2><div class="outline-text-2" id="text-1"><ul class="org-ul"><li><a href="http://qz.com/564513/a-not-so-brief-history-of-the-fall-and-fall-of-the-nigerian-naira/">A (not so) brief history of the fall and fall of the Nigerian naira</a>: Very good read for Angolans; if nothing else, it makes us understand that our precious Kwanza behaves in many ways like any other petro-currency. Source: <a href="https://twitter.com/KingDouyeAlfred/status/675280673561710592">King Alfred (twitter)</a>. </li><li><a href="https://www.youtube.com/watch?v=SRjwZvLo_hI">#ThisIsACoup - Episode 1- "Angela, suck our balls"</a>: A rather political take on the recent-ish financial mess in Greece. On a similar vein, BBC's <a href="http://www.bbc.co.uk/programmes/b06s1s5x">A Greek Drama</a> is worth a listen. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">Startups et al.</h2><div class="outline-text-2" id="text-2"><ul class="org-ul"><li><a href="http://techcrunch.com/2015/12/16/brazils-congress-has-shut-down-whatsapp-tonight-and-the-rest-of-the-social-web-could-be-next/?ncid=rss#.xiisrb:Oo9T">Brazilian Judge Shuts Down WhatsApp And Brazil’s Congress Wants To Shut Down The Social Web Next</a>: One of the most enlightened internet countries decides to shut it all down. Sad day for the Internet and for all Portuguese speakers. Source: Hacker News (twitter) </li><li><a href="http://www.wired.com/2015/12/bitcoins-creator-satoshi-nakamoto-is-probably-this-unknown-australian-genius/">Bitcoin’s Creator Satoshi Nakamoto Is Probably This Unknown Australian Genius</a>: So they found Satoshi (again). Hesitated in adding this link, to be totally honest - there have been far too many fakes to recount and the whole process is such a media circus that its best avoiding it altogether. But after reading it - questionable media behaviour notwhitstanding - it does appear to provide some insights into these bitcoin early days. Useful to anyone who likes BTC. There is also the <a href="http://gizmodo.com/this-australian-says-he-and-his-dead-friend-invented-bi-1746958692">Gizmodo report</a>, with additional evidence. This is all getting a bit too much for my liking though. </li><li><a href="https://blog.jolla.com/jolla-back-business/">Jolla is back in business!</a>: Good to hear Jolla is still going. Now that my Firefox OS phone is no longer supported, I am keen on getting a Jolla. Source: Hacker News (twitter) </li><li><a href="https://bitcoinmagazine.com/articles/tech-and-banking-giants-join-forces-with-the-linux-foundation-to-create-new-open-source-blockchain-hyperledger-1450384716">Tech and Banking Giants Join Forces with the Linux Foundation to Create New Open Source Blockchain 'Hyperledger'</a>: In truth, hard not to be sceptical - even though it's coming from the Linux Foundation. I guess - in this world of <a href="http://radar.oreilly.com/2015/01/blockchain-scalability.html">scalability wars</a> - this must come as good news. However, I still think there is a lot of misunderstanding around Bitcoin and the Blockchain, and there are far too many "AOLs" out there trying to create their gated communities, failing to understand history (again). Not quite sure on which side of the fence to place this initiative but, alas, I'm more inclined towards the AOL side. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">General Coding</h2><div class="outline-text-2" id="text-3"><ul class="org-ul"><li><a href="http://spectrum.ieee.org/view-from-the-valley/computing/software/yahoos-engineers-move-to-coding-without-a-net">Yahoo’s Engineers Move to Coding Without a Net</a>: How removing a testing team can help reduce the bug count and ramp up productivity. Source: <a href="https://twitter.com/newsycombinator/status/675420147365060608">Hacker News (twitter)</a></li><li><a href="http://githubengineering.com/move-fast/">Move Fast and Fix Things</a>: An <i>incredible</i> tale of real engineering from the GitHub guys with lots of take-ins - <a href="https://github.com/github/scientist">Scientist</a> is a pretty neat idea, for one. Worth a read and a re-read. Logically related to the previous article. Source: Hacker News (twitter) </li><li><a href="https://medium.com/@thi.ng/the-jacob-s-ladder-of-coding-4b12477a26c1#.v80mhs3cv">The Jacob’s Ladder of coding</a>: Reminiscences on our beloved profession of coding. Long and deep, so still parsing. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-4"><h2 id="sec-4">Databases</h2><div class="outline-text-2" id="text-4"><ul class="org-ul"><li><a href="https://wiki.postgresql.org/wiki/What's_new_in_PostgreSQL_9.5">What's new in PostgreSQL 9.5</a>: The RC's are starting and 9.5 looks to continue the trend of amazing Postgres releases. My only missing wish is for native (and full) support for bitemporality really, though to be fair <a href="http://pgxn.org/dist/temporal_tables/">Temporal Tables</a> is probably enough for <a href="http://clarkdave.net/2015/02/historical-records-with-postgresql-and-temporal-tables-and-sql-2011/">my needs</a>. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-5"><h2 id="sec-5">C++</h2><div class="outline-text-2" id="text-5"><ul class="org-ul"><li><a href="http://www.agner.org/optimize/optimizing_cpp.pdf">Optimizing software in C++</a>: One to bookmark now but to digest later. A whole load of stuff on optimisation. </li><li><a href="http://blogs.msdn.com/b/vcblog/archive/2015/12/15/support-for-android-cmake-projects-in-visual-studio.aspx">Support for Android CMake projects in Visual Studio</a>: So, as if the latest patches to Clang hadn't been enough, MS now decides to add support for CMake in Visual Studio. A bit embryonic, and a bit too android focused, but surely it should be extensible for more regular C++ use. Whats going on at MS? This is all far too cool to be true. </li><li><a href="http://probablydance.com/2015/12/19/quickly-loading-things-from-disk/">Quickly Loading Things From Disk</a>: interesting analysis about the state of affairs of serialisation in C++. I'll probably require a few passes to fully digest it. </li><li><a href="https://www.youtube.com/watch?v=FYtBv_OosYw">Beyond ad-hoc automation: leveraging structured platforms</a>: I've been consuming this presentation slowly but steadily. It deals with a lot of the questions we all have about the new world of containers and microservices, and it seems vital to learn from experience before one finds oneself in a much bigger mess than the monolith could ever get you into. Bridget Kromhout talks intelligently about the subject. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-6"><h2 id="sec-6">Layman Science</h2><div class="outline-text-2" id="text-6"><ul class="org-ul"><li><a href="http://wavewatching.net/2014/03/31/the-church-of-d-wave/">The Church of D-Wave</a>: So is D-Wave a quantum computer or not? It appears the verdict is "not", even with the 2X and the <a href="http://googleresearch.blogspot.co.uk/2015/12/when-can-quantum-annealing-win.html">Google paper</a>. </li><li><a href="https://www.youtube.com/watch?v=qZM9JREjnp4">Intelligence and the Brain</a>: Oldish but still very good and relevant. Another high-level introduction to HTM. </li><li><a href="https://www.newscientist.com/article/dn28452-nasa-probe-shows-how-solar-burps-may-have-stripped-mars-of-water/">NASA probe shows how solar burps may have stripped Mars of water</a>: How the sun could be responsible for stripping water away from the red planet. </li><li><a href="https://www.youtube.com/watch?v=GcQWZG50zX0">Artificial Intelligence Through Hierarchical Temporal Memory</a>: Continuing my adventures in the HTM space, Dr. Paul Cottrell is my latest find. I'm still not totally sure I understand all concepts in this video but what I do understand - assuming they have succeeded in doing what he describes - seem mondo-cool. Basically, it's all about the application of HTM to Finance and trading. He also introduces the idea of adding sub-cortical machinery to HTM (which is just cortical); a most puzzling concept. Once I finish parsing this video, I intend to move to <a href="https://www.youtube.com/watch?v=dDD7D-fm7Wc&amp;feature=youtu.be">Neuroscience Foundation For Artificial Intelligence</a>. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-7"><h2 id="sec-7">Other</h2><div class="outline-text-2" id="text-7"><ul class="org-ul"><li><a href="https://www.youtube.com/watch?v=6FFAQuJZmOA">Benjamin Clementine - Le Ring - Live</a>: Haven't totally made up my mind about Benjamin Clementine, but certainly a very interesting performance. </li></ul></div></div></div><div class="status" id="postamble"><p class="date">Created: 2015-12-21 Mon 23:31</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://mcraveiro.blogspot.com/2015/12/nerd-food-pull-request-driven.html">Nerd Food: Pull Request Driven Development</a></h2></div>
            <p class="text-muted">by <a href="http://mcraveiro.blogspot.com/">Marco Craveiro</a> on December 11, 2015 03:48 PM.</p>
          </div>
          <div class="panel-body">

            Nerd Food: Pull Request Driven Development<div id="content"><p>Being in this game for the best part of twenty years, I must confess that its not often I find something that revolutionises my coding ways. I do tend to try a lot of things, but most of them end up revealing themselves as fads or are incompatible with my flow. For instance, I never managed to get <a href="https://en.wikipedia.org/wiki/Behavior-driven_development">BDD</a> to work for me, try as I might. I will keep trying because it sounds really useful, but it hasn't clicked just yet. </p> <p>Having said all of that, these moments of enlightenment do occasionally happen, and when they do, nothing beats that life-changing feeling. "Pull Request Driven Development" (or PRDD) is my latest find. I'll start by confessing that "PRDD" as a name was totally made up for this post and hopefully you can see its rather tongue in cheek. However, the benefits of this approach are very real. In fact, I've been using PRDD for a while now but I just never really noticed its presence creeping in. Today, as I introduced a new developer to the process, I finally had the eureka moment and saw just how brilliant it has been thus far. It also made me realise that some people are not aware of this great tool in the developer's arsenal. </p> <p>But first things first. In order to explain what I mean by PRDD, I need to provide a bit of context. Everyone is migrating to git these days, even those of us locked behind corporate walls; in our particular case, the migration path implied exposure to <a href="https://en.wikipedia.org/wiki/Stash_(software)">Git Stash</a>. For those not in the know, picture it as an expensive and somewhat less featureful version of <a href="https://github.com/">GitHub</a>, but with most of the core functionality there. Of course, I'm sure GitHub is not that cheap for enterprises either, but hey at least its the tool everyone uses. Anyway - grumbling or not - we moved to Stash and all development started to revolve around Pull Requests (PRs), raised for each new <a href="https://www.atlassian.com/git/tutorials/comparing-workflows/feature-branch-workflow">feature</a>. </p> <p>Not long after PRs were introduced, a particularly interesting habit started to appear: developers begun opening the PRs earlier and earlier during the feature cycle rather than waiting to the very end. Taking this approach to the limit, the idea is that when you start to work on a new feature, you raise the ticket and the PR <i>before you write any code at all</i>. In practice - due to Stash's anachronisms - you need to push at least one commit, but the general notion is valid. This was never mandated anywhere, and there was no particular coordination. I guess one possible explanation for this behaviour is that one wants to get rid of the paperwork as quickly as possible to get to the coding. At any rate, the causes may be obscure but the emerging behaviour was not. </p> <p>When you combine early PRs with the <a href="https://sethrobertson.github.io/GitBestPractices/">commit early and commit often</a>approach - which you should be using anyway - the PR starts to become a living document; people see your development work as it progresses and they start commenting on it and possibly even sending you patches <i>as you go along</i>. In a way, this is an enabler for a very efficient kind of peer programming - particularly if you have a tightly knit team - because it gives you maximum parallelism but in a very subtle, non-noticeable way. The main author of the PR is coding as she would normally be, but whenever there is a lull in development - those moments where you'd be browsing the web for five minutes or so - you can quickly check for any comments on your PR and react to those. Similarly, other developers can carry on doing their own work and browse the PRs on their downtime; this allows them to provide feedback whenever it is convenient <i>to them</i>, and to choose the format of the feedback - lengthy or quick, as time permits. </p> <p>Quick feedback is many a times invaluable in large code bases because everyone tends to know their own little corner of the code and only very few old hands know how it all hangs together. Thus, seemingly trivial one liners such as "have you considered using API xyz instead of rolling your own" or "don't forget to do abc when you do that" could save you <i>many</i> hours of pain and enable knowledge to be transferred organically - something that no number of wiki pages could hope to achieve in a million years because its very difficult to find these pearls in a sea of uncurated content. And because you committed early and often, each commit is very small and very easy to parse in a small interval of time, so people are much more willing to review - as opposed to that several Kb (or even Mb!) patch that you will have to allocate a day or two for. Further: if you <a href="http://chris.beams.io/posts/git-commit/">take your commit message seriously</a> - as, again, you should - you will find that the number of reviewers will grow rapidly simply because developers are nosy and opinionated. </p> <p>Note that this review process involves no vague meetings and no lengthy and unfocused email chains; it is very high-quality because it is (or can be) very focused to specific lines of code; it causes no unwanted disruptions because you review where and when you choose to review; reviewers can provide examples and even fix things themselves if they so choose; it is totally inclusive because anyone who wants to participate can, but no one is forced to; and it equalises local and remote developers because they all have access to the same data (modulus some IRL conversations that always take place) - an important feature in this world of near-shoring, off-shoring and home-working. Most importantly, instead of finding out some fundamental errors of approach at the end of an intense period of coding, you now have timely feedback. This saves an <i>enormous</i> amount of time - an advantage that anyone who has been through lengthy code reviews and then spent a week or two reacting to that feedback can appreciate. </p> <p>I am now a believer in PRDD. So much so that whenever I go back to work on legacy projects in svn, I find myself cringing all the way to the end of the feature. It just feels so nineties. </p> <p><b>Update:</b> As I finished penning this post and started reflecting about it it suddenly dawned on me that a lot of things we now take for granted are only  possible because of git. And I don't mean DVCS', I specifically mean git. For  example PRDD is made possible to a large extent because committing in git is a  reversible process and history can be fluid if required. This means that people are not afraid of committing, which in turn enables a lot of the goodness I described  above. Many DVCS' didn't like this way of viewing history - and to be fair, I know of very few people that liked the idea until they started using it. Once you figure out what it is good for (and not so good for), it suddenly becomes an amazing tool. Git is full of little decisions like this that at first sight look either straight insane or just not particularly useful but then turn out to change entire development flows. </p> </div><div class="status" id="postamble"><p class="date">Created: 2015-12-11 Fri 13:12</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://mcraveiro.blogspot.com/2015/12/nerd-food-interesting.html">Nerd Food: Interesting...</a></h2></div>
            <p class="text-muted">by <a href="http://mcraveiro.blogspot.com/">Marco Craveiro</a> on December 09, 2015 03:02 PM.</p>
          </div>
          <div class="panel-body">

            Nerd Food: Interesting…<div id="content"><p>Time to flush all those tabs again. Some interesting stuff I bumped into recently-ish. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">Finance, Economics, Politics</h2><div class="outline-text-2" id="text-1"><ul class="org-ul"><li><a href="https://www.propublica.org/article/debt-collection-lawsuits-squeeze-black-neighborhoods">The Color of Debt: How Collection Suits Squeeze Black Neighborhoods</a>: Another great example of how markets are not so efficient for certain things and not exactly fair. </li><li><a href="http://www.economist.com/news/briefing/21678215-world-entering-third-stage-rolling-debt-crisis-time-centred-emerging">Pulled back in</a>: The Economist's take on how the emerging markets credit bubble will play out. Not sure if I agree with their analysis, but its certainly very worrying to see so much EM debt piling up in such a volatile world. </li><li><a href="http://www.politico.com/magazine/story/2015/11/isil-whos-calling-the-shots-213360">ISIL: Who’s Calling the Shots?</a>: Interesting analysis, much better than the usual superficial take one is used to from mass-media. </li><li><a href="http://www.newyorker.com/magazine/2015/08/31/the-other-france">The Other France</a>: As with the previous article, I cannot help but be surprised - even more so with this one. Truly, an amazing, in-depth job. Surprisingly good coming from the American media. If you have watched <a href="http://www.imdb.com/title/tt0113247/">La Haine</a>, read this. If you have read this, watch La Haine. </li><li><a href="https://www.youtube.com/watch?v=iavquu6PP9g">Elon Musk talks Climate Change and Carbon Tax at the Sorbone (12.2.15)</a>: Musk raises some interesting points, as usual, such as why we need to tax carbon or else. </li><li><a href="http://www.theguardian.com/society/2015/nov/29/future-of-work-gig-sharing-economy-juggling-jobs">'My father had one job in his life, I've had six in mine, my kids will have six at the same time'</a>: The Guardian's take in this new world of job displacement and "job context switching". Very interesting. </li><li><a href="https://www.youtube.com/watch?v=LZbsxs_VGtQ&amp;feature=youtu.be">Ship it! QuantLib, IPython Notebook, and Docker</a>: QuantLib conference is over, and sadly there are very few videos. This one bucks the trend. The ever informative Luigi talks about how QuantLib is moving with the times. </li><li><a href="http://www.theguardian.com/business/2015/dec/07/morgan-stanley-axes-400-bankers-bonds-jobs?CMP=Share_AndroidApp_Seesmic">Morgan Stanley axes 400 bankers as bond-trading income dives</a>: The contraction of the traditional banking industry continues, even as cryptos are growing insanely. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">Startups et al.</h2><div class="outline-text-2" id="text-2"><ul class="org-ul"><li><a href="http://blog.erratasec.com/2015/12/tesla-is-copying-apples-business-model.html#.VmL8A3VX9hG">Tesla is copying Apple's business model</a>: very interesting comparison between Tesla and Apple's businesses. I don't fully agree with the article, but to be fair it does raise a number of interesting points. I definitely think that when Tesla can deliver mass-market quantities they will dominate sales in a similar fashion to the iPhone. </li><li><a href="http://www.theguardian.com/technology/2015/nov/29/arm-cambridge-britain-tech-company-iphone">ARM: Britain's most successful tech company you've never heard of</a>: Short history of ARM. It would be great to have a book about these guys! </li><li><a href="https://medium.com/backchannel/doordash-wants-to-own-the-last-mile-27c03098a657">DoorDash Wants to Own the Last Mile</a>: interesting story of a startup that focuses on "last mile" delivery. </li><li><a href="https://www.bitpesa.co">BitPesa</a>: cool African start-up in the BitCoin / MPesa space. </li><li><a href="http://ventureburn.com/2015/10/lulalend-true-fintech-company-mixing-tech-finance/">LulaLend</a>: Another cool African start-up that is doing well in the payments space. </li><li><a href="https://www.youtube.com/watch?v=SqEo107j-uw">Elon Musk and Y Combinator President on Thinking for the Future</a>: Altman and Musk discuss the future. Shame the presenter is not a bit geekier or it could have been one of the best. </li><li><a href="https://www.youtube.com/watch?v=WwrEQklDoyE">Elon Musk with his Brother Kimbal Musk on a panel</a>: Since we're doing the Musk fanboy thing, here's a great panel with Elon and his brother. A more personal view of his achievements. </li><li><a href="http://www.bloomberg.com/news/articles/2015-11-24/jeff-bezos-vs-elon-musk-a-thrilling-new-space-race">Jeff Bezos vs. Elon Musk: A Thrilling, New Space Race</a>: More Musk fanboying; lets go all the way and read up on the latest about the space race. Very interesting. </li><li><a href="https://www.youtube.com/watch?v=u6IZRjP39do">Tesla Shareholders Meeting June 2015</a>: Final Musk fanboying. I think Tesla is one of the few companies where non-shareholders tune in just to listen and get inspiration. Elon, nerdy and awkward but great and inspiring as always. Choice quote: "I'd expect SpaceX to go public once we get regular flights to mars." - very few people could get away with a statement like that. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">General Coding</h2><div class="outline-text-2" id="text-3"><ul class="org-ul"><li><a href="http://www.nytimes.com/2015/11/13/technology/gene-amdahl-pioneer-of-mainframe-computing-dies-at-92.html?smprod=nytcore-ipad&amp;smid=nytcore-ipad-share">Gene Amdahl, Pioneer of Mainframe Computing, Dies at 92</a>: I've heard the name a lot but never really read about the man. </li><li><a href="http://jvns.ca/blog/2015/11/21/why-you-should-understand-a-little-about-tcp/">Why you should understand (a little) about TCP</a>: The new generation discovers the joys of understanding low-level protocols. And Nagle (yes, he of <a href="https://en.wikipedia.org/wiki/Nagle%2527s_algorithm">Nagle Algorithm</a> fame) replies on that thread. </li><li><a href="https://www.youtube.com/channel/UCvq_RgZp3kljp9X8Io9Z1DA">systemd.conf</a>: Videos from the conference. Have watched a couple, seemed like a lively conference. Hard to imagine an init system with its own conference though! </li></ul></div></div> <div class="outline-2" id="outline-container-sec-4"><h2 id="sec-4">Databases</h2><div class="outline-text-2" id="text-4"><ul class="org-ul"><li><a href="http://blog.2ndquadrant.com/when-are-we-going-to-contribute-bdr-to-postgresql/">When are we going to contribute BDR to PostgreSQL?</a>: For those (like me) who keep moaning about the lack of <a href="https://en.wikipedia.org/wiki/Multi-master_replication">BDR</a> in Postgres, a great explanation of how the patchset is being merged. Great work by the 2nd Quadrant guys. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-5"><h2 id="sec-5">C++</h2><div class="outline-text-2" id="text-5"><ul class="org-ul"><li><a href="http://blog.llvm.org/2015/11/new-elf-linker-from-llvm-project.html">New ELF Linker from the LLVM Project</a>: LLVM keeps on delivering! Now a new ELF linker. To be totally honest, I haven't even started using <a href="https://en.wikipedia.org/wiki/Gold_(linker)">Gold</a> in anger - I get the feeling the LLVM linker is going to be transitioned in much quicker than Gold. </li><li><a href="http://blogs.msdn.com/b/vcblog/archive/2015/12/04/introducing-clang-with-microsoft-codegen-in-vs-2015-update-1.aspx">Clang with Microsoft CodeGen in VS 2015 Update 1</a>: OMG, OMG how cool is this - MSFT decided to create a backend for Clang that is totally compatible with MSVC <span class="underline">AND</span> open source it! This is just insane. This means for example that you now can develop C++ on Windows without ever having to use MSVC and Visual Studio. It also means you can cross-compile from Linux into Windows with 100% certainty things will work. It means that projects like <a href="https://www.winehq.org/">Wine</a> and <a href="https://www.reactos.org/">ReactOS</a> can start thinking about a migration path into Clang (not quite as simple as it may sound but surely makes sense). <a href="https://www.jetbrains.com/clion/">CLion</a> with Clang on Windows will rock. The possibilities are just endless. I never quite understood what C2 was all about until I read this announcement - <a href="http://www.theregister.co.uk/2015/10/21/microsoft_promises_clang_for_windows_in_november_visual_c_update/">suddenly it all makes sense</a>. This is <i>fantastic</i> news. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-6"><h2 id="sec-6">Layman Science</h2><div class="outline-text-2" id="text-6"><ul class="org-ul"><li><a href="http://www.wired.com/brandlab/2015/05/jeff-hawkins-firing-silicon-brain/">Jeff Hawkins on Firing Up the Silicon Brain</a>: OK, let me totally honest: I <span class="underline">love</span> Jeff Hawkins. I read On Intelligence far too many times to count and would be lying if I didn't admit that it had a little bit to do with my forays into Computational Neuroscience. So as you can imagine, I'm rather excited about <a href="https://en.wikipedia.org/wiki/Hierarchical_temporal_memory">HTM</a>and <a href="https://en.wikipedia.org/wiki/Numenta">Numenta's</a> latest developments. This article is a good catch-up, if slightly high-level. If you want something slightly more technical but still very approachable, <a href="https://www.youtube.com/watch?v=6ufPpZDmPKA">Principles of Hierarchical Temporal Memory (HTM): Foundations of Machine Intelligence</a> is a must watch. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-7"><h2 id="sec-7">Other</h2><div class="outline-text-2" id="text-7"><ul class="org-ul"><li><a href="https://www.youtube.com/watch?v=lWJkrP4WPFw">NoiseRV Live</a>: Still discovering this Portuguese musician, but love his work. Great concert. Could do a little bit less talking between songs, but still - artists prerogative and all that. </li><li><a href="http://bff.fm/broadcasts/4499">Warm Focus: Winging It</a>: Interesting set of "intelligent dance music" as we used to call it back in the day. </li><li><a href="https://overcast.fm/+Bj7wZZ3Mg">Mosaic - The “First” Web Browser</a>: Super-cool podcasts about internet history. It would be great to have something like this for UNIX! </li><li><a href="https://www.youtube.com/watch?v=0va3F2PWBJc">Jackson C. Frank (1965)</a>: Tragic musician from the 60s. Great tunes. </li><li><a href="http://www.gutenberg.org/files/15000/15000-h/vol1.html">Reason in common sense</a>: Always wanted to read Santayana properly. Started, but I guess it will be a <span class="underline">very</span> long exercise. Interesting, if somewhat strange book. </li><li><a href="https://www.youtube.com/watch?v=OSD1mud8JZ8">Ceu - jazz baltica Live (2010)</a>: New find, Brazilian musician Ceu. </li></ul></div></div></div><div class="status" id="postamble"><p class="date">Created: 2015-12-09 Wed 12:49</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://mcraveiro.blogspot.com/2015/11/nerd-food-tooling-in-computational_30.html">Nerd Food: Tooling in Computational Neuroscience - Part II: Microscopy</a></h2></div>
            <p class="text-muted">by <a href="http://mcraveiro.blogspot.com/">Marco Craveiro</a> on December 01, 2015 04:43 PM.</p>
          </div>
          <div class="panel-body">

            Nerd Food: Tooling in Computational Neuroscience - Part II: Microscopy<div id="content"><p class="verse" style="text-align: right;"><small>Research is what I'm doing when I don't know what I'm doing. <br /><i>Wernher von Braun</i></small></p> <p>Welcome to the second instalment of our second series on Computational Neuroscience for lay people. You can find the first post of the previous series <a href="http://mcraveiro.blogspot.co.uk/2015/08/nerd-food-neurons-for-computer-geeks.html">here</a>, and the first post of the current series <a href="http://mcraveiro.blogspot.co.uk/2015/11/nerd-food-tooling-in-computational.html">here</a>. As you'd expect, this second series is slightly more advanced, and, as such, it is peppered with unavoidable technical jargon. Having said that, we shall continue to pursue our ambitious target of making things as easy to parse as possible (but no easier). If you read the first series, the second should hopefully make some sense.<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.1" id="fnr.1" name="fnr.1">1</a></sup></p> <p>Our <a href="http://mcraveiro.blogspot.co.uk/2015/11/nerd-food-tooling-in-computational.html">last post</a> discussed <a href="https://en.wikipedia.org/wiki/Computational_neuroscience">Computational Neuroscience</a> as a discipline, and the kind of things one may want to do in this field. We also spoke about models and their composition, and the desirable properties of a platform that runs simulations of said models. However, it occurred to me that we should probably build some kind of "end-to-end" understanding; that is, by starting with the simulations and models we are missing a vital link with the physical (i.e. non-computational) world. To put matters right, this part attempts to provide a high-level introduction on how data is acquired from the real world and can then be used - amongst other things - to inform the modeling process. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">Macro and Micro Microworlds</h2><div class="outline-text-2" id="text-1"><p>For the purposes of this post, the data gathering process starts with the microscope. Of course, keep in mind that we are focusing only on the <i>morphology</i> at present - the shape and the structures that make up the neuron - so we are ignoring other important activities in the lab. For instance, one can conduct experiments to measure voltage in a neuron, and these measurements provide data for the functional aspects of the model. Alas, we will skip these for now, with the promise of returning to them at a later date<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.2" id="fnr.2" name="fnr.2">2</a></sup>. </p> <p>So, microscopes then. <a href="https://en.wikipedia.org/wiki/Microscopy">Microscopy</a> is the technical name for the observation work done with the microscope. Because neurons are so small - some 4 to 100 microns in size - only certain types of microscopes are suitable to perform neuronal microscopy. To make matters worse, the sub-structures inside the neuron are an important area of study and they can be ridiculously small: a <a href="https://en.wikipedia.org/wiki/Dendritic_spine">dentritic spine</a> - the minute protrusions that come out of the dendrites - can be as tiny as 500 nanometres; the lipid bylayer itself is only 2 or 3 nanometres thick, so you can imagine how incredibly small ion channels and pumps are. Yet these are some of the things we want to observe and measure. Lets call this the "micro" work. On the other hand, we also want to understand connectivity and other larger structures, as well as perform observations of the evolution of the cell and so on. Lets call this the "macro" work. These are not technical terms, by the by, just so we can orient ourselves. So, how does one go about observing these differently sized microworlds? </p>  <div class="figure"><p><img alt="F1.large.jpg" height="300px" src="http://www.pnas.org/content/106/39/16877/F1.large.jpg" width="300px" /></p><p><span class="figure-number">Figure 1:</span> Example of measurements one may want to perform on a dendrite. Source: <a href="http://www.pnas.org/content/106/39/16877.abstract">Reversal of long-term dendritic spine alterations in Alzheimer disease models</a></p></div></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">Optical Microscopy</h2><div class="outline-text-2" id="text-2"><p>The "macro" work is usually done using the <a href="https://en.wikipedia.org/wiki/Optical_microscope">Optical</a> "family" of microscopes, which is what most of us think of when hearing the word microscope. As it was with <a href="https://en.wikipedia.org/wiki/Microscope">Van Leeuwenhoek's</a> tool in the sixteen hundreds, so it is that today's optical microscopes still rely on light and lenses to perform observations. Needless to say, things did evolve a fair bit since then, but standard optical microscopy has not completely removed the shackles of its limitations. These are of three kinds, as Wikipedia helpfully <a href="https://en.wikipedia.org/wiki/Microscopy#Optical_microscopy">tells us</a>: a) the objects we want to observe must be dark or strongly refracting - a problem, since the internal structures of the cell are transparent; b) visible light's <a href="https://en.wikipedia.org/wiki/Diffraction-limited_system">diffraction limit</a> means that we cannot go much lower than 200 nanometres - pretty impressive, but unfortunately not quite low enough for detailed sub-structure analysis; and c) out of focus light hampers image clarity. </p> <p>Workarounds to these limitations have been found in the guise of <i>techniques</i>, with the aim of augmenting the abilities of standard optical microscopy. There are many of these techniques. There is the <a href="https://en.wikipedia.org/wiki/Confocal_microscopy">Confocal Microscopy</a><sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.3" id="fnr.3" name="fnr.3">3</a></sup> - improving resolution and contrast; the <a href="https://en.wikipedia.org/wiki/Fluorescence_microscope">Fluorescence microscope</a>, which uses a <i><a href="https://en.wikipedia.org/wiki/Microscopy#Sub-diffraction_techniques">sub-diffraction technique</a></i>to reconstruct some of the detail that is missing due to diffraction; or the incredible-looking movies produced by <a href="http://blogs.scientificamerican.com/expeditions/journey-through-the-brain-multiphoton-microscopy/">Multiphoton Microscopy</a>. And of course, it is possible to combine multiple techniques in a single microscope, as is the case with the <a href="https://en.wikipedia.org/wiki/Multiphoton_fluorescence_microscope">Multiphoton Fluorescence Microscopes</a> (MTMs) and many others. </p> <p>In fact, given all of these developments, it seems there is no sign of optical microscopy dying out. Presumably some of this is due to the relative lower cost of this approach as well as to the ease of use. In addition, optical microscopy is complementary to the other more expensive types of microscopes; it is the perfect tool for "macro" work that can then help to point out where to do "micro" work. For example, you can use an optical microscope to assess the larger structures and see how they evolve over time, and eventually decide on specific areas that require more detailed analysis. And when you do, you need a <i>completely</i> different kind of microscope. </p></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">Electron Microscopy</h2><div class="outline-text-2" id="text-3"><p>When you need <i>really</i> high-resolution, there is only one tool to turn to: the <a href="https://en.wikipedia.org/wiki/Electron_microscope">Electron Microscope (EM)</a>. This crazy critter can provide <i>insane</i> levels of magnification by using a beam of electrons instead of visible light. Just how insane, you ask? Well, if you think that an optical microscope lives in the range of 1500x to 2000x - that is, can magnify a sample up to two thousand times - an EM can magnify as much as 10 <span class="underline">million times</span>, and provide a sub-nanometre resolution<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.4" id="fnr.4" name="fnr.4">4</a></sup>. It is mind boggling. If fact, we've already seen images of atoms using EM in <a href="http://mcraveiro.blogspot.co.uk/2015/08/nerd-food-neurons-for-computer-geeks_31.html">part II</a>, but perhaps it wasn't easy to appreciate just how amazing a feat that is. </p> <p>Of course, EM is itself a family - and a large one at that, with many and diverse members. As with optical microscopy, each member of the family specialises on a given technique or combination of techniques. For example, the <a href="https://en.wikipedia.org/wiki/Scanning_electron_microscope">Scanning Electron Microscope</a> (SEM) performs a scan of the object under study, and has a resolution of 1 nanometre or higher; the <a href="https://en.wikipedia.org/wiki/Scanning_confocal_electron_microscopy">Scanning Confocal Electron Microscope (SCEM)</a>uses the same confocal technique mentioned above to provide higher depth resolution; and <a href="https://en.wikipedia.org/wiki/Transmission_electron_microscopy">Transmission Electron Microscopy</a> (TEM) has the ability to penetrate inside the specimen during the imagining process, given samples with thickness of 100 nanometres or less. </p> <p>A couple of noteworthy points are required at this juncture. First, whilst some of these EM techniques may sound new and exciting, most have been around for a <i>very</i> long time; it just seems they keep getting better and better as they mature. For example, TEM was used in the fifties to show that neurons communicate over synaptic junctions but its still wildly popular today. Secondly, its important to understand that the entire imaging process is not at all trivial - certainly not for TEM, nor EM in general and probably not for Optical Microscopy either. It just is a <i>very</i> labour intensive and <i>very</i>specialised process - most likely done by an expert human neuroanatomist - and the difficulties range from the chemical preparation of the samples all the way up to creating the images. The end product may give the impression it was easy to produce, but easy it was not. </p> <p>At any rate, whatever the technical details, the fact is that the imagery that results from all these advances is truly evocative - haunting, even. Take this image produced by SEM: </p>  <div class="figure"><p><img alt="2014_06_26_human_ipsc_derived_neuron_deerinck.jpg" height="300px" src="http://ucsdnews.ucsd.edu/news_uploads/2014_06_26_human_ipsc_derived_neuron_deerinck.jpg" width="300px" /></p><p><span class="figure-number">Figure 2:</span> Human neuron. <a href="http://ucsdnews.ucsd.edu/pressrelease/new_reprogramming_method_makes_better_stem_cells">Source: New Reprogramming Method Makes Better Stem Cells</a></p></div> <p>Personally, I think it is incredibly beautiful; simultaneously awe-inspiring and depressing because it really conveys the messiness and complexity of wetware. By way of contrast, look at the neatness of man-made micro-structures: </p>  <div class="figure"><p><img alt="bluegeneq%20x%20420.jpg" height="300px" src="http://m.eet.com/media/1118299/bluegeneq%20x%20420.jpg" width="300px" /></p><p><span class="figure-number">Figure 3:</span> The BlueGene/Q chip. Source: <a href="http://www.eetimes.com/document.asp?doc_id=1260096">IBM plants transactional memory in CPU</a></p></div></div></div> <div class="outline-2" id="outline-container-sec-4"><h2 id="sec-4">Stacks and Stacks of 'Em</h2><div class="outline-text-2" id="text-4"><p>Technically, pictures like the ones above are called <a href="https://en.wikipedia.org/wiki/Micrograph">micrographs</a>. As you can see in the neuron micrograph, these images provide a great visual description of the topology of the object we are trying to study. You also may notice a slight coloration of the cell in that picture. This is most likely due to the fact that the people doing the analysis <a href="https://en.wikipedia.org/wiki/Staining">stain</a> the neuron to make it easier to image. Now, in practice - at least as far as I have seen, which is not very far at all, to be fair - 2D grayscale images are preferred by researchers to the nice, Public Relations friendly pictures like the one above; those appear to be more useful for magazine covers. The working micrographs are not quite as exciting to the untrained eye but very useful to the professionals. Here's an example: </p>  <div class="figure"><p><img alt="fetch.php?w=900&amp;tok=d88a10&amp;media=wiki:biomed-neurons.jpg" height="200px" src="http://www.leet.it/home/giusti/website/lib/exe/fetch.php?w=900&amp;tok=d88a10&amp;media=wiki:biomed-neurons.jpg" width="600px" /></p><p><span class="figure-number">Figure 4:</span> The left-hand side shows the original micrograph. On the right-hand side it shows the result of processing it with machine learning. Source: <a href="http://papers.nips.cc/paper/4741-deep-neural-networks-segment-neuronal-membranes-in-electron-microscopy-images.pdf">Deep Neural Networks Segment Neuronal Membranes in Electron Microscopy Images</a></p></div> <p>Let's focus on the left-hand side of this image for the moment. It was taken using <i>ssTEM</i> - serial-section TEM, an evolutionary step in TEM. The <i>ss</i> part of ssTEM is helpful in creating <i>stacks</i> of images, which is why you see the little drawings on the left of the picture; they are there to give you the idea that the top-most image is one of 30 in a stack<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.5" id="fnr.5" name="fnr.5">5</a></sup>. The process of producing the images above was as follows: they started off with a neuronal tissue sample, which is prepared for observation. The sample had 1.5 micrometres and was then sectioned into 30 slices of 50 nanometres. Each of these slices was imaged, at a resolution of 4x4 nanometres per pixel. </p> <p>As you can imagine, this work is extremely sensitive to measurement error. The trick is to ensure there is some kind of visual continuity between images so that you can recreate a 3D model from the 2D slices. This means for instance that if you are trying to figure out connectivity, you need some way to relate a dendrite to it's soma and say to the axon of the neuron it connects to - and that's one of the reasons why the slices have to be so thin. It would be no good if the pictures miss this information out as you will not be able to recreate the connectivity faithfully. This is actually really difficult to achieve in practice due to the minute sizes involved; a slight tremor that displaces the sample by some nanometres would cause shifts in alignment; even with the high-precision the tools have, you can imagine that there is always some kind of movement in the sample's position as part of the slicing process. </p> <p>Images in a stack are normally stored using traditional formats such as <a href="https://en.wikipedia.org/wiki/Tagged_Image_File_Format">TIFF</a><sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.6" id="fnr.6" name="fnr.6">6</a></sup>. You can see an example of the raw images in a stack <a href="https://github.com/unidesigner/groundtruth-drosophila-vnc/tree/master/stack2/raw">here</a>. Its worth noticing that, even though the images are 2D grey-scale, since the pixel size is only a few nanometres wide (4x4 in this case), the full size of an image is very large. Indeed, the latest generation of microscopes produce stacks on the 500 Terabyte range, making the processing of the images a "big-data" challenge. </p></div></div> <div class="outline-2" id="outline-container-sec-5"><h2 id="sec-5">What To Do Once You Got the Images</h2><div class="outline-text-2" id="text-5"><p>But back to the task at hand. Once you have the stack, the next logical step is to try to figure out what's what: which objects are in the picture. This is called segmentation and labelling, presumably because you are breaking the one big monolithic picture into discrete objects and give them names. Historically, segmentation has been done manually, but its a painful, slow and error-prone process. Due to this, there is a lot of interest in automation, and it has recently become feasible to do so - what with the abundance of cheap computing resources as well as the advent of "useful" <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning</a> (rather than the theoretical variety). Cracking this puzzle is gaining traction amongst the programming herds, as you can see by the popularity of challenges such as this one: <a href="http://fiji.sc/Segmentation_of_neuronal_structures_in_EM_stacks_challenge_-_ISBI_2012">Segmentation of neuronal structures in EM stacks challenge - ISBI 2012</a>. It is from this challenge we sourced the stack and micrograph above; the right-hand side is the finished product after machine learning processing. </p> <p>There are also open source packages to help with segmentation. A couple of notable contenders are <a href="http://fiji.sc/Fiji">Fiji</a> and <a href="http://ilastik.org/">Ilastik</a>. Below is a screenshot of Ilastik. </p>  <div class="figure"><p><img alt="Figure-2-a.png" height="300px" src="https://raw.githubusercontent.com/ilastik/ilastik.github.io/master/gallery/Figure-2-a.png" width="400px" /></p><p><span class="figure-number">Figure 5:</span> Source: <a href="http://ilastik.org/gallery.html">Ilastik gallery</a>.</p></div> <p>An activity that naturally follows on from segmentation and labelling is <a href="https://en.wikipedia.org/wiki/Neuronal_tracing">reconstruction</a>. The objective of reconstruction is to try to "reconstruct" morphology given the images in the stack. It could involve inferring the missing bits of information by mathematical means or any other kind of analysis which transforms the set of discrete objects spotted by segmentation into something looking more like a bunch of connected neurons. </p> <p>Once we have a reconstructed model, we can start performing <i>morphometric analysis</i>. As wikipedia tells us, <a href="https://en.wikipedia.org/wiki/Morphometrics">Morphometry</a> is "the quantitative analysis of form"; as you can imagine, there are a lot of useful things one may want to measure in the brain structures and sub-structures such as lengths, volumes, surface area and so on. Some of these measurements can of course be done in 2D, but life is made easier if the model is available in 3D. One such tool is <a href="http://wiki.blender.org/index.php/Extensions:2.6/Py/Scripts/Neuro_tool">NeuroMorph</a>. It is an open source extension written in Python for the popular open source 3D computer graphics software <a href="https://en.wikipedia.org/wiki/Blender_(software)">Blender</a>. </p>  <div class="figure"><p><img alt="NeuroMorph_screenshot.png" height="300px" src="http://wiki.blender.org/uploads/9/98/NeuroMorph_screenshot.png" width="300px" /></p><p><span class="figure-number">Figure 6:</span> Source: <a href="http://figshare.com/articles/Segmented_anisotropic_ssTEM_dataset_of_neural_tissue/856713">Segmented anisotropic ssTEM dataset of neural tissue</a></p></div></div></div> <div class="outline-2" id="outline-container-sec-6"><h2 id="sec-6">Conclusion</h2><div class="outline-text-2" id="text-6"><p>This post was a bit of a world-wind tour of some of the sources of real world data for Computational Neuroscience. As I soon found out, each of these sections could have easily been ten times bigger and still not provide you with a proper overview of the landscape; having said that, I hope that the post at least gives some impression of the terrain and its main features. </p> <p>From a software engineering perspective, its worth pointing out the lack of standardisation in information exchange. In an ideal world, one would want a pipeline with components to perform each of the steps of the complete process, from data acquisition off of a microscope (either opitical or EM), to segmentation, labelling, reconstruction and finally morphometric analysis. This would then be used as an input to the models. Alas, no such overarching standard appears to exist. </p> <p>One final point in terms of Free and Open Source Software (FOSS). On one hand, it is encouraging to see the large number of FOSS tools and programs being used. Unfortunately - at least for the lovers of Free Software - there are also some proprietary tools that are widely used such as <a href="http://www.mbfbioscience.com/neurolucida">NeuroLucida</a>. Since the software is so specialised, the fear is that in the future, the better funded commercial enterprises will take over more and more of the space. </p> <p>That's all for now. Don't forget to tune in for the next instalment! </p></div></div><div id="footnotes"><h2 class="footnotes">Footnotes: </h2><div id="text-footnotes"> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.1" id="fn.1" name="fn.1">1</a></sup> <p class="footpara">As it happens, what we are doing here is to apply a well-established learning methodology called the <a href="https://www.farnamstreetblog.com/2012/04/learn-anything-faster-with-the-feynman-technique/">Feynman Technique</a>. I was blissfully unaware of its existence all this time, even though <a href="https://en.wikipedia.org/wiki/Richard_Feynman">Feynman</a> is one of my heroes and even though I had read a fair bit about the man. On this topic (and the reason why I came to know about the Feynman Technique), its worth reading <a href="https://www.farnamstreetblog.com/2015/01/richard-feynman-knowing-something/">Richard Feynman: The Difference Between Knowing the Name of Something and Knowing Something</a>, where Feynman discusses his disappointment with science education in Brazil. Unfortunately the Portuguese and the Brazilian teaching systems have a lot in common - or at least they did when I was younger. </p></div> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.2" id="fn.2" name="fn.2">2</a></sup> <p class="footpara">Nor is the microscope the only way to figure out what is happening inside the brain. For example, there are <a href="https://en.wikipedia.org/wiki/Neuroimaging">neuroimagining</a> techniques which can provide data about both structure and function. </p></div> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.3" id="fn.3" name="fn.3">3</a></sup> <p class="footpara">Patented by <a href="https://en.wikipedia.org/wiki/Marvin_Minsky">Marvin Minsky</a>, no less - yes, he of Computer Science and AI fame! </p></div> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.4" id="fn.4" name="fn.4">4</a></sup> <p class="footpara">And, to be fair, sub-nanometre just doesn't quite capture just how low these things can go. For an example, read <a href="http://www.ncbi.nlm.nih.gov/pubmed/21844593">Electron microscopy at a sub-50 pm resolution</a>. </p></div> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.5" id="fn.5" name="fn.5">5</a></sup> <p class="footpara">For a more technical but yet short and understandable take, read <a href="http://www.jneurosci.org/content/26/47/12101.full">Uniform Serial Sectioning for Transmission Electron Microscopy</a>. </p></div> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.6" id="fn.6" name="fn.6">6</a></sup> <p class="footpara">On the topic of formats: its probably time we mention the <a href="https://www.openmicroscopy.org/site">Open Microscopy Environment</a> (OME). The microscopy world is dominated by hardware and as such its the perfect environment for corporations, their proprietary formats and expensive software packages. The OME guys are trying to buck the trend by creating a suite of open source tools and protocols, and by looking at some of <a href="http://help.openmicroscopy.org/viewing-data.html#screen">their stuff</a>, they seem to be doing alright. </p></div>  </div></div></div><div class="status" id="postamble"><p class="date">Created: 2015-11-30 Mon 23:12</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://mcraveiro.blogspot.com/2015/11/nerd-food-tooling-in-computational.html">Nerd Food: Tooling in Computational Neuroscience - Part I: NEURON</a></h2></div>
            <p class="text-muted">by <a href="http://mcraveiro.blogspot.com/">Marco Craveiro</a> on November 16, 2015 02:48 PM.</p>
          </div>
          <div class="panel-body">

            Nerd Food: Tooling in Computational Neuroscience - Part I<div id="content"><p>In the <a href="http://mcraveiro.blogspot.co.uk/2015/09/nerd-food-neurons-for-computer-geeks_16.html">previous series of posts</a> we did a build up of theory - right up to the point where we were just about able to make sense of <i>Integrate and Fire</i> - one of the simpler families of neuron models. The series used a <a href="https://en.wikipedia.org/wiki/Reductionism">reductionist</a> approach - or bottom up, if you prefer<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.1" id="fnr.1" name="fnr.1">1</a></sup>. We are now starting a new series with the opposite take, this time coming at it from the top. The objective is to provide a (very) high-level overview - in laymen's terms, still - of a few of the "platforms" used in computational neuroscience. As this is a rather large topic, we'll try to tackle a couple of platforms each post, discussing a little bit of their history, purpose and limitations - whilst trying to maintain a focus on <i>file formats</i>or DSLs. "File formats" may not sound particularly exciting at first glance, but it is important to keep in mind that these are instances of meta-models of the problem domain in question, and as such, their expressiveness is very important. Understand those and you've understood a great deal about the domain and about the engineering choices of those involved. </p> <p>But first, let's introduce <i>Computational Neuroscience</i>. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">Computers and the Brain</h2><div class="outline-text-2" id="text-1"><p><a href="http://mcraveiro.blogspot.co.uk/2015/09/nerd-food-neurons-for-computer-geeks_7.html">Part V</a> of our previous series discussed some of the reasons why one would want to model neurons (section <i>Brief Context on Modeling</i>). What we did not mention is that there is a whole scientific discipline dedicated to this endeavour, called Computational Neuroscience. Wikipedia has a <a href="https://en.wikipedia.org/wiki/Computational_neuroscience">pretty good working definition</a>, which we will take wholesale. It states: </p> <blockquote><p>Computational neuroscience […] is the study of brain function in terms of the information processing properties of the structures that make up the nervous system. It is an interdisciplinary science that links the diverse fields of neuroscience, cognitive science, and psychology with electrical engineering, computer science, mathematics, and physics. </p> <p>Computational neuroscience is distinct from psychological connectionism and from learning theories of disciplines such as machine learning, neural networks, and computational learning theory in that it emphasizes descriptions of functional and biologically realistic neurons (and neural systems) and their physiology and dynamics. These models capture the essential features of the biological system at multiple spatial-temporal scales, from membrane currents, proteins, and chemical coupling to network oscillations, columnar and topographic architecture, and learning and memory. </p> <p>These computational models are used to frame hypotheses that can be directly tested by biological or psychological experiments. </p></blockquote> <p>Lots of big words, of course, but hopefully they make <i>some</i> sense after the previous posts. If not, don't despair; what they all hint at is an "interdisciplinary" effort to create biologically plausible models, and to use these to provide insights on how the brain is performing certain functions. Think of the Computational Neuroscientist as the right-hand person of the Neuroscientist - the "computer guy" to the "business guy", if you like. The Neuroscientist (particularly the experimental Neuroscientist) gets his or her hands messy with wetware and experiments, which end up providing data and a better biological understanding; the Computational Neuroscientist takes these and uses them to make improved computer models, which are used to test hypothesis or to make new ones, which can then validated by experiments and so on, in a virtuous feedback loop.<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.2" id="fnr.2" name="fnr.2">2</a></sup>Where the "interdisciplinary" part comes in is that many of the people doing the role of "computer guys" are actually not computer scientists but instead come from a variety of backgrounds such as biology, physics, chemistry and so on. This variety adds a lot of value to the discipline because the brain is such a complex organ; understanding it requires all kinds of skills - and then some. </p></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">It's Models All the Way Down</h2><div class="outline-text-2" id="text-2"><p>At the core, then, the work of the Computational Neuroscientist is to create models. Of course, <a href="http://mcraveiro.blogspot.co.uk/2015/09/nerd-food-neurons-for-computer-geeks_7.html">as we already seen</a>, one does not just walk straight into Mordor and starts creating the "most biologically plausible" model of the brain possible; all models must have a scope as narrow as possible, if they are to become a) understandable and b) computationally feasible. Thus engineering trade-offs are crucial to the discipline. </p> <p>Also, it is important to understand that creating a model does not always imply writing things from scratch. Instead, most practitioners rely on a wealth of software available, all with different advantages and disadvantages. </p> <p>At this juncture you are probably wondering just what exactly are these "models" we speak so much of. Are they just equations like IaF? Well, yes and no. As it happens, all models have roughly the following structure: </p> <ul class="org-ul"><li><i>a morphology definition</i>: we've already <a href="http://mcraveiro.blogspot.co.uk/2015/08/nerd-food-neurons-for-computer-geeks.html">spoken a bit</a> about morphology; think of it as the definition of the entities that exist in your model, their characteristics and relationships. This is actually closer to what we, computer scientists think the word modeling means. For example, the morphology defines how many neurons you have, how many axons and dendrites, connectivity, spatial positioning and so on. </li><li><i>a functional, mathematical or physical definition</i>: I've heard it named in many ways, but fundamentally, what it boils down to is the definition of the equations that your model requires. For example, are you modeling electrical properties or reaction/diffusion? </li></ul> <p>For the simpler models, the morphology gets somewhat obscured - after all, in LIF, there is very little information about a neuron because all we are interested in are the spikes. For other models, a lot of morphological details are required. </p></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">The Tooling Landscape</h2><div class="outline-text-2" id="text-3"></div><div class="outline-3" id="outline-container-sec-3-1"><h3 id="sec-3-1">Idealised…</h3><div class="outline-text-3" id="text-3-1"><p>It is important to keep in mind that these models are to be used in a <i>simulation</i>; that is, we are going to run the program for a period of time (hours or days) and observe different aspects of its behaviour. Thus the functional definition of the model provides the equations that describe the dynamics of the system being simulated and the morphology will provide some of the inputs for those equations. </p> <p>From here one can start sketch the requirements for a system for the Computational Neuroscientist: </p> <ul class="org-ul"><li>a platform of some kind to provide simulation control: starting, stopping, re-running, storing the results and so on. As the simulations can take a long time to run, the data sets can be quite large - on the hundreds of gigs range - so efficiently handling of the output data is a must. </li><li>some kind of DSL that provides a user friendly way to define their models, ideally with a graphical user interface that helps author the DSL. The DSL must cover the two aspects we mention above. </li><li>efficient libraries of numerical routines to help solve the equations. The libraries must be exposed in someway to the DSL so that users can make use of these when defining the functional aspects of the model. </li></ul> <p>Architecturally, the ability to use a cluster or GPUs would of course be very useful, but we shall ignore those aspects for now. Given this idealised platform, we can now make a bit more sense of what actually exists in the wild. </p></div></div> <div class="outline-3" id="outline-container-sec-3-2"><h3 id="sec-3-2">… vs Actual</h3><div class="outline-text-3" id="text-3-2"><p>The multidisciplinary nature of Computational Neuroscience poses some challenges when it comes to software development: as mentioned, many of the practitioners in the field do not have a Software Engineering background; of those that do have, most tend not to have strong biology and neuroscience backgrounds. As a result, the landscape is fragmented and the quality is uneven. On one side, most of the software is open source, making reuse a lot less of a problem. On the other hand, things such as continuous integration, version control, portability, user interface guide lines, organised releases, packaging and so on are still lagging behind most "regular" Free and Open Source projects<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.3" id="fnr.3" name="fnr.3">3</a></sup>. </p> <p>In some ways, to enter Computational Neuroscience is a bit like travelling in time to a era before git, before GitHub, before Travis and all other things we take for granted. Not everywhere, of course, but still in quite a few places, particularly with the older and more popular projects. One cannot help but get the feeling that the field could do with some of the general energy we have in the FOSS community, but the technical barriers to contributing tend to be large since the domain is so complex. </p> <p>So after all of this boring introductory material, we can finally look at our first system. </p></div></div></div> <div class="outline-2" id="outline-container-sec-4"><h2 id="sec-4">NEURON</h2><div class="outline-text-2" id="text-4"><p>Having to choose, one feels compelled to start with <a href="http://www.neuron.yale.edu/neuron/">NEURON</a> - the most venerable of the lot, with roots in the 80s<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.4" id="fnr.4" name="fnr.4">4</a></sup>. NEURON is a simulation environment with great depth of functionality and a comprehensive user manual published as a (non-free) <a href="http://ebooks.cambridge.org/ebook.jsf?bid=CBO9780511541612">book</a>. For the less wealthy, an <a href="http://www.neuron.yale.edu/neuron/static/papers/hbtnn2/overviewforhbtnn2e.pdf">overview paper</a> is available, as are many other <a href="http://www.neuron.yale.edu/neuron/docs">online resources</a>. The software itself is fully open source, with a <a href="http://www.neuron.yale.edu/hg/neuron/nrn/file/5b5889f69d6e/src">public mercurial repo</a>. </p> <p>As with many of the older tools in this field, NEURON development has not quite kept up the pace with the latest and greatest. For instance, it still has a Motif'esque look to its UI but, alas, do not be fooled - its not Motif but <a href="https://en.wikipedia.org/wiki/InterViews">InterViews</a> - a technology I never heard of, but seems to have been popular in the 80's and early 90's. One fears that NEURON may just be the last widely used program relying on InterViews - and the fact that they carry <a href="http://www.neuron.yale.edu/hg/neuron/iv/file/91e22c4a0a0c/README">their own fork of it</a> does not make me hopeful. </p>  <div class="figure"><p><img alt="subset0.gif" height="300px" src="http://www.neuron.yale.edu/neuron/static/docs/cbtut/stylized/figs/subset0.gif" width="400px" /></p><p><span class="figure-number">Figure 1:</span> Source: NEURON Cell Builder</p></div> <p>However, once one goes past these layers of legacy, the domain functionality of the tool is very impressive. This goes some way to explain why so many people rely on it daily and why so many papers have been written using it - over 600 papers at the last count. </p> <p>Whilst NEURON is vast, we are particularly interested in only two aspects of it: <i>hoc</i> and <i>mod</i> (in its many incarnations). These are the files that can be used to define models. </p></div> <div class="outline-3" id="outline-container-sec-4-1"><h3 id="sec-4-1">Hoc</h3><div class="outline-text-3" id="text-4-1"><p><a href="https://en.wikipedia.org/wiki/Hoc_(programming_language)">Hoc</a> has a fascinating history and a pedigree to match. It is actually the creation of Kernighan and Pike, two UNIX luminaries, and has as contenders tools like bc and dc and so on. NEURON took hoc and extended it both in terms of syntax as well as the number of available functions; <a href="http://www.neuron.yale.edu/neuron/static/docs/refman/hoc.html">NEURON Hoc</a> is now an interpreted object oriented language, albeit with some limitations such as lack of inheritance. Programs written in hoc execute in an interpreter called <code>oc</code>. There are a few variations of this interpreter, with different kinds of libraries made available to the user (UI, neuron modeling specific functionality, etc) but the gist of it is the same, and the strong point is the interactive development with rapid feedback. On the GUI versions of the interpreter, the script can specify it's UI elements including input widgets for parameters and widgets to display the output. Hoc is then used as a mix between model/view logic and morphological definition language. </p> <p>To get a feel for the language, here's a very simple sample <a href="http://www.neuron.yale.edu/neuron/static/docs/elementarytools/writcode.htm">from the manual</a>: </p> <pre class="example"><br />create soma    // model topology<br />access soma    // default section = soma<br /><br />soma {<br />   diam = 10   // soma dimensions in um<br />   L = 10/PI   //   surface area = 100 um^2<br />}<br /></pre></div></div> <div class="outline-3" id="outline-container-sec-4-2"><h3 id="sec-4-2">NMODL</h3><div class="outline-text-3" id="text-4-2"><p>The second language supported by NEURON is <a href="http://www.neuron.yale.edu/neuron/static/docs/help/neuron/nmodl/nmodl.html">NMODL</a> - The NEURON extended MODL (Model Description Language). NMODL is used to specify a physical model in terms of equations such as simultaneous nonlinear algebraic equations, differential equations and so on. In practice, there are actually different versions of NMODL for different NEURON versions, but to keep things simple I'll just abstract these complexities and refer to them as one entity<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.5" id="fnr.5" name="fnr.5">5</a></sup>. </p> <p>As intimated above, NMODL is a descendant of MODL. As with Hoc, the history of MODL is quite interesting; it was a language was defined by the National Biomedical Simulation Resource to specify models for use with SCoP - the Simulation Control Program<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.6" id="fnr.6" name="fnr.6">6</a></sup>. From what I can gather of SCoP, its main purpose was to make life easier when creating simulations, providing an environment where users could focus on what they were trying to simulate rather than nitty-gritty implementation specific details. </p> <p>NMODL took MODL syntax and extended it with the primitives required by its domain; for instance, it added the NEURON block to the language, which allows multiple instances of "entities". As with MODL, NMODL is translated into efficient C code and linked against supporting libraries that provide the numerics; the NMODL translator to C also had to take into account the requirement of linking against NEURON libraries rather than SCoP. </p> <p>The below is a snippet of NMODL code, copied from the <a href="http://ebooks.cambridge.org/ebook.jsf?bid=CBO9780511541612">NEURON book</a>(chapter 9, listing 9.1): </p> <pre class="example"><br />NEURON {<br />  SUFFIX leak<br />  NONSPECIFIC_CURRENT i<br />  RANGE i, e, g<br />}<br /><br />PARAMETER {<br />  g = 0.001  (siemens/cm2)  &lt; 0, 1e9 &gt;<br />  e = -65    (millivolt)<br />}<br /><br />ASSIGNED {<br />  i  (milliamp/cm2)<br />  v  (millivolt)<br />}<br /></pre> <p>NMODL and hoc are used together to form a model; hoc to provide the UI, parameters and morphology and NMODL to provide the physical modeling. The website <a href="https://senselab.med.yale.edu/modeldb/default.cshtml">ModelDB</a> provides a database of models in a variety of platforms with the main objective of making research reproducible. <a href="https://senselab.med.yale.edu/modeldb/showModel.cshtml?model=83319&amp;file=/destexhe_benchmarks/NEURON/README">Here</a> you can see an example of a production NEURON model in its full glory, with a mix of hoc and NMODL files - as well as a few others such as session files, which we can ignore for our purposes. </p></div></div> <div class="outline-3" id="outline-container-sec-4-3"><h3 id="sec-4-3">Thoughts</h3><div class="outline-text-3" id="text-4-3"><p>NEURON is more or less a standard in Computational Neuroscience - together with a few other tools such as GENESIS, which we shall cover later. Embedded deeply in it source code is the domain logic learned painstakingly over several decades. Whilst software engineering-wise it is creaking at the seams, finding a next generation heir will be a non-trivial task given the features of the system, the amount of models that exist out there, and the knowledge and large community that uses it. </p> <p>Due to this, a solution that a lot of next-generation tools have developed is to use NEURON as a backend, providing a shiny modern frontend and then generating the appropriate hoc and NMODL required by NEURON. This is then executed in a NEURON environment and the results are sent back to the user for visualisation and processing using modern tools. Le Roi Est Mort, Vive Le Roi! </p></div></div></div> <div class="outline-2" id="outline-container-sec-5"><h2 id="sec-5">Conclusions</h2><div class="outline-text-2" id="text-5"><p>In this first part we've outlined what Computational Neuroscience is all about, what we mean by a model in this context and what services one can expect from a platform in this domain. We also covered the first of such platforms. Tune in for the next instalment where we'll cover more platforms. </p></div></div><div id="footnotes"><h2 class="footnotes">Footnotes: </h2><div id="text-footnotes"> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.1" id="fn.1" name="fn.1">1</a></sup> <p class="footpara">I still owe you the final post of that series, coming out soon, hopefully. </p></div> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.2" id="fn.2" name="fn.2">2</a></sup> <p class="footpara">Of course, once you scratch the surface, things get a bit murkier. <a href="http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000078">Erik De Schutter</a> states: </p> <blockquote><p>[…] The term is often used to denote theoretical approaches in neuroscience, focusing on how the brain computes information. Examples are the search for “the neural code”, using experimental, analytical, and (to a limited degree) modeling methods, or theoretical analysis of constraints on brain architecture and function. This theoretical approach is closely linked to systems neuroscience, which studies neural circuit function, most commonly in awake, behaving intact animals, and has no relation at all to systems biology.  […] Alternatively, computational neuroscience is about the use of computational approaches to investigate the properties of nervous systems at different levels of detail. Strictly speaking, this implies simulation of numerical models on computers, but usually analytical models are also included […], and experimental verification of models is an important issue. Sometimes this modeling is quite data driven and may involve cycling back and forth between experimental and computational methods. </p></blockquote></div> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.3" id="fn.3" name="fn.3">3</a></sup> <p class="footpara">This is a problem that has not gone unnoticed; for instance, this paper provides an interesting and thorough review of the state onion in Computational Neuroscience: <a href="http://arxiv.org/pdf/1205.3025.pdf">Current practice in software development for computational neuroscience and how to improve it.</a> In particular, it explains the dilemmas faced by the maintainers of neuroscience packages. </p></div> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.4" id="fn.4" name="fn.4">4</a></sup> <p class="footpara">The early story of NEURON is available <a href="http://neuron.duke.edu/userman/4/neuron.html">here</a>; see also the <a href="http://www.scholarpedia.org/article/Neuron_simulation_environment">scholarpedia page</a>. </p></div> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.5" id="fn.5" name="fn.5">5</a></sup> <p class="footpara">See the <a href="http://www.neuron.yale.edu/neuron/static/docs/help/neuron/nmodl/nmodl.html">NMODL page</a> for details, in the history section. </p></div> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.6" id="fn.6" name="fn.6">6</a></sup> <p class="footpara">As far as I can see, in the SCoP days MODL it was just called the <a href="http://www.neuron.yale.edu/ftp/ted/neuron/scop/scopman.html">SCoP Language</a>, but as the related paper is under a paywall I can't prove it either way. Paper: SCoP: An interactive simulation control program for micro- and minicomputers, from <a href="http://link.springer.com/article/10.1007/BF02459691">Springer</a>. </p></div>  </div></div></div><div class="status" id="postamble"><p class="date">Created: 2015-11-11 Wed 17:59</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://mcraveiro.blogspot.com/2015/11/nerd-food-interesting.html">Nerd Food: Interesting...</a></h2></div>
            <p class="text-muted">by <a href="http://mcraveiro.blogspot.com/">Marco Craveiro</a> on November 10, 2015 05:54 PM.</p>
          </div>
          <div class="panel-body">

            Nerd Food: Interesting…<div id="content"><p>Time to flush all those tabs again. Some interesting stuff I bumped into recently-ish. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">Finance</h2><div class="outline-text-2" id="text-1"><ul class="org-ul"><li><a href="https://medium.com/backchannel/how-bitcoins-blockchain-could-power-an-alternate-internet-bb501855af67">There’s a blockchain for that</a>!: The rise and rise of the blockchain… </li><li><a href="http://www.joecoin.com/2015/02/crypto-20-and-other-misconceptions.html">Crypto 2.0–And Other Misconceptions</a>: … but maybe we are getting a bit ahead of ourselves, and bitcoin is really what matters! </li><li><a href="http://www.michaelnielsen.org/ddi/how-the-bitcoin-protocol-actually-works/">How the Bitcoin protocol actually works</a>: Gory details of bitcoin's internals. Must say that the <a href="http://shop.oreilly.com/product/0636920032281.do">Bitcoin book</a> already provides a pretty good explanation, but interesting nonetheless. </li><li><a href="http://blogs.wsj.com/moneybeat/2015/11/03/bitbeat-bitcoin-surges-past-400-on-back-of-the-new-shining-star/">BitBeat: Bitcoin Surges Past $400 on Back of the New ‘Shining Star’</a>: Bitcoin is up again! Rollercoaster ride? </li><li><a href="http://modval.org/home/">ModVal</a>: How cool is that, a site for financial models. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">Startups et. al.</h2><div class="outline-text-2" id="text-2"><ul class="org-ul"><li><a href="http://www.newyorker.com/magazine/2015/02/23/shape-things-come">The Shape of Things to Come</a>: Jonathan Ive seems like a cool fellow, actually. Even though I'm not much of an apple fan. </li><li><a href="http://blog.ycombinator.com/yc-continuity-fund">Y Combinator Posthaven</a>: thoughts from the combinator. 1000 companies funded! </li><li><a href="https://medium.com/@EskoKilpi/movement-of-thought-that-led-to-airbnb-and-uber-9d4da5e3da3a#.d2dvu2nub">The Future of Firms. Is There an App for That?</a>: What does it mean to be a company in this world of change? </li></ul></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">General Coding</h2><div class="outline-text-2" id="text-3"><ul class="org-ul"><li><a href="https://medium.com/@landongn/12-years-later-what-i-ve-learned-about-being-a-software-engineer-d6e334d6e8a3">What I’ve learned so far about software development</a>: Tales from the trenches. </li><li><a href="https://codewords.recurse.com/issues/two/git-from-the-inside-out">Git from the inside out</a>: Gory details about git. And I mean <b>really</b>gory and <b>really</b> detailed. As with bitcoin, the <a href="http://shop.oreilly.com/product/9780596520137.do">git book</a> was already pretty detailed but interesting nonetheless. </li><li><a href="http://chris.beams.io/posts/git-commit/">How to Write a Git Commit Message</a>: jeez, each to their own! Here's a true geek of git commit messages. But very useful though. </li><li><a href="http://www.benstopford.com/2015/04/28/elements-of-scale-composing-and-scaling-data-platforms/">Elements of Scale: Composing and Scaling Data Platforms</a>: Interesting take on data, should help navigate the SQL/NoSQL debate. </li><li><a href="http://apihandyman.io/do-you-really-know-why-you-prefer-rest-over-rpc/">Do you really know why you prefer REST over RPC?</a>: Title says it all, interesting take on the RESTification of the world. </li><li><a href="http://highscalability.com/blog/2015/10/12/making-the-case-for-building-scalable-stateful-services-in-t.html">Making The Case For Building Scalable Stateful Services In The Modern Era</a>: Instead of knee-jerk reactions about statefulness, think deeply before you decide. With presentation: <a href="https://www.youtube.com/watch?v=H0i_bXKwujQ">"Building Scalable Stateful Services" by Caitie McCaffrey</a></li><li><a href="https://www.youtube.com/watch?v=9RMOc0SwRro">"Apache Kafka and the Next 700 Stream Processing Systems" by Jay Kreps</a>: Improved my understanding of Kafka somewhat. And the title made me curious, so I ended up reading <a href="http://www.cs.cmu.edu/~crary/819-f09/Landin66.pdf">The Next 700 Programming Languages</a>. </li><li><a href="http://www.theatlantic.com/technology/archive/2015/11/where-was-the-internet-born/413221/">The Room Where the Internet Was Born</a>: A quest for understanding the cloud. Rather long but great for those that like computer history. </li><li><a href="http://www.aaron-gray.com/a-criticism-of-scrum/">A Criticism of Scrum</a>: quite well thought out actually. I love agile but I must say, I agree with many of the points made. I guess in the end, the key is not to fall in love with ceremony. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-4"><h2 id="sec-4">Databases</h2><div class="outline-text-2" id="text-4"><ul class="org-ul"><li><a href="http://gotocon.com/dl/goto-berlin-2013/slides/HenningJacobs_and_ValentineGogichashvili_WhyZalandoTrustsInPostgreSQL.pdf">Why Zalando trusts in PostgreSQL</a>: Great to see how the elephant is used in anger. Picked up a few tips. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-5"><h2 id="sec-5">C++</h2><div class="outline-text-2" id="text-5"><ul class="org-ul"><li><a href="https://code.facebook.com/posts/1661982097368498">Futures for C++11 at Facebook</a>: futures are all the rage… </li><li><a href="http://instagram-engineering.tumblr.com/post/121930298932/c-futures-at-instagram">C++ Futures at Instagram</a>: … everywhere! </li><li><a href="https://www.livecoding.tv/videos/c-cplusplus/?sort=newest">Livestream</a>: WOT, C++ live coding? Man this is a weird notion! </li><li><a href="https://www.youtube.com/watch?v=nXaxk27zwlk&amp;feature=youtu.be">CppCon 2015: Chandler Carruth "Tuning C++: Benchmarks, and CPUs, and Compilers! Oh My!</a>: Chandler at his best - hilarious but extremely informative. </li><li><a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4367.html">Comparison in C++</a>: A weird but weirdly useful paper. Deep thinking about comparisons. For good measure, you should also watch the presentation: <a href="https://www.youtube.com/watch?v=fi0CQ7laiXE">CppCon 2015: Lawrence Crowl "Comparison is not simple, but it can be simpler"</a></li><li><a href="https://www.youtube.com/watch?v=mFUXNMfaciE">CppCon 2015: Eric Niebler "Ranges for the Standard Library"</a>: Ranges, ranges, ranges!! Can't wait! For good measure, you can also read <a href="http://bartoszmilewski.com/2014/10/17/c-ranges-are-pure-monadic-goodness/">C++ Ranges are Pure Monadic Goodness</a>. </li><li><a href="https://cryptocoding.net/index.php/Coding_rules">Crypto coding rules</a>: haven't parsed the entire document, but already found a few very useful points. </li><li><a href="https://github.com/emil-e/rapidcheck">RapidCheck</a>: Didn't know of QuickCheck or RapidCheck, but this may come in handy at some point… </li></ul></div></div> <div class="outline-2" id="outline-container-sec-6"><h2 id="sec-6">Layman Science</h2><div class="outline-text-2" id="text-6"><ul class="org-ul"><li><a href="https://nolaymanleftbehind.wordpress.com/2011/07/10/linear-algebra-what-matrices-actually-are/">Linear Algebra</a>: What matrices actually are: an attempt to make matrices accessible. </li><li><a href="http://betterexplained.com/articles/a-gentle-introduction-to-learning-calculus/">A Gentle Introduction To Learning Calculus</a>: Helpful when trying to remember all the stuff one did all those years ago… </li><li><a href="http://betterexplained.com/articles/a-visual-intuitive-guide-to-imaginary-numbers/">A Visual, Intuitive Guide to Imaginary Numbers</a>: … continued. </li><li><a href="http://esciencecommons.blogspot.co.uk/2011/01/new-theories-reveal-nature-of-numbers.html">New theories reveal the nature of numbers</a>: A <a href="http://www.imdb.com/title/tt0787524/">Ramanujan movie</a> is due out soon, and these are the guys doing the maths behind the scenes. Can't wait for the movie! </li><li><a href="http://v.cx/2010/04/feynman-brazil-education">Richard Feynman on education in Brazil</a>: Hilarious, but somewhat reminiscent of my own education, in a different country but culturally very similar and certainly with a very similar approach to science. </li><li><a href="http://neuralnetworksanddeeplearning.com/chap1.html">Using neural nets to recognize handwritten digits</a>: nice introduction to neural nets with a good example. </li><li><a href="http://nautil.us/issue/15/turbulence/your-brain-is-on-the-brink-of-chaos">Your Brain Is On the Brink of Chaos</a>: <b>Very</b> interesting. This is particularly interesting because I have been reading up on the delicate balance between inhibitory and excitatory neurons, but the literature always gives you this static impression of balance. If you assume chaos on the other hand… </li></ul></div></div> <div class="outline-2" id="outline-container-sec-7"><h2 id="sec-7">Other</h2><div class="outline-text-2" id="text-7"><ul class="org-ul"><li><a href="http://www.newyorker.com/magazine/2015/06/01/extreme-city-specter">Extreme City</a>: Luanda, my beloved, just keeps on getting crazier and crazier. Interesting - if somewhat expat-oriented - take on the city. </li><li><a href="http://www.slate.com/blogs/schooled/2015/09/17/kiera_wilmot_arrest_florida_teenager_reacts_to_ahmed_mohamed_story.html">This Florida Teenager Knows What Ahmed Mohamed Is Going Through. It Happened to Her in 2013</a>: sad, really. Whatever the real truth was about Ahmed. </li><li><a href="http://www.nytimes.com/2015/10/11/opinion/sunday/will-you-ever-be-able-to-upload-your-brain.html?_r=1">Will You Ever Be Able to Upload Your Brain?</a>: er., spoiler alert - not really. Interesting though. </li><li><a href="https://dl.dropboxusercontent.com/u/50282823/Flash%2520BBG%25202015-%2520October-Taleb.pptx.pdf">Dealing with “power laws” with upper (lower) bound</a>: most certainly not for laypeople. Taleb is back at it. Would be great to have this translated to laymen's maths. </li><li><a href="https://www.youtube.com/watch?v=5mcyUUf20Ng&amp;feature=youtu.be&amp;list=PL37ZVnwpeshH37NxpV6XbgdDpY-w48hMd">Lieke Boon: Unconscious Bias</a>: we're all guilty: How to be a bit more aware of your own the biases is my take on it. </li></ul></div></div></div><div class="status" id="postamble"><p class="date">Created: 2015-11-09 Mon 23:57</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://mcraveiro.blogspot.com/2015/09/nerd-food-neurons-for-computer-geeks_16.html">Nerd Food: Neurons for Computer Geeks - Part VI: LIF At Long Last!</a></h2></div>
            <p class="text-muted">by <a href="http://mcraveiro.blogspot.com/">Marco Craveiro</a> on September 16, 2015 05:13 PM.</p>
          </div>
          <div class="panel-body">

            Nerd Food: Neurons for Computer Geeks - Part VI: Integrate and Fire!<div id="content"><p>Welcome to part VI of a multi-part series on modeling neurons. In <a href="http://mcraveiro.blogspot.co.uk/2015/09/nerd-food-neurons-for-computer-geeks_7.html">part V</a> we added a tad more theory to link electricity with neurons, and also tried to give an idea of just how complex neurons are. Looking back on that post, I cannot help but notice I skipped one bit that is rather important to understanding Integrate-and-Fire (IAF) models. So lets look at that first and then return to our trail. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">Resting Potential and Action Potential</h2><div class="outline-text-2" id="text-1"><p>We have spoken <a href="http://mcraveiro.blogspot.co.uk/2015/09/nerd-food-neurons-for-computer-geeks_7.html">before</a> about the <a href="https://en.wikipedia.org/wiki/Membrane_potential">membrane potential</a> and the resting membrane potential, but we did so with such a high degree of hand-waving it now warrants revisiting. When we are talking about the <i>resting</i> membrane potential we mean just that - the value for the membrane potential when nothing much is happening. That is the magical circa -65mv we discussed before - with all of the related explanations on conventions around negative voltages. However, time does not stand still and things happen. The cell receives input from other neurons, and this varies over time. Some kinds of inputs can cause events to trigger on the receiving neuron: active ion channels may get opened or shut, ions move around, concentrations change and so forth, and thus, the cell will change its membrane potential in response. When these changes result in a higher voltage - such as moving to -60mv - we say a <i>depolarisation</i> is taking place. Conversely, when the voltage becomes more negative, we say <i>hyperpolarisation</i> is occurring. </p> <p>Now, it may just happen that there is a short-lived but "strong" burst of depolarisation, followed by equally rapid hyperpolarisation - and, as a result of which, the Axon's terminal decides to release <i>neurotransmitters</i> into the synapse (well, into the <i>synaptic gap</i> or <i>synaptic cleft</i> to be precise). This is called an <i><a href="https://en.wikipedia.org/wiki/Action_potential">action potential</a></i>, and it is also known by many other names such as "nerve impulses" or "spikes". When you hear that "a neuron has fired" this means that an action potential has just been emitted. If you record the neuron's behaviour over time you will see a <i>spike train</i> - a plot of the voltage over time, clearly showing the spikes. Taking a fairly random example: </p>  <div class="figure"><p><img alt="Simulation_of_hrose_neuron.png" height="300px" src="https://upload.wikimedia.org/wikipedia/commons/1/1b/Simulation_of_hrose_neuron.png" width="300px" /></p><p><span class="figure-number">Figure 1:</span> Source: Wikipedia, <a href="https://en.wikipedia.org/wiki/Neural_oscillation">Neural oscillation</a></p></div> <p>One way of picturing this is as a kind of "chain-reaction" whereby something triggers the voltage of the neuron to rise, which triggers a number of gates to open, which then trigger the voltage to rise and so on, until some kind of magic voltage threshold is reached where the inverse occurs: the gates that were causing the voltage to rise shut and some other gates that cause the voltage to decrease open, and so on, until we fall back down to the resting membrane potential. The process feeds back on itself, first as a positive feedback and then as a negative feedback. In the case of the picture above, something else triggers us again and again, until we finally come to rest. </p> <p>This spiking or firing behaviour is what we are trying to model. </p></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">Historical Background</h2><div class="outline-text-2" id="text-2"><p>As it happens, we are not the first ones to try to do so. A couple of years after Einstein's <i>annus mirabilis</i>, a french chap called <a href="https://en.wikipedia.org/wiki/Louis_Lapicque">Louis Lapicque</a> was also going through his own personal moment of inspiration, the output of which was the seminal <a href="http://www.snv.jussieu.fr/brette/papers/Lap07.pdf">Recherches quantitatives sur l'excitation électrique des nerfs traitée comme une polarisation</a>. It is summarised <a href="http://neurotheory.columbia.edu/~larry/AbbottBrResBul99.pdf">here</a> in fairly accessible English by Abbot. </p> <p>Lapicque had the insight of imagining the neuron as an RC circuit, with the membrane potential's behaviour explained as the interplay between capacitor and resistor; the action potential is then the capacitor reaching a threshold followed by a discharge. Even with our faint understanding of the subject matter, one cannot but appreciate Lapique's brilliance to have the ability to reach these conclusions in 1907. Of course, he also had to rely on the work of many others to get there, let's not forget. </p> <p>This model is still considered a useful model today, even though we know so much more about neurons now - a great example of what we mentioned <a href="http://mcraveiro.blogspot.co.uk/2015/09/nerd-food-neurons-for-computer-geeks_7.html">before</a> in terms of the choices of the level of detail when modeling. Each model is designed for a specific purpose and it should be as simple as possible for the stated end (but no simpler). As <a href="http://neurotheory.columbia.edu/~larry/AbbottBrResBul99.pdf">Abbot</a>says: </p> <blockquote><p>While Lapicque, because of the limited knowledge of his time, had no choice but to model the action potential in a simple manner, the stereotypical character of action potentials allows us, even today, to use the same approximation to avoid computation of the voltage trajectory during an action potential. This allows us to focus both intellectual and computation resources on the issues likely to be most relevant in neural computation, without expending time and energy on modeling a phenomenon, the generation of action potentials, that is already well understood. </p></blockquote></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">The IAF Family</h2><div class="outline-text-2" id="text-3"><p>Integrate-and-Fire is actually a family of models - related because all of them follow Lapicque's original insights. Over time, people have addressed shortcomings in the model by adding more parameters and modifying it slightly and from this other models were born. </p> <p>In general, models in the IAF family are single neuron models with a number of important properties (as per <a href="http://cns-classes.bu.edu/cn510/Papers/Izhikevich_Ch8.pdf">Izhikevich</a>): </p> <ul class="org-ul"><li>The spikes are all or none; that is, we either spike or we don't. This is a byproduct of the way spikes are added to the model, as we shall see later. This also means all spikes are identical because the are all created the same way. </li><li>The threshold for the spike is well defined and there is no ambiguity as to whether the neuron will fire or not. </li><li>It is possible to add a <i>refractory period</i>, similarly to how we add the spike. The refractory period is a time during which the neuron is less excitable (e.g. ignores inputs) and occurs right after the spike. </li><li>Positive currents are used as excitatory inputs and negative currents as inhibitory inputs. </li></ul> <p>But how do the members of this family look like? We will take a few examples from <a href="https://en.wikipedia.org/wiki/Biological_neuron_model">Wikipedia</a> to make a family portrait and then focus on LIF. </p></div> <div class="outline-3" id="outline-container-sec-3-1"><h3 id="sec-3-1">IAF: Integrate-and-Fire</h3><div class="outline-text-3" id="text-3-1"><p>This the Lapicque model. It is also called a "perfect" or "non-leaky" neuron. The formula is as follows: </p> \begin{align} I(t) = C_m \frac{dV_m(t)}{dt} \end{align}  <p>The <i>m</i>'s are there to signify <i>membrane</i>, nothing else. Note that its the job of the user to determine θ - that is the point at which the neuron spikes - and then to reset everything to zero and start again. If you are wondering why it's called "integrate", that's because the differential equation must be integrated before we can compare the current value to a threshold and then, if we're passed it, well - fire!. Hence Integrate-and-Fire. </p> <p>Wikipedia states this in a classier way, of course: </p> <blockquote><p>[This formula] is just the time derivative of the law of capacitance, Q = CV. When an input current is applied, the membrane voltage increases with time until it reaches a constant threshold Vth, at which point a delta function spike occurs and the voltage is reset to its resting potential, after which the model continues to run. The firing frequency of the model thus increases linearly without bound as input current increases. </p></blockquote></div></div> <div class="outline-3" id="outline-container-sec-3-2"><h3 id="sec-3-2">Integrate-and-Fire with Refractory Period</h3><div class="outline-text-3" id="text-3-2"><p>It is possible to extend IAF to take the refractory period into account. This is done by adding a period of time <i>t ref</i> during which the neuron does not fire. </p></div></div> <div class="outline-3" id="outline-container-sec-3-3"><h3 id="sec-3-3">LIF: Leaky Integrate-and-Fire</h3><div class="outline-text-3" id="text-3-3"><p>One of the problems of IAF is that it will "remember" stimulus, regardless of the time that elapses between stimuli. By way of example: if a neuron gets some input below the firing threshold at some time (say <i>ta</i>), then nothing for a long period of time and then subsequent stimulus at say <i>tb</i>, this will cause the neuron to fire (assuming the two inputs together are above the threshold). In the real world, neurons "forget" about below-threshold stimulus after certain amount of time has elapsed. This problem is solved in LIF by adding a <i>leak</i> term to IAF. The Wikipedia's formula is like so: </p> \begin{align} I_m(t) - \frac{V_m(t)}{R_m} = C_m \frac{dV_m(t)}{dt} \end{align}  <p>We will discuss it in detail later on. </p></div> <div class="outline-4" id="outline-container-sec-3-3-1"><h4 id="sec-3-3-1">Interlude: Leaky Integrators and Low-Pass Filters</h4><div class="outline-text-4" id="text-3-3-1"><p><b>Update</b>: this section got moved here from an earlier post. </p> <p>Minor detour into the world of "Leaky Integrators". As it turns out, mathematicians even have a name to describe functions like the one above: they are called <i><a href="https://en.wikipedia.org/wiki/Leaky_integrator">Leaky Integrators</a></i>. A leaky integrator is something that takes an input and "integrates" - that is, sums it over a range - but by doing so, starts "leaking" values out. In order words, a regular sum of values over a range should just result in an ever growing output. With a leaky integrator, we add up to a point, but then we start leaking, resetting the value of the sum back to where we started off. </p> <p>It turns out these kind of functions have great utility. For example, imagine that you have a range of inputs varying from some arbitrary low number to some other arbitrary high-number. When you supply these inputs to a leaky integrator, it can be used to "filter out" the high numbers; input numbers higher than a certain cut-off point just result in zeros in the output. This is known as a <i><a href="https://en.wikipedia.org/wiki/Low-pass_filter">low-pass filter</a></i>. One can conceive of a function that acted in the opposite way - a <i>high-pass filter</i>. </p></div></div></div> <div class="outline-3" id="outline-container-sec-3-4"><h3 id="sec-3-4">Exponential Integrate-and-Fire</h3><div class="outline-text-3" id="text-3-4"><p>In this model, spike generation is exponential: </p> \begin{align} \frac{dX}{dt} = \Delta_\tau exp(\frac{X - X_t}{\Delta_\tau}) \end{align}  <p>Wikipedia explains it as follows: </p> <blockquote><p>where X is the membrane potential, X<sub>T</sub> is the membrane potential threshold, and Δ<sub>T</sub> is the sharpness of action potential initiation, usually around 1 mV for cortical pyramidal neurons. Once the membrane potential crosses X<sub>T</sub>, it diverges to infinity in finite time. </p></blockquote></div></div> <div class="outline-3" id="outline-container-sec-3-5"><h3 id="sec-3-5">Others</h3><div class="outline-text-3" id="text-3-5"><p>We could continue and look into other IAF models, but you get the point. Each model has limitations, and as people work through those limitations - e.g. try to make the spike trains generated by the model closer to those observed in reality - they make changes to the model and create new members of the IAF family. </p></div></div></div> <div class="outline-2" id="outline-container-sec-4"><h2 id="sec-4">Explaining the LIF Formula</h2><div class="outline-text-2" id="text-4"><p>Let's look at a slightly more familiar formulation of LIF: </p> \begin{align} \tau_m \frac{dv}{dt} = -v(t) + RI(t) \end{align}  <p>By now this should make vague sense, but lets do it step by step breakdown just to make sure we are all on the same page. First, we know that the current of the RC circuit is defined like so: </p> \begin{align} I(t) = I_R + I_C \end{align}  <p>From Ohm's Law we also know that: </p> \begin{align} I_R = \frac {v}{R} \end{align}  <p>And from the <a href="http://mcraveiro.blogspot.co.uk/2015/09/nerd-food-neurons-for-computer-geeks_5.html">rigmarole of the capacitor</a> we also know that: </p> \begin{align} I_C = C \frac{dv}{dt} \end{align}  <p>Thus its not much of a leap to say: </p> \begin{align} I(t) = \frac {v(t)}{R} + C \frac{dv}{dt} \end{align}  <p>Now, if we now multiply both sides by R, we get: </p> \begin{align} RI(t) = v(t) + RC \frac{dv}{dt} \end{align}  <p>Remember that RC is τ, the <a href="https://en.wikipedia.org/wiki/RC_time_constant">RC time constant</a>; in this case, we are dealing with the membrane so hence the <i>m</i>. With that, the rest of the rearranging to the original formula should be fairly obvious. </p> <p>Also, if you recall, we mentioned <a href="https://en.wikipedia.org/wiki/Leaky_integrator">Leaky Integrators</a> before. You should hopefully be able to see the resemblance between these and our first formula. </p> <p>Note that we did not model spikes explicitly with this formula. However, when it comes to implementing it, all that is required is to look for a threshold value for the membrane potential - called the <i>spiking threshold</i>; when that value is reached, we need to reset the membrane potential back to a lower value - the <i>reset potential</i>. </p> <p>And with that we have enough to start thinking about code… </p></div></div> <div class="outline-2" id="outline-container-sec-5"><h2 id="sec-5">Method in our Madness</h2><div class="outline-text-2" id="text-5"><p>.. Or so you may think. First, a quick detour on discretisation. As it happens, computers are rather fond of discrete things rather than the continuous entities that inhabit the world of calculus. Computers are very much of the same opinion as <a href="https://en.wikipedia.org/wiki/George_Berkeley">the priest</a> <a href="http://www.maths.tcd.ie/pub/HistMath/People/Berkeley/Analyst/Analyst.pdf">who said</a>: </p> <blockquote><p>And what are these same evanescent Increments? They are neither finite Quantities nor Quantities infinitely small, nor yet nothing. May we not call them the Ghosts of departed Quantities? </p></blockquote> <p>So we cannot directly represent differential equations in the computer - not even the simpler ordinary differential equations (ODEs), with their single independent variable. Instead, we need to approximate them with a <i>method</i> for <i>numerical integration</i> of the ODE. Remember: when we say <i>integration</i> we just mean "summing". </p> <p>Once we enter the world of <i>methods</i> and <i>numerical analysis</i> we are much closer to our ancestral home of Software Engineering. The job of numerical analysis is to look for ways in which one can make discrete approximations of the problems in mathematical analysis - like, say, calculus. The little recipes they come up with are called <i>numerical methods</i>. A method is nothing more than an algorithm, a set of steps used iteratively. One such method is the <a href="https://en.wikipedia.org/wiki/Euler_method">Euler Method</a>: "[a] numerical procedure for solving ordinary differential equations (ODEs) with a given initial value", as Wikipedia tells us, and as it happens that is exactly what we are trying to do. </p> <p>So how does the Euler method work? Very simply. First you know that: </p> \begin{align} y(t_0) = y_0 \\ y'(t) = f(t, y(t)) \end{align}  <p>That is, at the beginning of time we have a known value. Then, for all other <i>t</i>'s, we use the current value in <i>f</i> in order to be able to compute the next value. Lets imagine that our steps - how much we are moving forwards by - are of a size <i>h</i>. You can then say: </p> \begin{align} t_{n+1} = t_n + h \\ y_{n+1} = y_n + h * f(x_n, t_n) \end{align}  <p>And that's it. You just need to know where you are right now, by how much you need to scale the function - e.g. the step size - and then apply the function to the current values of <i>x</i> and <i>t</i>. </p> <p>In code: </p> <div class="org-src-container"> <pre class="src src-c++">template&lt;typename F&gt;<br />void euler(F f, double y0, double start, double end, double h) {<br />    double y = y0;<br />    for (auto t(start); t &lt; end; t += h) {<br />        y += h * f(t, y, h);<br />    }<br />}<br /></pre></div> <p>We are passing <i>h</i> to the function <i>F</i> because it needs to know about the step size, but other than that it should be a pretty clean mapping from the maths above. </p> <p>This method is also known as <i>Forward Euler</i> or <i>Explicit Euler</i>. </p></div></div> <div class="outline-2" id="outline-container-sec-6"><h2 id="sec-6">What next?</h2><div class="outline-text-2" id="text-6"><p>And yet again, we run out of time yet again before we can get into serious coding. In the next instalment we shall cover the implementation of the LIF model. </p></div></div></div><div class="status" id="postamble"><p class="date">Created: 2015-09-16 Wed 18:05</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://mcraveiro.blogspot.com/2015/09/nerd-food-neurons-for-computer-geeks_5.html">Nerd Food: Neurons for Computer Geeks - Part IV: More Electricity</a></h2></div>
            <p class="text-muted">by <a href="http://mcraveiro.blogspot.com/">Marco Craveiro</a> on September 16, 2015 04:39 PM.</p>
          </div>
          <div class="panel-body">

            Nerd Food: Neurons for Computer Geeks - Part IV: More Electricity<div id="content"><p><a href="http://mcraveiro.blogspot.co.uk/2015/08/nerd-food-neurons-for-computer-geeks.html">Part I</a> of this series looked at a neuron from above; <a href="http://mcraveiro.blogspot.co.uk/2015/08/nerd-food-neurons-for-computer-geeks_31.html">Part II</a> attempted to give us the fundamental building blocks in electricity required to get us on the road to modeling neurons. We did a quick interlude with a bit of coding in <a href="http://mcraveiro.blogspot.co.uk/2015/09/nerd-food-neurons-for-computer-geeks_4.html">part III</a> but now, sadly, we must return to boring theory once more. </p> <p>Now that we grok the basics of electricity, we need to turn our attention to the <i>RC circuit</i>. As we shall see, this circuit is of particular interest when modeling neurons. The RC circuit is so called because it is a circuit, and it is composed of a Resistor and a Capacitor. We've already got some vague understanding of circuits and resistors, so lets start by having a look at this new crazy critter, <i>the capacitor</i>. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">Capacitors</h2><div class="outline-text-2" id="text-1"><p>Just like the battery is a source of current, one can think of the capacitor as a temporary store of current. If you plug a capacitor into a circuit with just a battery, it will start to "accumulate" charge over time, up to a "maximum limit". But how exactly does this process work? </p> <p><a href="https://www.khanacademy.org/science/physics/circuits-topic/circuits-with-capacitors/v/capacitors-and-capacitance">In simple terms</a>, the capacitor is made up of two metal plates, one of which will connect to the positive end of the battery and another which connects to the negative end. At the positive end, the metal plate will start to lose negative charges because these are attracted to the positive end of the battery. This will make this metal plate positively charged. Similarly, at the negative end, the plate will start to accumulate negative charges. This happens because the electrons are repelled by the negative end of the battery. Whilst this process is taking place, the capacitor is <i>charging</i>. </p> <p>At some point, the process reaches a kind of equilibrium, whereby the electrons in the positively charged plate are attracted equally to the plate as they are to the positive end of the battery, and thus stop flowing. At this point we say the capacitor is <i>charged</i>. It is interesting to note that both plates of the capacitor end up with the same "total" charge but different signs (i.e. <code>-q</code> and <code>+q</code>). </p></div> <div class="outline-3" id="outline-container-sec-1-1"><h3 id="sec-1-1">Capacitance</h3><div class="outline-text-3" id="text-1-1"><p>We mentioned a "maximum limit". A few things control this limit: how big the plates are, how much space there is between them and the kind of material we place between them, if any. The bigger the plates and the closer they are - without touching - the more you can store in the capacitor. The material used for the plates is, of course, of great importance too - it must be some kind of metal good at conducting. </p> <p>In a more technical language, this notion of a limit is captured by the concept of <i>capacitance</i>, and is given by the following formula: </p> \begin{align} C = \frac{q}{V} \end{align}  <p>Lets break it down to its components to see what the formula is trying to tell us. The role of <code>V</code> is to inform us about the potential difference between the two plates. This much is easy to grasp; since one plate is positively charged and other negatively charged, it is therefore straightforward to imagine that a charge will have a different electric potential in each plate, and thus that there will be an electric potential difference between them. <code>q</code> tells us about the magnitude of the charges that we placed on the plates - i.e. ignoring the sign. It wouldn't be to great a leap to conceive that plates with a larger surface area would probably have more "space" for charges and so a larger <code>q</code> - and vice-versa. </p> <p>Capacitance is then the ratio between these two things; a measure of how much electric charge one can store for a given potential difference. It may not be very obvious from this formula, but capacitance is constant. That is to say, a given capacitor has a capacitance, influenced by the properties described above. This formula does not describe the discharging or charging process - but of course, capacitance is used in the formulas that describe those. </p> <p>Capacitance is measured in SI units of Farads, denoted by the letter  <code>F</code>. A farad is 1 coulomb over 1 volt: </p> \begin{align} 1F = \frac{C}{V} \end{align} </div></div> <div class="outline-3" id="outline-container-sec-1-2"><h3 id="sec-1-2">Capacitors and Current</h3><div class="outline-text-3" id="text-1-2"><p>After charging a capacitor, one may be tempted to discharge it. For that one could construct a simple circuit with just the capacitor. Once the circuit is closed, the negative charges will start to flow to the positively charged plate, at full speed - minus the resistance of the material. Soon enough both plates would be made neutral. At first glance, this may appear to be very similar to our previous circuit with a battery. However, there is one crucial difference: the battery circuit had a constant voltage and a constant current (for a theoretical battery) whereas a circuit with a discharging capacitor has voltage and current that <i>decay</i> over time. By "decaying", all we really mean is that we start at some arbitrarily high value and we move towards zero over a period of time. This makes intuitive sense: you cannot discharge the capacitor forever; and, as you discharge it, the voltage starts to decrease - for there are less charges in the plates and so less potential difference - and similarly, so does the current - for there is less "pressure" to make the charges flow. </p> <p>This intuition is formally captured by the following equation: </p> \begin{align} I(t) = C \frac{dV(t)}{dt} \end{align}  <p>I'm rather afraid that, at this juncture, we have no choice but to introduce Calculus. A proper explanation of Calculus a tad outside the remit of these posts, so instead we will have to make do with some common-sense but extremely hand-waved interpretations of the ideas behind it. If you are interested in a light-hearted but still comprehensive treatment of the subject, perhaps <a href="http://betterexplained.com/articles/a-gentle-introduction-to-learning-calculus/">A Gentle Introduction To Learning Calculus</a> may be to your liking. </p> <p>Let's start by taking a slightly different representation of the formula above and then compare these two formulas. </p> \begin{align} i = C \frac{dv}{dt} \end{align}  <p>In the first case we are talking about the current <code>I</code>, which normally is some kind of average current over some unspecified period. Up to now, <i>time</i> didn't really matter - so we got away with just talking about <code>I</code> in these general terms. This was the case with the Ohm's Law in <a href="http://mcraveiro.blogspot.co.uk/2015/08/nerd-food-neurons-for-computer-geeks_31.html">part II</a>. However, as we've seen, it is not so with capacitors - so we need to make the current specific to a point in time. For that we supply an "argument" to I - <code>I(t)</code>; here, a mathematician would say that that <code>I</code> is a function of <i>time</i>. In the second case, we make use of <code>i</code>, which is the <i>instantaneous current</i> through the capacitor. The idea is that, somehow, we are able to know - for any point in time - what the instantaneous current is. </p> <p>How we achieve that is via the magic of Calculus. The expression <code>dv/dt</code> in the second formula provides us with the instantaneous rate of change of the voltage over time. The same notion can be applied to <code>V</code>, as per first formula. </p> <p>These formulas may sound awfully complicated, but what they are trying to tell us is that the capacitor's current has the following properties: </p> <ul class="org-ul"><li>it varies as a "function" of time; that is to say, different time points have different currents. Well, that's pretty consistent with our simplistic notion of a decaying current. </li><li>it is "scaled" by the capacitor's capacitance <code>C</code>; "bigger" capacitors can hold on to higher currents for longer when compared to "smaller" capacitors. </li><li>the change in electric potential difference varies as a function of time. This is subtle but also makes sense: we imagined some kind of decay for our voltage, but there was nothing to say the decay would remain <i>constant</i> until we reached zero. This formula tells us it does not; voltage may decrease faster or slower at different points in time. </li></ul></div></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">Circuits: Parallel and Series</h2><div class="outline-text-2" id="text-2"><p>The RC circuit can appear in a parallel or series form, so its a good time to introduce these concepts. One way we can connect circuits is in <i>series</i>; that is, all components are connected along a single path, such that the current flows through <i>all</i> of them, one after the other. If any component fails, the flow will cease. </p> <p>This is best understood by way of example. Lets imagine the <a href="http://www.physicsclassroom.com/class/circuits/Lesson-4/Two-Types-of-Connections">canonical example</a> of a battery - our old friend the 1.5V AA battery - and a three small light bulbs. A circuit that connects them in series would be made up of a cable segment plugged onto one of the battery's terminals - say <code>+</code>, then connected to the first light bulb. A second cable segment would then connect this light bulb to another light bulb, followed by another segment and another light bulb. Finally, a cable segment would connect the light build to the other battery terminal - say <code>-</code>. Graphically - and pardoning my inability to use <a href="https://wiki.gnome.org/Apps/Dia/">Dia</a> to create circuit diagrams - it would look more or less like this: </p>  <div class="figure"><p><img alt="series_circuit.png" height="200px" src="https://github.com/mcraveiro/neurite/raw/master/doc/blog/images/series_circuit.png" width="300px" /></p><p><span class="figure-number">Figure 1:</span> Series circuit. Source: Author</p></div> <p>This circuit has a few interesting properties. First, if any of the light bulbs fail, all of them will stop working because the circuit is no longer closed. Second, if one were to add more and more light bulbs, the brightness of each light bulb will start to decrease. This is because each light bulb is in effect a resistor - the light shining being a byproduct of said resistance - and so they are each decreasing the current. So it is that in a series circuit the total resistance is given by the sum of all individual resistances, and the current is the same for all elements. </p> <p>Parallel circuits are a bit different. The idea is that two or more components are connected to the circuit <i>in parallel</i>, i.e. there are two or more paths along which the current can flow at the same time. So we'd have to modify our example to have a path to each of the light bulbs which exists in parallel to the main path - quite literally a segment of cable that connects the other segments of cable, more or less like so: </p>  <div class="figure"><p><img alt="parallel_circuit.png" height="200px" src="https://github.com/mcraveiro/neurite/raw/master/doc/blog/images/parallel_circuit.png" width="300px" /></p><p><span class="figure-number">Figure 2:</span> Parallel circuit. Source: Author</p></div> <p>Here you can see that if a bulb fails, there is still a closed loop in which current can flow, so the other bulbs should be unaffected. This also means that the voltage is the same for all components in the circuit. Current and resistance are now "relative" to each component, and it is possible to compute the overall current for the circuit via <a href="https://en.wikipedia.org/wiki/Kirchhoff%2527s_circuit_laws#Kirchhoff.27s_current_law_.28KCL.29">Kirchhoff's Current Law</a>. Simplifying it, it means that the current for the circuit is the sum of all currents flowing through each component. </p> <p>This will become significant later on when we finally return to the world of neurons. </p></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">The RC Circuit</h2><div class="outline-text-2" id="text-3"><p>With all of this we can now move to the <i>RC circuit</i>. In its simplest form, the circuit has a source of current with a resistor and a capacitor: </p>  <div class="figure"><p><img alt="Discharging_capacitor.svg" height="300px" src="https://upload.wikimedia.org/wikipedia/commons/a/a4/Discharging_capacitor.svg" width="300px" /></p><p><span class="figure-number">Figure 3:</span> Source: Wikipedia, <a href="https://en.wikipedia.org/wiki/RC_circuit">RC circuit</a></p></div> <p>Let's try to understand how the capacitor's voltage will behave over time. This circuit is rather similar to the one we analysed when discussing capacitance, with the exception that we now have a resistor as well. But in order to understand this, we must return to Kirchhoff's current law, which we hand-waved a few paragraphs ago. Wikipedia tells us that: </p> <blockquote><p>The algebraic sum of currents in a network of conductors meeting at a point is zero. </p></blockquote> <p>One way to understand this statement is to think that the total quantity of current entering a junction point must be identical to the total quantity leaving that junction point. If we consider entering to be positive and leaving to be negative, that means that adding the two together must yield zero. </p> <p>Because of Kirchhoff's law, we can state that, for the positive terminal of the capacitor: </p> \begin{align} i_c(t) + i_r(t) = 0 \end{align}  <p>That is: at any particular point in time <i>t</i>, the current flowing through the capacitor added to the current flowing through the resistor must sum to zero. However, we can now make use of the previous formulas; after all, our section on capacitance taught us that: </p> \begin{align} i_c(t) = C \frac{dv(t)}{dt} \end{align}  <p>And making use of Ohm's Law we can also say that: </p> \begin{align} i_r(t) = \frac{v(t)}{R} \end{align}  <p>So we can expand the original formula to: </p> \begin{align} C \frac{dv(t)}{dt} + \frac{v(t)}{R} \end{align}  <p>Or: </p> \begin{align} C \frac{dV}{dt} + \frac{V}{R} \end{align}  <p>I'm not actually going to follow the remaining steps to compute <code>V</code>, but you can see them <a href="http://www.digilentinc.com/classroom/realanalog/text/Chapter_2p4p2.pdf">here</a> and they are fairly straighforward, or at least as straightforward as calculus gets. The key point is, when you solve the differential equation for <code>V</code>, you get: </p> \begin{align} V(t) = V_0e^{-\frac{t}{RC}} \end{align}  <p>With <code>V0</code> being voltage when time is zero. This is called the circuit's <i>natural response</i>. This equation is <i>very important</i>. Note that we are now able to describe the behaviour of voltage over time with just a few inputs: the starting voltage, the time, the resistance and the capacitance. </p> <p>A second thing falls off of this equation: the RC Time constant, or τ. It is given by: </p> \begin{align} \tau = RC \end{align}  <p>The Time Constant is described in a very useful way <a href="http://www.tpub.com/neets/book2/3d.htm">in this page</a>, so I'll just quote them and their chart here: </p> <blockquote><p>The time required to charge a capacitor to 63 percent (actually 63.2 percent) of full charge or to discharge it to 37 percent (actually 36.8 percent) of its initial voltage is known as the TIME CONSTANT (TC) of the circuit. </p></blockquote>  <div class="figure"><p><img alt="32NE0159.GIF" src="http://www.tpub.com/neets/book2/32NE0159.GIF" /></p><p><span class="figure-number">Figure 4:</span> The RC Time constant. Source: <a href="http://www.tpub.com/neets/book2/1.htm">Concepts of alternating current</a></p></div></div></div> <div class="outline-2" id="outline-container-sec-5"><h2 id="sec-5">What next?</h2><div class="outline-text-2" id="text-5"><p>Now we understand the basic behaviour of the RC Circuit, together with a vague understanding of the maths that describe it, we need to return to the neuron's morphology. Stay tuned. </p></div></div></div><div class="status" id="postamble"><p class="date">Created: 2015-09-05 Sat 18:56</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://mcraveiro.blogspot.com/2015/08/nerd-food-neurons-for-computer-geeks_31.html">Nerd Food: Neurons for Computer Geeks - Part II: The Shocking Complexity of Electricity</a></h2></div>
            <p class="text-muted">by <a href="http://mcraveiro.blogspot.com/">Marco Craveiro</a> on September 14, 2015 04:39 PM.</p>
          </div>
          <div class="panel-body">

            Nerd Food: Neurons for Computer Geeks - Part II: The Shocking Complexity of Electricity<div id="content"><p>In <a href="http://mcraveiro.blogspot.co.uk/2015/08/nerd-food-neurons-for-computer-geeks.html">part I</a> we started to describe the basic morphology of the neuron. In order to continue, we now need to take a detour around the world of electricity. If you are an electricity nerd, I apologise in advance; this is what happens when a computer scientist escapes into your realm, I'm afraid. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">"Honor the charge they made!"</h2><div class="outline-text-2" id="text-1"><p>First and foremost, we need to understand the concept of <i>charge</i>. It is almost a tautology that atoms are made up of "sub-atomic" particles. These are the <i>proton</i>, the <i>neutron</i> and the <i>electron</i>. The neutron is not particularly interesting right now; however the electron and the proton are, and all because they have a magical property called <i>charge</i>. For our purposes, it suffices to know that "charge" means that certain sub-atomic particles attract or repeal each other, according to a well defined set of rules. </p> <p>You can think of a charge as a property attached to the sub-atomic particle, very much like a person has a weight or height, but with a side-effect; it is as if this property makes people push or hug each other when they are in close proximity, and they do so with the same strength when at the same distance. This "strength" is the <i>electric force</i>. How they decide whether to hug or push the next guy is based on the "sign" of the charge - that is, positive or negative - with respect to their own charge "sign". Positives push positives away but hug negatives and vice-versa. </p> <p>For whatever historical reasons, very clever people decided that an electron has one negative unit of charge and a proton has a positive unit of charge. The sign is, of course, rather arbitrary. We could have just as well said that protons are red and electrons are blue or some other suitably binary-like convention to represent these permutations. Just because protons and electrons have the same charge, it does not follow that they are similar in other respects. In fact, they are <i>very</i> different creatures. For example, the electron is very "small" when compared to the proton - almost 2000 times "smaller". The relevance of this "size" difference will become apparent later on. Physicists call this "size" <i>mass</i>, by the by. </p> <p>As it happens, all of these sub-atomic crazy critters are rather minute entities. So small in fact that it would be really cumbersome if we had to talk about charges in terms of the charge of an electron; the numbers would just be too big and unwieldy. So, the very clever people came up with a sensible way to bundle up the charges of the sub-atomic particles in bigger numbers, much like we don't talk about millimetres when measuring the distance to the Moon. However, unlike the nice and logical metric system, with its neat use of the decimal system, physicists came up instead with the <i>Coulomb</i>, or <i>C</i>, one definition of which is: </p> <ul class="org-ul"><li>1 Coloumb (1C) = 6.241 x 10<sup>18</sup> protons </li><li>-1 Coloumb (-1C) = 6.241 x 10<sup>18</sup> electrons </li></ul> <p>This may sound like a <i>very</i> odd choice - hey, why not just 1 x 10<sup>20</sup>or some other "round" number? - but just like a <a href="http://www.quora.com/Why-is-a-kilogram-equal-to-1000-grams-but-a-kilobyte-equals-1024-bytes">kilobyte is 1024 bytes rather 1000</a>, this wasn't done by accident either. In fact, all related <a href="https://en.wikipedia.org/wiki/International_System_of_Units">SI units</a> were carefuly designed to work together and make calculations as easy as possible. </p> <p>Anyway, whenever you see <code>q</code> or <code>Q</code> in formulas it normally refers to a charge in Coulombs. </p></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">Units, Dimensions, Measures, Oh My!</h2><div class="outline-text-2" id="text-2"><p>Since we are on the subject of SI, this is probably a good point to talk about units, dimensions, measurements, magnitudes, conversions and other such exciting topics. Unfortunately, these are important to understand how it all hangs together. </p> <p>A number such as <code>1A</code> makes use of the SI <i>unit of measure</i> "Ampere" and it exists in a <i>dimension</i>: the dimension of all units which can talk about electric charges. This is very much in the same way we can talk about time in seconds or minutes - we are describing points in the time dimension, but using different <i>units of measure</i> - or just <i>units</i>, because we're lazy. A <i>measurement</i> is the recording of a quantity with a unit in a dimension. Of course, it would be too simple to call it a "quantity", so instead physicists, mathematicians and the like call it <i>magnitude</i>. But for the lay person, its not too bad an approximation to replace "magnitude" with "quantity". </p> <p>Finally, it is entirely possible to have <i>compound dimensional units</i>; that is, one can have a unit of measure that refers to more than one dimension, such as say "10 kilometres per second". </p> <p>I won't discuss conversions just now, but you can easily imagine that formulas that contain multiple units may provide ways to convert from one unit to another. This will become relevant later on. </p></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">Go With the Flow</h2><div class="outline-text-2" id="text-3"><p>Now we have a way of talking about charge, and now we know these things can move - since they attract and repel each other - the next logical thing is to start to imagine <i>current</i>. The name sounds magical, but in reality it is akin to a current in a river: you are just trying to figure out how much water is coming past you every second (or in some other suitable unit in the time dimension). The exact same exercise could be repeated for the number of cars going past in a motorway or the number of runners across some imaginary point in a track. For our electric purposes, current tells you how many charges have zipped past over a period of time. </p> <p>In terms of SI units, current is measured in <i>Amperes</i>, which have the symbol <i>A</i>; an Ampere tells us how many Coloumbs have flown past in a second. Whenever you see <code>I</code> in formulas it normally refers to current. </p> <p>Now lets see how these two things - Coulombs and Amperes - could work together. Lets imagine an arbitrary "pipe" between two imaginary locations, one side of which with a pile of positive charges and, on the other side, a pile of negative charges - both measured in Coulombs, naturally. In this <i>extraordinarily</i> simplified and non-existing world, the negative charges would "flow" down the pipe, attracted by the positive charges. Because the positive charges are so huge they won't budge, but the negative charges - the lighter electrons - would zip across to meet them. The number of charges you see going past in a time tick is the current. </p></div></div> <div class="outline-2" id="outline-container-sec-4"><h2 id="sec-4">Resist!</h2><div class="outline-text-2" id="text-4"><p>Going back to our example of current in a river, one can imagine that some surfaces are better at allowing water to flow than others; for example, a river out in the open is a lot less "efficient" at flowing than say a plastic pipe designed for that purpose. One reason is that the river has to deal with twists and turns as it finds a path over the landscape whereas the pipe could be laid out as straight as possible; but it is also that the rocks and other elements of the landscape slow down water, whereas a nice flat pipe would have no such impediments. If one were to take these two extremes - a plastic pipe designed for maximum water flow versus a landscape - one could see that they affect flow differently; and one could be tempted to name the property of "slowing down the flow" <i>resistance</i>, because it describes how much "resistance" these things are offering to the water. If you put up a barrier to avoid flooding, you probably would want it to "resist" water quite a lot rather than allow it to flow; and you can easily imagine that sand and sandbags "resist" water in very different ways. </p> <p>Resistance is a fundamental concept in the electrical world. The gist of it is similar to the contrived examples above, in that not all materials behave the same way with regards to allowing charges to flow. Some allow them to flow freely nearly at maximum speed whereas others do not allow them to flow at all. </p> <p>Since we are dealing with physics, it is of course possible to measure resistance. We do so in SI units of <i>Ohms</i>, denoted by the Greek letter upper-case Ω. </p> <p>As we shall see, not all materials are nicely behaved when it comes to resistance. </p></div></div> <div class="outline-2" id="outline-container-sec-5"><h2 id="sec-5">You've Got Potential Baby!</h2><div class="outline-text-2" id="text-5"><p>Lets return to our non-existing "pipe that allows charges to flow" scenario, and take it one step further. Imagine that for whatever reason our pipe becomes clogged up with a blockage somewhere in the middle. Nothing could actually flow due to this blockage so our current drops to zero. </p> <p>According to the highly simplified rules that we have learned thus far, we do know that - were there to be no blockage - there <i>would</i> be movement (current). That is, the setup of the two bundles in space is such that, given the right conditions, we would start to see things flowing. But, alas, we do not have the right conditions because the pipe is blocked; hence no flow. You could say this setup has "the potential" to get some flow going, if only we could fix the blockage. </p> <p>In the world of electricity, this idea is captured by a few related concepts. If we highly simplify them, they amount to this: </p> <ul class="org-ul"><li><i>electric potential</i>: the idea that depending where you place a charge in space, it may have different "potential" to generate energy. We'll define energy a bit better latter on, but for now a layman's idea of it suffices. By way of an example: if you place a positive charge next to a lump of positive charges and let it go, it will move a certain distance away from the lump. Before you let the charge go, you know the charge has potential to move away. You can also see that the charge will move by different amounts depending how close you place it to the lump; the closer you place it, the more it will move. When we are thinking of electric potential, we think of just one charge. </li><li><i>electric potential energy</i>: clearly it would be possible to move two or three charges too, as we did for the one; and clearly they should produce more energy than a single charge. So one simple way of understanding electric potential energy is to think of it as the case of electric potential that deals with the total number of charges we're interested in, rather than just one. </li></ul> <p>Another way of imagining these two concepts is to think that electric potential is a good way to measure things when you don't particularly care about the number of charges involved; it is as if you scaled everything to just one unit of charge. Electric potential energy is more when you are thinking of a system with an actual number of charges. But both concepts deal with the notion that placing a charge at different points in space may have an impact in the energy you can get out of it. </p> <p>Having said all of that we can now start to think about <i>electric potential difference</i>. It uses the same approach as electric potential, in that everything is scaled to just one unit of charge, but as the name implies, it provides a measurement of <i>the difference</i>between the electric potential of two points. Electric potential difference is more commonly known as <i>voltage</i>. Interestingly, it is also known as <i>electric pressure</i>, and this may be the most meaningful of its names; this is because when there is an electric potential difference, it applies "pressure" on charges which force them to move. </p> <p>The SI unit <i>Volt</i> is used to measure electric potential, electric potential energy and electric potential difference amongst other things. This may sound a bit weird at first, but it is just because one is unfamiliar with these concepts. Take <i>time</i>, for example: we use minutes as a unit of measure of all sorts of things (duration of a football game, time it takes for the moon to go around the earth, etc.). We did not invent a new unit for each phenomenon because we recognised - at some point - that we were dealing with points in the same dimension. </p></div></div> <div class="outline-2" id="outline-container-sec-6"><h2 id="sec-6">Quick Conceptual Mop-Up</h2><div class="outline-text-2" id="text-6"><p>Before we move over to the formulas, it may be best to tie up a few loose ends. These are not strictly necessary, but just make the picture a bit more complete and moves us to a more realistic model - if still very simplistic. </p> <p>First, we should start with atoms; we mentioned charges but skipped them. Atoms are (mostly) a stable arrangement of charges, placed in such a way that the atoms themselves are neutral - i.e. contain exactly the same amount of negative and positive charges. We mentioned before that protons and electrons don't really get along, and neutrons are kind of just there, hanging around. In truth, neutrons and protons also really get along, via the aptly named <i>nuclear force</i>; this is what binds them together in the nucleus of the atom. Electrons are attracted to protons and live their existences in a "cloud" around the nucleus. Note that the nucleus is more than 99% of the mass of the atom, which gives you an idea of just how small electrons are. </p> <p>The materials we will deal with in our examples are made of atoms, as are, well, quite a few things in the universe. These materials are themselves stable arrangements of atoms, just like atoms are stable arrangements of protons, neutrons and electrons. As you can see in the picture, these look like lattices of some kind. </p>  <div class="figure"><p><img alt="carbon-atoms.jpg" src="https://sciencemonday.files.wordpress.com/2011/09/carbon-atoms.jpg" /></p><p><span class="figure-number">Figure 1:</span> Microscopic View of Carbon Atoms. Source: <a href="https://sciencemonday.wordpress.com/2011/09/04/quantum-physics-the-brink-of-knowing-something-wonderful/">Quantum Physics: The Brink of Knowing Something Wonderful</a></p></div> <p>In practice, copper wires are made up of a great many things rather than just atoms of copper. One such "kind of thing" is the <i>unbound electrons</i> - or free-moving electrons; basically electrons are not trapped into an atom. As we mentioned before, electrons are the ones doing most of the moving. Left to their own devices, electrons in a conducting material will just move around, bumping into atoms in a fairly random way. However, lets say you take one end of a copper wire and plug it to the <code>+</code> side of a regular AA battery and then take other end and plug it to the <code>-</code> side of the battery. According to all we've just learned, its easy to imagine what will happen: the electrons stored in the <code>-</code> side will zip across the copper to meet their proton friends at the other end. This elemental construction, with its circular path, is called a <i>circuit</i>. What you've done is to upset the neutral balance of the copper wire and got all the electrons to move in a coordinated way (rather than random) from the <code>-</code> side to the <code>+</code> side. </p> <p>It is at this juncture that we must introduce the concept of ions. An <i>ion</i> is basically an atom that is no longer neutral - either because it has more protons than electrons (called a <i>cation</i>) or more electrons than protons (called an <i>anion</i>). In either case, this comes about because the atom has gained or lost some electrons. Ions will become of great interest when we return to the neuron. </p> <p>One final word on resistance and its sister concept of <i>conductance</i>: </p> <ul class="org-ul"><li><i>Resistance</i> is in effect a <a href="http://education.jlab.org/qa/current_02.html">byproduct of the way the electrons are arranged in the electron cloud</a> and is related to the ionisation mentioned above; certain arrangements just don't allow electrons to flow across. </li><li><i>Conductance</i> is the inverse of resistance. When you talk about resistance you are focusing on the material's ability to impair movement of charges; when you talk about conductance you are focusing on the material's ability to let charge flow through. </li></ul> <p>The reason we choose copper or other metals for our examples is because they are good at <i>conducting</i> these pesky electrons. </p></div></div> <div class="outline-2" id="outline-container-sec-7"><h2 id="sec-7">Ohm's Law</h2><div class="outline-text-2" id="text-7"><p>We have now introduced all the main actors required for one of the main parts in the play: Ohm's Law. It can be stated very easily: </p> <pre class="example"><br />V = R x I<br /></pre> <p>And here's a picture to aid intuition. </p>  <div class="figure"><p><img alt="4KhUg.jpg" src="http://i.stack.imgur.com/4KhUg.jpg" /></p><p><span class="figure-number">Figure 2:</span> Source: <a href="http://physics.stackexchange.com/questions/161650/could-someone-intuitively-explain-to-me-ohms-law">Could someone intuitively explain to me Ohm's law?</a></p></div> <p>The best way to understand this law is to create a simple circuit. </p>  <div class="figure"><p><img alt="Ohm's_Law_with_Voltage_source_TeX.svg" src="https://upload.wikimedia.org/wikipedia/commons/b/b4/Ohm's_Law_with_Voltage_source_TeX.svg" /></p><p><span class="figure-number">Figure 3:</span> Simple electrical circuit. Source: Wikipedia, <a href="https://en.wikipedia.org/wiki/Electrical_network">Electrical network</a></p></div> <p>On the left we have a voltage source, which could be our 1.5V AA battery. On the right of the diagram we have a <i>resistor</i> - an electric component that is designed specifically to "control" the flow of the electric current. Without the resistor, we would be limited by how much current the battery can pump out and how much "natural" resistance the copper wire has, which is not a lot since it is very good at conducting. The resistor gives us a way to limit current flow from these theoretical maximum limitations. </p> <p>Even if you are not particularly mathematically oriented, you can easily see that Ohm's Law gives us a nice way to find any of these three variables, given the other two. That is to say: </p> <pre class="example"><br />R = V / I<br />I = V / R<br /></pre> <p>These tell us many interesting things such as: for the same resistance, current increases as the voltage increases. For good measure, we can also find out the conductance too: </p> <pre class="example"><br />G = I / V = 1 / R<br /></pre> <p>It is important to notice that not everything obeys Ohm's law - i.e. behave in a straight line. The conductors that obey this law are called <i>ohmic conductors</i>. Those that do not are called <i>non-ohmic conductors</i>. There are also things that obey to Ohm's Law, for the most part. These are called <i>quasi-ohmic</i>. </p></div> <div class="outline-3" id="outline-container-sec-7-1"><h3 id="sec-7-1">What next?</h3><div class="outline-text-3" id="text-7-1"><p>We have already run out of time for this instalment but there are still some more fundamental electrical concepts we need to discuss. The next part will finish these and start to link them back to the neuron. </p></div></div></div></div><div class="status" id="postamble"><p class="date">Created: 2015-08-31 Mon 19:27</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://mcraveiro.blogspot.com/2015/08/nerd-food-neurons-for-computer-geeks.html">Nerd Food: Neurons for Computer Geeks - Part I: A Neuron From Up On High</a></h2></div>
            <p class="text-muted">by <a href="http://mcraveiro.blogspot.com/">Marco Craveiro</a> on September 14, 2015 04:32 PM.</p>
          </div>
          <div class="panel-body">

            Nerd Food: Neurons for Computer Geeks - Part I: A Neuron From Up On High<div id="content"><p>As any computer geek would tell you, computer science is great in and of itself and many of us could live long and contented lives inside that box. But things certainly tend to become interesting when there is a whole problem domain to model, and doubly so when that domain is outside of our comfort zone. As it happens, I have managed to step outside said zone - rather, quite far outside - so it seemed like a good idea to chronicle these adventures here. </p> <p>The journey we are about to embark starts with a deceptively simple mission: to understand how one can use computers to model neurons. The intended audience of these posts is anyone who loves coding but has no idea about electricity, circuits, cells and so on - basically someone very much like me. We shall try to explain, at least to a degree, all of the required core concepts in order to start coding. As it turns out, there are quite a few. </p> <p>But hey, as <a href="http://skeptics.stackexchange.com/questions/8742/did-einstein-say-if-you-cant-explain-it-simply-you-dont-understand-it-well-en">they say</a>, "If you can't explain something to a six year-old, you really don't understand it yourself". So lets see if I got it or not. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">I'm a Cell, Get Me Out Of Here!</h2><div class="outline-text-2" id="text-1"><p>A neuron is a <i>cell</i>, so it makes sense to start with cells. Cells are a basic building block in biology and can be considered as the smallest unit of a living organism - at least for our purposes, if nothing else. The key idea behind a cell is as obvious as you'd like: there is the inside, the outside, and the thing that separates both. </p> <p>Of course, this being biology, we need to give it complicated names. Accordingly, the inside of the cell is the <i>cytoplasm</i> and the thing that separates the cell from the outside world is the <i>membrane</i>. You can think of it as a <i>tiny</i> roundy-box-like thing, with some gooey stuff inside. The material of the box is the membrane. The gooey stuff is the cytoplasm. When we start describing the different cellular structures - as we are doing here - we are talking about the cell's <i>morphology</i>. </p> <p>Living beings are made up of many, many cells - according to some estimates, a human body would have several trillion - and cells themselves come in many, <i>many</i> kinds. Fortunately, we are interested in just one kind: the <i>neuron</i>. </p></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">The Neuron Cell</h2><div class="outline-text-2" id="text-2"><p>The neuron is a nerve cell. Of course, there are many, <i>many</i> kinds of neurons - nature just seems to love complexity - but they all share things in common, and those things define their neuron-ness. </p> <p>Unlike the "typical" cell we described above (i.e. "roundy-box-like thing"), the neuron is more like a roundy-box-like thing with some branches coming out of it. The box-like thing is the cell body and is called <i>soma</i>. There are two types of branches: axons and dendrites. A <i>dendrite</i> tends to be short, and it branches like a tree with a very small trunk. The <i>axon</i> tends to be long and it also branches off like a tree, but with a very long trunk. As we said, there are many kinds of neurons, but a fair generalisation is that they tend to have few axons (one or maybe a couple) and many dendrites (in the thousands). </p>  <div class="figure"><p><img alt="8808542_f520.jpg" src="http://usercontent1.hubimg.com/8808542_f520.jpg" /></p><p><span class="figure-number">Figure 1:</span> Source: <a href="http://mariexotoni.hubpages.com/hub/What-is-a-Neuron2">What is a Neuron?</a></p></div> <p>This very basic morphology is already sufficient to allows to start to think of a neuron as a "computing device" - a strange kind of device where the dendrites provide inputs and the axon outputs. The neuron receives all these inputs, performs some kind of computation over them, and produces an output. </p> <p>The next logical question for a computer scientist is, then: "where do the outputs come from and where do they go?". Imagining an idealised neuron, the dendrites would be "connecting" to other dendrites or to axons. At this juncture (pun not intended), we need to expand on what exactly these "connections" are. In truth, its not that the axon binds directly to the dendrite; there is always a gap between them. But this gap is a special kind of gap, first because it is a very small gap and second because it is one over which things can travel, from the axon into the dendrite. This kind of connectivity between neurons is called a <i>synapse</i>. </p> <p>From this it is an easy leap to imagine that these sets of neurons connected to other neurons begin to form "networks" of connectivity, and these networks will also have computational-device-like properties, just like a neuron. These are called <i>neural networks</i>. Our brain happens to be one of these "neural networks", and a pretty large one at that: it can have <a href="http://www.nature.com/scitable/blog/brain-metrics/are_there_really_as_many">as many as 80-100 billion neurons</a>, connected over some 1 quadrillion synapses. In these days of financial billions and trillions, it is easy to be fooled into thinking 100 billion is not a very large number, so to get a sense of perspective lets compare it to another large network. The biggest and fastest growing human-made network is the Internet, estimated to have <a href="http://www.gartner.com/newsroom/id/2905717">some 5 billion connected devices</a> but less than <a href="http://bgp.potaroo.net/">600k connections in its core</a> - and yet we are already <a href="http://research.dyn.com/2014/08/internet-512k-global-routes/">creacking at the seams</a>. </p></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">The Need To Go Lower</h2><div class="outline-text-2" id="text-3"><p>Alas, we must dig deeper before we start to understand how these things behave in groups. Our skimpy first pass at the neuron morphology left a lot of details out, which are required to understand how they behave. As we explained, neurons have axons and dendrites, and these are responsible for hooking them together. However, what is interesting is what they talk about once they are hooked. </p> <p>A neuron is can be thought of as an <i>electrical device</i>, and much of its power (sorry!) stems from this. In general, as computer scientists, we don't like to get too close to the physical messiness of the world of hardware; we deem it sufficient to understand some high-level properties, but rarely do we want to concern ourselves with transistors or even - regrettably - registers or pipelines in the CPU. With neurons, we can't get away with it. We need to understand the hardware - or better, the wetware - and for that we have to go <i>very</i> low-level. </p> <p>We started off by saying cells have a membrane that separates the outside world from the cytoplasm. That was a tad of an oversimplification; after all, if the membrane did not allow anything in, how would the cell continue to exist - or even come about in the first place? In practice these membranes are permeable - or to be precise, <i>semi-permeable</i>. This just means that it allows some stuff in and some stuff out, under controlled circumstances. This is how a cell gets energy <i>in</i> to do its thing and how it expels its unwanted content <i>out</i>. Once things started to move in and out selectively, something very interesting can start to happen: the build up of "electric potential". However, rather unfortunately, in order to understand what we mean by this, we need to cover the fundamentals of electricity. </p> <p>Onward and downwards we march. Stay tuned for Part II. </p></div></div></div><div class="status" id="postamble"><p class="date">Created: 2015-08-31 Mon 17:25</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://mcraveiro.blogspot.com/2015/09/nerd-food-neurons-for-computer-geeks_7.html">Nerd Food: Neurons for Computer Geeks - Part V: Yet More Theory</a></h2></div>
            <p class="text-muted">by <a href="http://mcraveiro.blogspot.com/">Marco Craveiro</a> on September 07, 2015 04:29 PM.</p>
          </div>
          <div class="panel-body">

            Nerd Food: Neurons for Computer Geeks - Part V: Yet More Theory<div id="content"><p>Welcome to part V of a multi-part series on modeling neurons. In <a href="http://mcraveiro.blogspot.co.uk/2015/09/nerd-food-neurons-for-computer-geeks_5.html">part IV</a> we introduced the RC Circuit by making use of the foundations we painstakingly laid in previous posts. In truth, we could now move on to code and start looking at the <a href="http://icwww.epfl.ch/~gerstner/SPNM/node26.html">Leaky Integrate-and-Fire</a> (LIF) model, since we've already covered most required concepts. However, we are going to do just a little bit more theory before we get to that. </p> <p>The main reason for this detour is that I do not want to give you the impression neurons are <i>easy</i>; if there is one thing that they are <b>not</b> is <i>easy</i>. So we're going to resume our morphological and electrical exploits to try to provide a better account of the complexity inside the neuron, hopefully supplying enough context to appreciate the simplifications done in LIF. </p> <p>The content of this post is highly inspired from <a href="http://www.cambridge.org/us/academic/subjects/life-sciences/neuroscience/principles-computational-modelling-neuroscience">Principles of Computational Modelling in Neuroscience</a>, a book that is a must read introduction if you decide to become serious on this subject. If so, you may also want to check the Gerstner videos: <a href="http://klewel.com/conferences/epfl-neural-networks/index.php?talkID=1">Neural networks and biological modeling</a>. </p> <p>But you need not worry, casual reader. Our feet are firmly set in layman's land and we'll remain so until the end of the series. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">Brief Context on Modeling</h2><div class="outline-text-2" id="text-1"><p>Before we get into the subject matter proper, I'd like us to ponder a few "meta-questions" in terms of modeling. </p></div> <div class="outline-3" id="outline-container-sec-1-1"><h3 id="sec-1-1">Why Model?</h3><div class="outline-text-3" id="text-1-1"><p>A layperson may think that we model neurons because we want to build a "computer brain": one that is similar to a real brain, with its amazing ability to learn, and one which at some point may even <i>think and be conscious</i>. Hopefully, after you finish this series of posts, you will appreciate the difficulty of the problem and see that it's not very likely we'll be able to make a "realistic" "computer brain" any time soon - for sensible values of "realistic", "computer brain" and "any time soon". </p> <p>Whilst we have good models that explain part of the behaviour of the neuron and good models for neural networks too, it is not the case that we can put all of these together to form some kind of "unified neuron model", multiply it by 80 billion, add a few quadrillion synapses and away we go: artificial consciousness. Given what we know at the moment, this approach is far too computationally demanding to be feasible. Things would change if there was a massive leap in computational power, of course, but not if they stay at present projections - even with <a href="https://en.wikipedia.org/wiki/Moore%2527s_law">Moore's Law</a>. </p> <p>So if we are not just trying to build a computer brain, then why bother? Well, if you set your sights a little lower, computational models are actually amazingly useful: </p> <ul class="org-ul"><li>one can use code to explore a small portion of the problem domain, making and validating predictions using computer models, and then test those predictions in the lab with real wetware. The iterative process is orders of magnitude faster. </li><li>computer models are now becoming quite sophisticated, so in some cases they are good representations of biological processes. This tends to be the case for small things such as individual cells or smaller. As computers get faster and faster according to <a href="https://en.wikipedia.org/wiki/Moore%2527s_law">Moore's Law</a>, the power and scope of these models grows too. </li><li>distributing work with Free and Open Source Software licences means it is much easier for researchers to reproduce each others work, as well as for them to explore avenues not taken by those who did the work originally, speeding things up considerably. Standing on the shoulders of giants and all that. </li></ul></div></div> <div class="outline-3" id="outline-container-sec-1-2"><h3 id="sec-1-2">What Tools Do We Model With?</h3><div class="outline-text-3" id="text-1-2"><p>The focus of these posts is on writing models from scratch, but that's not how most research is conducted. In the real world, people try their best to reuse existing infrastructure - of which there is plenty. For example there is <a href="https://www.neuron.yale.edu/neuron/">NEURON</a>, <a href="http://neuralensemble.org/PyNN/">PyNN</a>, <a href="http://briansimulator.org/">Brian</a> and much more. Tools and processes have evolved around these ecosystems, and there is a push to try to standardise around the more successful frameworks. </p> <p>There is also a push to find some kind of standard "language" to describe models so that we can all share information freely without having to learn the particulars of each others representations. The world is not quite there yet, but initiatives such as <a href="https://www.neuroml.org/">NeuroML</a> are making inroads in this direction. </p> <p>However, the purpose of our this series is simplification, so we will swerve around all of this. Perhaps material for another series. </p></div></div> <div class="outline-3" id="outline-container-sec-1-3"><h3 id="sec-1-3">At What Level Should One Model?</h3><div class="outline-text-3" id="text-1-3"><p>A related question to the previous ones - and one that is not normally raised in traditional software engineering, but is very relevant in biology - is the level of detail at which one should model. </p> <p>Software Engineers tend to believe there is <i>a model</i> for <i>a problem</i>, and once you understand enough about the problem domain you will come up with it and <i>all will be light</i>. Agile and sprints are just a way to converge to it, to the perfection that exists somewhere in the platonic cloud. Eric Evans with <a href="https://domainlanguage.com/ddd/">DDD</a> started to challenge that assumption somewhat by making us reflect on just what it is that we mean by "model" and "modeling", but, in general, we have such an ingrained belief in this idea that is very hard to shake it off or to even realise the belief is there in the first place. Most of us still think of the code representation of the domain model as <i>the model</i> - rather than accept it is one of a multitude of possible representations, each suitable for a given purpose. </p> <p>Alas, all of this becomes incredibly obvious when you are faced with a problem like modeling a neuron or a network of neurons. Here, there is just no such thing as the "right model"; only a set of models at a different perspectives, each with a different set of trade-offs, and any of them only make sense in the context of what one is trying to study. It may make sense to model neurons like networks, ignoring the finer details of each one and looking at their behaviour as a group, or it may make sense to model individual bits of the neuron as an entity. What makes it "right" or "wrong" is what it is that we are using the model for and how much computational power one has at one's disposal. </p> <p>Having said all of that, lets resume our morphology adventures. </p></div></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">Electricity and Neurons</h2><div class="outline-text-2" id="text-2"><p>We started off with <a href="http://mcraveiro.blogspot.co.uk/2015/08/nerd-food-neurons-for-computer-geeks.html">an overview of the neuron</a> and then moved over to <a href="http://mcraveiro.blogspot.co.uk/2015/08/nerd-food-neurons-for-computer-geeks_31.html">lots</a> and <a href="http://mcraveiro.blogspot.co.uk/2015/09/nerd-food-neurons-for-computer-geeks_5.html">lots</a> of electricity; now it's time to see how those two fit together. </p> <p>As we explained in <a href="http://mcraveiro.blogspot.co.uk/2015/08/nerd-food-neurons-for-computer-geeks.html">part I</a>, there is a electric potential difference between the inside of the cell and the outside, called the <i>membrane potential</i>. The convention to compute this potential is to subtract the potential inside the cell to the potential outside the cell; current is positive when there is a flow of positive charge from the inside to the outside and negative otherwise. Taken into account these definitions, one should be able to make sense of the <i>resting membrane potential</i>: it is around -65mv. But how does this potential change? </p></div> <div class="outline-3" id="outline-container-sec-2-1"><h3 id="sec-2-1">Ion Channels</h3><div class="outline-text-3" id="text-2-1"><p><a href="http://mcraveiro.blogspot.co.uk/2015/08/nerd-food-neurons-for-computer-geeks_31.html">Earlier</a>, we spoke about ions - atoms that either lost or gained electrons and so are positively or negatively charged. We also said that, in general, the cell's membrane is impermeable, but there are tiny gaps in the membrane which allow things in and out of the cell. Now we can expand a bit further. <i>Ion channels</i> are one such gap, and they have that name because they let ions through. There are <i>many</i> kinds of ion channels. One way of naming them is to use the ion they are most permeable to - but of course, this being biology, the ion channels don't necessarily always have a major ion they are permeable to. </p> <p>Another useful categorisation distinguishes between <i>passive</i> and <i>active</i> ion channels. Active channels are those that change their permeability depending on external factors such as the membrane potential, the concentration of certain ions, and so on. For certain values they are open - i.e. permeable - whereas for other values they are closed, not allowing any ions through. Passive channels are simpler, they just have a fixed permeability behaviour. </p> <p>There are also <i>ionic pumps</i>. These are called pumps because they take one kind of ion out, exchanging it for another kind. For instance, the sodium-potassium pump pushes potassium into the cell and expels sodium out. A pump has a <i>stoichiometry</i>, which is a fancy word to describe the ratio of ions being pumped in and out. </p></div></div> <div class="outline-3" id="outline-container-sec-2-2"><h3 id="sec-2-2">Complexity Starts To Emerge</h3><div class="outline-text-3" id="text-2-2"><p>As you can imagine, the key to understating electric behaviour is understanding how these pesky ions move around. Very simplistically, ions tend to move for two reasons: because there is a potential difference between the inside and the outside of the cell, or because of the <i>concentration gradient</i> of said ion. The concentration gradient just means that, left to their own devices, concentration becomes uniform over time. For example, if you drop some ink in a glass of water, you will start by seeing the ink quite clearly; given enough time, the ink will diffuse in the water, making it all uniformly coloured. The same principle applies to ions - they want to be uniformly concentrated. </p> <p>It should be fairly straightforward to work out that a phenomenal number of permutations is possible here. Not only do we have a great number of channels, all with different properties - some switching on and off as properties change around the cell - but we also have the natural flow of ions being affected by the membrane's potential and the concentration gradient, all of which are changing over time. To make matters worse, factors interact with each other such that even if you have simple models to explain each aspect individually, the overall behaviour is still incredibly complex. </p> <p>Now imagine more than <a href="http://pubs.acs.org/doi/abs/10.1021/jp0120662">50 thousand</a> such ion channels - of over one hundred (known) types - in just a single neuron and you are starting to get an idea of the magnitude of the task. </p></div></div> <div class="outline-3" id="outline-container-sec-2-3"><h3 id="sec-2-3">Equivalent Circuit for a Patch of Membrane</h3><div class="outline-text-3" id="text-2-3"><p>But lets return to simplicity. The very clever people determined that it is possible to model the behaviour of ions and its electric effects by thinking of it as an electric circuit. Taking a patch of membrane as an example, it can be visualised as an electric circuit like so: </p>  <div class="figure"><p><img alt="Cell_membrane_equivalent_circuit.svg" height="500px" src="https://upload.wikimedia.org/wikipedia/commons/e/e5/Cell_membrane_equivalent_circuit.svg" width="500px" /></p><p><span class="figure-number">Figure 1:</span> Source: Wikipedia, <a href="https://en.wikipedia.org/wiki/Membrane_potential">Membrane Potential</a></p></div> <p>What this diagram tells us is that the membrane itself acts as a capacitor, with its capacitance determined by the properties of the <i>lipid bilayer</i>. We didn't really discuss the lipid bilayer before so perhaps a short introduction is in order. The membrane is made up of two sheets of lipids (think fatty acids), which when layered so, have interesting properties: the outside of the sheets are impermeable to most things such as water molecules and ions. The membrane itself is pretty thin, at around 5nm. </p> <p>The membrane capacitance is considered constant. We then have a series of ion channels: sodium, potassium, chlorine, calcium. Each of these can be thought of as a pairing of a resistor with variable conductance coupled with a battery. Note that the resistor and the battery are in series, but the ion channels themselves form a parallel circuit. The voltages for each pathway are determined by the different concentrations of the ion inside and outside the cell. </p> <p>If we further assume fixed ion concentrations and passive ion channels, we can perform an additional simplification on the circuit above and we finally end up with an RC Circuit: </p>  <div class="figure"><p><img alt="Cell_membrane_reduced_circuit.svg" height="300px" src="https://upload.wikimedia.org/wikipedia/commons/b/b6/Cell_membrane_reduced_circuit.svg" width="300px" /></p><p><span class="figure-number">Figure 2:</span> Source: Wikipedia, <a href="https://en.wikipedia.org/wiki/Membrane_potential">Membrane Potential</a></p></div> <p>The circuit now has one resistance, which we call the membrane resistance, and a membrane battery. </p></div></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">What next?</h2><div class="outline-text-2" id="text-3"><p>Hopefully you can start to see both the complexity around modeling neurons and the necessity to create simpler models to make them computationally feasible - just look at the amount of simplification that was required for us to get to an RC Circuit! </p> <p>But at least we can now look forward to implementing LIF. </p></div></div></div><div class="status" id="postamble"><p class="date">Created: 2015-09-07 Mon 17:12</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://mcraveiro.blogspot.com/2015/09/nerd-food-neurons-for-computer-geeks_4.html">Nerd Food: Neurons for Computer Geeks - Part III: Coding Interlude</a></h2></div>
            <p class="text-muted">by <a href="http://mcraveiro.blogspot.com/">Marco Craveiro</a> on September 05, 2015 02:31 PM.</p>
          </div>
          <div class="panel-body">

            Nerd Food: Neurons for Computer Geeks - Part III: Coding Interlude<div id="content"><p>If you are anything like me, the first two parts of this series have already bored you silly with theory (<a href="http://mcraveiro.blogspot.co.uk/2015/08/nerd-food-neurons-for-computer-geeks.html">Part I</a>, <a href="http://mcraveiro.blogspot.co.uk/2015/08/nerd-food-neurons-for-computer-geeks_31.html">Part II</a>) and you are now hankering for some code - any code - to take away the pain. So part III is here to do exactly that. However, let me prefix that grandiose statement by saying this is not the best code you will ever see. Rather, its just a quick hack to introduce a few of the technologies we will make use of for the remainder of these series, namely: </p> <ul class="org-ul"><li><a href="http://www.cmake.org/">CMake</a> and <a href="http://martine.github.io/ninja/">Ninja</a>: this is how we will build our code. </li><li><a href="http://www.webtoolkit.eu/wt">Wt</a>: provides a quick way to knock-up a web frontend for C++ code. </li><li><a href="http://www.boost.org/">Boost</a>: in particular <a href="http://www.boost.org/doc/libs/1_59_0/doc/html/boost_units.html">Boost Units</a> and later on <a href="http://www.boost.org/doc/libs/1_59_0/libs/numeric/odeint/doc/html/index.html">Boost OdeInt</a>. Provides us with the foundations for our numeric work. </li></ul> <p>What I mean by a "quick hack" is: there is no validation, no unit tests, no "sound architecture" and none of the things you'd expect from production code. But it should serve as an introduction to modeling in C++. </p> <p>All the code is available in GitHub under <a href="https://github.com/mcraveiro/neurite">neurite</a>. Lets have a quick look at the project structure. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">CMake</h2><div class="outline-text-2" id="text-1"><p>We just took a slimmed down version of the <a href="https://github.com/DomainDrivenConsulting/dogen">Dogen</a> build system to build this code. We could have gotten away with a much simpler CMake setup, but I intend to use it for the remainder of this series so that's why its a bit more complex than what you'd expect. It is made up of the following files: </p> <ul class="org-ul"><li>Top-level <code>CMakeLists.txt</code>: ensures all of the dependencies can be found and configured for building, sets up the version number and debug/release builds. </li><li><code>build/cmake</code>: any Find* scripts that are not supplied with the CMake distribution. We Google for these and copied them here. </li><li><code>projects/CMakeLists.txt</code>: sets up all of the compiler and linker flags we need to build the project. Uses pretty aggressive flags such as <code>-Wall</code> and <code>-Werror</code>. </li><li><code>projects/ohms_law/src/CMakeLists.txt</code>: our actual project, the bit that matters for this article. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2"><code>ohms_law</code> Project</h2><div class="outline-text-2" id="text-2"><p>The project is made up of two classes, in files <code>calculator.[hc]pp</code>and <code>view.[hc]pp</code>. The names are fairly arbitrary but they try to separate View from Model: the user interface is in <code>view</code> and the "number crunching" is in <code>calculator</code>. </p></div> <div class="outline-3" id="outline-container-sec-2-1"><h3 id="sec-2-1">The View</h3><div class="outline-text-3" id="text-2-1"><p>Lets have a quick look at <code>view</code>. In the header file we simply define a Wt application with a few widgets: </p> <pre class="example"><br />class view : public Wt::WApplication {<br />public:<br />  view(const Wt::WEnvironment&amp; env);<br /><br />private:<br />  Wt::WLineEdit* current_;<br />  Wt::WLineEdit* resistance_;<br />  Wt::WText* result_;<br />};<br /></pre> <p>It is implemented in an equally trivial manner. We just setup the widgets and hook them together. Finally, we create a trivial event handler that performs the "computations" when the button is clicked. </p> <pre class="example"><br />view::view(const Wt::WEnvironment&amp; env) : Wt::WApplication(env) {<br />  setTitle("Ohm's Law Calculator");<br /><br />  root()-&gt;addWidget(new Wt::WText("Current: "));<br />  current_ = new Wt::WLineEdit(root());<br />  current_-&gt;setValidator(new Wt::WDoubleValidator());<br />  current_-&gt;setFocus();<br /><br />  root()-&gt;addWidget(new Wt::WText("Resistance: "));<br />  resistance_ = new Wt::WLineEdit(root());<br />  resistance_-&gt;setValidator(new Wt::WDoubleValidator());<br /><br />  Wt::WPushButton* button = new Wt::WPushButton("Calculate!", root());<br />  button-&gt;setMargin(5, Wt::Left);<br />  root()-&gt;addWidget(new Wt::WBreak());<br />  result_ = new Wt::WText(root());<br /><br />  button-&gt;clicked().connect([&amp;](Wt::WMouseEvent&amp;) {<br />      const auto current(boost::lexical_cast&lt;double&gt;(current_-&gt;text()));<br />      const auto resistance(boost::lexical_cast&lt;double&gt;(resistance_-&gt;text()));<br /><br />      calculator c;<br />      const auto voltage(c.voltage(resistance, current));<br />      const auto s(boost::lexical_cast&lt;std::string&gt;(voltage));<br />      result_-&gt;setText("Voltage: " + s);<br />    });<br />}<br /></pre></div></div> <div class="outline-3" id="outline-container-sec-2-2"><h3 id="sec-2-2">The Model</h3><div class="outline-text-3" id="text-2-2"><p>The model is equally as simple as the view. It is made up of a single class, <code>calculator</code>, whose job is to compute the voltage using Ohm's Law. It does this by making use of Boost Units. This is obviously not necessary, but we wanted to take the opportunity to explore this library as part of this series of articles. </p> <pre class="example"><br />double calculator::<br />voltage(const double resistance, const double current) const {<br />  boost::units::quantity&lt;boost::units::si::resistance&gt;<br />    R(resistance * boost::units::si::ohms);<br />  boost::units::quantity&lt;boost::units::si::current&gt;<br />    I(current * boost::units::si::amperes);<br />  auto V(R * I);<br />  return V.value();<br />}<br /></pre></div></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">Compiling and Running</h2><div class="outline-text-2" id="text-3"><p>If you are on a debian-based distribution, you can do the following steps to get the code up and running. First install the dependencies: </p> <pre class="example"><br />$ sudo apt-get install libboost-all-dev witty-dev ninja-build cmake clang-3.5<br /></pre> <p>Then obtain the source code from GitHub: </p> <pre class="example"><br />$ git clone https://github.com/mcraveiro/neurite.git<br /></pre> <p>Now you can build it: </p> <pre class="example"><br />cd neurite<br />mkdir output<br />cd output<br />cmake ../ -G Ninja<br />ninja -j5<br /></pre> <p>If all went according to plan, you should be able to run it: </p> <pre class="example"><br />$ stage/bin/neurite_ohms_law --docroot . --http-address 0.0.0.0 --http-port 8080<br /></pre> <p>Now using a web browser such as chrome, connect to <a href="http://127.0.0.1:8080">http://127.0.0.1:8080</a> and you should see a "shiny" Ohm's Law calculator! Sorry, just had to be done to take away the boredom a little bit. Lets proceed with the more serious matters at hand, with the promise that the real code will come later on. </p></div></div></div><div class="status" id="postamble"><p class="date">Created: 2015-09-04 Fri 17:16</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://mcraveiro.blogspot.com/2015/05/nerd-food-prelude-of-things-to-come.html">Nerd Food: A Prelude of Things to Come</a></h2></div>
            <p class="text-muted">by <a href="http://mcraveiro.blogspot.com/">Marco Craveiro</a> on May 26, 2015 11:19 PM.</p>
          </div>
          <div class="panel-body">

            Nerd Food: A Prelude of Things to Come<div id="content"><p>This sprint I found myself making one of those historical transitions: moving my entire Emacs infrastructure from a old, creaking at the seams approach, to the new all-singing-all-dancing way of doing things. This post documents the start of this transition. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">The Road to Cunene</h2><div class="outline-text-2" id="text-1"><p>I have been using <a href="http://www.gnu.org/software/emacs/">Emacs</a> since around 1998. One of the biggest reasons to use the great old editor is its infinite configurability. Really, to call Emacs "configurable" is rather like saying that <a href="http://en.wikipedia.org/wiki/Leonhard_Euler">Euler</a> wasn't bad with numbers. In truth - and it takes you a while to really grok this - Emacs is just a lisp platform with a <span class="underline">giant</span> editing library built on top; a library that keeps on getting extended on a daily basis by a large number of Emacs users. And, of course, you configure Emacs using lisp, so that the lines between "configuration" and "development" are, at best, blurry. </p> <p>But lets go back to the beginning. Like every other Emacs newbie in those days, I too started with a plain (i.e. non-configured) Emacs and soon evolved to a very simple <span class="underline"><a href="http://www.emacswiki.org/emacs/InitFile">.emacs</a></span> - this file being one of the possible places in which to store its configuration. The reason why almost all Emacs users start configuring Emacs very early on is because its defaults are astonishingly atrocious. It still amazes me to the day that some people are able to use plain Emacs and come out at the other end as Emacs users. In some ways, I guess it is a test of fire: do you <span class="underline">really</span> want to use Emacs? There are two responses to this test: most give up, but a few persist and soon start changing the editor to behave in a slightly saner manner. </p> <p>The <span class="underline">.emacs</span> starts small, especially if you are not familiar with lisp. Sooner or later it occurs to you that, <span class="underline">surely</span>, someone must have already done one of these before, and then you find the amazing world of <span class="underline">.emacs</span> "development". This opens up entire new vistas of the Emacs landscape, because with each <span class="underline">.emacs</span> you find, you discover untold numbers of configuration knobs and - much more importantly - many new <span class="underline">modes</span> to install. In Emacs lingo, a <span class="underline">mode</span> is kind of like a "plug-in" for Eclipse or Visual Studio users. But this is just an approximation; as with everything "Emacs", there is actually no real equivalent way of describing Emacs terminology with analogies outside of Emacs. The problem with IDEs and most other editors is that they can only be extended in ways that their designers thought useful. In Emacs, <span class="underline">everything</span> is extensible. And I do mean <span class="underline">everything</span>. I remember the day I realised that a key press was really just the invocation of the <code>self-insert-command</code> function and, like any other function, it too could be changed in a myriad of ways. </p> <p>But I digress. As with most users, my <span class="underline">.emacs</span> evolved over the years as I found more and more modes. I soon found that it was very painful to keep all my machines with the same setup; invariably I would change something at work but forget to change it at home or Uni or vice-versa. To make matters worse, some machines were on Windows. And in those days, there was no Emacs package management support, so you ended up copying lots of modes around. Life was painful and brute in my first decade of Emacs. </p> <p>Around six years ago, things got a lot better: I started to use git in anger, refactored my <span class="underline">.emacs</span> into something slightly saner and called it Cunene - after <a href="http://en.wikipedia.org/wiki/Cunene_River">the river</a> in Southern Angola. Eventually I <a href="https://github.com/mcraveiro/cunene">put it on GitHub</a>. I believe - but don't recall exactly - that most of the refactoring ideas were stolen from Phil Hagelberg's <a href="https://github.com/technomancy/emacs-starter-kit">Starter Kit</a> and <a href="https://github.com/alexott/emacs-configs">Alex Ott's .emacs</a>. </p> <p>Whatever the source of ideas, the improvements were undeniable. Cunene offered a all-in-one place to go to for my <span class="underline">.emacs</span>, and it combined all the experience I had in seeing other people's <span class="underline">.emacs</span>. At over twenty megs it wasn't exactly svelte, but my objective was to have a "zero-conf" setup; given a new machine, all I wanted to do was to <code>git clone</code> cunene, start Emacs and have exactly the same environment as everywhere else. </p> <p>Further, I could update Cunene from any machine and push it back to GitHub. Cunene contained all the modes I needed, all byte-compiled, and all at trusted versions and with some (very minor) patches. I could easily upgrade one or more modes from one machine and then just <code>git pull</code> from all other machines. It also handled any Windows-specific workarounds, ensuring things worked well out of the box there too. </p> <p>To be fair, for the last 6 years, this setup has served me well, but time also revealed its limitations: </p> <ul class="org-ul"><li>package management support was limited. I tried using <a href="http://emacswiki.org/emacs/ELPA">Elpa</a> but, at the time, not many packages were available. Package management has evolved in leaps and bounds - <a href="http://melpa.org/#/">Melpa</a>, <a href="https://marmalade-repo.org/">Marmelade</a>, etc - but Cunene was still stuck with the old Elpa support. </li><li>the accumulation of modes over such a long period meant that starting Emacs took quite a long time. And to make matters worse, only a small percentage of the modes were truly useful. </li><li>most of the modes were at stale versions. Since things worked for me, I had no incentive to keep up with latest and greatest - and for all the easiness, it was still not exactly trivial to upgrade modes. This meant that I ended up having to put up with bugs that had long been fixed in HEAD, and worse, whenever I upgraded to latest, I saw massive changes in behaviour. </li><li>I was stuck on Emacs 23. For whatever reason, some parts of Cunene did not work with Emacs 24 properly and I was never able to get to the bottom of this. Being on an old version of Emacs has been a problem because I make use of C++-11 but Emacs 23 doesn't really indent it properly. And of course, Emacs 24 is just improved all around. </li><li>Cunene had a lot of boilerplate code. Since I never really learnt how to code in Emacs lisp, I was most likely writing a lot of non-idiomatic code. Also, the Emacs API has moved on considerably in fifteen years, so certain things were not being done in the best way possible. </li><li>Cedet and Org-mode are now part of Emacs but we were still carrying our own copies. I never managed to get Cedet to work properly either. </li><li>many new modes have appeared of late that provide much better solutions to some of the problems I had, but Cunene insulated me from these developments. In addition, adding new modes would only add to the complexity so I had no incentive to do so. </li></ul> <p>There had to be a better way of doing things; something that combined the advantages of Cunene but fixed its shortcomings. </p> <p>Then I heard of <a href="https://github.com/bbatsov/prelude#automated">Prelude</a>. </p></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">The Road to Prelude</h2><div class="outline-text-2" id="text-2"><p>According to the official documentation: </p> <blockquote><p>Prelude is an Emacs distribution that aims to enhance the default Emacs experience. Prelude alters a lot of the default settings, bundles a plethora of additional packages and adds its own core library to the mix. The final product offers an easy to use Emacs configuration for Emacs newcomers and lots of additional power for Emacs power users. </p></blockquote> <p>I am still finding my way around - so don't quote me - but from what I have seen, it seems to me that Prelude is like the Cunene "framework" but done by people that know what they are doing. It covers all of the advantages described above, but shares none of its disadvantages. In particular: </p> <ul class="org-ul"><li>it provides a sensible set of baseline defaults that "we all can agree on". I found it quite surprising that a plain Prelude looked almost like Cunene. Of course, no two Emacs users agree on anything, really, so there is still a lot to be tweaked. Having said that, the great thing is you can start by seeing what Prelude says and giving it a good go using it; if the baseline default does not work for you, you can always override it. Just because you have been doing something in a certain way for a long time does not mean its the best way, and the move to Prelude provides an opportunity to reevaluate a lot of "beliefs". </li><li>all the framework code is now shared by a large number of Emacs users. This means it is well designed and maintained, and all you have to worry about is your small extensibility points. With over 1k forks in GitHub, you can rest assured that Prelude will be around for a long time. In addition, if you find yourself changing something that is useful to the Prelude community, you can always submit a pull request and have that code shared with the community. You no longer have to worry about staleness or non-idiomatic code. </li><li>Prelude integrates nicely with several package managers and handles updates for you. </li><li>There are lots of examples of Prelude users - you just need to follow the GitHub forks. It would be nice to have a list of "good examples" though, because at 1K forks its not easy to locate those. </li><li>If you fork Prelude the right way, you should be able to update from upstream frequently without having too many conflicts. I am still getting my head around this, but the model seems sound at first blush. </li></ul> <p>But to know if it worked required using it in anger, and that's what will cover in the next few sections. </p></div> <div class="outline-3" id="outline-container-sec-2-1"><h3 id="sec-2-1">From Cunene to Prelude</h3><div class="outline-text-3" id="text-2-1"><p>Emacs users are creatures of habit and changing your entire workflow is not something to take lightly. Having said that, I always find that the best way to do it is to just go for it. After all, you can always go back to how you did things before. In addition, I did not want to do a wholesale port of Cunene for two reasons: </p> <ul class="org-ul"><li>I didn't want to bring across any bad habits when Prelude was already solving a problem properly. </li><li>I wanted to get rid of all of the accumulated cruft that was no longer useful. </li></ul> <p>What follows are my notes on the porting work. This is a snapshot of the work, a few days into it. If there is a reason, I may do further write-ups to cover any new developments. </p></div> <div class="outline-4" id="outline-container-sec-2-1-1"><h4 id="sec-2-1-1">Initial Setup</h4><div class="outline-text-4" id="text-2-1-1"><p>Prelude recommends you to create a fork and then add to it your personal configuration. I decided to create a branch in which to store the personal configuration rather than pollute master. This has two advantages: </p> <ul class="org-ul"><li>pulling from upstream will always be conflictless; </li><li>if I do decide to submit a pull request in the future, I can have a clean feature branch off of master that doesn't have any of the personal cruft in it. </li></ul> <blockquote><p>As it happens, I later found out that other Prelude users also use this approach such as <a href="https://github.com/danielwuz">Daniel Wu</a>, as you can see <a href="https://github.com/danielwuz/prelude/tree/personal/personal">here</a>. I ended up using Daniel's approach in quite a few cases. </p></blockquote> <p>I created <a href="https://github.com/mcraveiro/prelude">my prelude fork</a> in GitHub using the web interface. Once the fork was ready, I moved Cunene out of the way by renaming the existing <code>.emacs.d</code> directory and performed the following setup: </p> <pre class="example"><br />$ curl -L https://github.com/bbatsov/prelude/raw/master/utils/installer.sh -o installer.sh<br />$ chmod +x installer.sh<br />$ ./installer.sh -s git@github.com:mcraveiro/prelude.git<br /></pre> <p>This created a Prelude-based <code>~/.emacs.d</code>, cloned off of my fork. I then setup upstream: </p> <pre class="example"><br />$ cd ~/.emacs.d<br />$ git remote add upstream git@github.com:bbatsov/prelude.git<br /></pre> <p>This means I can now get latest from upstream by simply doing: </p> <pre class="example"><br />$ git checkout master<br />$ git pull upstream master<br />$ git push origin master<br /></pre> <p>I then setup the <code>personal</code> branch: </p> <pre class="example"><br /> $ git branch --track personal origin/personal<br /> $ git branch<br />   master<br /> * personal<br /></pre> <p>For good measure, I also setup <code>personal</code> to be the default branch in GitHub. This hopefully means there is one less configuration step when setting up new machines. Once all of that was done, I got ready to start Emacs 24. The version in Debian Testing at present is 24.4.1 - not quite the latest (24.5 is out) but recent enough for those of us stuck in 23. </p> <p>The start-up was a bit slow; Prelude downloaded a number of packages, taking perhaps a couple of minutes and eventually was ready. For good measure I closed Emacs and started it again; the restart took a few seconds, which was quite pleasing. I was ready to start exploring Prelude. </p></div></div> <div class="outline-4" id="outline-container-sec-2-1-2"><h4 id="sec-2-1-2">The "Editor" Configuration</h4><div class="outline-text-4" id="text-2-1-2"><p>My first step in configuration was to create a <code>init.el</code> file under <code>.emacs.d/personal</code> and add <code>prelude-personal-editor.el</code>. I decided to follow this naming convention by looking at the Prelude core directory; seems vaguely in keeping. This file will be used for a number of minor tweaks that are not directly related to an obvious major mode (at least from a layman's perspective). </p></div> <ul class="org-ul"><li><a id="sec-2-1-2-1" name="sec-2-1-2-1"></a>Fonts, Colours and Related Cosmetics<br /><div class="outline-text-5" id="text-2-1-2-1"><p>The first thing I found myself tweaking was the default colour theme. Whilst I actually quite like <a href="https://github.com/bbatsov/zenburn-emacs">Zenburn</a>, I find I need a black background and my font of choice. After consulting a number of articles such as <a href="http://stackoverflow.com/questions/20781746/emacs-prelude-background-color">Emacs Prelude: Background Color</a> and the <a href="http://emacswiki.org/emacs/SetFonts">Emacs Wiki</a>, I decided to go with this approach: </p> <div class="org-src-container"> <pre class="src src-emacs-lisp">;; set the current frame background and font.<br />(set-background-color "black")<br />(set-frame-font "Inconsolata Bold 16" nil t)<br /><br />;; set the font and background for all other frames.<br />(add-to-list 'default-frame-alist<br />             '(background-color . "black")<br />             '(font .  "Inconsolata Bold 16"))<br /></pre></div> <p>The font works like a charm, but for some reason the colour gets reset during start-up. On the plus side, new frames are setup correctly. I have raised an issue with Prelude: <a href="https://github.com/bbatsov/prelude/issues/855">What is the correct way to update the background colour in personal configuration?</a> For now there is nothing for it but to update the colour manually. Since I don't restart Emacs very often this is not an urgent problem. </p> <p>One nice touch was that <code>font-lock</code> is already global so there is no need for additional configuration there. </p></div></li> <li><a id="sec-2-1-2-2" name="sec-2-1-2-2"></a>Widgets and Related Cosmetics<br /><div class="outline-text-5" id="text-2-1-2-2"><p>Pleasantly, Prelude already excludes a lot of annoying screen artefacts and it comes with mouse wheel support out of the box - which is nice. All and all, a large number of options where already setup the way I like it: </p> <ul class="org-ul"><li>no splash screen; </li><li>no menu-bars or tool-bars; </li><li>good frame title format with the buffer name; </li><li>no annoying visible bell; </li><li>displaying of column and line numbers, as well as size of buffers out of the box; </li><li>not only search had highlight, but the all shiny <a href="https://github.com/syohex/emacs-anzu">Anzu mode</a> is even niftier! </li><li>no need for hacks like <code>fontify-frame</code>. </li></ul> <p>However, Preludes includes scroll-bars and tool-tips - things I do not use since I like to stick to the keyboard. It also didn't have date and time in the mode line; and for good measure, I disabled clever window splitting as I found it a pain in the past. Having said that, I am still not 100% happy with time and date since it consumes a lot of screen real estate. This will be revisited at some point in the context of <a href="http://www.emacswiki.org/emacs/DiminishedModes">diminish</a> and other mode line helpers. </p> <div class="org-src-container"> <pre class="src src-emacs-lisp">;; disable scroll bar<br />(scroll-bar-mode -1)<br /><br />;; disable tool tips<br />(when window-system<br />  (tooltip-mode -1))<br /><br />;; time and date<br />(setq display-time-24hr-format t)<br />(setq display-time-day-and-date t)<br />(display-time)<br /></pre></div> <p>One note on line highlighting. Whilst I quite like this feature in select places such as grep and dired, I am not a fan of using it globally like Prelude does. However, I decided to give it a try and disable it later if it becomes too annoying. </p></div></li> <li><a id="sec-2-1-2-3" name="sec-2-1-2-3"></a>Tabs, Spaces, Newlines and Indentation<br /><div class="outline-text-5" id="text-2-1-2-3"><p>In the realm of "spacing", Prelude scores well: </p> <ul class="org-ul"><li>no silly adding of new lines when scrolling down, or asking when adding a new line at save; </li><li>pasting performs indentation automatically (yank indent etc)- default handling of tabs and spaces is fairly sensible - except for the eight spaces for a tab! A few minor things are missing such as <code>untabify-buffer</code>. These may warrant a pull request at some point in the near future. </li><li>a nice whitespace mode which is not quite the same as I had it in Cunene but seems to be equally as capable so I'll stick to it. </li></ul></div></li> <li><a id="sec-2-1-2-4" name="sec-2-1-2-4"></a>To Prompt or Not to Prompt<br /><div class="outline-text-5" id="text-2-1-2-4"><p>There are a few cases where me and Prelude are at odds when it comes to prompts. First, I seem to try to exit Emacs by mistake and I do that <span class="underline">a lot</span>. As any heavy Emacs user will tell you, there is nothing more annoying than exiting Emacs by mistake (in fact, when else do you exit Emacs?). I normally have more than 50 buffers open and not only does it take forever to bring up Emacs with that much state, but it never quite comes back up exactly the way I left it. Anyway, suffices to say that I strongly believe in the "are you sure you want to exit Emacs" prompt, so I had that copied over from Cunene. And, of course, one does not like typing "yes" when "y" suffices: </p> <div class="org-src-container"> <pre class="src src-emacs-lisp">;; Make all "yes or no" prompts show "y or n" instead<br />(fset 'yes-or-no-p 'y-or-n-p)<br /><br />;; confirm exit<br />(global-set-key<br /> (kbd "C-x C-c")<br /> '(lambda ()<br />    (interactive)<br />    (if (y-or-n-p-with-timeout "Do you really want to exit Emacs ?" 4 nil)<br />        (save-buffers-kill-emacs))))<br /></pre></div> <p>There is a nice touch in Prelude enabling a few disabled modes such as upper/down casing of regions - or perhaps the powers that be changed that for Emacs 24. Whoever is responsible, its certainly nice not to have to worry about it. </p></div></li> <li><a id="sec-2-1-2-5" name="sec-2-1-2-5"></a>Keybindings<br /><div class="outline-text-5" id="text-2-1-2-5"><p>One of the biggest cultural shocks, inevitably, happened with keybindings. I am giving Prelude the benefit of the doubt - even though my muscle memory is not happy at all. The following has proved annoying: </p> <ul class="org-ul"><li>Apparently arrow keys are discouraged. Or so I keep hearing in my minibuffer every time I press one. As it happens, the warnings are making me press them less. </li><li><code>C-b</code> was my ido key. However, since I should really not be using the arrow keys, I had to get used to using the slightly more standard <code>C-x b</code>. </li><li>Eassist include/implementation toggling was mapped to <code>M-o</code> and <code>M-i</code> was my quick way of opening includes in semantic (more on that later). However, these bindings don't seem to work any more. </li><li><a href="http://emacswiki.org/emacs/PcSelectionMode">pc-select</a> is a bit screwed in some modes such as C++ and Emacs lisp. But that's alright since you shouldn't be using the arrow keys right? What is annoying is that it works ok'ish in Org-mode so I find that I behave differently depending on the mode I'm on. </li><li>in addition, win-move is using the default shift-arrow keys and its not setup to handle multiple frames. This is a problem as I always have a few frames. These will have to be changed, if nothing else just to preserve my sanity. </li><li>talking about pc-select, I still find myself pasting with <code>C-v</code>. I just can't help it, its buried too deeply into the muscle memory. But it must be said, it's rather disconcerting to see your screen move up when you press <code>C-v</code>; it makes you think your paste has totally screwed up the buffer, when in reality its just the good old muscle memory biting again. </li><li><code>C-x u</code> now doesn't just undo like it used to. On the plus side, undo-tree just rocks! We'll cover it below. </li><li><code>C-backspace</code> doesn't just delete the last word, it seems to kill a whole line. Will take some getting used to. </li></ul> <p>All and all, after a few days, the muscle memory seems to have adapted well enough. I'm hoping I'll soon be able to use <code>C-b</code> and <code>C-f</code>without thinking, like a real Emacs user. </p></div></li></ul></div> <div class="outline-4" id="outline-container-sec-2-1-3"><h4 id="sec-2-1-3">Modes From Cunene</h4><div class="outline-text-4" id="text-2-1-3"><p>Unfortunately, package management was not quite as complete as I had hoped and so, yet again, I ended up with a number of modes that had to be copied into git. Fortunately these are a lot less in number. I decided to place them under <a href="https://github.com/mcraveiro/prelude/tree/personal/personal/vendor">personal/vendor</a> as I wasn't sure what the main <span class="underline">vendor</span> folder was for. </p></div> <ul class="org-ul"><li><a id="sec-2-1-3-1" name="sec-2-1-3-1"></a>Cedet<br /><div class="outline-text-5" id="text-2-1-3-1"><p>After almost losing my mind trying to configure Cedet from Emacs 24, I decided to bite the bullet and upgrade to the latest development version. In the past this was a safe bet; I'm afraid to report it still is the best way to get Cedet up and running. In fact, I got it working within minutes after updating to develop versus a whole day of fighting against the built-in version. Pleasantly, it is now available in git: </p> <pre class="example"><br />git clone http://git.code.sf.net/p/cedet/git cedet<br /></pre> <p>Building it was a simple matter of calling make, both at the top-level and in contrib: </p> <pre class="example"><br />$ cd cedet<br />$ make EMACS=emacs24<br />$ cd contrib<br />$ make EMACS=emacs24<br /></pre> <p>The setup was directly copied from their INSTALL document, so I recommend reading that. </p> <p>Still in terms of Cedet, a very large win was the move to <a href="https://github.com/randomphrase/ede-compdb">EDE Compilation Database</a>. I really cannot even begin to do justice to the joys of this mode - it is truly wonderful. I did the tiniest of changes to my build process by defining an extra macro: </p> <pre class="example"><br />cmake ../../../dogen -G Ninja -DCMAKE_EXPORT_COMPILE_COMMANDS=TRUE<br /></pre> <p>With just that - and a couple of lisp incantations (see the <a href="https://github.com/mcraveiro/prelude/blob/personal/personal/init-cedet.el#L78">cedet init file</a>) - and suddenly I stopped having to worry about supplying flags to flymake (well, <span class="underline">flycheck</span> - but that's another story), semantic, the whole shebang. I haven't quite worked out all of the details just yet, but with very little configuration the compilation database seems to just get everything working magically. </p> <p>Because of this, I am now finding myself using Cedet a lot more; the intelisense seems to just work on the majority of cases. The only snag is the annoyance of old: having Emacs block on occasion whilst it builds some semantic database or other. It doesn't happen often but its still a pain when it does. Which gave me the idea of <a href="http://sourceforge.net/p/cedet/mailman/message/34145936/">replacing it</a>with a Clang based "semantic database generator". Lets see what the Cedet mailinglist says about it. </p> <p>All and all, Cedet is much improved from the olden days; so much so I feel it warrants a proper review after a few months of using it in anger. In fact, I feel so brave I may even setup <a href="https://github.com/chrisbarrett/emacs-refactor">emacs-refactor</a> or <a href="https://github.com/tuhdo/semantic-refactor">semantic-refactor</a>. It is also high-time to revisit <a href="http://tuhdo.github.io/c-ide.html">C/C++ Development Environment for Emacs</a> and pick up some new tips. </p></div></li> <li><a id="sec-2-1-3-2" name="sec-2-1-3-2"></a>Git-emacs<br /><div class="outline-text-5" id="text-2-1-3-2"><p><a href="https://github.com/tsgates/git-emacs">Git-emacs</a> makes me a bit sad. In truth, I am a perfectly content magit user (more on that later) except for <span class="underline">one</span> feature - the file status "dot". This is something I got used from the svn days and still find it quite useful. Its silly really, especially in these days of <a href="https://github.com/syohex/emacs-git-gutter">git-gutter</a>, but I still like to know if there have been any changes to a file or not, and I haven't found a good way of doing this outside of git-emacs. It provides a nice little red or green dot in the modeline, like so: </p>  <div class="figure"><p><img alt="git-emacs.png" src="https://raw.githubusercontent.com/DomainDrivenConsulting/dogen/master/doc/blog/git-emacs.png" /></p><p><span class="figure-number">Figure 1:</span> Git-emacs state modeline</p></div> <p>However, there are no packaged versions of git-emacs and since everyone uses magit these days, I can't see it making to Elpa. Also, it is rather annoying having to load the whole of git-emacs for a dot, but there you go. </p></div></li> <li><a id="sec-2-1-3-3" name="sec-2-1-3-3"></a>Doxymacs<br /><div class="outline-text-5" id="text-2-1-3-3"><p>Very much in the same vein as git-emacs, <a href="http://doxymacs.sourceforge.net/">doxymacs</a> is also one of those more historical modes that seem a bit unmaintained. And very much like git-emacs, I only use it for the tiniest of reasons: it syntax-highlights my doxygen comments. I know, I know. On the plus side, it seems to do a whole load of other stuff - I just never quite seem to need any other feature besides the nice syntax highlighting of comments. </p></div></li></ul></div> <div class="outline-4" id="outline-container-sec-2-1-4"><h4 id="sec-2-1-4">Modes From Prelude or Emacs 24</h4><div class="outline-text-4" id="text-2-1-4"><p>In this section we cover modes that are either new/updated for Emacs 24 or available from Prelude via Elpa. </p></div> <ul class="org-ul"><li><a id="sec-2-1-4-1" name="sec-2-1-4-1"></a>Dired<br /><div class="outline-text-5" id="text-2-1-4-1"><p>Dired is configured in a fairly sensible manner out of the box. For example, one no longer has the annoying prompts when deleting/copying directories with files - it never occurred to me you could configure that away for some reason. </p> <p>On the down side, it is not configured with <a href="http://emacswiki.org/emacs/DiredReuseDirectoryBuffer">dired-single</a>, so the usual proliferation of dired buffers still occurs. I have decided not to setup dired-single for a few days and see how bad it gets. </p> <p>The other, much more annoying problem was that hidden files are displayed by default. I first tried solving this problem with dired-omit as per <a href="https://truongtx.me/2013/04/24/dired-as-default-file-manager-3-dired-details/%0A">this page</a>: </p> <div class="org-src-container"> <pre class="src src-emacs-lisp">(setq-default dired-omit-mode t)<br />(setq-default dired-omit-files "^\\.?#\\|^\\.$\\|^\\.\\.$\\|^\\.")<br /></pre></div> <p>However, I found that omit with regexes is not that performant. So I ended up going back to the old setup of <code>ls</code> flags: </p> <pre class="example"><br />(setq dired-listing-switches "-l")<br /></pre></div></li> <li><a id="sec-2-1-4-2" name="sec-2-1-4-2"></a>Undo-tree and browse-kill-ring<br /><div class="outline-text-5" id="text-2-1-4-2"><p>As mentioned before, <code>C-x u</code> is not just undo, it's undo-tree! Somehow I had missed this mode altogether up til now. Its pretty nifty, as it allows you to navigate the undo-tree - including forks. It is quite cool. </p> <p>I also found that the latest version of browse-kill-ring is very nice; so much so that I find myself using it a lot more now. The management of the clipboard will never be the same. </p></div></li> <li><a id="sec-2-1-4-3" name="sec-2-1-4-3"></a>Org-mode<br /><div class="outline-text-5" id="text-2-1-4-3"><p>One rather annoying thing was that with the latest Org-mode, the clock-table is a bit broken. I quickly found out I wasn't the only one to notice: <a href="http://emacs.stackexchange.com/questions/9528/is-it-possible-to-remove-emsp-from-clock-report-but-preserve-indentation">Is it possible to remove ' ' from clock report but preserve indentation?</a></p> <p>This link implies the problem is fixed in Emacs 24.4, but I am running it and sadly it doesn't seem to be the case. I also found out that the automatic resizing of clock tables is no longer… well, automatic. Instead, we now have to supply the size. My final setup for the clock-table is as follows: </p> <pre class="example"><br />#+begin: clocktable :maxlevel 3 :scope subtree :indent nil :emphasize nil :scope file :narrow 75<br /></pre> <p>This seems to generate a table that is largely like the ones we had prior to upgrading. </p> <p>Other than that, Org-mode has behaved - but then again, I'm not exactly a poweruser. </p></div></li> <li><a id="sec-2-1-4-4" name="sec-2-1-4-4"></a>Bongo<br /><div class="outline-text-5" id="text-2-1-4-4"><p>I use the amazing <a href="https://github.com/dbrock/bongo">Bongo</a> media player to play the few internet radio stations I listen to - mainly SomaFM, to be honest. Its good to see it in Melpa. It's still not quite as straightforward as you'd like to save a playlist - I always find that loading the buffer itself does not trigger bongo mode for some reason - but other than that, it works fine. </p> <p>On the downside, I use the venerable <a href="http://www.emacswiki.org/emacs/Mpg123">mpg123</a> to play random albums and that hasn't made it to Melpa yet. I've decided to try to use Bongo for this use case too, but if that doesn't work out then I'll have to add it to vendor… </p></div></li> <li><a id="sec-2-1-4-5" name="sec-2-1-4-5"></a>Shell<br /><div class="outline-text-5" id="text-2-1-4-5"><p>Prelude comes with eshell configured by default. I must confess I have always been a bash user - simple and easy. I'll persevere with eshell for a couple of days, but I can already see that this may be a bridge too far. </p></div></li> <li><a id="sec-2-1-4-6" name="sec-2-1-4-6"></a>Flycheck<br /><div class="outline-text-5" id="text-2-1-4-6"><p>One of the main reasons that made me consider moving to prelude was <a href="http://flymake.sourceforge.net/">Flymake</a>. I added it to cunene fairly early on, some 6 years ago, and I was amazed at how I had managed to use Emacs for over a decade without using Flymake. However, after a good 6 years of intensive usage, I can attest that Flymake is showing its age. The main problem is how it locks up Emacs whilst updating. If you combine that with the insane errors one gets in C++, all you need is an angle-bracket out of place and your coding flow is disrupted for potentially several minutes. To be fair, this happens very infrequently, but its still a major nuisance. So I was keen to explore <a href="https://github.com/flycheck/flycheck">Flycheck</a>. </p> <p>All I can say is: wow! The same feeling of amazement I felt for Flymake when I first used has been repeated with Flycheck. Not only its blazingly fast, it supports multiple checkers and the errors buffer is a dream to work with. And with the Compilation Database integration it means there is no configuration required. I can't believe I survived this long without Flycheck! </p></div></li> <li><a id="sec-2-1-4-7" name="sec-2-1-4-7"></a>Magit<br /><div class="outline-text-5" id="text-2-1-4-7"><p>One of my favourite modes in Emacs - at least of the new generation of modes - is <a href="http://magit.vc/">Magit</a>. So much so that I find that I rarely use git from anywhere else, it's just so easy to do it from Magit. Which makes me extremely sensitive to any changes to Magit's interface. </p> <p>The version in Prelude - presumably from Melpa - is a tad different from the legacy one I was using in Cunene. On the plus side, most of the changes are improvements such as having a "running history" in the git process buffer, with font-lock support. The main Magit buffer also looks very nice, with lots of little usability touches. A tiny few changes did result in slow-downs of my workflow, such as a sub-menu on commit. Its not ideal but presumably one will get used to it. </p> <p>The only negative change seems to be that Magit is not quite as responsive as it used to be. Hard to put a finger yet, but I was used to having pretty much zero wait time on all operations in Magit, and yet now it seems that a few things are no longer instantaneous. It will require some more analysis to properly point the finger, but its a general feel. </p></div></li></ul></div></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">Conclusions</h2><div class="outline-text-2" id="text-3"><p>It's still early days, but the move to Emacs 24 and Prelude is already paying off. The transition has not been entirely straightforward, and it certainly has slowed things down for the moment - if not for anything else, just due to the keybinding changes! But one can already see that this is the future for most Emacs users, particularly those that are not power-users like myself but just like the editor. </p> <p>The future is certainly bright for Emacs. And we haven't yet started covering the latest and greatest modes such as <a href="https://github.com/Malabarba/smart-mode-line">smart-mode-line</a>. But that's a story for another blog post. </p></div></div></div><div class="status" id="postamble"><p class="date">Created: 2015-05-27 Wed 00:18</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.4.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://mcraveiro.blogspot.com/2014/09/nerd-food-start-ups-at-gate-trends-in.html">Nerd Food: Start-ups at the Gate: Trends in the Technology Industry</a></h2></div>
            <p class="text-muted">by <a href="http://mcraveiro.blogspot.com/">Marco Craveiro</a> on September 25, 2014 08:45 PM.</p>
          </div>
          <div class="panel-body">

            Nerd Food: Start-ups at the Gate: Trends in the Technology Industry  <div id="preamble"> </div> <div id="content"> <p>It is very difficult to convey the vast scale at which the largest Internet companies operate. To make matters worse, we are fast becoming immune to statistics such as <a href="http://mashable.com/2014/04/23/facebook-1-billion-mobile-users/">one billion users</a> and <a href="http://www.statisticbrain.com/google-searches/">five trillion searches per day</a>, surrounded as we are by a sea of large numbers on a daily basis. Having said that, any Information Technology (IT) professional worth his or her salt cannot help but feel in awe at what has been achieved. It is not just that these platforms are big; they work at a scale that is <i>qualitatively</i> different from anything that has come before. The sort of things that are possible at this scale are mind-boggling, and we have only begun to scratch the surface<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.1" name="fnr.1">1</a></sup>. </p><p>Perhaps even more revolutionary is the fact that these companies have made it possible for anyone to start thinking about data in the same way as they do, and to start handling it using the very same tools they use. There is now a never-ending archive of the very best large-scalability tools, all available for free, with code that anyone can inspect, modify and optimise to meet their specific requirements. The tools come with a wealth of practical documentation on how to put solutions together - either freely available or at low-cost - and with a number of passionate user communities that provide expert advice and are eager to accept modifications. </p><p>The ecosystem they have created is truly staggering. As an example, Facebook has open sourced almost <a href="https://code.facebook.com/posts/292625127566143/9-9-million-lines-of-code-and-still-moving-fast-facebook-open-source-in-2014/">10M lines of code</a> to date. Twitter, Google and LinkedIn are not far behind<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.2" name="fnr.2">2</a></sup>. It is also important to notice that non-Internet companies are making extremely large contributions too, such as Microsoft and IBM. All told, the overall pool of open source code is growing exponentially, as demonstrated by a <a href="http://dirkriehle.com/publications/2008-2/the-total-growth-of-open-source/">2008 study</a>. In most cases, these are full-fledged products, tested in the most challenging production conditions imaginable. Of course, one must also not forget the contributions made to projects that are not under company control such as the Linux Kernel, the Apache web-server and the GNU Compiler GCC. </p><p>In order to understand why modern start-ups provide such a compelling financial case, one must first understand how we got to the amazing technology landscape we have today. To do so, we shall divide recent technology history into eras, and explain each era's contribution. We will then focus on modern start-ups, and explain how this model can be deployed to a large gamut of industries and in particular to the financial sector. </p> <div class="outline-2" id="outline-container-1"><h2 id="sec-1">First Era: Dot-com Bubble</h2><div class="outline-text-2" id="text-1">  <p>Silicon Valley was and still is the world's start-up factory so, unsurprisingly, it was ground zero for the start-up revolution that took place at the end of the nineties. It would eventually be known as <a href="http://en.wikipedia.org/wiki/Dot-com_bubble">The Dot-com Bubble</a>. Most people remember those days as a heady time, where each and every idea was packaged as a website and sold for millions or in some cases billions of dollars. Of course, we all had a steep price to pay when the bubble burst - an extinction event that decimated the young Internet sector and IT companies in general. </p><p>There is however another way to look at this bubble: it was a gigantic experiment to determine whether there were successful business models to be found in the large scale of the Internet. Whilst much mal-investment occurred, the bubble still produced or pushed forward several of the giants of today such as Google, Amazon and Yahoo. </p><p>Most of these companies share a similar technology story. Originally faced with a dearth of investment but with bright young engineers, they found themselves relying on Free and Open Source Software (FOSS) and cheap, off-the shelf hardware. Once they became big enough, it just didn't make sense to replace all of that infrastructure with software and hardware supplied by commercial vendors. </p><p>This turn of events was crucial. If these companies had had larger budgets and less skilled engineers, they would have relied on the cutting edge technology of the time. The short-term gain would reveal itself as long term pain, for their ability to scale would be inevitably restricted. In addition, many of the business models wouldn't have worked due to this cost structure<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.3" name="fnr.3">3</a></sup>. As it was, since they couldn't even afford the relatively cheap licences of commercial software, they had to make do with what was available for free. </p><p>The engineers in these companies - and many others that didn't make it through the dot-com filter - spent countless hours improving FOSS tools and gave back much of these improvements to communities such as Linux, MySQL, Apache, GCC and so on. However, they kept private the plumbing work done to manage the large cluster of cheap machines, as well as the domain related technology - in industry-speak, the <i>Secret Sauce</i>. </p><p>By the time the dot-com bubble had run its course and the dust settled, the landscape looked as follows: </p><ul><li>A model had been created whereby a small number of engineers could   bootstrap an Internet-based company at very low cost, serving a   small number of users initially. </li><li>The model had been stretched to very large numbers of users and had   been found to scale extremely well; as the business proved itself   and investment came in, it was possible increase the size of the   computing infrastructure to cope with demand. </li><li>Because of the open nature of the technologies involved, the ideas   became widespread over the internet. </li></ul>  <p>The basic high-scalability FOSS stack - ready for start-ups - was born; the Data Centre, where large amounts of computing are available at low cost, soon followed. It would eventually morph into the Cloud. </p></div> </div> <div class="outline-2" id="outline-container-2"><h2 id="sec-2">Second Era: Social Media</h2><div class="outline-text-2" id="text-2">  <p>The bursting of the dot-com bubble did not dampen the entrepreneurial spirits, but it did dry up all the easily available capital and thus pushed the aspiring start-ups to be ever more frugal. In addition, VCs started to look for better ways to evaluate prospects. The problem they faced was no different from what they had faced during the dot-com days: how to figure out the potential of a company with no defined business model and nothing else to compare it against. </p><p>Google had proved comprehensively that the traditional valuation methods did not make sense in the world of start-ups. After all, here was a company which it's founders couldn't sell for 1M USD and yet a few years later was generating billions of dollars in revenues. Very few saw this coming. VCs were keen not to make the same mistake with the next Google<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.4" name="fnr.4">4</a></sup>. </p><p>So it was that a system to determine potential by proxy emerged over the years, using indicators such as the size of the user base, time spent by users on the platform and so on - effectively, any attribute that was deemed to have given a competitive advantage to Google and other successful dot-com companies. </p><p>In this environment, <i>social media</i> start-ups took took centre stage. Following on from the examples of their predecessors, these companies took for granted that they were to operate on very large data sets. They inherited a very good set of scalable tools, but found that much still had to be built on top. Unlike their predecessors, many chose to do some or all of the infrastructure work out in the open, joining or creating new communities around the tools. This was in no small part due to the scarcity of funds, which encouraged collaboration. </p><p>The social media start-ups soon found themselves locked in an arms race for size, where the biggest would be the winner and all others would be doomed to irrelevance<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.5" name="fnr.5">5</a></sup>. The size of the user base of the successful companies exploded<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.6" name="fnr.6">6</a></sup>, and the tooling required to manage such incredibly large volumes of data had to improve at the same pace or faster. Interestingly, these start-ups continued to view in-house code largely as a cost, not an asset, even after they started to bring in large revenue. The size of the secret sauce was to be kept at a minimum and the pace of open sourcing accelerated over time<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.7" name="fnr.7">7</a></sup>. </p><p>A final factor was the rise of the next iteration of the data centre, popularised by Amazon with <a href="http://en.wikipedia.org/wiki/Amazon_Web_Services">AWS and EC2</a>. It allowed <i>any</i> company to scale out without ever having to concern themselves with physical hardware. This was revolutionary because it allowed razor-thin costs for scalability: </p><ul><li><b>Pay only for what you use</b>: the <i>elastic</i> nature of EC2 meant that   one could grow or shrink one's cluster based on real time traffic   demands and availability of capital. </li><li><b>Zero-cost software</b>: FOSS was available in Amazon from the very   beginning and was extremely popular with start-ups. </li><li><b>Fully automated environments via APIs</b>: resource constrained   start-ups could now start to automate all aspects of the product   life-cycle. This meant they could release faster, which in turn   allowed them to fight more effectively for their user base. This   would in time become the <a href="http://en.wikipedia.org/wiki/DevOps">DevOps movement</a>. </li></ul>  <p>By the end of the decade, the scalability tooling was largely complete. It was now possible for a small start-up to create a small website and to see it scale from hundreds to millions, restricted only by their ability to bring in capital. </p></div> </div> <div class="outline-2" id="outline-container-3"><h2 id="sec-3">Third Era: Mobile</h2><div class="outline-text-2" id="text-3">  <p>Mobile phones have been growing close to an exponential rate for over two decades. However, the rise of the smart phones was a game changer, and the line in the sand was drawn with the release of the iPhone. What makes mobile so important to our story is it's penetration. Until smart phones became ubiquitous, there was a large segment of the population that was either totally inaccessible or accessible for limited periods of time. With increasingly large numbers of people carrying smart phones as they go about their day, many use cases that were never before thought possible came to the table. So whilst we call this "the Mobile era", the true heroes are smart phones and, to a smaller extent, the tablets. </p><p>The mobile era started with simple apps. Smart phones were still new and applications for each platform were novelty. There was a need to reinvent all that existed before in the world of PCs and adapt it to the new form factor. It was during this phase that the economies of scale of mobile phones became obvious. Whereas consumer PC software had prices on the range of tens to hundreds of dollars, mobile phones bootstrapped a completely different pricing model, with many apps selling for less than one dollar. Volume made up for the loss in revenue per unit. The model was so incredibly successful that a vibrant environment of apps sprung up around each of the successful platforms, carefully nurtured by the companies running the show via their <i>app stores</i>. </p><p>Soon enough the more complex apps came about. Companies like Four Square and WhatsApp were trailblazers in the mobile space, merging it with ideas from social media. Many others like Spotify took their wares from the stagnant PC environment and moved to the ever growing mobile space. Complex apps differed from the simple apps in that they required large backends to manage operations. Since these companies were cash strapped - a perennial condition of all start-ups - they found themselves reusing all of the technology developed by the social media companies and became part of the exact same landscape. Of course, the social media companies were eventually forced to jump on the mobile bandwagon - lest they got crushed by it. </p><p>So it was that the circle was closed between the three eras. </p></div> </div> <div class="outline-2" id="outline-container-4"><h2 id="sec-4">Evolutionary Pressures and Auto-Catalytic Processes</h2><div class="outline-text-2" id="text-4">  <p>The changes just described are so revolutionary that one cannot help but look for models to approximate some kind of explanation for what took place. Two stand out. The first is to imagine the population of start-up companies as a small segment of the overall company population that was submitted to an unbelievably harsh fitness function: to grow the data volumes exponentially while growing costs less than linearly. This filter generated new kinds of companies, new kinds of technologies and new kinds of ways of managing technology. </p><p>Secondly, there is the auto-catalytic nature of the processes that shaped the current technology landscape. Exponential growth tends to have at its root this kind of self-reinforcing cycle, whereby improvements in an area A trigger improvements in another area B, which in turn forces A to improve. The process keeps on repeating itself whilst it manages to retain stability. </p><p>It is this relationship we currently have between start-ups and FOSS: the better the software gets, the cheaper it is to create new start-ups and the faster these can grow with the same amount of capital. By the same token, the more start-ups rely on FOSS, the more they find themselves contributing back or else risk falling behind - both technologically and cost-wise. This feedback loop is an emerging property of the entire system and it has become extremely pronounced over time. </p></div> </div> <div class="outline-2" id="outline-container-5"><h2 id="sec-5">Finance and the Age of Disruption</h2><div class="outline-text-2" id="text-5">  <p>The concept of <i>disruption</i> was developed in the nineties by Clayton Christensen in <a href="http://www.amazon.co.uk/Innovators-Dilemma-Technologies-Management-Innovation/dp/142219602X/ref=sr_1_1?ie=UTF8&amp;qid=1411676026&amp;sr=8-1&amp;keywords=the+innovator%27s+dilemma">Innovator's Dilemma</a>. This book has seen a resurgence in popularity as well as in criticism<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.8" name="fnr.8">8</a></sup>. For good or bad, the ideas in this book became the intellectual underpinnings of a new generation of start-ups. </p><p>They seek to combine all of the advances of the previous start-ups to create solutions to problems far outside the traditional IT realm. Examples are the hotel industry (<a href="http://mcraveiro.blogspot.com/feeds/posts/default#www.airbnb.co.uk">AirBnB</a>), the taxi industry (<a href="http://mcraveiro.blogspot.com/feeds/posts/default#www.uber.com">Uber</a>, <a href="https://www.lyft.com/">Lyft</a>) and even the banking industry (<a href="https://www.simple.com/">Simple</a>). Whilst it's still early days, and whilst there have been many teething problems such as issues with regulation, the destination of travel is already clear: there will be more and more start-ups following the disruptive route. </p><p>What makes these companies a compelling proposition to VCs is that they are willing to take on established concerns, with cost structures that are orders of magnitude larger than that of these start-ups. Their thinking is two-fold: the established companies are leaving a lot of money on the table, consumed by their inefficiency; and they are not exploiting the opportunities to their full potential because they do not understand how to operate at a vast scale. </p><p>It is in this context that finance scene comes into the picture - as part of the expansionary movement of the disruption movement. VCs have longed eyed enviously the financial industry because they believed that the problems being solved in trading are not that dissimilar to those faced by many large scale start-ups. And yet the rewards are disproportional large in Finance, when compared with say social media. </p><p><i>Fintech</i> soon emerged. As applied to start-ups, Fintech is the umbrella name given to the ecosystem of start-ups and VCs that focus specifically on financial technology. This ecosystem has grown from 930M USD in 2008 to around 3Bn in 2013 <a href="http://www.accenture.com/Microsites/fsinsights/capital-markets-uk/Documents/Accenture-Global-Boom-in-Fintech-Investment.pdf">according to Accenture</a>. Centred mainly in London, but with smaller offshoots in other financial centres, the Fintech scene is starting to attract established players in the world of Finance. For instance, Barclays has joined the fray by creating an incubator. They farmed off the work to a third-party (Tech Stars) but allowed all the start-ups in the programme to have unprecedented access to their Mobile APIs. Their target is to own the next generation of financial applications on Mobile devices. </p><p>Whist Barclays is disrupting from the outside, it is obvious that the investment banking legacy platforms are a fertile ground for start-ups. This is where the scalability stack has a near-perfect fit. A typical example is <a href="http://mcraveiro.blogspot.com/feeds/posts/default#www.opengamma.com">OpenGamma</a>. The start-up designed an open source Risk platform, initially focused on back office use. They have received over <a href="http://www.opengamma.com/about-us">20M USD in funding as of 2014</a> and have already been the recipient of several of the <a href="http://www.riskfocus.com/opengamma-wins-waters-sell-side-technology-award-for-best-market-risk-product">industry's awards</a>. There are now several open source trading platforms to choose from including TradeLink and OpenGamma, as well as the popular quantitative analytics library QuantLib. </p><p>As we have seen in the previous sections, there is an auto-catalytic process at play here. Once source code becomes widely available, the cost of creating the next Financial startup goes down dramatically because they can reuse the tools. This in turn means many more start-ups will emerge, thus improving the general quality of the publicly available source code. </p></div> </div> <div class="outline-2" id="outline-container-6"><h2 id="sec-6">Conclusions</h2><div class="outline-text-2" id="text-6">  <p>The objective of this article was to provide a quick survey of the impact of start-up companies in the technology landscape, and how these relate to finance. We now turn our attention to the logical conclusions of these developments. </p><ul><li><b>Finance will increasingly be the target of VCs and start-ups</b>: The   Fintech expansion is to continue over the coming years and it will   affect everyone involved in the industry, particularly the   established participants. More companies will take the route of   Barclays, trying to be part of the revolution rather than dethroned   by it. </li><li><b>Banks and other established companies will begin to acquire   start-ups</b>: Related to the previous item in some ways; but also with   a twist. As part of the <a href="http://www2.deloitte.com/global/en/pages/technology-media-and-telecommunications/articles/tmt-predictions-2013-technology-media-telecommunications-report.html">Deloitte TMT predictions</a> event, Greg   Rogers - the manager of Barclays Accelerator - stated that the   acquisition of non-financial start-ups by banks was on the cards. He   was speaking about Facebook's acquisition of WhatsApp for 18Bn USD,   one of the largest of the year. As Google and Facebook begin   integrating payments into their social platforms, banking firms will   find their traditional business models under attack and will have no   option but to retaliate. </li><li><b>Finance will turn increasingly to FOSS</b>: The cost structure that   finance firms had up to 2008 is not suitable to the post 2008   world. At present, the volume of regulatory work is allowing these   cost structures to persist (and in cases increase). However,   eventually banks will have to face reality and dramatically reduce   their costs, in line with the new kind of revenues they are expected   to make in a highly-regulated financial world. There will be a   dramatic shift away from proprietary technologies of traditional   vendors, unless these become much more competitive against their   fierce FOSS rivals. </li><li><b>A FOSS financial stack will emerge over the next five years</b>:   Directly related to the previous point, but taking it further. Just   as it was with social media companies, so it seems likely that   financial firms will eventually realise that they cannot afford to   maintain all the infrastructure code. Once an investment bank takes   the leap and starts relying on FOSS for trading or back-office, the   change will ripple through the industry. The state of the FOSS code   is production ready, and a number of hedge funds are already using   it in anger. All that is required is for the cost structure to be   squeezed even further in the investment banking sector. </li></ul>  <div id="footnotes"><h2 class="footnotes">Footnotes: </h2><div id="text-footnotes"><p class="footnote"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.1" name="fn.1">1</a></sup> As one of many examples, see <a href="http://en.wikipedia.org/wiki/Google_Flu_Trends">Google Flu Trends</a>. It is a predictor of outbreaks of the flu virus, with a prediction rate of about 97%. For a more comprehensive - if somewhat popular - take on the possibilities of large data sets, see <a href="http://www.amazon.co.uk/Big-Data-Revolution-Transform-Think/dp/1848547927">Big Data: A Revolution That Will Transform How We Live, Work and Think</a>. For a very different take - highliting the dangers of Big Data - see Taleb's views on the ever decreasing noise to signal ratio: <a href="https://dl.dropboxusercontent.com/u/50282823/Noise%20Bottleneck.pdf">The Noise Bottleneck or How Noise Explodes Faster than Data</a>. </p> <p class="footnote"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.2" name="fn.2">2</a></sup> In fact, by some measures, Google has contributed several times that amount. For one such take, see <a href="http://readwrite.com/2014/02/04/open-source-5-companies-code-projects">Lauren Orsini's article</a>. </p> <p class="footnote"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.3" name="fn.3">3</a></sup> As an example, it was common practice for vendors to charge according to the number of processors, users and so on. Many of the better funded start-ups made use of technology from Cisco, Sun, Oracle and other large commercial vendors, but companies that did so are not very well represented in the population that survived the dot-com bubble, and they are not represented at all in the <a href="http://www.crn.com/slide-shows/channel-programs/240154736/the-25-biggest-tech-companies-on-the-fortune-500.htm">2014 Fortune 500 list</a>. Google, Amazon and E-Bay are the only Fortune 500 companies from that crop and they all relied to a very large extent on in-house technology. Note though that we are making an empirical argument here rather than a statistical one, both due to the lack of data available, as well as concern for <a href="http://en.wikipedia.org/wiki/Survivorship_bias">Survivorship Bias</a>. </p> <p class="footnote"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.4" name="fn.4">4</a></sup> For one of many takes on the attempt to sell Google, see <a href="http://techcrunch.com/2010/09/29/google-excite/">When Google Wanted To Sell To Excite For Under 1 Million~— And They Passed</a>. To get a flavour of how poorly understood Google's future was as late as 2000, see <a href="http://www.sfgate.com/business/article/Google-Senses-That-It-s-Time-to-Grow-Up-3237385.php">Google Senses That It's Time to Grow Up</a>. Finally, the success story is best told by the growth of revenues between 2001 and 2003 - see Google's <a href="https://investor.google.com/financial/2003/tables.html">2003 Financial Tables</a>. </p> <p class="footnote"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.5" name="fn.5">5</a></sup> Twitter, Facebook, YouTube, LinkedIn and the like were the victors, but for every victor, a worthwhile foe was defeated; MySpace, Hi5, Orkut and many others were all very popular at one time but lost the war and faded into obscurity. </p> <p class="footnote"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.6" name="fn.6">6</a></sup> As an example, the number of Facebook users grew at an exponential rate between 2004 and 2013 - see <a href="http://www.theguardian.com/news/datablog/2014/feb/04/facebook-in-numbers-statistics">Facebook: 10 years of social networking, in numbers</a>. </p> <p class="footnote"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.7" name="fn.7">7</a></sup> A possible explanation for this decision is the need for continuous scalability. Even companies as large as Facebook or Google cannot dedicate the resources required to adequately maintain every single tool they own; their code bases are just too large. At the same time, they cannot afford for code to become stale because it must continually withstand brutal scalability challenges. The solution to this conundrum was to open source aggressively and to create vibrant communities around tooling. Converting themselves to stewards of the tools, they could now place quasi-skeleton crews to give direction to development, and then rely on the swarms of new start-ups to contribute patches. Once there are enough improvements, the latest version of these tools can be incorporated into the internal infrastructure. This proved to be a very cost-effective strategy, even for large companies, and allowed continued investment across the technology stack. </p> <p class="footnote"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.8" name="fn.8">8</a></sup> There are quite a few to choose from but <a href="http://www.newyorker.com/magazine/2014/06/23/the-disruption-machine">Lepore's</a> is one of the best because it robustly attacks both the ideology and the quality of the data. </p></div></div> </div></div></div> <div id="postamble"><p class="date">Date: 2014-09-25 21:37:47 BST</p><p class="creator">Org version 7.8.02 with Emacs version 23</p><a href="http://validator.w3.org/check?uri=referer">Validate XHTML 1.0</a> </div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://mcraveiro.blogspot.com/2014/09/nerd-food-dogen-lessons-in-incremental.html">Nerd Food: Dogen: Lessons in Incremental Coding</a></h2></div>
            <p class="text-muted">by <a href="http://mcraveiro.blogspot.com/">Marco Craveiro</a> on September 08, 2014 09:03 AM.</p>
          </div>
          <div class="panel-body">

            Nerd Food: Dogen: Lessons in Incremental Coding  <div id="preamble"> </div> <div id="content"> <p>A lot of interesting lessons have been learned during the development of <a href="https://github.com/DomainDrivenConsulting/dogen">Dogen</a> and I'm rather afraid many more are still in store. As it is typical with agile, I'm constantly reviewing processes in search of improvements. One such idea was that putting pen to paper could help improving the retrospective process itself. The result is this rather long blog post, which hopefully is of use to developers in similar circumstances. Unlike the typical bullet-point based retrospective, this post it is a rambling narrative as it aims to provide context to the reader. Subsequent retrospectives will be a lot smaller and more to the point. </p><p>Talking about context: I haven't spoken very much about Dogen in this blog, so a small introduction is in order. Dogen is an attempt to create a domain model generator. The <a href="https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/manual/manual.org#fundamental-building-blocks">manual</a> goes into quite a bit more detail, but for the purposes of this exercise, it suffices to think of it as a C++ code generator. Dogen has been developed continuously since 2012 - with a few dry spells - and reached its <a href="https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/sprint_backlog_50.org">fiftieth sprint</a>recently. Having said that, our road to a finished product is still a <a href="https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/definition_of_done.org">long one</a>. </p><p>The remainder of this article looks at what what has worked and what has not worked so well thus far into Dogen's development history. </p> <div class="outline-2" id="outline-container-1"><h2 id="sec-1">Understanding Time</h2><div class="outline-text-2" id="text-1">  <p>Dogen was conceived when we were trying to do our <a href="http://kitanda.co.uk/html/index.html">first start up</a>. Once that ended - around the back end of 2012 - I kept working on the tool in my spare time, and this was a setup that has continued ever since. There are no other contributors; development just keeps chugging along, slowly but steadily, with no pressures other than to enjoy the sights. </p><p>Working on my own and in my spare time meant that I had two conflicting requirements: very little development resources and very ambitious ideas that required lots of work. With family commitments and a full time job, I quickly found out that there weren't a lot of spare cycles left. In fact, after some analysis, I realised I was in a conundrum. Whilst there is was a lot of "dead-time" in the average week, it was mostly "low-quality grade time": lots of discontinued segments of varying and unpredictable lengths. Summed together in a naive way it seemed like a lot, but - as every programmer knows - six blocks of ten minutes do not one solid hour make. </p><p>Nevertheless, one has to play the game with the cards that were dealt. I soon realised that the correct question to ask was: "what kind of development style makes one productive under these conditions?". The answer turned out to be opportunistic coding. This is rooted in having a better understanding of the different "qualities" of time and how best to exploit them. For example, when you have say five to fifteen minutes available, it makes sense to do small updates to the manual or fix trivial problems - a typo in the documentation, renaming variables in a function, mopping up the backlog and other activities of that ilk. A solid block of forty minutes to an hour affords you more: for instance, implementing part or the whole of stories for which the analysis has been completed, or doing some analysis for existing stories. On those rare cases where half-a-day or longer is available, one must make the most of it and take on a complex piece of work that requires sustained concentration. This sessions proved to be most valuable when the output is a set of well defined stories that are ready for implementation. </p><p>One needs very good processes in order to be able to manage the usage of time in this fashion. Luckily, agile provides it. </p></div> </div> <div class="outline-2" id="outline-container-2"><h2 id="sec-2">Slow Motion Agile</h2><div class="outline-text-2" id="text-2">  <p>Looking back on ~2.4k commits, one of the major wins in terms of development process was to think incrementally. Of course, agile already gives you a mental framework for that, and we had a functioning scrum process during our start up days: daily stand-ups, bi-weekly sprints, pre-sprint planning, post-sprint reviews, demos and all of that good stuff. It worked really well, and keep us honest and clean. We used a very simple org-mode file to keep track of all the open stories, and at one point we even built a simple burn-down chart generator to allow us to measure velocity. </p><p>Granted, when you are working alone in your spare time, a chunk of agile may not make sense; for instance, providing status updates to yourself may not be the most productive use of scarce time. Surprisingly, I found quite a bit of process to be vital. I've kept the bi-weekly sprint cycle, the sprint logs, the product backlog and the time-tracking we had originally setup and found them <b>extremely</b> useful - quite possibly the thing that has kept me going for such an extended period of time, to be brutally honest. When you are working on an open source project it is very easy to get lost in its open-ended-ness and find yourself giving up, particularly if you are not getting (or expecting) any user feedback. Even Linus himself has said many times he would have given up the kernel if it wasn't for other people bringing him problems to keep him interested. </p><p>Lacking Linus' ability to attract crowds of interested developers, I went for the next best thing: I made them up. Well, at least in metaphorical way, I guess, as this is what user stories are when you have no external users to drive them. As I am using the product in anger, I find it very easy to put myself in the head of a user and come up with requirements that push development forward. These stories really help, because they transform the cloud of possibilities into concrete, simple, measurable deliverables that one can choose to deliver or not. Once you have a set of stories, you have no excuse to be lazy because you can visualise in your head just how much effort it would require you to implement a story - and hey, since nerds are terrible at estimating, it's never that much effort at all. As everyone knows, it's not quite that easy in the end; but once you've started, you get the feeling you have to at least finish the task at hand, and so on, one story at a time, one sprint at a time, until a body of work starts building up. It's slow, excruciatingly slow, but it's steady like water working in geological time; when you look back 5 sprints, you cannot help but be amazed on how much can be achieved in such a incremental way - and how much is still left. </p><p>And then you get hooked into measurements. I now love measuring everything, from how long it takes me to complete a story, to where time goes in an sprint, to how many commits I do a day, to, well, everything that can easily be measured without adding any overhead. There is no incentive for you to game the system - hell, you could create a script that commits 20 times a day, if the commit count is all you care about. But it's not, so why bother. Due to this, statistics start to actually tell you valuable information about the world and to impel you forward. For instance, GitHub streaks mean that I always try to at least make one commit per day. Because of this, even on days when I'm tired, I always force my self to do <i>something</i>and sometimes that quick commit morphs into an hour or two of work that wouldn't have happened otherwise. </p><p>As I mentioned before, it was revealing to find out that there are different types of time. In order to to take advantage of this heterogeneity, one must make scrupulous use of the product backlog. This has proven invaluable, as you can attest by its <a href="https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/product_backlog.org">current</a>size. Whether we are part way through a story or just idly daydreaming, each and every idea must be added to the product backlog, with sufficient detail to allow one to reconstruct one's train of thought at that point in time. Once in the backlog, items can be continuously refined until eventually we find a suitable sprint to tackle them or they get deprecated altogether. But without an healthy backlog it is not possible to make the most these illusive time slots. Conversely, it is important to try to make each story as small and as focused as possible, and to minimise spikes unless they really are on the critical path of the story. This is mainly for psychological reasons: one needs to mark stories as complete, to feel like work has been done. Never-ending stories are just bad for morale. </p><p>In general, this extreme incrementalism has served us well. Not all is positive though. The worst problem has been a great difficulty in tackling complex problems - those that require several hours just to load them into your head. These are unavoidable in any sufficiently large code base. Having lots of discontinued segments of unpredictable duration have reduced efficiency considerably. In particular, I notice I have spent a lot more time lost in conceptual circles, and I've taken a lot longer to explore alternatives when compared to working full time. </p></div> </div> <div class="outline-2" id="outline-container-3"><h2 id="sec-3">DVCS to the Core</h2><div class="outline-text-2" id="text-3">  <p>We had already started to use git during the start-up days, and it had proved to be a major win at the time. After all, one never quite knows where one will be coding from, and whether internet access is available or not, so it's important to have a self-contained environment. In the end we found out it brought many, many more advantages such as great collaborative flows, good managed web interfaces/hosting providers (<a href="http://www.github.com">GitHub</a> and, to some extent, <a href="http://www.bitbucket.com">BitBucket</a>), amazing raw speed even on low-powered machines, and a number of other wins - all covered by lots and lots of posts around the web, so I won't bore you with that. </p><p>On the surface it may seem that DVCS is most useful on a multi-developer team. This is not the case. The more discontinued your time is, the more you start appreciating its distributed nature. This is because each "kind" of time has a more suitable device - perhaps a netbook for the train, a desktop at someone's house or even a phone while waiting somewhere. With DVCS you can easily to switch devices and continue exactly where you left off. With GitHub you can even author using the web interface, so a mobile phone suddenly becomes useful for reading and writing. </p><p>Another decision that turned out to be a major win is still not the done thing. Ever the trailblazers, we decided to put everything related to the project in version control. And by "everything" I do mean <b>everything</b>: documentation, bug reports, agile process, blog posts, the whole lot. It did seem a bit silly not to use GitHub's Wiki and Issues at the time, but, on hindsight, having everything in one versioned controlled place proved to be a major win: </p><ul><li>searching is never further than a couple of greps away, and it's not   sensitive to connectivity; </li><li>all you need is a tiny sliver of connectivity to push or pull, and   work can be batched to wait for that moment; </li><li>updates by other people come in as commits and can be easily   reviewed as part of the normal push/pull process - not that we got   any of late, to be fair; </li><li>changes can easily be diffed; </li><li>history can be checked using the familiar version control interface,   which is available wherever you go. </li></ul>  <p>When you have little time, these advantages are life-savers. </p><p>The last but very important lesson learned was to commit early and commit often. It's rather obvious in hindsight, really. After all, if you have very small blocks of time to do work, you want to make sure you don't break anything; last thing you need is to spend a week debugging a tricky problem, with no idea of where you're going or how far you still have to travel. So it's important to make your commits <i>very small</i> and <i>very focused</i> such that a bisection would almost immediately reveal a problem - or at least provide you with an obvious rollback strategy. This has proved itself to be invaluable far too many times to count. The gist of this approach it is to split changes in an almost OCD sort of way, to the point that anyone can look at the commit comment and the commit diff and make a judgement as to whether the change was correct or not. To be fair, it's not quite always that straightforward, but that has been the overall aim. </p></div> </div> <div class="outline-2" id="outline-container-4"><h2 id="sec-4">Struggling to stay Continuously Integrated</h2><div class="outline-text-2" id="text-4">  <p>After the commit comes the build, and the proof is in the pudding, as they say. When it comes to code, that largely means CI; granted, it may not be a very reliable proof, but nevertheless it is the best proof we've got. One of the major wins from the start up days was to setup CI, and to give it as wide a coverage as we could muster. We setup multiple build agents across compilers and platforms, added dynamic analysis, code coverage, packaging and basic sanity tests on those packages. </p><p>All of these have proven to be major steps in keeping the show on the road, and once setup, they were <i>normally</i> fairly trivial to maintain. We did have a couple of minor issues with <a href="http://www.cdash.org/">CDash</a> whilst we were running our own server. Eventually we moved over to the <a href="http://my.cdash.org/index.php?project=Dogen">hosted CDash server</a> but it has limitations on the number of builds, which meant I had to switch some build agents off. In addition to this, the main other stumbling block is finding the time to do large infrastructural updates to the build agents such as setting up new versions of <a href="http://www.boost.org/users/history/version_1_56_0.html">Boost</a>, new compilers and so on. These are horrendously time consuming across platforms because you never know what issues you are going to hit, and each platform has their own way of doing things. </p><p>The biggest lesson we learned here is that CI is vital but software products with no time at all should not waste time managing their own CI. There are just not enough hours in the day. I have been looking into <a href="https://travis-ci.org/">travis</a> to make this process easier in the future. Also, whilst being cross-platform is a very worthy objective, one has to weigh the costs with the benefits. If you have a tiny user base, it may make sense to stick to one platform and continue to do portable coding without "proof"; once users start asking for multiple platforms, it is then worth considering doing the work required to support them. </p><p>The packaging story was also a very good one to start off with - after all, most users will probably rely on those - but it turned out to be <b>much</b> harder than first thought. We spent quite a bit of time integrating with the GitHub API, uploading packages into their downloads section, downloading them from there, testing, and then renaming them for user consumption. Whilst it lasted, this setup was very useful. Unfortunately it didn't last very long as GitHub decided to decommission their downloads section. Since most of the upload and download code was GitHub specific, we could not readily move over to a different location. The lesson here was that this sort of functionality is extremely useful, and it is worth dedicating time to it, but one should always have a plan B and even a plan C. To make a long story short, the end result is that we don't have any downloads available at all - not even a stale ones - nor do we have any sanity checks on packages we produce; they basically go to <code>/dev/null</code>. </p><p>In summary, all of our pains led us to conclude that one should externalise early, externalise often and externalise everything. If there is a free (or cheap) provider in the cloud that can take on some or all of your infrastructure work away, you should always consider using them first rather than host your own infrastructure. And remember: your time is worth some money, and it is better spent coding. Of course, it is important to ensure that the provider is reliable, has been around for a while and is used by a critical mass. There is nothing worse than spending a lot of effort migrating to a platform, only to find out that it is about to dramatically change its APIs, prices, terms and conditions - or even worse, to be shutdown altogether. </p></div> </div> <div class="outline-2" id="outline-container-5"><h2 id="sec-5">Loosely Coupled</h2><div class="outline-text-2" id="text-5">  <p>Another very useful lesson I learned was to keep the <i>off-distro</i>dependencies to a minimum. This is rather related to the previous points on CI and cross-platform-ness, really. During the start up days we started off by requiring a C++ compiler with good C++ 11 support, and a Boost library with a few off-tree libraries - mainly <a href="http://www.boost.org/doc/libs/1_56_0/libs/log/doc/html/index.html">Boost.Log</a>. This meant we had to have our own little "chroot" with all of these, and we had to build them by hand, sprinkled with plenty of helper scripts. In those dark days, almost nothing was supplied by the distro and life was painful. It was just about workable when we had time on our hands, but this is really not the sort of thing you want to spend time maintaining if you are working on a project in your spare time. </p><p>To be fair, I had always intended to move to distro-supplied packages as soon as they caught up, and when that happened the transition was smooth enough. As things stand, we have a very small off-distro footprint - mainly <a href="http://www.codesynthesis.com/products/odb/">ODB</a> and <a href="http://epa.codeplex.com/">EOS</a>. The additional advantage of not having off-distro dependencies is that you can start to consider yourself for inclusion on a distro. Even in these days of Docker, being shipped by a distro is still a good milestone for any open source project, so it's important to aim for it. Once more, it's the old psychological factors. </p><p>All and all, it seems to me we took the right decisions as both C++ 11 and Boost.Log have proven quite useful; but in the future I certainly will think very carefully about adding dependencies to off-distro libraries. </p></div> </div> <div class="outline-2" id="outline-container-6"><h2 id="sec-6">Conclusions</h2><div class="outline-text-2" id="text-6">  <p>In general, the first fifty iterations of Dogen have been very positive. It has been a rather interesting journey, and dealing with pure uncertainty is not always easy - after all, one always wants to reach a destination. At the same time, much has been learned in the process, and a setup has been created that is sustainable given the available resources. In the near future I intend to improve the visibility of the project as I believe that, for all it's faults, it is still useful in its current form. </p></div></div></div> <div id="postamble"><p class="date">Date: 2014-09-07 22:02:42 BST</p><p class="creator">Org version 7.8.02 with Emacs version 24</p><a href="http://validator.w3.org/check?uri=referer">Validate XHTML 1.0</a> </div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://mcraveiro.blogspot.com/2014/09/nerd-food-dogen-old-demo.html">Nerd Food: Dogen: Old Demo</a></h2></div>
            <p class="text-muted">by <a href="http://mcraveiro.blogspot.com/">Marco Craveiro</a> on September 07, 2014 09:25 PM.</p>
          </div>
          <div class="panel-body">

            Nerd Food: Dogen: Old Demo  <div id="preamble"> </div> <div id="content"> <p>As part of my attempt to make the work in Dogen a bit more visible, I thought I'd repost an old demo here. The interface has changed very little since those days so it's still a useful introduction. </p>  </div> <div id="postamble"><p class="date">Date: 2014-09-07 22:23:58 BST</p><p class="creator">Org version 7.8.02 with Emacs version 24</p><a href="http://validator.w3.org/check?uri=referer">Validate XHTML 1.0</a> </div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://mcraveiro.blogspot.com/2014/08/nerd-food-using-mono-in-anger-part-iv.html">Nerd Food: Using Mono In Anger - Part IV</a></h2></div>
            <p class="text-muted">by <a href="http://mcraveiro.blogspot.com/">Marco Craveiro</a> on August 12, 2014 02:20 PM.</p>
          </div>
          <div class="panel-body">

            Nerd Food: Using Mono In Anger - Part IV  <div id="preamble"> </div> <div id="content"> <p><i>In which we discuss the advances in MonoDevelop 5</i></p><p>This is the fourth and final part of a series of posts on my experiences using Mono for a fairly demanding project. For more context please read <a href="http://mcraveiro.blogspot.co.uk/2014/05/nerd-food-using-monodevelop-in-anger.html">part 1</a>, <a href="http://mcraveiro.blogspot.co.uk/2014/05/nerd-food-using-mono-in-anger-part-ii_3422.html">part 2</a> and <a href="http://mcraveiro.blogspot.co.uk/2014/05/nerd-food-using-mono-in-anger-part-iii.html">part 3</a>. </p><p>In this instalment we shall have a look at latest incarnation of MonoDevelop. </p> <div class="outline-2" id="outline-container-1"><h2 id="sec-1">Getting Latest and Greatest</h2><div class="outline-text-2" id="text-1">  <p>As I was part-way through these series of blog posts, Xamarin <a href="http://developer.xamarin.com/releases/studio/xamarin.studio_5.0/xamarin.studio_5.0/">announced</a> Xamarin Studio 5 - the commercial product based off of MonoDevelop. Clearly I had to get my hands on it. However, in this particular instance Debian unstable was proven to be rather… stable. The latest versions of Mono and MonoDevelop are rather quaint, and the <a href="http://lists.alioth.debian.org/pipermail/pkg-mono-devel/">packaging mailing list</a> is not the most active, as <a href="http://lists.alioth.debian.org/pipermail/pkg-mono-devel/2014-June/001053.html">my request</a> for news on packaging revealed. </p><p>Building is not an entirely trivial experience, as <a href="http://mcraveiro.blogspot.com/2014/05/nerd-food-using-mono-in-anger-part-ii_3422.html?showComment=1403591218536#c7416906974882038233">Brendan's comment</a>on a previous post demonstrated, so I was keen on going for binary packages. Surprisingly, there are not many private repos that publish up-to-date debian packages for mono. After much searching, I found an Ubuntu PPA that did: </p><pre class="example"><br />add-apt-repository 'deb  http://ppa.launchpad.net/ermshiperete/monodevelop/ubuntu quantal main'<br />apt-get install monodevelop-current<br /></pre>  <p>Running it was as easy as using the launcher script: </p><pre class="example"><br />/opt/monodevelop/bin/monodevelop-launcher.sh<br /></pre>  <p>And just as I was about to moan from the sidelines and beg Xamarin to try and help out Debian and Linux packagers in general, Miguel sent the following tweet: </p><blockquote> <p>Miguel de Icaza‏@migueldeicaza 4h Mono snapshots: @directhex just published our daily Linux packages <a href="http://mono-project.com/DistroPackages/Jenkins">http://mono-project.com/DistroPackages/Jenkins</a></p></blockquote>  <p>It's like Xamarin just reads my mind! </p><p>Haven't had the chance to play with these packages yet, and I didn't see any references to MonoDevelop in Jenkins (admittedly, it wasn't the deepest search I've done), but seems like a great step forward. </p></div> </div> <div class="outline-2" id="outline-container-2"><h2 id="sec-2">Playing with Latest and Greatest</h2><div class="outline-text-2" id="text-2">  <p>So what has changed? The UI may look identical to the previous version, but lord has the polish level gone up. Basically, almost all the problems I had bumped into have gone away. </p> </div> <div class="outline-3" id="outline-container-2-1"><h3 id="sec-2-1">NuGet support</h3><div class="outline-text-3" id="text-2-1"> <p><b>Update:</b> See <a href="http://lastexitcode.com/blog/2014/08/10/NuGetSupportInXamarinStudio5-2/">this post</a> by Matt Ward for more details on NuGet support.  </p><p>As I mentioned <a href="http://mcraveiro.blogspot.co.uk/2014/05/nerd-food-using-mono-in-anger-part-ii_3422.html">before</a>, whilst the NuGet plugin was great for basic usage, it did have a lot of corner cases including the certificates issues, full restore not working properly and so on. This has all been sorted out in MonoDevelop 5. It sports an internal implementation as explained in the release notes, and it has been flawless up till now. </p><p>I did bump into an annoying problem, but I think its more Visual Studio's fault than anything else. Basically, Microsoft decided to add some <code>NuGet.targets</code> to the solution by copying them to <code>.nuget</code>. Now, to their credit, they appear to have thought about mono: </p><pre class="example"><br />        &lt;!-- We need to launch nuget.exe with the mono command if we're not on windows --&gt;<br />       &lt;NuGetToolsPath&gt;$(SolutionDir).nuget&lt;/NuGetToolsPath&gt;<br /></pre>  <p>However, this fails miserably. The <code>DownloadNuGet</code> target does not appear to exist in mono, and copying <code>NuGet.exe</code> manually into <code>.nuget</code> also failed - apparently its not just a binary these days. The lazy man solution was to find the NuGet binaries in MonoDevelop and copy them across to the <code>.nuget</code> directory (had them at <code>monodevelop-5.0/external/nuget-binary</code>). Once this was done, building worked just fine. </p><p>Note also that I didn't have time to test the <code>.nuget</code> directory properly, by overriding the default directory with something slightly more sensible. However, I don't particularly like having my packages in the middle of the source tree so I'll be trying that very soon. </p><p>Overall, the NuGet experience is great, and package restoring Just Works (TM). </p></div> </div> <div class="outline-3" id="outline-container-2-2"><h3 id="sec-2-2">Intellisense and Friends</h3><div class="outline-text-3" id="text-2-2">  <p>I was already quite pleased with Intellisense in MonoDevelop 4, but I did find it was easy to confuse it when files got in to a bit of a state - say when pasting random chunks of code into a file. All of these problems are now gone with MonoDevelop 5. In more challenging situations, I have noticed the syntax highlighting disappearing for a little bit but as soon as the code is vaguely sensible, it returns straight away. </p><p>It is also a pleasure to use Ctrl-Shift-T to go to definitions, in some ways it seems even more powerful than ReSharper. It is certainly more responsive, even on my lowly NetBook with 1GB of RAM. </p><p>One slight snag is that extract interface seems to have gone missing - I was pretty sure I had used it on MonoDevelop 4, but for the life of me can't find it on 5. </p></div> </div> <div class="outline-3" id="outline-container-2-3"><h3 id="sec-2-3">NUnit</h3><div class="outline-text-3" id="text-2-3">  <p>I was a very happy user of the NUnit add-on for weeks on end and it performed flawlessly. However, today it got stuck loading tests and I ended up having to restart MonoDevelop to fix it. Bearing in mind I normally leave it running for weeks at a time, this annoyed me slightly. Of course, to be fair, I do restart Visual Studio every couple of days or so, so the odd MonoDevelop restart is not exactly the end of the world. </p><p>But in general, one complaint I have against both Visual Studio and MonoDevelop is with the opaqueness of unit testing. For me, it all started with shadow copying in NUnit UI and went downhill from there, really. If only one could see what exactly what it is that the IDE is trying to do, it would be fairly trivial to debug it; as it is, all I know is that my tests are "loading" but fail to load a few minutes later. </p><p>Anyway, that's just me ranting. Other than that, unit testing has worked really well, and I even started making use of the "Results Pad" and all - shiny charts! </p></div> </div> <div class="outline-3" id="outline-container-2-4"><h3 id="sec-2-4">Git FTW, UI Quirks and Resources</h3><div class="outline-text-3" id="text-2-4">  <p>I had mentioned before that there were some minor UI quirks. For instance I recall seeing a search box that was not properly drawn, and having problems with the default layout of the screen. I'm happy to report that all of my UI quirks have gone away with 5. It is quite polished in that regard. </p><p>I've also started making use of the version control support - to some extent, of course, as I still think that <a href="http://magit.github.io/">Magit</a> is above sliced bread. Having said that, its very useful to see a diff against what was committed or going up and down the history of a file without having to go to emacs. Version control is extremely quick. Even though Visual Studio now has git support integrated, it is a lot slower that MonoDevelop. I basically never wait at all for git on MonoDevelop. </p><p>Finally, a word on resources. I can still use MonoDevelop on my NetBook with its 1GB of RAM, much of it taken by Gnome 3 and Chrome. However, I did see it using over 250 MB of RAM on my desktop PC. I wonder if MonoDevelop is more aggressive on its usage of memory when it sees there is a lot available. </p></div></div> </div> <div class="outline-2" id="outline-container-3"><h2 id="sec-3">Conclusions</h2><div class="outline-text-2" id="text-3">  <p>Whilst I'll still be using MonoDevelop for a few weeks longer, I think we have done enough on this four part series. My main objective was really to pit Mono and MonoDevelop against Visual Studio 2013 on a fairly serious project, requiring all the usual suspects: .Net, Castle, Log4Net, MongoDB and so on. To my surprise, I found I had very few interoperability problems - on the whole, the exact same source code, configuration, etc just worked for both Windows and Linux. It says a lot on how far Mono has progressed. </p><p>Regrettably, I didn't get as far as playing around with vNext - the coding is taking a lot longer than expected - but if I do get as far as that I shall post an update. </p><p>It's great news that Xamarin is improving their Linux support; I can imagine that there must be a number of companies out there considering Docker for their .Net environments. Xamarin is going to be in a great position to win over these tight-Windows-shops with the great products they have. </p></div></div></div> <div id="postamble"><p class="date">Date: 2014-08-09 00:51:03 BST</p><p class="creator">Org version 7.8.02 with Emacs version 23</p><a href="http://validator.w3.org/check?uri=referer">Validate XHTML 1.0</a> </div>
          </div>
        </div>
        
        
        
        <div class="panel panel-default">
          <div class="panel-heading">
            <div class="panel-title"><h2><a href="http://mcraveiro.blogspot.com/2014/05/nerd-food-using-mono-in-anger-part-iii.html">Nerd Food: Using Mono In Anger - Part III</a></h2></div>
            <p class="text-muted">by <a href="http://mcraveiro.blogspot.com/">Marco Craveiro</a> on May 27, 2014 09:30 PM.</p>
          </div>
          <div class="panel-body">

            Nerd Food: Using Mono In Anger - Part III  <div id="preamble"> </div> <div id="content"><p><i>In which we discuss the various libraries and tools used.</i></p><p>This is the third part of a series of posts on my experiences using Mono for a fairly demanding project. For more context please read <a href="http://mcraveiro.blogspot.co.uk/2014/05/nerd-food-using-monodevelop-in-anger.html">part 1</a> and <a href="http://mcraveiro.blogspot.co.uk/2014/05/nerd-food-using-mono-in-anger-part-ii_3422.html">part 2</a>. </p><p>In this instalment we shall focus more on the libraries, tools and technologies that I ended up using. </p> <div class="outline-2" id="outline-container-1"><h2 id="sec-1">Castle</h2><div class="outline-text-2" id="text-1">  <p>I've mentioned Castle a few times already. It appears to be the <i>de facto</i> IoC container for .Net, so its very important to have a good story around it. As I explained on the previous post, I added NuGet references to <i>Castle Core</i> and <i>Castle Windsor</i> and after that it was pretty much smooth sailing. I setup <a href="http://docs.castleproject.org/Windsor.Installers.ashx">Windor Installers</a> as described by Mark Seemann in his post <a href="http://blog.ploeh.dk/2010/01/26/IWindsorInstaller/">IWindsorInstaller</a> and that worked as described. My main program does exactly as Mark's: </p>   <pre class="example">var container = new WindsorContainer();<br />container.Install(new MyModule.WindsorInstaller(), new OtherModule.WindsorInstaller());<br />return container.Resolve&lt;IEntryPoint&gt;();<br /></pre>  <p>Basically, I have a number of IWindsorInstallers (e.g. <code>MyModule.WindsorInstaller()</code> etc.) that get installed, and then all that needs to be done is to resolve the "entry point" for the app - e.g. whatever your main workflow is. </p><p>All of this worked out of the box without any tweaking from my part. </p></div> </div> <div class="outline-2" id="outline-container-2"><h2 id="sec-2">MongoDB</h2><div class="outline-text-2" id="text-2">  <p>I've used MongoDB as the store for my test tool; I'll give a bit of context before I get into the Mono aspects. Mentally, I picture MongoDB somewhere in between PostgreSQL and <a href="http://www.oracle.com/technetwork/middleware/coherence/overview/index.html?ssSourceSiteId=opn">Coherence</a> / <a href="http://memcached.org/">MemCached</a>. That is, it's obviously not a relational database but one of those NoSQL specials: a schemaless, persistent, document database. You can do a lot of this stuff using <a href="http://www.postgresql.org/docs/9.4/static/hstore.html">hstore</a>, of course, and it now even sports something similar-but-not-quite-the-same-as <a href="http://bsonspec.org/">BSON</a> - <a href="http://www.depesz.com/2014/03/25/waiting-for-9-4-introduce-jsonb-a-structured-format-for-storing-json/">JSONB</a>, in the usual humorist Postgres way. MongoDB's setup is somewhat easier than Postgres, on both replicated and non-replicated scenarios. It also offers Javascript-based querying which, to be fair, <a href="http://blog.endpoint.com/2013/11/using-javascript-in-postgresql.html">Postgres also does</a>. I'd say that, if you have to choose between the two, go for MongoDB if you need a quick setup (replication included), if you <a href="http://jkb.netii.net/index.php/pub/sinosqldb/mongodb-security">don't care too much about security</a> and if you do not need any RDBMS support. Otherwise, use latest Postgres. And RTM. A Lot. </p><p>MongoDB is obviously also much easier to setup than Coherence. Of course, if you go for the trivial setup, Coherence is easy; but once you get into proper distributed setups I found it to be an absolute nightmare, requiring a lot of expertise just to understand why your data has been evicted. That's excluding the more complex scenarios such as invocation services, backing maps and so on. Sure, you can get the performance and the scalability, but you <span style="text-decoration: underline;">really</span> need to know what you are doing. And let's not mention the licence costs. Basically, for the plain in-memory cache job with an easy setup, just use Memcached. </p><p>But let's progress with MongoDB. Regrettably, there are no packages in Testing for it, but the wiki has a rather straightforward set of instructions under <a href="http://docs.mongodb.org/manual/tutorial/install-mongodb-on-debian/">Install MongoDB on Debian</a>. It boils down to: </p>   <pre class="example"># apt-key adv --keyserver keyserver.ubuntu.com --recv 7F0CEB10<br /># echo 'deb http://downloads-distro.mongodb.org/repo/debian-sysvinit dist 10gen' | sudo tee /etc/apt/sources.list.d/mongodb.list<br /># apt-get update<br /># apt-get install mongodb-org<br /></pre>  <p>Since I'm using <code>systemd</code> I was a bit apprehensive with their control scripts. As it turns out, it worked out of the box without any problems. I did find the installation to vary depending on the machines: on some I got <a href="http://blog.mongodb.org/post/33700094220/how-mongodbs-journaling-works">journaling</a> by default, but on my really low-end NetBook it was disabled. Also, the other thing to bear in mind is that if you have a small <code>root</code> or <code>var</code> partition - e.g. the one storing <code>/var/lib/mongodb</code> - you may run into trouble. I ended up symlinking this directory to a drive that had more space just to avoid problems. </p><p>Once MongoDB was up and running, it was time to find a management UI. Unfortunately, <a href="http://www.mongovue.com/">MongoVue</a> - the UI that all the Windows cool kids use - is not available on Linux. This is a bit disappointing because it seems rather full featured and well funded and - just to rub salt in the wounds - <i>it's a .Net application</i>. The old lack of cross-platform mentality surfaces yet again. Undeterred once more, I settled on <a href="http://robomongo.org/">RoboMongo</a> instead. Not quite as matured, but seemed good enough for my needs. Simple to setup too: </p>   <pre class="example">$ wget -O robomongo-0.8.4-x86_64.deb http://robomongo.org/files/linux/robomongo-0.8.4-x86_64.deb<br />$ gdebi-gtk robomongo-0.8.4-x86_64.deb<br /></pre>  <p>If you don't have <code>gdebi-gtk</code> any other debian installer would do, including <code>dpkg -i robomongo-0.8.4-x86_64.deb</code>. </p><p>If you are an emacs user, be sure to install the <a href="https://github.com/tobiassvn/inf-mongo">inferior mode</a> for Mongo. Works well on Linux but has the usual strange input-consumption problems one always gets on Windows. </p><p>Going back to Mono, all one needs to do is to use NuGet to install the <i>CSharp Mongo Driver</i>. Once that was done, reading, writing, updating etc all worked out of the box. </p></div> </div> <div class="outline-2" id="outline-container-3"><h2 id="sec-3">Log4Net</h2><div class="outline-text-2" id="text-3">  <p>Paradoxically, where I thought I was going to have the least amount of trouble ended up being the most troublesome of all of my dependencies. Getting log4net to work was initially really easy - the usual NuGet install. But then, not happy with such easy success, I decided I needed a single <code>log4net.config</code> file for all my projects. This is understandable since all that was different amongst them was the log file name; it seemed a bit silly to have lots of copy and paste XML lying around. So I decided to use Dynamic Properties, as explained in this blog post: <a href="http://kyleleneau.com/blog/2009/06/12/log4net-dynamic-properties-in-xml-configuration/">Log4net Dynamic Properties in XML Configuration</a>. This failed miserably. </p><p>As everyone knows, log4net is a pain in the backside to debug. For the longest time I didn't have the right configuration; eventually I figured out what I was doing wrong. It turns out the magic incantation is this (I missed the <code>type</code> bit): </p>   <pre class="example">        &lt;appender name="RollingFileAppender" type="log4net.Appender.RollingFileAppender"&gt;<br />            &lt;file type="log4net.Util.PatternString" value="APrefix.%property{ApplicationId}.log" /&gt;<br /></pre>  <p>Just when I thought I was out of the woods, I hit a Mono limitation: <code>CallContext.LogicalGetData</code> is not yet implemented in Mono 3.0. It is available on later versions of Mono, but these are not yet in Debian Testing. Undeterred, I decided to try to compile Mono from scratch. It turned out to be rather straightforward: </p>   <pre class="example">$ git clone https://github.com/mono/mono<br />$ cd mono<br />$ ./autogen.sh --prefix=${YOUR_INSTALL_LOCATION}<br />$ make -j${NUMBER_OF_CORES}<br />$ make install<br /></pre>  <p>Replace (or set) <code>${YOUR_INSTALL_LOCATION}</code> and <code>${NUMBER_OF_CORES}</code>as required. Once you got it installed, you need to tell MonoDevelop about the new runtime. Go to <i>Edit</i>, <i>Preferences</i> then choose <i>.Net Runtimes</i> and click on <i>Add</i>. Point to the top-level directory containing your installation (e.g. <code>${YOUR_INSTALL_LOCATION}</code>) and it should find the newly built Mono. I then set that as my default. Incredibly enough, from then on it all just worked. </p> <div class="figure"><p><img src="http://4.bp.blogspot.com/-KXopT6xb-Vc/U4UBNVmitwI/AAAAAAAAAnQ/5TrpusbNA7o/s1600/monodevelop_add_runtime.png" /></p><p>Runtimes in MonoDevelop</p></div> </div> </div> <div class="outline-2" id="outline-container-4"><h2 id="sec-4">NUnit</h2><div class="outline-text-2" id="text-4">  <p>As mentioned in the previous post, you should replace the NUnit references you get from MonoDevelop with NuGet ones. This is because you may be using some of the newer features of NUnit - which are not available with the version that ships with Mono. At any rate, it just gives you more confidence on the dependency rather than depending on the environment. </p><p>Another problem I found was disabling shadow copying. This does not seem to be an option in the MonoDevelop UI or the solution. It is rather annoying if you need to have some log4net config files in the test directory - as I did, due to the Dynamic Properties mentioned above. </p><p>Other than that, NUnit worked very well. </p></div> </div> <div class="outline-2" id="outline-container-5"><h2 id="sec-5">Libraries Overview</h2><div class="outline-text-2" id="text-5">  <p>Compiling Mono from source is obviously not ideal, but perhaps the main thing to worry about is how to get latest Mono packages. As with MongoDB, it perhaps would be better to have a repository supported by the Mono community that offers more up-to-date packages, at least for the more intrepid users. Although some of these existed in the past (particularly Ubuntu PPAs) they all seem to have gone stale. </p><p>Having said that, there are still no showstoppers - the code is working on both Visual Studio 2013 and Mono. </p></div></div></div> <div id="postamble"><p class="date">Date: 2014-05-27 22:29:38 BST</p><p class="creator">Org version 7.8.02 with Emacs version 23</p><a href="http://validator.w3.org/check?uri=referer">Validate XHTML 1.0</a> </div>
          </div>
        </div>
        
        
      </div>
      <div class="col-md-3">
        <div class="panel panel-default">
          <div class="panel-heading">
            <h3 class="panel-title">Feed list</h3>
          </div>
          <ul class="list-group">
            
            <li class="list-group-item"><a href="http://ankursinha.in/blog/feeds/categories/research.atom.xml">ankursinha.in/blog</a></li>
            
            <li class="list-group-item"><a href="http://blogs.biomedcentral.com/bmcseriesblog/feed/">BMC Series blog</a></li>
            
            <li class="list-group-item"><a href="http://www.blogger.com/feeds/2672427473119923109/posts/default">Marco Craveiro</a></li>
            
            <li class="list-group-item"><a href="http://feeds.plos.org/plos/blogs/neuro">PLOS Neuroscience Community</a></li>
            
            <li class="list-group-item"><a href="http://feeds.plos.org/plos/Blog">Public Library of Science</a></li>
            
            <li class="list-group-item"><a href="http://biocomputation.herts.ac.uk/feeds/all.atom.xml">UH Biocomputation Group</a></li>
            
          </ul>
        </div>
      </div>
    </div>
    <footer id="site-footer">
      <p class="text-center text-muted">All content on this page is owned by their respective owners. The source code used to generate this page can be found <a href="http://github.com/sanjayankur31/planet-neuroscientists">here</a>.</p>
      </div>
    </footer>
  </body>
</html>

