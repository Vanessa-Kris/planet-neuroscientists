<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
  <head>
    <title>Planet Neuroscientists</title>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet"> 
    <link href="https://fonts.googleapis.com/css?family=Comfortaa" rel="stylesheet">
  </head>

  <body>
    <div class="container">
      <div class="page-header">
        <h1>Planet Neuroscientists</h1>
        <p>
        last updated by <a href="http://intertwingly.net/code/venus/">Venus</a> 
        on Nov. 25, 2016, 1:31 a.m. on behalf of Ankur Sinha.
        </p>
      </div>
    </div>

    <div class="container">
      <div class="col-md-9">
        <ul class="list-group">
          
          
          <li class="list-group-item"><h4>A stepwise neuron model fitting procedure designed for recordings with high spatial resolution: application to layer 5 pyramidal cells.</h4>

            <p><a class="reference external" href="http://www.med.uio.no/klinmed/english/people/aca/tuomomm/">Tuomo Mäki-Marttunen</a> joins us for a special journal club session this week.</p>
<hr class="docutils" />
<p>The recent progress in electrophysiological and optical methods for neuronal recordings provides vast amounts of high-resolution data. In parallel, the development of computer technology has allowed simulating ever larger neuronal circuits. A challenge in taking advantage of these developments is the construction of single-cell and network models in a way that faithfully reproduces neuronal biophysics with subcellular level of details while keeping the simulation costs at an acceptable level. In this talk, I will present our work on a stepwise method for fitting a neuron model to data with fine spatial resolution, such as that achievable with voltage sensitive dyes (VSDs) and Ca2+ imaging.</p>
<p>We applied our method to simulated data from layer 5 pyramidal cells (L5PCs) and constructed a model with reduced neuronal morphology. We connected the reduced-morphology neurons into a network and validated against simulated data from a high-resolution L5PC network model. The reduced-morphology neuron model obtained using our approach reliably reproduced the membrane potential dynamics across the dendrites as predicted by the full-morphology model, and was more than 20 times faster to simulate. The network models produced using our method are cost-efficient and predict that interconnected L5PCs, largely due to the medium afterhyperpolarization mediated by the Ca2+-activated SK current, are able to amplify delta-range oscillatory inputs across a large range of network sizes and topologies.</p>
<p><strong>Date:</strong> 25/11/2016 <br />
<strong>Time:</strong> 12:00 <br />
<strong>Location</strong>: LB252/C258 (TBD)</p>

            <p class="text-muted">in 'UH Biocomputation group' on November 23, 2016 04:10 PM. <a href="http://biocomputation.herts.ac.uk/2016/11/23/a-stepwise-neuron-model-fitting-procedure-designed-for-recordings-with-high-spatial-resolution-application-to-layer-5-pyramidal-cells.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Error correction over optical transmission.</h4>

            <p>Reducing bit error rate and improving performance of modern coherent optical communication system is a significant issue. As the distance travelled by the information signal increases, bit error rate will degrade. Support Vector Machines are the most up to date machine learning method for error correction in optical transmission systems. Wavelet transform has been a popular method to signals processing. In this study, the properties of most used Haar and Daubechies wavelets are implemented for signals correction. Our results show that the bit error rate can be improved by using classification based on wavelet transforms (WT) and support vector machine (SVM).</p>
<p><strong>Date:</strong> 18/11/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>

            <p class="text-muted">in 'UH Biocomputation group' on November 14, 2016 03:12 PM. <a href="http://biocomputation.herts.ac.uk/2016/11/14/error-correction-over-optical-transmission.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Neuronal computation: dendrites at work.</h4>

            <p>Brain dynamics emerge from the collective and orchestrated activity of single neurons. The main characteristics of neurons are their morphologically elaborate structures to receive and integrate inputs (i.e., the dendrites) and communicate their signal to other neurons (i.e., the axons). Because dendrites receive, integrate and transform inputs into relevant output they can be considered as the functional workhorses of the brain.</p>
<p>In this presentation, I’ll outline the problematic relation between dendrite structure and function in neurons. Then I’ll show how highly non-trivial processing can take place in neurons due to the spatial extend of dendrites. Lastly, I will present my current work on distilling the essence of dendritic computations using simplified models.</p>
<p><strong>Date:</strong> 11/11/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>

            <p class="text-muted">in 'UH Biocomputation group' on November 10, 2016 10:15 AM. <a href="http://biocomputation.herts.ac.uk/2016/11/10/neuronal-computation-dendrites-at-work.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Self-sustained Asynchronous Irregular states and Up-Down states in thalamocortical networks of nonlinear integrate-and-fire neurons.</h4>

            <p>In this talk I will present a paper [1] about a thalamocortical network model I will use as part of my research. I will start by providing a brief summary of the background and the research questions.</p>
<p>Our collaborators at Erasmus Medical Center, Rotterdam, The Netherlands, found that it is possible to stop epileptic absence seizures by exciting cerebellar nucleus (CN) neurons in a closed loop system (this work was done together with a former PhD student, Parimala Alva, [2]). In my PhD work, I will try to understand the mechanisms underlying the termination of seizures by optogenetic stimulation of CN neurons. For this purpose, I will use a thalamocortical network model of adaptive exponential integrate-and-fire neurons, as described in [1].</p>
<p>In the paper [1] the occurrence of Asynchronous Irregular (AI) states in thalamocortical networks of non-linear integrate-and-fire neurons has been investigated together with the role of spike-frequency adaptation. The main findings are that the thalamocortical networks can display AI states or Up-Down state dynamics, depending on the level of adaptation in cortical cells.</p>
<p><strong>Date:</strong> 04/11/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>
<p>[1] <a class="reference external" href="https://www.ncbi.nlm.nih.gov/pubmed/19499317">Destexhe A. Self-sustained asynchronous irregular states and up-down states in thalamic, cortical and thalamocortical networks of nonlinear integrate-and-fire neurons. J Comput Neurosci 2009; 27:493-506</a> <br /></p>
<p>[2] <a class="reference external" href="https://www.ncbi.nlm.nih.gov/pubmed/25762286">Kros et al, Cerebellar Output Controls Generalised Spike-and-Wave Discharge Occurrence, Ann Neurol, 2015</a></p>

            <p class="text-muted">in 'UH Biocomputation group' on November 02, 2016 04:18 PM. <a href="http://biocomputation.herts.ac.uk/2016/11/02/self-sustained-asynchronous-irregular-states-and-up-down-states-in-thalamocortical-networks-of-nonlinear-integrate-and-fire-neurons.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>The pricing of options and corporate liabilities.</h4>

            <p><a class="reference external" href="https://www.jstor.org/stable/1831029">The pricing of options and corporate liabilities (1973)</a></p>
<p>If options are correctly priced in the market, it should not be
possible to make sure profits by creating portfolios of long and short
positions in options and their underlying stocks. Using this
principle, a theoretical valuation formula for options is derived.
Since almost all corporate liabilities can be viewed as combinations
of options, the formula and the analysis that led to it are also
applicable to corporate liabilities such as common stock, corporate
bonds, and warrants. In particular, the formula can be used to derive
the discount that should be applied to a corporate bond because of the
possibility of default.</p>
<hr class="docutils" />
<p>The objectives of this talk are as follows:</p>
<ul class="simple">
<li>provide a general overview of the arguments provided by Black,
Merton and Scholes to a non-financial audience;</li>
<li>convey the importance of the <a class="reference external" href="https://en.wikipedia.org/wiki/Black%E2%80%93Scholes_model">Option Pricing formula</a> derived in
this paper to the financial markets today;</li>
<li>cover some of its shortcomings and subsequent changes done by the
financial markets.</li>
</ul>
<div class="line-block">
<div class="line"><br /></div>
</div>
<p><strong>Date:</strong> 28/10/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>

            <p class="text-muted">in 'UH Biocomputation group' on October 27, 2016 09:09 AM. <a href="http://biocomputation.herts.ac.uk/2016/10/27/the-pricing-of-options-and-corporate-liabilities.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Principal component analysis.</h4>

            <p>Principle Component Analysis (PCA) is used by many but understood by few.</p>
<p>In this talk I hope to explain some of the math behind the tool, to raise awareness for its potential (and pitfalls) and to discuss the relationship between PCA and cluster analysis.
In addition I will present some examples of its use in neuro-science, from my own work in robotics and an application in economics.</p>
<p><strong>Date:</strong> 21/10/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>

            <p class="text-muted">in 'UH Biocomputation group' on October 20, 2016 12:30 PM. <a href="http://biocomputation.herts.ac.uk/2016/10/20/principal-component-analysis.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>On jargon.</h4>

            <p>Jargon is more often than not looked at unfavourably. Jargon is just the "language of a trade" and so, by itself, I don't see why I should denounce it. Rather, to me, it is the usage of jargon that is the issue. If you think of a workplace where people are aware of the context and meaning of certain jargon, I see no reason why it isn't appropriate usage. In fact, in such scenarios, jargon makes conversation efficient since the parties must not needlessly simplify their communications. So, when I go over to my lab mate's desk and say "<em>well, the STDP rule doesn't seem to result in an AI state</em>", he knows exactly what I mean. I'd find it quite difficult to rephrase that sentence to make it any simpler. The same applies for most professions if not all of them. Whether it's farming or mechanics; IT or medicine; cooking or sewing; designing or the media; they will all have some specialised terminology. It is just normal evolution of language in the same way that "selfie" is now a word. Jargon is simply a set of words that encapsulate concepts that are frequently used in a context.</p>
<p>So why are we up in arms about jargon, then? Why is everyone continuously talking about how we need to cut it out? Quite simply, because when jargon is used in the wrong scenario, it hampers transfer of information. If work related terminology is used in a social setting where other listeners are not privy to it, for example, the conversation does not serve to pass on any material. Furthermore, it usually has the effect of making the audience feel out of place. It is quite similar to speaking to a single member of a group in a language that the others do not comprehend. It is considered impolite.</p>
<p>To take it a step further, jargon seems to be used frequently with the malintent to obfuscate - especially in sales and marketing. The idea seems to be to coin and use fancy wording to trick consumers into buying products. The billboards and slogans that we see on a daily basis while not untrue, are not always created with aim to elucidate facts.</p>
<p>Another use of jargon is straightforward snobbery. It makes the snob feel like part of an exclusive club. There isn't much to say about this other than that one should simply not engage with such individuals.</p>
<p>Scenarios where the use of jargon is unintentional are more complex to deal with. Most research falls in this category. Consider people like me who spend a majority of their time in an environment that requires the use of an uncommon vocabulary. So, I read research papers that contain specific words, I write papers using these same words, the discussions I partake in utilise these too - this jargon is quite unavoidable to a large extent in work life. I'm only 2 years into my Ph.D. and I find it hard to speak about the same subject matter without employing the same dialect already. While this does not affect my daily activities as they are limited to colleagues who are well versed in our diction, it greatly limits my ability to spread the science I work in to a wider audience. This, in contrast, does effect me, and you too. If we're not working similar areas, we have very little understanding of each other's work.</p>
<p>While I can't speak for types of work, this, in general, is an issue in research and academia - the lack of ability in us researchers to disseminate our work to people in other streams, especially non research careers, is an accepted weakness.</p>
<p>Computational neuroscience, for example, is extremely multidisciplinary. At my lab alone, we have biologists, physicist, mathematicians, and us computer scientists, all working under the same roof on similar research questions. The dialect each of us speak is different. Yet, we read and publish in the same channels. When I read a paper that is heavy on biological detail, I find it much harder because the text utilises biological terminology that I'm not well aware of. In our case, though, there's only the one solution of learning what we need to know. It is how we manage to collaborate across disciplines, and it takes work - the difference in jargon ever so slightly increasing the required exertions.</p>
<p>Extend this scenario to someone who isn't working in computational neuroscience at all. Of course, it'll be even harder for them to understand the same text. Given how important research is for all life in general, it is imperative that people who do not conduct research be made aware of progress that is continuously made. If you don't understand why research is important, let me point out to you that <em>every</em> manufactured product you use in your home is the end result of some research somewhere. Take a moment to wonder how it all came about - it isn't magic; it is years of hard work and failure.</p>
<p>To insure the future of research, it is important that young students are exposed to it at an early age. It is the simplest way of arousing enough interest in them to guarantee that research receives a constant stream of capable bearers to build on past innovations. It really doesn't matter what they take up - contributions to each field count.</p>
<p>It is also helpful for consumers to have some idea of how things are manufactured and the amount of work that goes into it. It helps them pick between brands and decide what price they should pay for a product. A general awareness helps build immunity to the different tricks in use today that gently nudge consumers into buying products - creating demand for a product that wasn't required some time before.</p>
<p>A last but important note is that most research makes use of public funds that are obtained via government grants. If the tax payer is funding some research, the tax payer should know how the money is being utilised.</p>
<p>So, yes, making research information easily accessible to everyone is of great value. This is where jargon stands out as quite a bottle neck. Individuals that are not aware of the context, or those that do not have the required background knowledge cannot be expected to read research papers to understand the state of knowledge. Rather, academics have to work towards simplifying the data to an extent that it can be consumed by individuals from all walks of life. This isn't easy, and simplification usually goes hand in hand with omission of lesser important details but it is certainly possible to synthesise an overall picture of a concept.</p>
<p>What I've written isn't new by any standards. The problem is well known, and communities are working towards making knowledge more understandable. If you watch the stuff the BBC puts up, for example, you'll see a lot of work by individuals like <a class="reference external" href="https://en.wikipedia.org/wiki/Brian_Cox_(physicist)">Professor Brian Cox</a> that is aimed at explaining complex physical phenomena in simpler terms. A start has certainly been made.</p>
<p>The point of this post was to give myself some time to think about the issue. After writing about a thousand words on the subject, I have a better understanding of it myself. I also have a better handle on what I should do to do my bit. It simply takes practice and some feedback. That's all it is. So, as I blog frequently about my Fedora related activities, I am going to make more of an attempt to write about my research too. A target is always helpful. Since it takes some effort at the moment, I'm going to set myself a target of one research related post every two to three weeks to begin with. Today being the 16th of October, I'll publish the first one before the 7th of November. Let's see how that goes.</p>

            <p class="text-muted">in 'Ankur Sinha' on October 17, 2016 07:26 AM. <a href="http://ankursinha.in/blog/2016/10/17/on-jargon.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Optimising hierarchical load balancing for the Cloud.</h4>

            <p>In the first half of the presentation we will cover the evolution and characteristics of the cloud computing. We will look in particular at the different existing algorithms for load balancing in the cloud. In second half we will see where my research topic fits in along with the challenges and significance of my research.</p>
<p><strong>Date:</strong> 14/10/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>

            <p class="text-muted">in 'UH Biocomputation group' on October 13, 2016 10:14 AM. <a href="http://biocomputation.herts.ac.uk/2016/10/13/optimising-hierarchical-load-balancing-for-the-cloud.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Open Position: Lecturer/Senior Lecturer in Computer Science (Machine learning / Biocomputation).</h4>

            <p>Salary: £32,004 to £48,327 per annum depending on qualifications and experience <br />
FTE: Full time position working 37 hours per week (1.0 FTE) <br />
Closing date: 21 October 2016</p>
<p>Applications are invited for a Lecturer or Senior Lecturer in the School of Computer Science, University of Hertfordshire. The successful candidate will be expected to contribute to the School's teaching and curriculum development activities, and to strengthen its research activities. We are looking to recruit specifically a computer scientist with background in machine learning or data science related to biocomputation (including computational neuroscience). By Data Science we broadly mean the extraction of meaning from large quantities of data. The successful candidate will also have the flexibility to teach across mainstream topics in computer science. The School has an international reputation for teaching and research, with 58 academic staff, 20 adjunct lecturer staff, and 65 research students and postdoctoral research staff. With a history going back to 1958, the School teaches one of the largest cohorts of undergraduate students in the UK, and also delivers a thriving online computer science degree programme.</p>
<p>The person appointed will be expected to contribute to learning and teaching relevant to core computer science topics, participate in curriculum review and development, design and develop new modules, and supervise student projects at all levels. The appointee will strengthen the research culture in the School by pursuing research as part of a larger research team, seeking external funding, publishing papers, supervising research students, and participating in commercial activity as appropriate. Preference will be given to candidates who can contribute to teaching and research in databases as outlined above.</p>
<p>Applicants must hold a PhD (or equivalent) in a relevant subject, possess excellent communication skills in English and the ability to teach at undergraduate and postgraduate level. It is desirable that candidates have a track record of publication, external research funding, collaboration across disciplines, experience of different types of assessment and higher education quality assurance. They should also have the ability to play a role in the routine running of the School of Computer Science.</p>
<p>Applications should be made through <a class="reference external" href="http://www.herts.ac.uk/contact-us/jobs-and-vacancies/academic-vacancies">http://www.herts.ac.uk/contact-us/jobs-and-vacancies/academic-vacancies</a> (reference 014050). Informal enquiries may be addressed to Dr Volker Steuber (Head of the Biocomputation Research Group, v.steuber at herts.ac.uk) or Professor William Clocksin (Dean of School, w.clocksin at herts.ac.uk). Please note that applications sent directly to these email addresses will not be accepted.</p>
<p>We are committed to providing a supportive environment. The university also provides an onsite childcare facility and child-centred holiday clubs. The University is required to meet UKVI visa regulations. Applicants who do not currently have the right to work in the UK will have to satisfy UKVI regulations before they can be appointed.</p>

            <p class="text-muted">in 'UH Biocomputation group' on October 08, 2016 04:06 PM. <a href="http://biocomputation.herts.ac.uk/2016/10/08/open-position-lecturer-senior-lecturer-in-computer-science-machine-learning-biocomputation.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Computational models of synaptic plasticity and information processing in the cerebellum.</h4>

            <p>A central theme of the computational neuroscience research in the Biocomputation Research Group is synaptic plasticity, the activity-dependent strengthening and weakening of connections between neurons in the brain. In this talk, I will describe a number of previous PhD projects in the group that have studied computational functions, and the underlying mechanisms, of synaptic plasticity. I will focus on the functional roles and mechanisms of synaptic plasticity in the cerebellum, a brain structure that is important for the control of movements, motor learning and many higher cognitive functions. Our results suggest that different forms of synaptic plasticity at different  time scales can implement many diverse functions such as associative memory, noise resistance, multiplicative operations and the transformation  between different types of neural code. Moreover, I will discuss the relation between cerebellar synaptic plasticity and movement disorders that are based on cerebellar dysfunction, and I will describe the application of machine learning algorithms to analyse neuronal activity during epileptic seizures.</p>
<p><strong>Date:</strong> 07/10/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>

            <p class="text-muted">in 'UH Biocomputation group' on October 04, 2016 07:21 AM. <a href="http://biocomputation.herts.ac.uk/2016/10/04/computational-models-of-synaptic-plasticity-and-information-processing-in-the-cerebellum.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Opposing effects of neuronal activity on structural plasticity.</h4>

            <p>The connectivity of the brain is continuously adjusted to new environmental
influences by several activity-dependent adaptive processes. The most
investigated adaptive mechanism is activity-dependent functional or synaptic
plasticity regulating the transmission efficacy of existing synapses. Another
important but less prominently discussed adaptive process is structural
plasticity, which changes the connectivity by the formation and deletion of
synapses. In this review, we show, based on experimental evidence, that
structural plasticity can be classified similar to synaptic plasticity into two
categories: (i) Hebbian structural plasticity, which leads to an increase
(decrease) of the number of synapses during phases of high (low) neuronal
activity and (ii) homeostatic structural plasticity, which balances these
changes by removing and adding synapses.  Furthermore, based on experimental
and theoretical insights, we argue that each type of structural plasticity
fulfills a different function. While Hebbian structural changes enhance memory
lifetime, storage capacity, and memory robustness, homeostatic structural
plasticity self-organizes the connectivity of the neural network to assure
stability. However, the link between functional synaptic and structural
plasticity as well as the detailed interactions between Hebbian and homeostatic
structural plasticity are more complex. This implies even richer dynamics
requiring further experimental and theoretical investigations.</p>
<p>The complete paper can be found here: <a class="reference external" href="http://journal.frontiersin.org/article/10.3389/fnana.2016.00075/full">http://journal.frontiersin.org/article/10.3389/fnana.2016.00075/full</a></p>
<p><strong>Date:</strong> 30/09/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location:</strong> LB252</p>

            <p class="text-muted">in 'UH Biocomputation group' on September 28, 2016 08:40 PM. <a href="http://biocomputation.herts.ac.uk/2016/09/28/opposing-effects-of-neuronal-activity-on-structural-plasticity.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Next generation sequencing (NGS).</h4>

            <p>My talk will be a summary of my research so far in investigating the effects of
artefacts which occur during the library preparation stage of Next generation
sequencing.</p>
<p>Next generation sequencing (NGS) of DNA has dramatically transformed approaches
to genomic and genetic research. DNA sequencing refers to a laboratory method
used to determine the sequence of a DNA molecule. Some of the well-known
technologies that are applied in this process include the Roche GS-FLX 454
Genome Sequencer (originally 454 sequencing), the Illumina Genome Analyser
(originally Solexa technology), the ABI SOLiD analyser, Polonator G.007 and the
Helicos HeliScope platforms. These technologies (also referred to as massively
parallel sequencing technologies) have enabled the sequencing of DNA at
unprecedented speeds compared to the "original" sequencing methodology known as
the Sanger method.</p>
<p>Although NGS has revolutionised biology by increasing current understanding of
many genes and genomic regions involved in the pathogenesis of human diseases,
there are challenges associated with the use of these new technologies. For
example, the sequencing of parts of a genome characterized by extremely biased
base composition is still a great challenge to the currently available NGS
platforms. The genomes of certain important pathogenic organisms like
Plasmodium falciparum and Escherichia coli display extremes of base
composition, high AT content and high GC content respectively. The sequencing
"coverage" of these genomes can be affected by artefacts that may be introduced
at various stages of the sequencing process, thus affecting final sequencing
output.</p>
<p>My project studies the effects of artefacts that occur during the initial stage
of the sequencing work flow referred to as library preparation. The purpose of
this research is to identify known artefacts that can occur during the library
preparation stage from existing literature, and to analyse the extent to which
sequencing coverage may be affected by these artefacts. In other words, a study
of problems that can arise from the library preparation stage of the sequencing
work flow and how they affect final sequencing output forms the basis of my
work.</p>
<ul class="simple">
<li><a class="reference external" href="http://www.biomedcentral.com/1471-2164/13/1">Oyola, S.O., Otto, T.D., Gu, Y., Maslen, G., et al. (2012) Optimizing Illumina
next-generation sequencing library preparation for extremely AT-biased genomes.
BMC genomics.</a></li>
<li><a class="reference external" href="http://www.pnas.org/content/74/12/5463.short">Sanger, F., Nicklen, S. &amp; Coulson, A.R. (1977) DNA sequencing with
chain-terminating inhibitors. Proceedings of the National Academy of Sciences
of the United States of America.</a></li>
<li><a class="reference external" href="http://www.sciencedirect.com/science/article/pii/S1673852711000300">Zhang, J., Chiodini, R., Badr, A. &amp; Zhang, G. (2011) The impact of
next-generation sequencing on genomics. Journal of genetics and genomics = Yi
chuan xue bao.</a></li>
</ul>
<p><strong>Date:</strong> 16/09/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>

            <p class="text-muted">in 'UH Biocomputation group' on September 14, 2016 04:01 PM. <a href="http://biocomputation.herts.ac.uk/2016/09/14/next-generation-sequencing-ngs.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Removing noisy features via feature weights: preliminary results in mixed-model Gaussian distributions.</h4>

            <p>In this article, we purpose an unsupervised feature selection algorithm that removes uniform noisy features encapsulated
in the mixed model Gaussian distribution. The method is based on feature weighting principle and assumes that the noisy
features have least feature weight and therefore have less or no contribution to cluster recovery. Experiments show that the proposed feature selection algorithm is more efficient in identifying noisy features compare to other similar algorithms like feature selection based on feature similarity (FSFS) or the intelligent K-Means feature selection(iKFS).</p>
<p><strong>Date:</strong> 09/09/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>

            <p class="text-muted">in 'UH Biocomputation group' on September 08, 2016 10:12 AM. <a href="http://biocomputation.herts.ac.uk/2016/09/08/removing-noisy-features-via-feature-weight-preliminary-results-in-mixed-model-gaussian-distribution.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Using NEURON - Part II.</h4>

            <p><a class="reference external" href="https://senselab.med.yale.edu/ModelDB/ModelList.cshtml?id=1882">ModelDB</a> is a popular resource where the computational neuroscience community puts up models that were used in various publications. Since I'm quite new to <a class="reference external" href="http://www.neuron.yale.edu/neuron/">NEURON</a>, I thought I'd play with some existing models to get a hang of things. Here I document how to run an existing model.</p>
<p><a class="reference external" href="https://senselab.med.yale.edu/ModelDB/ModelList.cshtml?id=1882">ModelDB</a> has quite a few models that use <a class="reference external" href="http://www.neuron.yale.edu/neuron/">NEURON</a>. Find one that suits you. I'll pick <a class="reference external" href="https://senselab.med.yale.edu/ModelDB/ShowModel.cshtml?model=139653">L5b PC model constrained for BAC firing and perisomatic current step firing (Hay et al., 2011)</a> for now.</p>
<div class="section" id="download-the-model">
<h2>Download the model</h2>
<p><a class="reference external" href="https://senselab.med.yale.edu/modeldb/eavBinDown.cshtml?o=139653&amp;a=23&amp;mime=application/zip">Download the zip</a> file from the model page to a convenient location. There's a link right on the top of the page. Extract it.</p>
<pre class="code bash literal-block">$ unzip L5bPCmodelsEH.zip
$ lash
total 668K
4.0K drwxr-xr-x. <span class="m">7</span> asinha asinha 4.0K Mar <span class="m">30</span>  <span class="m">2013</span> L5bPCmodelsEH
664K -rw-r-----. <span class="m">1</span> asinha asinha 662K Sep  <span class="m">2</span> 13:55 L5bPCmodelsEH.zip
</pre>
</div>
<div class="section" id="building-and-running-the-model">
<h2>Building and running the model</h2>
<p>Enter the directory:</p>
<pre class="code bash literal-block"><span class="nb">cd</span> L5bPCmodelsEH/
</pre>
<p><a class="reference external" href="http://www.neuron.yale.edu/neuron/">NEURON</a> code comprises of two sets of code files. You have the HOC files, and the NMODL files. NMODL files need to be compiled before the model can be run.</p>
<pre class="code bash literal-block">$ ~/dump/neuron-installation/x86_64/bin/nrnivmodl mod
Creating x86_64 directory <span class="k">for</span> .o files.

/home/asinha/dump/neuron-blog/L5bPCmodelsEH
mod/CaDynamics_E2.mod mod/Ca_HVA.mod mod/Ca_LVAst.mod mod/epsp.mod mod/Ih.mod mod/Im.mod mod/K_Pst.mod mod/K_Tst.mod mod/Nap_Et2.mod mod/NaTa_t.mod mod/NaTs2_t.mod mod/SK_E2.mod mod/SKv3_1.mod
CaDynamics_E2.mod Ca_HVA.mod Ca_LVAst.mod epsp.mod Ih.mod Im.mod K_Pst.mod K_Tst.mod Nap_Et2.mod NaTa_t.mod NaTs2_t.mod SK_E2.mod SKv3_1.mod
<span class="s2">"/home/asinha/dump/neuron-installation/x86_64/bin/nocmodl"</span> CaDynamics_E2
Translating CaDynamics_E2.mod into CaDynamics_E2.c
Thread Safe
<span class="s2">"/home/asinha/dump/neuron-installation/share/nrn/libtool"</span> --tag<span class="o">=</span>CC --mode<span class="o">=</span>compile mpicc -DHAVE_CONFIG_H  -I. -I.. -I<span class="s2">"/home/asinha/dump/neuron-installation/include/nrn"</span> -I<span class="s2">"/home/asinha/dump/neuron-installation/x86_64/lib"</span>      -O2 -g -pipe -Wall -Werror<span class="o">=</span>format-security -Wp,-D_FORTIFY_SOURCE<span class="o">=</span><span class="m">2</span> -fexceptions -fstack-protector-strong --param<span class="o">=</span>ssp-buffer-size<span class="o">=</span><span class="m">4</span> -grecord-gcc-switches -specs<span class="o">=</span>/usr/lib/rpm/redhat/redhat-hardened-cc1 -m64 -mtune<span class="o">=</span>generic -c -o CaDynamics_E2.lo CaDynamics_E2.c
libtool: compile:  mpicc -DHAVE_CONFIG_H -I. -I.. -I/home/asinha/dump/neuron-installation/include/nrn -I/home/asinha/dump/neuron-installation/x86_64/lib -O2 -g -pipe -Wall -Werror<span class="o">=</span>format-security -Wp,-D_FORTIFY_SOURCE<span class="o">=</span><span class="m">2</span> -fexceptions -fstack-protector-strong --param<span class="o">=</span>ssp-buffer-size<span class="o">=</span><span class="m">4</span> -grecord-gcc-switches -specs<span class="o">=</span>/usr/lib/rpm/redhat/redhat-hardened-cc1 -m64 -mtune<span class="o">=</span>generic -c CaDynamics_E2.c  -fPIC -DPIC -o .libs/CaDynamics_E2.o
CaDynamics_E2.c:94:34: warning: missing braces around initializer <span class="o">[</span>-Wmissing-braces<span class="o">]</span>
  static VoidFunc hoc_intfunc<span class="o">[]</span> <span class="o">=</span> <span class="o">{</span>
  ...
  ....
  ...
  ...
</pre>
<p>You'll see a new <code>x86_64</code> directory which contains the compiled code. Now, simply run <a class="reference external" href="http://www.neuron.yale.edu/neuron/">NEURON</a> as usual. If everything went well, the simulation will run:</p>
<pre class="code bash literal-block">$ ~/dump/neuron-installation/x86_64/bin/nrngui mosinit.hoc
</pre>
<p>Remember that you must run <code>nrngui</code> in the directory where the <code>x86_64</code> directory resides for <a class="reference external" href="http://www.neuron.yale.edu/neuron/">NEURON</a> to find it.</p>
<p>That's it!</p>
</div>

            <p class="text-muted">in 'Ankur Sinha' on September 02, 2016 12:39 PM. <a href="http://ankursinha.in/blog/2016/09/02/using-neuron-part-ii.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Open Positions: Early Career Research Fellowships in systems biology/machine learning for food and disease.</h4>

            <p>Salary: £31,656 - £37,768 per annum depending on skills and experience <br />
Closing Date: 27th Oct 2016 <br />
Full time position working 37 hours per week. <br />
Fixed term contract for a period of five years. <br /></p>
<p>The postdoctoral fellowship will focus on emerging methods in biocomputation to improve food and health or combat plant, animal or human diseases. A first degree in biology, computer science or a relevant subject and a doctoral degree in bioinformatics, machine learning, quantitative biology or related subjects is required. Experience in systems biology, big data science or genomics will be useful. The fellowship is offered for a period of 5 years with the expectation that the fellow will obtain a permanent academic post supported.</p>
<div class="section" id="qualifications-required">
<h2>Qualifications required</h2>
<p>You must have a first degree in a science, such as biology, computer science, mathematics or a relevant subject, and a doctoral degree in areas such as bioinformatics, machine learning, quantitative biology or a related subject area.  Experience in systems biology, big data science or genomics will be useful.</p>
</div>
<div class="section" id="research-focus-and-environment">
<h2>Research focus and environment</h2>
<p>The Fellow is expected to develop her/his own line of research. This should include a focus on emerging methods in biocomputation that generate and exploit large data sets of biological information to better understand mechanisms such as those underlying host resistance/immunity and/or resistance breakdown.  The Fellow will generate an improved understanding of relevant biological systems to develop specific strategies to improve food and health or combat plant, animal or human diseases.  This Fellowship will be supported by existing collaborations between colleagues in Schools of Life &amp; Medical Sciences (Kukol, Stotz, Barling, Fitt) and Computer Science (Steuber).  The Fellow is expected to use the University’s high performance computer cluster.</p>
</div>
<div class="section" id="experience-and-skills-required-for-the-post">
<h2>Experience and skills required for the post</h2>
<ul class="simple">
<li>Ability to develop and apply computational methods to biological problems;</li>
<li>Experience with techniques such as machine learning or mathematical modelling of biological datasets, for example in genomics or proteomics;</li>
<li>Evidence of original research and ability to publish in high impact journals.</li>
</ul>
</div>
<div class="section" id="research-expectations">
<h2>Research expectations</h2>
<p>The Fellow is expected to develop a collaborative research program with our academic partners.  We envisage that the Research Fellow will become a permanent staff member, supported by funding from successful research grant applications and developing new areas of teaching, especially at the post-graduate level. To ensure this, the two Schools will provide career training for the Fellow. The Fellow will have established collaborations with companies and successfully obtained co-funded industry-government projects. The Fellow will publish high-impact papers and be building a research team.</p>
</div>
<div class="section" id="description-of-the-school-s">
<h2>Description of the School(s)</h2>
<p>This Early Career Research Fellow will work with and receive support from the School of Life and Medical Sciences and the School of Computer Science.  The successful candidate can build on the strengths of both Schools and may combine experiment-based empirical research with data-based analysis.</p>
<p>Within the <a class="reference external" href="http://www.herts.ac.uk/apply/schools-of-study/life-and-medical-sciences/research">School of Life and Medical Sciences</a>, the Centre for Agriculture, Food and Environmental Management (CAFEM) is a research and teaching collaboration with the Royal Veterinary College, Rothamsted Research and Oaklands College.  The Fellow will work with researchers in CAFEM who have experience with systems biology applicable to crop protection, combining experimental field and lab research with computational modelling.  Within the School of Computer Science, research in the <a class="reference external" href="http://biocomputation.herts.ac.uk/">Biocomputation Research Group</a> involves development of computational models to study biological systems and application of biologically-inspired machine learning algorithms for the analysis of "real-world" data.  Members of the Biocomputation Group analyse and simulate computational models at different levels of complexity and collaborate closely with leading experimentalists in the UK and abroad.</p>
<hr class="docutils" />
<p>Informal enquiries are encouraged and should be made to: <br />
Professor Bruce Fitt, <br />
Professor of Plant Pathology, <br />
email: <a class="reference external" href="mailto:b.fitt@herts.ac.uk">b.fitt@herts.ac.uk</a>  <br />
Tel + 44 (0)1707 284751</p>
<p>or</p>
<p>Dr. Volker Steuber, <br />
Reader in Biocomputation and Head of the Biocomputation Research Group, <br />
email:  <a class="reference external" href="mailto:v.steuber@herts.ac.uk">v.steuber@herts.ac.uk</a> <br />
Tel: +44 (0)1707 284350.</p>
<p>Applications should be made through <a class="reference external" href="http://www.herts.ac.uk/contact-us/jobs-and-vacancies/research-vacancies">http://www.herts.ac.uk/contact-us/jobs-and-vacancies/research-vacancies</a></p>
</div>

            <p class="text-muted">in 'UH Biocomputation group' on September 02, 2016 09:58 AM. <a href="http://biocomputation.herts.ac.uk/2016/09/02/open-positions-early-career-research-fellowships-in-systems-biology-machine-learning-for-food-and-disease.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Quickly scripting a grid-search for parameter tuning.</h4>

            <p>A lot of models rely on different parameters. In my cortical models, these are usually variables like conductances of different sets of synapses, the sparsity of different synapse sets, learning rates of spike time dependent plasticity learning rules and so on. Given how finely tuned neuronal networks sometimes are, models don't depict the expected behaviours for the entire domain of parameter values. Instead, we often must find the right ranges of these parameters.</p>
<p>In my simulations, I have some sets of synapses, and in my recent investigations, I needed to find the right "balance" between them. The standard way of going about this is to carry out an organised parameter search, what I think is referred to as a "grid search". In a grid search, each point in the parameter space is tested to find the ranges where the required behaviour is simulated - really just simple brute force at play here. Now, since I have three parameters to test, my parameter space would be a three dimensional grid - the Cartesian product of the domains of the three parameters - <code>p1 x p2 x p3</code>. For all possible ordered sets of p1, p2, and p3, I need to run my simulation - the number of possible combinations being <code>n(p1) x n(p2) x n(p3)</code>, where <code>n</code> is the cardinality of each set.</p>
<p>Of course, I wrote myself a script. Modifying the parameters by hand and then queuing up all these simulations manually on the cluster would just take too much time.</p>
<div class="section" id="the-idea">
<h2>The idea</h2>
<p>It's a simple Python script, and this fits well with my <a class="reference external" href="http://ankursinha.in/blog/feeds/categories/20160531-some-tips-and-tricks-for-running-simulations-on-a-cluster.rst">workflow</a> (which intensively uses Git and scripts to queue jobs on the cluster). The idea is:</p>
<ul class="simple">
<li>create a new Git branch for the grid search (so we keep things organised!)</li>
<li>use a simple scripting language to iterate over the parameter space</li>
<li>modify the parameters in the simulation source code</li>
<li>create a new commit for each point in the parameter space</li>
<li>queue up all these commits on the cluster</li>
</ul>
</div>
<div class="section" id="the-script">
<h2>The script</h2>
<p>I've used Python - you can use another scripting language that you prefer. I wouldn't recommend a shell script - even though it's powerful, handling arrays and floats and the sort is quite tedious in bash.</p>
<pre class="code Python literal-block"><span class="ch">#!/usr/bin/env python3</span>
<span class="sd">"""
Copyright 2016 Ankur Sinha
Author: Ankur Sinha &lt;sanjay DOT ankur AT gmail DOT com&gt;

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.
"""</span>

<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">subprocess</span>
<span class="kn">import</span> <span class="nn">datetime</span>


<span class="k">class</span> <span class="nc">GridSearch</span><span class="p">:</span>

    <span class="sd">"""Set up your simulations for a grid search.


    This will modify the source in a branch, make changes, commit
    and then you can set these commits up on the cluster.
    """</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">"""Initialise."""</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">source</span> <span class="o">=</span> <span class="s2">"/path/to/source/file/"</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">branch</span> <span class="o">=</span> <span class="s2">"master"</span>

    <span class="k">def</span> <span class="nf">usage</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">"""Print usage."""</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">"Usage:"</span><span class="p">,</span> <span class="nb">file</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">"python3 grid_search.py &lt;branch&gt;"</span><span class="p">,</span> <span class="nb">file</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">"Branch MUST be specified."</span><span class="p">,</span> <span class="nb">file</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">branch</span><span class="p">,</span> <span class="n">range_dict</span><span class="p">):</span>
        <span class="sd">"""Set it up."""</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">branch</span> <span class="o">=</span> <span class="n">branch</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">range_dict</span><span class="p">[</span><span class="s1">'param1'</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param1_increment</span> <span class="o">=</span> <span class="mf">0.5</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param1_min</span> <span class="o">=</span> <span class="n">range_dict</span><span class="p">[</span><span class="s1">'param1'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param1_max</span> <span class="o">=</span> <span class="n">range_dict</span><span class="p">[</span><span class="s1">'param1'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">param1_increment</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">range_dict</span><span class="p">[</span><span class="s1">'param1'</span><span class="p">])</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param1_increment</span> <span class="o">=</span> <span class="n">range_dict</span><span class="p">[</span><span class="s1">'param1'</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param1_min</span> <span class="o">=</span> <span class="n">range_dict</span><span class="p">[</span><span class="s1">'param1'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param1_max</span> <span class="o">=</span> <span class="n">range_dict</span><span class="p">[</span><span class="s1">'param1'</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">param1_increment</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s2">"param1 not found in dict. Exiting."</span><span class="p">,</span> <span class="nb">file</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">False</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">range_dict</span><span class="p">[</span><span class="s1">'param2'</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param2_increment</span> <span class="o">=</span> <span class="mf">0.5</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param2_min</span> <span class="o">=</span> <span class="n">range_dict</span><span class="p">[</span><span class="s1">'param2'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param2_max</span> <span class="o">=</span> <span class="n">range_dict</span><span class="p">[</span><span class="s1">'param2'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">param2_increment</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">range_dict</span><span class="p">[</span><span class="s1">'param2'</span><span class="p">])</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param2_increment</span> <span class="o">=</span> <span class="n">range_dict</span><span class="p">[</span><span class="s1">'param2'</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param2_min</span> <span class="o">=</span> <span class="n">range_dict</span><span class="p">[</span><span class="s1">'param2'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param2_max</span> <span class="o">=</span> <span class="n">range_dict</span><span class="p">[</span><span class="s1">'param2'</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">param2_increment</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s2">"param2 not found in dict. Exiting."</span><span class="p">,</span> <span class="nb">file</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">False</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">range_dict</span><span class="p">[</span><span class="s1">'param3'</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param3_increment</span> <span class="o">=</span> <span class="mf">0.5</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param3_min</span> <span class="o">=</span> <span class="n">range_dict</span><span class="p">[</span><span class="s1">'param3'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param3_max</span> <span class="o">=</span> <span class="n">range_dict</span><span class="p">[</span><span class="s1">'param3'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">param3_increment</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">range_dict</span><span class="p">[</span><span class="s1">'param3'</span><span class="p">])</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param3_increment</span> <span class="o">=</span> <span class="n">range_dict</span><span class="p">[</span><span class="s1">'param3'</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param3_min</span> <span class="o">=</span> <span class="n">range_dict</span><span class="p">[</span><span class="s1">'param3'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param3_max</span> <span class="o">=</span> <span class="n">range_dict</span><span class="p">[</span><span class="s1">'param3'</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">param3_increment</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s2">"param3 not found in dict. Exiting."</span><span class="p">,</span> <span class="nb">file</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">False</span>

        <span class="k">return</span> <span class="bp">True</span>

    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">"""Run."""</span>
        <span class="c1"># checkout the branch</span>
        <span class="n">git_args</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"checkout"</span><span class="p">,</span> <span class="s2">"-b"</span><span class="p">,</span> <span class="s2">"grid_search-{}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="nb">str</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">date</span><span class="o">.</span><span class="n">today</span><span class="p">())),</span> <span class="bp">self</span><span class="o">.</span><span class="n">branch</span><span class="p">]</span>
        <span class="n">subprocess</span><span class="o">.</span><span class="n">call</span><span class="p">([</span><span class="s1">'git'</span><span class="p">]</span> <span class="o">+</span> <span class="n">git_args</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">param1</span> <span class="ow">in</span> <span class="n">numpy</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param1_min</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">param1_max</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">param1_increment</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">param2</span> <span class="ow">in</span> <span class="n">numpy</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param2_min</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">param2_max</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">param2_increment</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">param3</span> <span class="ow">in</span> <span class="n">numpy</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param3_min</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">param3_max</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">param3_increment</span><span class="p">):</span>

                    <span class="n">sed_args_param1</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'sed'</span><span class="p">,</span> <span class="s1">'-i'</span><span class="p">,</span>
                                <span class="s2">"s/param1 = .*$/param1 = {}/"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">param1</span><span class="p">),</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">source</span><span class="p">]</span>
                    <span class="n">subprocess</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">sed_args_param1</span><span class="p">)</span>

                    <span class="n">sed_args_param2</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'sed'</span><span class="p">,</span> <span class="s1">'-i'</span><span class="p">,</span>
                                <span class="s2">"s/param2 = .*$/param2 = {}/"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">param2</span><span class="p">),</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">source</span><span class="p">]</span>
                    <span class="n">subprocess</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">sed_args_param2</span><span class="p">)</span>

                    <span class="n">sed_args_param3</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'sed'</span><span class="p">,</span> <span class="s1">'-i'</span><span class="p">,</span>
                                <span class="s2">"s/param3 = .*$/param3 = {}/"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">param3</span><span class="p">),</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">source</span><span class="p">]</span>
                    <span class="n">subprocess</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">sed_args_param3</span><span class="p">)</span>

                    <span class="n">git_args</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"add"</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">source</span><span class="p">]</span>
                    <span class="n">subprocess</span><span class="o">.</span><span class="n">call</span><span class="p">([</span><span class="s1">'git'</span><span class="p">]</span> <span class="o">+</span> <span class="n">git_args</span><span class="p">)</span>

                    <span class="n">commit_msg</span> <span class="o">=</span> <span class="s2">"""{} {} {} {}"""</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="nb">str</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">date</span><span class="o">.</span><span class="n">today</span><span class="p">()),</span> <span class="n">param1</span><span class="p">,</span>
                        <span class="n">param2</span><span class="p">,</span> <span class="n">param3</span><span class="p">)</span>

                    <span class="n">git_args</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"commit"</span><span class="p">,</span> <span class="s2">"-m"</span><span class="p">,</span> <span class="n">commit_msg</span><span class="p">]</span>
                    <span class="n">subprocess</span><span class="o">.</span><span class="n">call</span><span class="p">([</span><span class="s1">'git'</span><span class="p">]</span> <span class="o">+</span> <span class="n">git_args</span><span class="p">)</span>

        <span class="n">git_args</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"checkout"</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">branch</span><span class="p">]</span>
        <span class="n">subprocess</span><span class="o">.</span><span class="n">call</span><span class="p">([</span><span class="s1">'git'</span><span class="p">]</span> <span class="o">+</span> <span class="n">git_args</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s2">"__main__"</span><span class="p">:</span>
    <span class="n">search</span> <span class="o">=</span> <span class="n">GridSearch</span><span class="p">()</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">search</span><span class="o">.</span><span class="n">usage</span><span class="p">()</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">branch</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1"># dictionary that holds the required grid ranges</span>
        <span class="c1"># specify min, max if want a grid search, else specify only one value</span>
        <span class="c1"># if you specify max, min, you must specify increment</span>
        <span class="n">setup_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">'param1'</span><span class="p">:</span> <span class="p">[</span><span class="mf">3.</span><span class="p">],</span>
            <span class="s1">'param2'</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>
            <span class="s1">'param3'</span><span class="p">:</span> <span class="p">[</span><span class="o">-</span><span class="mf">5.</span><span class="p">,</span> <span class="o">-</span><span class="mf">30.</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.</span><span class="p">],</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="n">search</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">branch</span><span class="p">,</span> <span class="n">setup_dict</span><span class="p">):</span>
            <span class="n">search</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
</pre>
<p>Since I'm calling <code>sed</code> to modify my source and replace the parameter values, the only requirement here is that my source code needs to have the three lines (look at the regular expressions):</p>
<pre class="code Python literal-block"><span class="n">param1</span> <span class="o">=</span> <span class="o">..</span>
<span class="n">param2</span> <span class="o">=</span> <span class="o">..</span>
<span class="n">param3</span> <span class="o">=</span> <span class="o">..</span>
</pre>
<p>If all goes well, you should have a new branch:</p>
<pre class="code console literal-block"><span class="go">* 74866b6 - (3 months ago) Bugfix - neurons first, synapses later — Ankur Sinha (Ankur Sinha Gmail)
| * fd6a7fa - (5 days ago) 2016-08-22 3.0 3.0 -30.0 — Ankur Sinha (Ankur Sinha Gmail) (origin/grid_search-2016-08-22, grid_search-2016-08-22)
| * 33c95be - (5 days ago) 2016-08-22 3.0 3.0 -25.0 — Ankur Sinha (Ankur Sinha Gmail)
| * 51f96c1 - (5 days ago) 2016-08-22 3.0 3.0 -20.0 — Ankur Sinha (Ankur Sinha Gmail)
| * e8c106e - (5 days ago) 2016-08-22 3.0 3.0 -15.0 — Ankur Sinha (Ankur Sinha Gmail)
| * eaa7341 - (5 days ago) 2016-08-22 3.0 3.0 -10.0 — Ankur Sinha (Ankur Sinha Gmail)
| * 4597114 - (5 days ago) 2016-08-22 3.0 3.0 -5.0 — Ankur Sinha (Ankur Sinha Gmail)
| * a111e00 - (5 days ago) 2016-08-22 3.0 2.5 -30.0 — Ankur Sinha (Ankur Sinha Gmail)
| * 5261f4b - (5 days ago) 2016-08-22 3.0 2.5 -25.0 — Ankur Sinha (Ankur Sinha Gmail)
| * d10a686 - (5 days ago) 2016-08-22 3.0 2.5 -20.0 — Ankur Sinha (Ankur Sinha Gmail)
| * 91bc10e - (5 days ago) 2016-08-22 3.0 2.5 -15.0 — Ankur Sinha (Ankur Sinha Gmail)
| * add5188 - (5 days ago) 2016-08-22 3.0 2.5 -10.0 — Ankur Sinha (Ankur Sinha Gmail)
| * c93c817 - (5 days ago) 2016-08-22 3.0 2.5 -5.0 — Ankur Sinha (Ankur Sinha Gmail)
| * 8e779b9 - (5 days ago) 2016-08-22 3.0 2.0 -30.0 — Ankur Sinha (Ankur Sinha Gmail)
| * 9f67e1c - (5 days ago) 2016-08-22 3.0 2.0 -25.0 — Ankur Sinha (Ankur Sinha Gmail)
.....</span>
</pre>
<p>Now, with the help of some bash hacking I get a list of all the commits I need to queue up in a single line:</p>
<pre class="code bash literal-block"><span class="c1"># list all commits reachable from grid_search.. branch but not from the base_branch
</span>$ git log base_branch..grid_search-2016-08-22  --oneline <span class="p">|</span> cut -f1 -d<span class="s2">" "</span> <span class="p">|</span> tr <span class="s2">"\n"</span> <span class="s2">" "</span>
fd6a7fa 33c95be 51f96c1 .. e8c106e eaa7341
</pre>
<p>Then, I use the bash <code>for</code> construct to queue them all up as before:</p>
<pre class="code bash literal-block">$ <span class="k">for</span> commit in fd6a7fa 33c95be 51f96c1 .. e8c106e eaa7341<span class="p">;</span> <span class="k">do</span> ./start-job.sh <span class="s2">"</span><span class="nv">$commit</span><span class="s2">"</span> 32<span class="p">;</span> sleep 1m<span class="p">;</span> <span class="k">done</span>
</pre>
<p>Note - I used the <code>sleep</code> command to space out each job by a minute. This is because my workflow uses folder names which are timestamps of when the job was queued up, like this: <code>201608121234</code> (YYYYMMDDHHMM). So, I can't have two commits starting at the same minute.</p>
<p>There are many ways of carrying out the same method. This is what I quickly came up with. <a class="reference external" href="http://scikit-learn.org">Scikit</a>, for example has <a class="reference external" href="http://scikit-learn.org/stable/modules/grid_search.html">methods for grid search</a>, but they don't gel well with my simulations.</p>
</div>
<div class="section" id="postprocessing-all-this-data">
<h2>Postprocessing all this data</h2>
<p>I have a bunch of scripts for post processing too - this grid search had 36 simulations, the postprocessing is still trudging along. The bigger question is: is there a good way of visualising all these results? I've had to resort to a spreadsheet - but if you have any suggestions, please do let me know. I really haven't found a nice front-end that would let me log results to a database and visualise them - over time, over parameters and so on - does anyone know one? What do people use to keep track of all their data?</p>
<p>Anyway, it's a long weekend here with Monday being a bank holiday. Enjoy the weekend, everyone!</p>
</div>

            <p class="text-muted">in 'Ankur Sinha' on August 27, 2016 09:10 AM. <a href="http://ankursinha.in/blog/2016/08/27/quickly-scripting-a-grid-search-for-parameter-tuning.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Using NEURON - Part I.</h4>

            <div class="section" id="what-is-neuron">
<h2>What is NEURON</h2>
<p>From the <a class="reference external" href="http://www.neuron.yale.edu/neuron/what_is_neuron">website</a>:</p>
<p><em>NEURON is a simulation environment for modeling individual neurons and networks of neurons. It provides tools for conveniently building, managing, and using models in a way that is numerically sound and computationally efficient. It is particularly well-suited to problems that are closely linked to experimental data, especially those that involve cells with complex anatomical and biophysical properties.</em></p>
</div>
<div class="section" id="installing-neuron-on-fedora-24">
<h2>Installing NEURON on Fedora 24</h2>
<p>The first thing you do is install the simulator. I've been trying to build <a class="reference external" href="https://copr.fedorainfracloud.org/coprs/ankursinha/neuroscience-research/">copr</a> packages but they're not as simple as I'd have liked - the configurations that upstream uses for iv and neuron are outdated and require quite a bit of patching.</p>
<div class="section" id="download-the-sources">
<h3>Download the sources</h3>
<p>First, download the source files:</p>
<pre class="code bash literal-block"><span class="c1"># Make sure we're in the /home/&lt;user&gt; directory
</span><span class="nb">cd</span>
<span class="c1"># Make a new directory - use what you want but be consistent
</span>mkdir -p dump/neuron

<span class="c1"># Another one for the installed files
# You can use /opt or /usr/local or any other directory
# Using a directory in your home folder doesn't require root access
</span>mkdir -p dump/neuron-installation

<span class="c1"># Keep the sources here
</span><span class="nb">cd</span> ~/dump/neuron

<span class="c1"># Install mercurial to checkout the neuron source code
</span>sudo dnf install hg
<span class="c1"># Download the source code
# Can't build from the latest tar somehow.
# http://www.neuron.yale.edu/neuron/download/getdevel
</span>hg clone http://www.neuron.yale.edu/hg/neuron/nrn

<span class="c1"># Check http://www.neuron.yale.edu/neuron/download/getstd for correct links
</span>wget http://www.neuron.yale.edu/ftp/neuron/versions/v7.4/iv-19.tar.gz

<span class="c1"># Untar the source for iv - this seems to work
</span>tar -xvf iv-19.tar.gz
</pre>
</div>
<div class="section" id="prep">
<h3>Prep</h3>
<p>We need to build iv first. On Fedora 24, the default gcc flags include <code>-Wformat-security</code> so a quick patch needs to be applied to iv to get it to build. The patch <a class="reference external" href="https://www.neuron.yale.edu/phpBB/viewtopic.php?f=20&amp;t=3536">has been reported here</a>:</p>
<pre class="code diff literal-block"><span class="gh">diff -ur ../iv-18.orig/src/lib/IV-2_6/matcheditor.cpp ./src/lib/IV-2_6/matcheditor.cpp
</span><span class="gd">--- ../iv-18.orig/src/lib/IV-2_6/matcheditor.cpp   2014-01-08 19:10:44.895487120 +1100
</span><span class="gi">+++ ./src/lib/IV-2_6/matcheditor.cpp   2014-01-08 19:11:05.949315579 +1100
</span><span class="gu">@@ -82,7 +82,7 @@
</span>         strncpy(buf, text-&gt;Text(), length);
         while (length &gt; 0) {
             buf[length] = '\0';
<span class="gd">-            if (sscanf(buf, pattern) == EOF) {
</span><span class="gi">+            if (sscanf(buf, "%s", pattern) == EOF) {
</span>                 break;
             }
             --length;
</pre>
<p>Copy the diff into a file and call it <code>iv-format-security.patch</code>. Place this in the directory where you have the neuron sources (<code>~/dump/neuron</code>).
To apply the patch, enter the uncompressed iv directory:</p>
<pre class="code bash literal-block"><span class="nb">cd</span> iv
patch -p1 &lt; ../iv-format-security.patch
<span class="c1"># On success, it'll say:
# patching file src/lib/IV-2_6/matcheditor.cpp</span>
</pre>
<p>Before we build either iv or neuron, we need to install the build dependencies:</p>
<pre class="code bash literal-block"><span class="c1"># Install dependencies from the standard repositories
</span>sudo dnf install xorg-x11-server-devel chrpath libtiff-devel imake libX11-devel automake autoconf libtool libXext-devel ncurses-devel readline-devel Random123-devel Cython openmpi-devel
</pre>
<p>I've left out Java - I have no intention of using the Java support. Instead of openmpi, you can also use mpich - that's up to you - replace <code>openmpi-devel</code> with <code>mpich-devel</code>.</p>
</div>
<div class="section" id="build">
<h3>Build</h3>
<p>Follow the instructions <a class="reference external" href="http://www.neuron.yale.edu/neuron/download/compile_linux">here</a>.
First we build iv:</p>
<pre class="code bash literal-block"><span class="c1"># we're already in the iv source directory
# ./configure --help for all available options
# I use the default Fedora CFLAGS and CXXFLAGS
# You needn't use these
# rpm -E %optflags will tell you what the default ones on your system are
# echo $CFLAGS
# -O2 -g -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -m64 -mtune=generic
# echo $CXXFLAGS
# -O2 -g -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -m64 -mtune=generic
</span>
<span class="c1"># iv doesn't build with -Wnarrowing which is also default, so we disable it
</span><span class="nb">export</span> <span class="nv">CFLAGS</span><span class="o">=</span><span class="s2">"</span><span class="nv">$CFLAGS</span><span class="s2"> -Wno-narrowing"</span>
<span class="nb">export</span> <span class="nv">CXXFLAGS</span><span class="o">=</span><span class="s2">"</span><span class="nv">$CXXFLAGS</span><span class="s2"> -Wno-narrowing"</span>

<span class="c1"># configure, make, make install
</span>./configure --prefix<span class="o">=</span>/home/asinha/dump/neuron-installation/ --with-x
<span class="c1"># I have 24 processors, check to see how many you do
</span>make -j24
make install
</pre>
<p>Then, we build neuron</p>
<pre class="code bash literal-block"><span class="nb">cd</span> ../nrn
<span class="c1"># configure --help to see all options
# Enable MPI
</span>module load mpi/openmpi-x86_64
<span class="c1"># More change to flags to get the thing to build
</span><span class="nb">export</span> <span class="nv">CFLAGS</span><span class="o">=</span><span class="s2">"</span><span class="nv">$CFLAGS</span><span class="s2"> -Wno-narrowing -std=c99 -D_POSIX_C_SOURCE=200809L"</span>
<span class="nb">export</span> <span class="nv">CXXFLAGS</span><span class="o">=</span><span class="s2">"</span><span class="nv">$CXXFLAGS</span><span class="s2"> -Wno-narrowing -D_POSIX_C_SOURCE=200809L"</span>
./build.sh
./configure --prefix<span class="o">=</span>/home/asinha/dump/neuron-installation/ --with-x --with-paranrn --with-mpi --with-multisend --with-nrniv --with-iv<span class="o">=</span>/home/asinha/dump/neuron-installation
<span class="c1"># I have 24 processors, check to see how many you do
</span>make -j24
make install
</pre>
</div>
<div class="section" id="check">
<h3>Check</h3>
<p>Follow the instructions <a class="reference external" href="http://www.neuron.yale.edu/neuron/download/compile_linux">here</a>.</p>
<pre class="code bash literal-block"><span class="nb">cd</span>
<span class="nb">cd</span> dump/neuron-installation/
find . -name <span class="s2">"neurondemo"</span>
<span class="c1"># You'll get something like: ./x86_64/bin/neurondemo
</span>./86_64/bin/neurondemo
<span class="c1"># Will give out something like:
# NEURON -- VERSION 7.5 (1454:2350fc838a79) 2016-08-01
# Duke, Yale, and the BlueBrain Project -- Copyright 1984-2016
# See http://neuron.yale.edu/neuron/credits
#
# loading membrane mechanisms from /home/asinha/dump/neuron-installation/share/nrn/demo/release/x86_64/.libs/libnrnmech.so
# Additional mechanisms from files
#  cabpump.mod cachan1.mod camchan.mod capump.mod invlfire.mod khhchan.mod mcna.mod nacaex.mod nachan.mod release.mod
# first instance of j
# first instance of itmp
# first instance of using_cvode_
# first instance of movie_frame_dur_
# first instance of realtime
# first instance of running_
# first instance of rtstart
# first instance of stdrun_quiet
# first instance of screen_update_invl
# first instance of tstop
# first instance of steps_per_ms
# first instance of nstep_steprun
# first instance of runStopAt
# first instance of runStopIn
# first instance of global_ra
# first instance of mapped_nrnmainmenu_
# first instance of v_init
# first instance of n_graph_lists
# first instance of i
# first instance of eventslow
# first instance of eventcount
# first instance of cnt
# oc&gt;
#</span>
</pre>
</div>
<div class="section" id="post">
<h3>Post</h3>
<p>Last, we update the PATH and things so that everything works smoothly in the future. The docs suggest an <code>nrnenv</code> file that can be sourced in the <code>.bashrc</code> file. We'll just follow the suggested method.</p>
<pre class="code bash literal-block">cat &gt;&gt; ~/dump/neuron-installation/x86_64/bin/nrnenv <span class="s">&lt;&lt; EOF
export NRNINSTALLATION="\$HOME/dump/neuron-installation"
export NRNCPU="x86_64"
export PATH="\$PATH:\$NRNINSTALLATION/\$NRNCPU/bin"

EOF</span>
</pre>
<p>and modify <code>.bashrc</code> to source it:</p>
<pre class="code bash literal-block"><span class="nb">echo</span> <span class="s2">"source /home/asinha/dump/neuron-installation/x86_64/bin/nrnenv"</span> &gt;&gt; ~/.bashrc
</pre>
<p>Log out and back in, or source the file again: <code>source ~/.bashrc</code>.  All the binaries for neuron should then be available to you:</p>
<pre class="code bash literal-block">$ ls ~/dump/neuron-installation/x86_64/bin/
bbswork.sh   iclass  idraw  memacs        modlunit  mos2nrn2.sh  nocmodl  nrngui  nrniv_makefile  nrnmech_makefile  nrnoc_makefile  nrnpyenv.sh  set_nrnpyenv.sh
hel2mos1.sh  idemo   ivoc   mkthreadsafe  mos2nrn   neurondemo   nrnenv   nrniv   nrnivmodl       nrnoc             nrnocmodl       oc           sortspike

$ which idraw
~/dump/neuron-installation/x86_64/bin/idraw
$ which nrniv
~/dump/neuron-installation/x86_64/bin/nrniv
$ which nrnoc
~/dump/neuron-installation/x86_64/bin/nrnoc
$ which oc
~/dump/neuron-installation/x86_64/bin/oc
</pre>
<p>I think that should be it! I've tested the instructions on my Fedora 24 machine but if you run into issues, drop a comment and I'll look into it.</p>
</div>
</div>

            <p class="text-muted">in 'Ankur Sinha' on August 05, 2016 12:24 PM. <a href="http://ankursinha.in/blog/2016/08/05/using-neuron-part-i.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Tinkering with OpenLayers and JS - Cajal - a hacked up neuroscience research map.</h4>

            <p>I was a bit fed up with the various minute issues my simulations kept throwing at me and decided I needed a distraction to keep me from completely burning out. Research is hard work, and sometimes we hit solid walls where no progress seems possible. I haven't hit one yet, but I was beginning to see that my performance had begun to drop. The simplest answer to this situation is to take a holiday - a change of scenery. Unfortunately, I haven't any plans to take one at the moment. I've never understood the appeal of wandering around crowded cities with throngs of tourists anyway. Instead, I decided to set my simulations aside for a few days and tinker with other things for a bit.</p>
<p>I decided to take up a short "passion project". It needed to be something that would keep me occupied for a few days at the most. I'd tinkered with <a class="reference external" href="http://openlayers.org/">OpenLayers</a> before and I'd been meaning to brush up on my <a class="reference external" href="https://www.javascript.com/">JavaScript</a> recently seeing as how it's become quite a dominant scripting language. So I thought up a simple web application that would use the two to do something useful.</p>
<div class="section" id="cajal">
<h2>Cajal</h2>
<p>To start with, the app needs to have a name. I've come up with some unique ones before (<a class="reference external" href="http://ankursinha.in/blog/tag/zaphod/">Zaphod</a>, <a class="reference external" href="http://ankursinha.in/blog/tag/calliope/">Calliope</a>). This time I decided to pay homage to <a class="reference external" href="https://en.wikipedia.org/wiki/Santiago_Ram%C3%B3n_y_Cajal">Santiago Ramón y Cajal</a> who is considered the father of modern neuroscience. There are multiple applications called Cajal already, but not too many of them seem to be related to neuroscience. Unique enough, then.</p>
<p>Cajal is a simple web page that shows a world map. On this map are markers that denote different neuroscience laboratories. The markers are clickable, so when you click one of these, some information about the laboratory is displayed below the map - the principal investigator, the website address, and the sort. I've only managed to add a few laboratories to it now, but I've hosted a working demo <a class="reference external" href="http://ankursinha.in/cajal-map/">here</a>. The screenshot below shows what it looks like.</p>
<a class="reference external image-reference" href="http://ankursinha.in/blog/images/20160804-cajal.png"><img alt="Screenshot of Cajal web application" class="align-center" src="http://ankursinha.in/blog/images/20160804-cajal.png" style="height: 400.0px;" /></a>
<p>The code is quite simple. The data is stored in a <code>yaml</code> file at <code>data/groups.yaml</code>. The Python script <code>bin/populate_map.py</code> takes this file and generates a <a class="reference external" href="https://www.javascript.com/">JavaScript</a> file with functions to set up the map, overlay the markers, and assign them all <code>singleclick</code> events that display information - <code>js/cajal.js</code>. The main <code>index.html</code> file uses this JavaScript file to show a map and the markers with their associated information.</p>
<p>Maybe there is a better, less hacky, way of going about it, but this works for a quick two day project. In the future, maybe I can use a server side database and so on - it depends on how much it needs to scale. I know my shared hosting account can't handle all that!</p>
<p>The <a class="reference external" href="https://github.com/sanjayankur31/cajal/">source code is available on Github</a>. To add more laboratories, entries need to be added to the <code>data/groups.yaml</code> file - that's all. If you're a neuroscience researcher and want to add to the map, please open pull requests and I can then periodically regenerate the page as required.</p>
</div>

            <p class="text-muted">in 'Ankur Sinha' on August 04, 2016 05:49 PM. <a href="http://ankursinha.in/blog/2016/08/04/tinkering-with-openlayers-and-js-cajal-a-hacked-up-neuroscience-research-map.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Sloping the interview and career development playing fields in your favour.</h4>

            <p>Organisations have to ensure that they recruit the best candidates at every level and develop their staff in paths closely aligned with their corporate styles, missions and objectives.  This not only ensures a positive and integrated work force and organisation, it also allows protection against maverick interviewers and managers promoting or overlooking staff randomly (or worse). To achieve this, most professional organisations have clearly defined processes which guide and regulate interviewers and which formalise staff development.  Understanding these formal processes and methods will give candidates and staff a substantial advantage over those who don't.  My talk will give attendees a comprehensive view of real examples of interview questions and crucially the real assessment criteria that the interviewer is looking to document evidence of suitability against.  In respect of career development my talk will give you a comprehensive example of how career paths in a professional services organisation are defined and the success criteria for progression.  In both cases I will give you the insider's view and my own rules and  tips for success, accumulated over many years in blue chip international corporations.</p>
<p><strong>Date:</strong> 22/07/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>

            <p class="text-muted">in 'UH Biocomputation group' on July 19, 2016 01:30 PM. <a href="http://biocomputation.herts.ac.uk/2016/07/19/sloping-the-interview-and-career-development-playing-fields-in-your-favour.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Automated morphological classification of galaxies using machine learning techniques.</h4>

            <p>The predominant method to analyse the morphology of galaxies is to use human visual inspection. <a class="reference external" href="https://www.galaxyzoo.org/">The Galaxy Zoo project</a> has successfully scaled this process to incorporate crowd sourced inspection and has released detailed classifications of hundreds of thousands of galaxies. However, the next generation of telescopes are now being designed and built. An optical telescope called the <a class="reference external" href="https://www.lsst.org/">Large Synoptic Sky Telescope</a>, for example, is due to come online in 2019 and will image half the sky every few days to catalogue ~40 billion objects. This is beyond the capability of even the significant crowd sourced resources of Galaxy Zoo. Therefore, astronomers are now investigating automated solutions using machine learning. In this talk I outline the key issues that need to be resolved in order to automate galaxy morphological analysis in large surveys. I describe existing automated systems that analyse galaxies, and I describe the results of my work using unsupervised machine learning approaches to characterize galaxies.</p>
<p><strong>Date:</strong> 15/07/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>

            <p class="text-muted">in 'UH Biocomputation group' on July 14, 2016 10:42 AM. <a href="http://biocomputation.herts.ac.uk/2016/07/14/automated-morphological-classification-of-galaxies-using-machine-learning-techniques.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Detecting road surface wetness from audio: a deep learning approach.</h4>

            <p>We introduce a recurrent neural network architecture for automated road surface wetness detection from audio of tire-surface interaction. The robustness of our approach is evaluated on 785,826 bins of audio that span an extensive range of vehicle speeds, noises from the environment, road surface types, and pavement conditions including international roughness index (IRI) values from 25 in/mi to 1400 in/mi. The training and evaluation of the model are performed on different roads to minimize the impact of environmental and other external factors on the accuracy of the classification. We achieve an unweighted average recall (UAR) of 93.2% across all vehicle speeds including 0 mph. The classifier still works at 0 mph because the discriminating signal is present in the sound of other vehicles driving by.</p>
<p>The complete paper can be found here: <a class="reference external" href="http://arxiv.org/abs/1511.07035">http://arxiv.org/abs/1511.07035</a></p>
<p><strong>Date:</strong> 08/07/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>

            <p class="text-muted">in 'UH Biocomputation group' on July 07, 2016 03:26 PM. <a href="http://biocomputation.herts.ac.uk/2016/07/07/detecting-road-surface-wetness-from-audio-a-deep-learning-approach.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Research team from UNESP-Brazil reports its works on Genomics: from basic science to biotechnology.</h4>

            <p><a class="reference external" href="https://scholar.google.co.in/citations?user=zJtKwFsAAAAJ&amp;hl=en&amp;oi=sra">Gui Valente</a> joins us for a special journal club session.</p>
<hr class="docutils" />
<p>This lecture is made possible through an international partnership between <a class="reference external" href="http://researchprofiles.herts.ac.uk/portal/en/persons/bruce-fitt(1cc9437f-0d99-46b2-9266-caac2a320501).html">Prof. Fitt</a> and <a class="reference external" href="http://researchprofiles.herts.ac.uk/portal/en/persons/henrik-stotz(ba09c915-8b5e-47a4-a658-e079174637d4)">Dr. Stotz</a> (University of Hertfordshire) with Dr. Valente (São Paulo State University, UNESP-Brazil) with funding from the Santander Bank. The aim of this meeting it to report what Valente's team has been doing in science to establish future international cooperation between both universities as a result of Santander funding.</p>
<p>Dr. Valente leads the Systems Biology and Genomics Lab. at the São Paulo State University, Brazil (UNESP). Despite being a quite new group (2015), they have worked on several biological topics, including biofuel, health science, plant research and basic sciences (genome organization and evolution). They focus on using bioinformatics as an important "toolbox" for better understanding biological questions. This, the presentation will therefore introduce Valente's research group, showing projects they are working on right now. He will show results on ncRNAs, HIV+HCV/HBV evolution, B chromosome science, genomic entropies, enzyme discoveries in plants and <em>S. cerevisiae</em> ethanol tolerance.</p>
<p><strong>Date:</strong> 24/06/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>

            <p class="text-muted">in 'UH Biocomputation group' on June 22, 2016 09:37 AM. <a href="http://biocomputation.herts.ac.uk/2016/06/22/research-team-from-unesp-brazil-reports-its-works-on-genomics-from-basic-science-to-biotechnology.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Nerd Food: Interesting....</h4>

            Nerd Food: Interesting…<div id="content"><p>Time to flush all those tabs again. Some interesting stuff I bumped into recently-ish. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">Finance, Economics, Politics</h2><div class="outline-text-2" id="text-1"><ul class="org-ul"><li><a href="http://www.strongtowns.org/journal/2016/3/20/dbuidkmm60m63enun84oqs07mktdwq">Understanding Growth, part 1</a>: looks very promising although I've only started parsing it. Also pointed me to - Tomas Sedlacek and the <a href="http://www.amazon.co.uk/Economics-Good-Evil-Economic-Gilgamesh/dp/019932218X">Economics of Good and Evil</a>. Bought the book, but still reading it. Seems very thoughtful. </li><li><a href="http://www.bloomberg.com/features/2016-ev-oil-crisis/">Here’s How Electric Cars Will Cause the Next Oil Crisis</a>: Extremely interesting take on the relationship between electric cars and the oil price. Its along the lines of articles posted in the past, to be fair, but still. Basically, it won't take a huge number of sales of electric cars to start knocking down the oil price. And with Model 3 <a href="http://www.bloomberg.com/news/features/2016-03-22/how-tesla-model-3-can-complete-its-take-over-of-the-u-s-luxury-market">coming out</a>, this all seems quite ominous to the oil producing countries. Here we go again, Angola. </li><li><a href="http://www.zdnet.com/article/red-hat-becomes-first-2b-open-source-company/">Red Hat becomes first $2b open-source company</a>: I may not use their wares any more but RedHat will always be one of my favourite companies. Really happy to see they are growing nicely and hopefully continuing all of their incredible investment on Linux. </li><li><a href="https://stratechery.com/2016/the-amazon-tax/">The Amazon Tax</a>: Really, <b>really</b> good article about Amazon and their strategy. If you read only one, read this. Amazon is amazing - and its dominance is very worrying because they are so good at executing! See also Bezos letter. </li><li><a href="https://stratechery.com/2016/its-a-tesla/">It’s a Tesla</a>: Great article about Tesla. Some of the usual Fanboyism we all know and love, of course, but still a lot of very good points. The core of the article is a interesting comparison between Tesla and Apple. By the by, not at all convinced about that dashboard and the launch ceremony itself was a bit sparse too! But, Model 3 looks great. I'm officially a Stratechery fanboy now. </li><li><a href="http://www.wired.com/2016/04/googles-alphabet-transition-tougher-b-c/">Google’s Alphabet Transition Has Been Tougher Than A-B-C</a>: Great article on the pains of moving to a single monolithic structure to something more distributed. In truth, what would one expect with such a seismic change? And, also, how come it took Google so long to make this shift? After all, programmers are supposedly taught how important separation of concerns is. The other very interesting point is the CED difficulties. These guys were able founders (at least able enough to get bought out by Google) but seem to fail badly at the CEO'ing malarky. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">Startups et al.</h2><div class="outline-text-2" id="text-2"><ul class="org-ul"><li><a href="https://stratechery.com/2015/venture-capital-and-the-internets-impact/">Venture capital and the internet’s impact</a>: From the same guys as the Amazon post, this is also a very interesting take on VCs and the internet. Highly recommended. </li><li><a href="http://news.efinancialcareers.com/uk-en/240115/believe-not-want-quit-banking-job-tech-unicorn/">Believe me, you do not want to quit your banking job for a tech unicorn</a>: Stories from the trenches on how Unicorns are not always rosy. Of course, given it comes from "eFinacialCareers", one must assume they are talking their book. Cautionary tale, nonetheless. </li><li><a href="http://obscurehandhelds.com/2016/02/sir-clive-sinclair-revives-the-zx-spectrum/">Sir Clive Sinclair Revives the ZX Spectrum</a>: so the Spectrum is back! I know I shouldn't - there isn't a single logical reason to back it up - but I just feel like I need to get me one of these… </li></ul></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">General Coding</h2><div class="outline-text-2" id="text-3"><ul class="org-ul"><li><a href="http://www.theregister.co.uk/2016/03/24/water_utility_hacked/">Water treatment plant hacked, chemical mix changed for tap supplies</a>: this is a tad worrying. Can you imagine the amount of systems out there with vulnerabilities, etc - many of which are connected to the internet. </li><li><a href="http://www.metzdowd.com/pipermail/cryptography/2016-March/028824.html">On the Impending Crypto Monoculture</a>: Talking about security, very worrying news from the crypto front. It seems our foundations are much less solid than expected - and after all the OpenSSL bugs, this is a surprising statement indeed. Very interesting email on the subject. The LWN article is a must read too. </li><li><a href="http://lumiverse.io/video/part-1-data-and-architecture">Neural Networks Demystified - Part 1: Data and Architecture</a>: just started browsing this in my spare time, but it looks very promising. For the layperson. </li><li><a href="http://www.telegraph.co.uk/technology/2016/03/24/microsofts-teen-girl-ai-turns-into-a-hitler-loving-sex-robot-wit/">Microsoft deletes 'teen girl' AI after it became a Hitler-loving sex robot within 24 hours</a>: friggin' hilarious in a <i>funny-not-funny</i>sort of way. This tweet said it best: "Tay" went from "humans are super cool" to full nazi in &lt;24 hrs and I'm not at all concerned about the future of AI. – Gerry </li><li><a href="http://www.beepsend.com/2016/04/05/abandoning-gitflow-github-favour-gerrit/">Abandoning Gitflow and GitHub in favour of Gerrit</a>: I've always wanted to know more about Gerrit but never seem to find the time. The article explains it to my required extent, contrasting it with the model I'm more familiar with - GitHub, forks and pull requests. I must say, still not convinced about Gerrit, but having said that, it seems there is definitely scope for some kind of hybrid between the two. A lot of the issues they mention in the article are definitely pain points for GitHub users. </li><li><a href="http://githubengineering.com/introducing-dgit/">Introducing DGit</a>: OK this one is a puzzling post, from our friends at GitHub engineering. I'm not sure I get it at all, but seems amazing. Basically, they talk about all the hard work they've made to make git distributed. Fine, I'm jesting - but not totally. The part that leaves no doubts is that GitHub as a whole is a lot more reliable after this work and can handle a lot more traffic - <b>without</b>increasing its hardware requirements. Amazing stuff. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-4"><h2 id="sec-4">Databases</h2><div class="outline-text-2" id="text-4"><ul class="org-ul"><li><a href="https://www.citusdata.com/blog/17-ozgun-erdogan/403-citus-unforks-postgresql-goes-open-source">Citus Unforks From PostgreSQL, Goes Open Source</a>: Great news everyone! Sharding in Postgres just became easier with the open sourcing of Citus! Also worth watching / reading: <a href="https://www.citusdata.com/blog/15-marco-slot/402-interactive-analytics-github-data-using-postgresql-citus">Interactive Analytics on GitHub Data using PostgreSQL with Citus</a>. This explains in a very understandable way how you will use Citus to shard. </li><li><a href="http://blog.2ndquadrant.com/parallel-aggregate/">Parallel Aggregate – Getting the most out of your CPUs</a>: The elephant just keeps getting better and better. Improved scaling on multi-CPU for a few scenarios is coming on 9.6. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-5"><h2 id="sec-5">C++</h2><div class="outline-text-2" id="text-5"><ul class="org-ul"><li><a href="https://randomascii.wordpress.com/2016/03/24/compiler-bugs-found-when-porting-chromium-to-vc-2015/">Compiler Bugs Found When Porting Chromium to VC++ 2015</a>: great tales form the frontline. Also good to hear that MS is really responsive to bug reports. Can't wait to be able to build my C++ 14 code on Windows… </li><li><a href="https://github.com/haptork/easylambda">EasyLambda</a>: C++ 14 library for data processing. Based on MPI though. Still, seems like an interesting find. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-6"><h2 id="sec-6">Layperson Science</h2><div class="outline-text-2" id="text-6"><ul class="org-ul"><li><a href="http://www.fastcompany.com/3042443/mendeley-elsevier-and-the-future-of-scholarly-publishing">The Open Publishing Revolution, Now Behind A Billion-Dollar Paywall</a>: this is very sad news. How science has regressed yet again, now that Mendeley has been bought out. This saga gets worse and worse. On the slightly more positive side: <a href="http://techcrunch.com/2014/03/03/from-crowdfunding-to-open-access-startups-are-experimenting-with-academic-research/">From Crowdfunding To Open Access, Startups Are Experimenting With Academic Research</a>. But will they succeed? </li><li><a href="https://www.edge.org/conversation/stephen_wolfram-ai-the-future-of-civilization">AI &amp; The Future Of Civilization</a>: Very interesting chat with Wolfram. Absurdly long but worth a read. </li><li><a href="https://www.quora.com/What-is-the-best-way-to-explain-the-concept-of-manifold-to-a-novice">What is the best way to explain the concept of manifold to a novice?</a>: Bumped into this in Quora. If only we had more of these. We need an entire book of "mathematics for lay people". </li><li><a href="http://kernelmag.dailydot.com/issue-sections/staff-editorials/16335/neuroskeptic-neurohype-brain-training-apps/?utm_content=buffer874e9&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer">Why we’re living in an era of neuroscience hype</a>: One that everyone interested on the field should read. Interesting take on the wave of progress on the neuroscience front. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-7"><h2 id="sec-7">Other</h2><div class="outline-text-2" id="text-7"><ul class="org-ul"><li><a href="https://medium.com/@thatdavidhopkins/how-a-tv-sitcom-triggered-the-downfall-of-western-civilization-336e8ccf7dd0#.gjnifjo0k">How a TV Sitcom Triggered the Downfall of Western Civilization</a>: OK, I got to say that with a click bait title as bad as this, I almost immediately ignored this article. Somehow I went back to it. Its very long and a bit crazy but its actually very interesting. Friends (the sitcom) as the signal of the end. </li></ul></div></div></div><div class="status" id="postamble"><p class="date">Created: 2016-06-17 Fri 10:56</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>

            <p class="text-muted">in 'Marco Craveiro' on June 17, 2016 09:58 AM. <a href="http://mcraveiro.blogspot.com/2016/06/nerd-food-interesting.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Nerd Food: The Strange Case of the Undefined References.</h4>

            Nerd Food: The Strange Case of the Undefined References<div id="content"><p>As a kid, I loved reading Sherlock Holmes and Poirot novels. Each book got me completely spellbound, totally immersed and pretty much unable to do anything else until I finally found out <i>whodunnit</i>. Somehow, the culprits were never the characters I suspected of. Debugging and troubleshooting difficult software engineering problems is a lot like the plot of a crime novel: in both cases you are trying to form a mental picture of something that happened, with very incomplete information - the <i>clues</i>; in both cases, experience and attention to detail is crucial, with many a wrong path taken before the final eureka moment; and, in both cases too, there is this overwhelming sense of urgency in figuring out <i>whodunnit</i>. Of course, unlike a crime novel, we'd all prefer not having to deal with these kinds of "interesting" issues, but you don't choose the problems - they choose you. </p> <p>I recently had to deal with one such problem, which annoyed me to no end until I finally fixed it. It was so annoying I decided it was worth blogging about - if nothing else, it may save other people from the same level of pain and misery. </p> <p>A bit of context for those that are new here. <a href="https://github.com/DomainDrivenConsulting/dogen">Dogen</a> is a pet project that I've been maintaining for a few years now. Like many other C++ projects, it relies on the foundational <a href="http://www.boost.org/">Boost libraries</a>. To be fair, we rely on other stuff as well - libraries such as <a href="http://xmlsoft.org/">LibXML2</a> and so on - but Boost is our core C++ dependency and the only one where latest is greatest, so it tends to cause us the most problems. I've covered my past woes in terms of <a href="https://mcraveiro.blogspot.co.uk/2015/12/nerd-food-dogen-package-management-saga.html">dependency management</a> and how happy I was to find <a href="https://www.conan.io/">Conan</a>. And so it was that life was bliss for a number of builds, until one day… </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">It All Started With a Warning</h2><div class="outline-text-2" id="text-1"><p>It was a rainy day and I must have been bored because I noticed a rather innocuous-looking warning on my Travis build, related to Conan: </p> <pre class="example"><br />CMake Warning (dev) in build/output/conanbuildinfo.cmake:<br />  Syntax Warning in cmake code at<br />    /home/travis/build/DomainDrivenConsulting/dogen/build/output/conanbuildinfo.cmake:142:88<br />  Argument not separated from preceding token by whitespace.<br />Call Stack (most recent call first):<br />  CMakeLists.txt:30 (include)<br />This warning is for project developers.  Use -Wno-dev to suppress it.<br /></pre> <p>Little did I know that this simple discovery would lead to a sequence of troublesome events and to many a broken build. I decided to <a href="https://github.com/conan-io/conan/issues/138">report</a>the problem to the Conan developers who, with their usual promptness, rolled up their sleeves, quickly bounced ideas back and forth and then did a sterling job in spinning fixes until we got to the bottom of the issue. Some of the fixes were to Conan itself, whereas some others were related to rebuilding <a href="https://www.conan.io/source/Boost/1.60.0/lasote/testing">Boost</a>. In the heat of the investigation, I bumped into some very troubling - and apparently unrelated - linking errors: </p> <pre class="example"><br />/home/travis/.conan/data/Boost/1.60.0/lasote/stable/package/ebdc9c0c0164b54c29125127c75297f6607946c5/lib/libboost_log.so: undefined reference to `std::invalid_argument::invalid_argument(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;)@GLIBCXX_3.4.21'<br />/home/travis/.conan/data/Boost/1.60.0/lasote/stable/package/ebdc9c0c0164b54c29125127c75297f6607946c5/lib/libboost_log.so: undefined reference to `std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;::find(char const*, unsigned long, unsigned long) const@GLIBCXX_3.4.21'<br /></pre> <p>The build was littered with errors such as these. But the most puzzling thing was that I had changed nothing of consequence on my side and the Conan guys changed very little at their end too! What on earth was going on? </p> <p>After quite a lot of thinking, Conan's <i><a href="https://github.com/memsharded">memsharded</a></i> came up a startling conclusion: we've been hit by one of those rare-but-dreadful ABI-transitions! His comment is worth <a href="https://github.com/conan-io/conan/issues/138#issuecomment-185163060">reading in full</a>, but the crux of his findings is as follows (copied <i>verbatim</i>): </p> <blockquote><ul class="org-ul"><li>Boost packages, generated with travis use docker to manage different versions of gcc, as gcc 5.2 or gcc 5.3 </li><li>Those docker images are using modern linux distros, e.g. &gt; Ubuntu 15.10 </li><li>By default, new modern linux distros have switched to the gcc &gt; 5.1 new C++11 ABI, that is libstdc++ is built with gcc &gt; 5.1, usually named libcxx11, as well as the rest of the system. The libcxx11 ABI is incompatible with the old gcc &lt; 5.1 libcxx98 ABI. </li><li>Building in such environment links with the new libcxx11 by default. </li><li>Now, we move to our user, package consumer environment, which could be an Ubuntu 14.04, or a travis VM (12.04). Those distros use a libcxx98 libstdc++, as a lot of programs of those distros depends on the old libcxx98 ABI. It is not simple to replace it for the new one, requiring to rebuild or reinstall large part of the system and applications. Maybe it could be installed for dev only, and specified in the build, but I have not been able yet. </li></ul></blockquote> <p>Reading the above may have given you that sad, sinking feeling: "what on earth is he on about, I just want to compile my code!", "Why oh why is C++ so damn complicated!" and so forth. So, for the benefit of those not in the know, let me try to provide the required background to fully grok <i>memsharded</i>'s comment. </p></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">What's this ABI Malarkey Again?</h2><div class="outline-text-2" id="text-2"><p>This topic may sound oddly familiar to the faithful reader of Nerd Food and with good reason: we did cover ABIs in the distant past, at a slightly lower level. The post in question was <a href="https://mcraveiro.blogspot.co.uk/2012/05/nerd-food-mingw-cygwin-and-wine-up-home.html">On MinGW, Cygwin and Wine</a> and it does provide some useful context to this discussion, but, if you want a TL;DR, it basically dealt with kernel space and user space and with things such as the C library. This time round we will turn our attention to the C++ Standard Library. </p> <p>In addition to specifying the C++ language, the <a href="https://en.wikipedia.org/wiki/C%252B%252B#Standardization">C++ Standard</a> also defines the <a href="http://en.wikipedia.org/wiki/Application_programming_interface">API</a> of the C++ Standard Library - the classes and their methods, the functions and so on. The C++ Standard Library is responsible for providing a set of services for applications compiled with a C++ compiler. So far, so similar to the C Standard Library. Where things begin to differ is in the crucial matter of the <a href="http://en.wikipedia.org/wiki/Application_binary_interface">ABI</a>. But first, lets get a working definition for ABI, just so we are all on the same page. For this, we can do worse than using <a href="https://www.amazon.co.uk/Linux-System-Programming-Talking-Directly/dp/1449339530">Linux System Programming</a>: </p> <blockquote><p>Whereas an API defines a source interface, an ABI defines the low-level binary interface between two or more pieces of software on a particular architecture. It defines how an application interacts with itself, how an application interacts with the kernel, and how an application interacts with libraries. An ABI ensures binary compatibility, guaranteeing that a piece of object code will function on any system with the same ABI, without requiring recompilation. </p> <p>ABIs are concerned with issues such as calling conventions, byte ordering, register use, system call invocation, linking, library behavior, and the binary object format. The calling convention, for example, defines how functions are invoked, how arguments are passed to functions, which registers are preserved and which are mangled, and how the caller retrieves the return value. </p></blockquote> <p>The second paragraph is especially crucial. You see, although both the C and the C++ Standards are somewhat silent on the matter of specifying an ABI, C tends to have a <i>de facto</i> standard for <i>a given OS on a given architecture</i>. This may not sound like much and you may be saying: "what, wait: the same OS on a different architecture has a different ABI?" Yep, that is indeed the case. If you think about it, it makes perfect sense; after all, C was carefully designed to be equivalent to "portable assembler"; in order to achieve maximum performance, one must not create artificial layers of indirection on top of the hardware but instead expose it as is. So, by the same token, two different C compilers working on the same architecture and OS will tend to agree on the ABI. The reason why is because the OS will also follow the hardware where it must, for performance reasons; and where the OS can make choices, it more or less makes the choice for everybody else. For example, until recently, if you were on Windows, it did you no good to compile code into an <a href="https://en.wikipedia.org/wiki/Executable_and_Linkable_Format">ELF</a> binary because the law of the land was <a href="https://en.wikipedia.org/wiki/Portable_Executable">PE</a>. Things have now <a href="https://blogs.msdn.microsoft.com/wsl/2016/04/22/windows-subsystem-for-linux-overview/">changed dramatically</a>, but the general point remains: the OS and the hardware rule. </p> <p>C++ inherits much of C's approach to efficiency, so at first blush you may be fooled into thinking it too would have a <i>de facto</i> ABI standard ("for a given OS, " etc. etc.). However, there are a few crucial differences that have grave consequences. Let me point out a few: </p> <ul class="org-ul"><li>C++'s support for genericity - such as function overloading, templates, etc - is implemented by using <a href="https://en.wikipedia.org/wiki/Name_mangling">name mangling</a>; however, each compiler tends to have their own mangling scheme. </li><li>implementation details such as the memory layout of objects in the C++ Standard Library - in particular, as we shall see, <code>std::string</code> - are important. </li></ul> <p>In the past, compiler vendors tended exacerbate differences such as these; as it was with the <a href="https://en.wikipedia.org/wiki/Unix_wars">UNIX wars</a>, so too during the "C++ wars" did it make sense to be as incompatible as possible in the never ending hunt for monetisation. Thus, ABI specifications were kept internal and were closely guarded secrets. But since then the world has changed. To a large extent, C++ lost the huge amounts of funding it once had during the nineties and part of the naughties, and many vendors either went under or greatly reduced their efforts in this space. Two compilers emerged as victors: <a href="https://en.wikipedia.org/wiki/Visual_C%252B%252B">MSVC</a> on the Windows platform and - once the dust of the <a href="http://www.h-online.com/open/features/GCC-We-make-free-software-affordable-1066831.html%253Fpage=3">EGCS fork</a> finally settled - GCC everywhere else. The excellent quality of GCC across a vast array of platforms and its strict standards adherence - coupled with a quick response to the standardisation efforts - resulted in total domination outside of Windows. So much so that only recently did it meet a true challenger in <a href="https://en.wikipedia.org/wiki/Clang">Clang</a>. The brave new world in which we now find ourselves in is one where C++ ABI standardisation is a real possibility - see <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4028.pdf">Defining a Portable C++ ABI</a>. </p> <p>But pray forgive the old hand, I digress again. The main point is that, for a given OS on a given architecture, you normally had to compile all your code with a single compiler; if you did that, you were good to go. Granted, GCC never made any official promises to keep its releases ABI-compatible, but in practice we came to rely on the fact that new and old releases interoperated just fine since the days of 3.x. And so did Clang, respecting GCC's ABI so carefully it made us think of them as one happy family. Then, C++-11 arrived. </p></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">Mixing and Matching</h2><div class="outline-text-2" id="text-3"><p>As described in <a href="http://developers.redhat.com/blog/2015/02/05/gcc5-and-the-c11-abi/">GCC5 and the C++11 ABI</a>, this pleasant state of affairs was too idyllic to last forever: </p> <blockquote><p>[…] [S]ome new complexity requirements in the C++11 standard require ABI changes to several standard library classes to satisfy, most notably to <code>std::basic_string</code> and <code>std::list</code>. And since <code>std::basic_string</code> is used widely, much of the standard library is affected. </p></blockquote> <p>On hindsight, the improvements in the <code>std::string</code> implementation are great; as a grasshopper, I recall spending hours on end debugging my code in the long forgotten days of EGGS 2.91, only to find out there was a weird bug in the <a href="https://en.wikipedia.org/wiki/Copy-on-write">COW</a> implementation for my architecture. That was the first time - and as it happens, the last time too - I found a library bug, and it made a strong impression on me, at that young age. These people were not infallible. </p> <p>These days I sit much higher up in the C++ stack. Like many, I didn't read that carefully the GCC 5 release notes when it came out, relying as usual on my distro to do the right thing. And, as usual, the distros largely did, even though, unbeknown to many, a stir was happening in their world <sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.1" id="fnr.1" name="fnr.1">1</a></sup>. But hey, who reads distro blogs, right?  Hidden comfortably under my Debian Testing lean-to, I was blissfully unaware of this transition since my code continued to compile just fine. Also, where things start to get hairy is when you need to mix and match compiler versions and build settings - and who on their right mind does that, right? </p> <p>As it happens, this is a situation in which modern C++ users of Travis may easily find themselves in, stuck as they are on either on Ubuntu 12.04 (2012) or Ubuntu 14.04 (2014). Nick Sarten's <a href="http://genbattle.bitbucket.org/blog/2016/01/17/c++-travis-ci/">blog post</a> rams the point home in inimitable fashion: </p> <blockquote><p>Hold on, did I say GCC 4.6? Clang 3.4? WHAT YEAR IS IT? </p></blockquote> <p>Yes, what year is it indeed. So it is that most of us rely on PPA's to bring the C++ environment on Travis up to date, such as the Ubuntu Toolchain: </p> <pre class="example"><br />sudo add-apt-repository -y ppa:ubuntu-toolchain-r/test<br /></pre> <p>This always seemed like an innocent thing to do but after my linking errors and <i>memsharded</i> discoveries, one suddenly started to question everything: what settings did the PPA use to build? What settings were used to build the Boost Conan packages? With what compiler? In what distro? The nightmare was endless. It was clear this was going to lead to tears before bedtime. </p></div></div> <div class="outline-2" id="outline-container-sec-4"><h2 id="sec-4">The Long Road to a Solution</h2><div class="outline-text-2" id="text-4"><p>Whilst <i>memsharded</i> honed into the problem pretty quickly - less than a couple of weeks - a complete solution to my woes was a lot more elusive. In truth, this is the kind of situation where you need long spells of concentrated effort, so working in your copious spare time does not help at all. I first tried the easiest approach: to pray that it would all go away by itself, given enough time. And, lo and behold, things did work again, for a little while! And then started to fail again; the Boost package in Conan got rebuilt and the build broke. And that way it stayed. </p> <p>Once waiting was no longer an option, I had to take it seriously and started investigating in earnest. Trouble is, when you lose trust in the compilation settings you then need to methodically validate absolutely <i>everything</i>, until you bottom out the problem. And that takes time. Many things were tried, including: </p> <ul class="org-ul"><li>rebuilding Boost locally, attempting to reproduce the issue - to no avail. </li><li>rebuilding the Conan Boost packages with the old ABI; a fail (<a href="https://github.com/lasote/conan-boost/issues/12">#12</a>). </li><li>reading up a variety of articles on the subject, most of them linked in this post. </li><li>building the Boost packages locally and exporting them into Travis using DropBox's public folders. Another fail, but DropBox was a win. </li><li>obtaining the exact same Ubuntu 14.04 image as Travis is using, use the compiler from the PPA and export Boost to Travis using DropBox and replicating the problem locally in a VM. This worked. </li></ul> <p>Predictably, the final step is the one I should have tried first, but one is always lazy. Still, all of this got me wondering why had things been so complicated. Normally one would be able to <code>ldd</code> or <code>nm -C</code>the binary and figure out the dependencies, but in this case I seemed to always be pointing to <code>libstdc++.so.6</code> regardless. Most puzzling. And then I found the Debian wiki page on <a href="https://wiki.debian.org/GCC5">GCC5</a>, which states: </p> <blockquote><p>The good news is, that GCC 5 now provides a stable libcxx11 ABI, and stable support for C++11 (GCC version before 5 called this supported experimental). This required some changes in the libstdc++ ABI, and now libstdc++6 provides a dual ABI, the classic libcxx98 ABI, and the new libcxx11 (GCC 5 (&lt;&lt; 5.1.1-20) only provides the classic libcxx98 ABI). The bad news is that the (experimental) C++11 support in the classic libcxx98 ABI and the new stable libcxx11 ABIs are not compatible, and upstream doesn't provide an upgrade path except for rebuilding. Note that even in the past there were incompatibilities between g++ versions, but not as fundamental ones as found in the g++-5 update to stable C++11 support. </p> <p>Using different libstdc++ ABIs in the same object or in the same library is allowed, as long as you don't try to pass std::list to something expecting <code>std::__cxx11::list</code> or vice versa. We should rebuild everything with g++-5 (once it is the default). Using g++-4.9 as a fallback won't be possible in many cases. </p> <p>libstdc++ (&gt;= 5.1.1-20) doesn't change the soname, provides a dual ABI. Existing C++98 binary packages will continue to work. Building these packages using g++-5 is expected to work after build failures are fixed. </p></blockquote> <p>The crux is, of course, all the stuff about a <i>dual ABI</i>. I had never bumped into the <i>dual ABI</i> beast before, and now that I did I'm not sure I am entirely pleased. It's probably great when it just works, but it's tricky to troubleshoot when it doesn't: are you linking against a <code>libstdc++</code> with dual ABI disabled/unsupported? Or is it some other error you've introduced? Personally, having a completely different SO name like <i>memsharded</i> had suggested seems like a less surprising approach - e.g. call it <code>libcxx11</code> instead of <code>libstdc++</code>. But, as always, one has to play with the cards that were dealt so there is no point in complaining. </p></div></div> <div class="outline-2" id="outline-container-sec-5"><h2 id="sec-5">Conclusion</h2><div class="outline-text-2" id="text-5"><p>The Ubuntu 14.04 build of Boost did get us a <a href="https://travis-ci.org/DomainDrivenConsulting/dogen/builds/137848143">green build again</a>, but for all the joyous celebrations, there is still a grey cloud hovering above since the mop-up exercise is not completed. I now need to figure out how to build Boost with Conan on 14.04 and upload this version into the package manager's repo. However, for now <i>carpe diem</i>. After so much unproductive time, there is a real need for a few weeks (months!)  of proper coding - the reason why I have a spare time project in the first place. But some lessons were learned. </p> <p>Firstly, one cannot but feel truly annoyed at <code>${COSMIC_DEITY}</code> for having to deal with issues such as this. After all, one of the reasons I prefer C++ to the languages I use at work (C# and Java) is that it is usually very transparent; normally I can very quickly reproduce, diagnose and fix a problem in my code. Of course, lord knows this statement is not true of <i>all</i> C++ code, but at least it tends to be valid for most Modern C++ - and over the last five years that's all the C++ I dealt with in anger. It was indeed rather irritating to find out that the pain has not yet been removed from the language, and on occasion, even experienced developers get bitten. Hard. </p> <p>A second point worth of note is that in C++ - more so than in any other language - one cannot just blindly trust the package manager. There are just so many configuration knobs and buttons for that to be possible, and one can easily get bitten by assumptions. The sad truth is that even when using Conan, one should probably upload one's own packages built with a well understood configuration. True, this may cost time - but on the other hand, it will avoid wild goose chases such as this one. </p> <p>Finally, its also important to note that this whole episode illustrates the sterling job that package maintainers do in distributions. Paradoxically, their work is often so good that we tend to be blissfully unaware of its importance. Articles such as <a href="http://kmkeen.com/maintainers-matter/">Maintainers Matter</a> take a heightened sense of urgency after an experience like this. </p> <p>The road was narrow, long and troublesome. But, as with all Poirot novels, there is always that satisfying feeling of finally finding out <i>whodunnit</i> in the end. </p></div></div> <div class="outline-2" id="outline-container-sec-6"><h2 id="sec-6">Post Script</h2><div class="outline-text-2" id="text-6"><p>There is one final twist to this story, which adds insult to injury and further illustrates <code>${COSMIC_DEITY}</code>'s sense of humour. When I finally attempted to restore our <a href="https://travis-ci.org/DomainDrivenConsulting/dogen/jobs/137859606">clang builds</a>, I found out that LLVM has <a href="http://lists.llvm.org/pipermail/llvm-dev/2016-June/100400.html">disabled their APT repo</a> for an unspecified length of time: </p> <blockquote><p>&gt; TL;DR: APT repo switched off due to excessive load / traffic </p></blockquote> <p>There are no alternatives at present to build with a recent clang. Sometimes one has the feeling that the universe does not want to play ball. Stiff upper lip and all that; mustn't grumble. </p></div></div><div id="footnotes"><h2 class="footnotes">Footnotes: </h2><div id="text-footnotes"> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.1" id="fn.1" name="fn.1">1</a></sup> <p class="footpara">For example, see <a href="http://allanmcrae.com/2015/06/the-case-of-gcc-5-1-and-the-two-c-abis/">The Case of GCC-5.1 and the Two C++ ABIs</a> to understand Arch's pains. </p></div>  </div></div></div><div class="status" id="postamble"><p class="date">Created: 2016-06-16 Thu 14:12</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>

            <p class="text-muted">in 'Marco Craveiro' on June 17, 2016 09:49 AM. <a href="http://mcraveiro.blogspot.com/2016/06/nerd-food-strange-case-of-undefined.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>From morphology to network-level activity patterns: dendritic arrangement and clustering among inferior olive neurons.</h4>

            <p><a class="reference external" href="https://scholar.google.co.in/citations?hl=en&amp;user=Nadz-doAAAAJ&amp;view_op=list_works&amp;sortby=pubdate">Marylka Uusisaari</a> from the Erasmus Medical Centre, Rotterdam joins us for a special journal club session.</p>
<hr class="docutils" />
<p>Anatomical understanding of the neuronal circuitry, comparable to electronic chip blueprint underlies theories and models of computational capabilities of various brain structures. The fundamental and essential nature of this knowledge is recently gaining visibility in the form of large-scale connectomic mapping initiatives. Their work aims (among others) to define the communication pathways between neurons, most commonly delineated in terms of axonal termination spaces and their overlaps with the target neurons’ dendritic fields.</p>
<p>The axo-dendritic or axo-somatic chemical synaptic connection is not, however, the only mechanism for fast interneuronal communication, as gap junctions linking neighbouring neurons provide the means for electrical signal propagation and synchronisation of spiking activity. A prime example of a structure where this mechanism plays a key role in shaping network activity is the inferior olive (IO), a nucleus in the brainstem integrating multimodal sensorimotor input and providing the climbing fibre input to the cerebellum. Intriguingly, there seem to be no local chemical synapses within the IO; instead, the coherence of inter-olivary network relies entirely on gap junctional communication. Thus, it is of key interest to define the anatomical arrangement of IO cells in respect to each other, as the amount of electrical coupling between individual IO cells - defining the emerging spatio-temporal patterns of olivo-cerebellar activity - must depend on the extent of dendritic overlap.</p>
<p>It is generally assumed that the IO cells are spherical neurons interspersed homogeneously throughout the nucleus, with the strength of electrical coupling decreasing with increasing inter-somata distance. However, this assumption has not been rigorously examined until now; and indeed, early anatomical works (Sotelo et al., 1974) described the olive as formed of segregated clusters of olivary cells.</p>
<p>To gain insight into the possible inhomogeneity and anisotropy present on anatomical level in the IO, we employed a novel “sparse viral labelling” technique that preserves the flexibility of genetically targetable staining but results in a sparse, Golgi-stain-like labelling of neurons. This method allows detailed reconstruction of large number of neurons in thick brain sections and thereby quantitative assessment of their dendritic morphology in respect to the boundaries of the IO as well as to the neighbouring cohort of IO cells.</p>
<p>Examining a large number of reconstructed cells as well as the overall arrangement of thousands of IO cell bodies revealed that while closely positioned IO cells’ dendritic fields may overlap to a great extent, the inter-somatic distance is not necessarily indicative of overlap. In contrast, IO cells can show strong avoidance regarding their neighbouring cells’ dendritic fields, suggesting that the functional clustering of IO as well as their axonal activity (i.e., the climbing fibre) is defined by the IO cell dendrite arrangement. Such non-uniform neuronal arrangement calls for re-evaluation of our hypotheses regarding the origins of cerebellar complex spike synchrony.</p>
<p><strong>Date:</strong> 17/06/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>

            <p class="text-muted">in 'UH Biocomputation group' on June 11, 2016 09:21 AM. <a href="http://biocomputation.herts.ac.uk/2016/06/11/from-morphology-to-network-level-activity-patterns-dendritic-arrangement-and-clustering-among-inferior-olive-neurons.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Could a neuroscientist understand a microprocessor?.</h4>

            <p>There is a popular belief in neuroscience that we are primarily data
limited, that producing large, multimodal, and complex datasets will,
enabled by data analysis algorithms, lead to fundamental insights into
the way the brain processes information. Microprocessors are among
those artificial information processing systems that are both complex
and that we understand at all levels, from the overall logical flow,
via logical gates, to the dynamics of transistors. Here we take a
simulated classical microprocessor as a model organism, and use our
ability to perform arbitrary experiments on it to see if popular data
analysis methods from neuroscience can elucidate the way it processes
information. We show that the approaches reveal interesting structure
in the data but do not meaningfully describe the hierarchy of
information processing in the processor. This suggests that current
approaches in neuroscience may fall short of producing meaningful
models of the brain.</p>
<p>The complete paper can be found here: <a class="reference external" href="http://www.biorxiv.org/content/early/2016/05/26/055624.abstract">http://www.biorxiv.org/content/early/2016/05/26/055624.abstract</a></p>
<p><strong>Date:</strong> 10/06/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>

            <p class="text-muted">in 'UH Biocomputation group' on June 09, 2016 04:20 PM. <a href="http://biocomputation.herts.ac.uk/2016/06/09/could-a-neuroscientist-understand-a-microprocessor.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Checking your LaTeX sources for spelling errors with Hunspell.</h4>

            <p>I usually use <a class="reference external" href="http://www.vim.org/">Vim</a> and a <a class="reference external" href="https://en.wikipedia.org/wiki/Makefile">Makefile</a> when writing LaTeX documents. Even though <a class="reference external" href="http://vimdoc.sourceforge.net/htmldoc/spell.html">Vim does permit you to check your spellings</a>, it's always nice to run the entire text through a standalone spell checker before passing your documents on to others.</p>
<p>The workflow is quite simple. Once you've written your text, you commit your changes, and then you can use one of either <a class="reference external" href="http://aspell.net/">Aspell</a> or <a class="reference external" href="http://hunspell.github.io/">Hunspell</a> to check your text for spelling errors. Both provide an interactive interface that makes them easy to use.</p>
<p>On <a class="reference external" href="http://getfedora.org">Fedora</a>, you can install them using <code>dnf</code>:</p>
<pre class="code bash literal-block">sudo dnf install aspell hunspell
</pre>
<p>You'll also need to make sure you have the language files installed:</p>
<pre class="code bash literal-block">sudo dnf install aspell-en hunspell-en
</pre>
<p>Then, to check all your <code>.tex</code> files, you can use something like this:</p>
<pre class="code bash literal-block">find . -name <span class="s2">"*.tex"</span> -exec aspell --lang<span class="o">=</span>en --mode<span class="o">=</span>tex check <span class="s2">"{}"</span> <span class="se">\;</span> <span class="c1"># Aspell
</span>find . -name <span class="s2">"*.tex"</span> -exec hunspell -t -i utf-8 <span class="s1">'{}'</span> <span class="se">\;</span> <span class="c1"># Hunspell</span>
</pre>
<p>I looked around a bit, and decided to use <a class="reference external" href="http://hunspell.github.io/">Hunspell</a>. It's used by LibreOffice, Firefox, and other applications. I commit my work first and then run the above command which opens a window like this:</p>
<a class="reference external image-reference" href="http://ankursinha.in/blog/images/hunspell-example.png"><img alt="Hunspell screenshot" src="http://ankursinha.in/blog/images/hunspell-example.png" style="width: 750px;" /></a>
<p>Once you've gone through it and made your changes, you can then use <code>git diff --word-diff</code> to review your changes. If you'd like to undo some of them, use <code>git add -i</code> and so on:</p>
<a class="reference external image-reference" href="http://ankursinha.in/blog/images/git-word-diff.png"><img alt="Git diff screenshot" src="http://ankursinha.in/blog/images/git-word-diff.png" style="width: 750px;" /></a>
<p>That's it! Happy writing!</p>

            <p class="text-muted">in 'Ankur Sinha' on June 02, 2016 10:42 AM. <a href="http://ankursinha.in/blog/2016/06/02/checking-your-latex-sources-for-spelling-errors-with-hunspell.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Convolutional neural networks.</h4>

            <p><a class="reference external" href="http://papers.nips.cc/paper/4824-imagenet-classification-w">In 2012, Krishevsky et al, submitted an entry to the ImageNet competition that smashed the previous error rate record</a>. Krishevsky’s solution won the competition using deep convolutional nets (conv nets) and GPUs. From 2012 the ImageNet competition error rate has continued to plummet from ~15% to just over 3%, with all winning entries using deep conv nets and GPUs. In this talk I review the history of deep conv nets, the key points from Khrishevsky’s paper, conv nets strengths and weaknesses and briefly show how easy it is to create your own deep conv net using Google’s new machine learning library <a class="reference external" href="https://www.tensorflow.org/">TensorFlow</a>.</p>
<p><strong>Date:</strong> 03/06/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>

            <p class="text-muted">in 'UH Biocomputation group' on June 01, 2016 10:33 AM. <a href="http://biocomputation.herts.ac.uk/2016/06/01/convolutional-neural-networks.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Some tips and tricks for running simulations on a cluster.</h4>

            <p>To begin with, you must use a terminal multiplexer! I use <a class="reference external" href="http://byobu.org/">Byobu with tmux</a> to multiplex a single SSH session. I use it on all my machines. It's an excellent tool.</p>
<div class="section" id="monitoring-your-jobs">
<h2>Monitoring your jobs</h2>
<p>Three of my Byobu screens run these commands to monitor the queue and my jobs:</p>
<pre class="code bash literal-block">watch -n <span class="m">30</span> qstat main
watch -n <span class="m">30</span> qstat -B
watch -n <span class="m">30</span> /usr/local/maui/bin/showq -u asinha
</pre>
<p><code>showq</code> may be installed elsewhere. Use <code>which showq</code> to locate it. More information on the commands can be found in their manuals:</p>
<pre class="code bash literal-block">man watch
man qstat
</pre>
<p>Remember, to find a man page, you can use the <code>apropos</code> command.</p>
<p>I run all my simulations in a specific directory on the shared data disk. I usually also monitor this folder. It gives me an idea of how much my simulations have progressed. Something like this works:</p>
<pre class="code bash literal-block">watch -n <span class="m">30</span> <span class="s1">'du -sch *'</span> <span class="c1"># in the directory that stores simulation results*</span>
</pre>
</div>
<div class="section" id="use-git">
<h2>Use Git</h2>
<p>Of course. If you make frequent changes, you must use a version control system. I stick to <code>git</code> myself. You can use <code>svn</code> or <code>hg</code> if you wish - whatever floats your boat.</p>
<p>An issue I've stumbled upon while working with the cluster is that the program you want it to run is not loaded into memory until your job begins to run. So, if you want to run a certain version of your program on the cluster, say some version_1, you must not make any changes to this version until the queued job has begun to run. This is extremely inconvenient, especially if you make frequent changes to your simulations, as is often the case in research. I would, for example, like to queue separate jobs in parallel for a myriad of tiny changes and then compare results.</p>
<p>Enter <a class="reference external" href="https://git-scm.com/docs/git-worktree">git work-tree</a>! The simplest solution to the aforementioned issue is to checkout different work-trees for commits you want to test and queue up jobs for each individually. This would work really well. Once the simulation finishes, you can remove the work-tree.</p>
<p>Unfortunately, clusters usually run stable long term support oriented versions of Linux distributions - EL/CentOS/Scientific. As a result, it's quite probable that the version of git on the cluster doesn't support work-trees - as is the case with the cluster I use. I came up with a workaround which works somewhat like work-trees - I manually clone my source repository to a temporary location, checkout the commit I want to run (which is what work-trees sort of are), and set up a job that runs this particular simulation version. It uses two scripts:</p>
<ul class="simple">
<li>A template PBS script for the simulation run. This will be passed to <code>qsub</code>.</li>
<li>A script that clones my repo, checks out the required commit, completes the template script, and calls <code>qsub</code> to queue up the job.</li>
</ul>
<p>The first is a simple PBS script:</p>
<pre class="code bash literal-block"><span class="c1"># File: run-sim.sh
</span>
<span class="c1">#PBS -l walltime=48:00:00
#PBS -l nodes=50
#PBS -m abe
#PBS -N nest_v_s
</span>
module unload mpi/mpich-x86_64
module load mvapich2-1.7

<span class="nv">SIM_PATH</span><span class="o">=</span><span class="s2">"/stri-data/asinha/simulations-nest/"</span>
<span class="nv">SIM_TIME</span><span class="o">=</span><span class="s2">""</span>
<span class="nv">PROGRAM_PATH</span><span class="o">=</span><span class="s2">"</span><span class="nv">$SIM_PATH</span><span class="s2">""</span><span class="nv">$SIM_TIME</span><span class="s2">""/Sinha2016/src/Sinha2016.py"</span>
<span class="nv">RESULT_PATH</span><span class="o">=</span><span class="s2">"</span><span class="nv">$SIM_PATH</span><span class="s2">""</span><span class="nv">$SIM_TIME</span><span class="s2">""/result/"</span>
<span class="nv">NUM_NODES</span><span class="o">=</span>50

<span class="nb">echo</span> ------------------------------------------------------
<span class="nb">echo</span> <span class="s1">'Job is running on nodes'</span><span class="p">;</span> cat <span class="nv">$PBS_NODEFILE</span>
<span class="nb">echo</span> ------------------------------------------------------
<span class="nb">echo</span> PBS: qsub is running on <span class="nv">$PBS_O_HOST</span>
<span class="nb">echo</span> PBS: originating queue is <span class="nv">$PBS_O_QUEUE</span>
<span class="nb">echo</span> PBS: executing queue is <span class="nv">$PBS_QUEUE</span>
<span class="nb">echo</span> PBS: working directory is <span class="nv">$PBS_O_WORKDIR</span>
<span class="nb">echo</span> PBS: execution mode is <span class="nv">$PBS_ENVIRONMENT</span>
<span class="nb">echo</span> PBS: job identifier is <span class="nv">$PBS_JOBID</span>
<span class="nb">echo</span> PBS: job name is <span class="nv">$PBS_JOBNAME</span>
<span class="nb">echo</span> PBS: node file is <span class="nv">$PBS_NODEFILE</span>
<span class="nb">echo</span> PBS: current home directory is <span class="nv">$PBS_O_HOME</span>
<span class="nb">echo</span> PBS: <span class="nv">PATH</span> <span class="o">=</span> <span class="nv">$PBS_O_PATH</span>
<span class="nb">echo</span> ------------------------------------------------------

<span class="nb">echo</span> <span class="s2">"ANKUR&gt;&gt; Begun at </span><span class="nv">$SIM_TIME</span><span class="s2">"</span>
<span class="nb">echo</span> <span class="s2">"ANKUR&gt;&gt; Script: </span><span class="si">${</span><span class="nv">0</span><span class="si">}</span><span class="s2">"</span>

mkdir -pv <span class="nv">$RESULT_PATH</span>
<span class="nb">cd</span> <span class="nv">$RESULT_PATH</span>

/usr/local/bin/mpiexec -n <span class="nv">$NUM_NODES</span> python <span class="nv">$PROGRAM_PATH</span>

<span class="nv">END_TIME</span><span class="o">=</span><span class="k">$(</span>date +%Y%m%d%H%M<span class="k">)</span>
<span class="nb">echo</span> <span class="s2">"ANKUR&gt;&gt; Ended at </span><span class="nv">$END_TIME</span><span class="s2">"</span>
</pre>
<p>It sets up the required PBS options, then loads the MPI module I wish to use. It creates a directory where my simulation's results will be stored, enters it, and then uses <code>mpiexec</code> to run my Python program.</p>
<p>The second script is a wrapper that clones the required commit, sets up the correct paths in the above script and the calls <code>qsub</code>:</p>
<pre class="code bash literal-block"><span class="c1"># File: setup-job.sh
</span>
<span class="nv">SOURCE_PATH</span><span class="o">=</span><span class="s2">"/home/asinha/Documents/02_Code/00_repos/00_mine/Sinha2016/"</span>
<span class="nv">GIT_COMMIT</span><span class="o">=</span><span class="s2">""</span>
<span class="nv">SIM_PATH</span><span class="o">=</span><span class="s2">"/stri-data/asinha/simulations-nest/"</span>
<span class="nv">SIM_TIME</span><span class="o">=</span><span class="k">$(</span>date +%Y%m%d%H%M<span class="k">)</span>
<span class="nv">RUN_SCRIPT</span><span class="o">=</span><span class="s2">"scripts/cluster/nest-runsim.sh"</span>
<span class="nv">RUN_NEW</span><span class="o">=</span><span class="s2">""</span>
<span class="nv">ERROR</span><span class="o">=</span><span class="s2">"no"</span>
<span class="nv">NUM_NODES</span><span class="o">=</span>50
<span class="nv">CUR_SIM_PATH</span><span class="o">=</span><span class="s2">""</span>

<span class="k">function</span> queue_task
<span class="o">{</span>
    <span class="nb">pushd</span> <span class="s2">"</span><span class="nv">$CUR_SIM_PATH</span><span class="s2">"</span>
        qsub <span class="s2">"</span><span class="nv">$RUN_NEW</span><span class="s2">"</span>
    <span class="nb">popd</span>
<span class="o">}</span>

<span class="k">function</span> setup_env
<span class="o">{</span>
    <span class="nv">CUR_SIM_PATH</span><span class="o">=</span><span class="s2">"</span><span class="nv">$SIM_PATH</span><span class="s2">""</span><span class="nv">$SIM_TIME</span><span class="s2">"</span>
    <span class="nb">echo</span> <span class="s2">"This simulation will run in: </span><span class="nv">$CUR_SIM_PATH</span><span class="s2">"</span>
    mkdir -pv <span class="s2">"</span><span class="nv">$CUR_SIM_PATH</span><span class="s2">"</span>

    <span class="nb">pushd</span> <span class="s2">"</span><span class="nv">$CUR_SIM_PATH</span><span class="s2">"</span>
        <span class="nb">echo</span> <span class="s2">"Cloning source repository..."</span>
        git clone <span class="s2">"</span><span class="nv">$SOURCE_PATH</span><span class="s2">"</span> <span class="s2">"Sinha2016"</span>

        <span class="nb">pushd</span> <span class="s2">"Sinha2016"</span>
            <span class="nb">echo</span> <span class="s2">"Checking out commit </span><span class="nv">$GIT_COMMIT</span><span class="s2">..."</span>
            git checkout -b this_sim <span class="s2">"</span><span class="nv">$GIT_COMMIT</span><span class="s2">"</span>
            <span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="nv">$?</span><span class="s2">"</span> -ne <span class="m">0</span> <span class="o">]</span>
            <span class="k">then</span>
                <span class="nb">echo</span> <span class="s2">"Error occured. Could not checkout </span><span class="nv">$GIT_COMMIT</span><span class="s2">. Exiting..."</span>
                <span class="nv">ERROR</span><span class="o">=</span><span class="s2">"yes"</span>
            <span class="k">fi</span>
        <span class="nb">popd</span>

        <span class="k">if</span> <span class="o">[</span> <span class="s2">"xyes"</span> <span class="o">==</span>  x<span class="s2">"</span><span class="nv">$ERROR</span><span class="s2">"</span> <span class="o">]</span>
        <span class="k">then</span>
            <span class="nb">exit</span> -1
        <span class="k">fi</span>

        <span class="nv">RUN_NEW</span><span class="o">=</span><span class="s2">"nest_""</span><span class="nv">$GIT_COMMIT</span><span class="s2">"".sh"</span>
        <span class="nb">echo</span> <span class="s2">"Setting up </span><span class="nv">$RUN_NEW</span><span class="s2">..."</span>
        cp <span class="s2">"</span><span class="nv">$SOURCE_PATH</span><span class="s2">""</span><span class="nv">$RUN_SCRIPT</span><span class="s2">"</span> <span class="s2">"</span><span class="nv">$RUN_NEW</span><span class="s2">"</span> -v
        sed -i <span class="s2">"s|nest_v_s|nest_</span><span class="nv">$GIT_COMMIT</span><span class="s2">|"</span> <span class="s2">"</span><span class="nv">$RUN_NEW</span><span class="s2">"</span>
        sed -i <span class="s2">"s|nodes=.*|nodes=</span><span class="nv">$NUM_NODES</span><span class="s2">|"</span> <span class="s2">"</span><span class="nv">$RUN_NEW</span><span class="s2">"</span>
        sed -i <span class="s2">"s|NUM_NODES=.*|NUM_NODES=</span><span class="nv">$NUM_NODES</span><span class="s2">|"</span> <span class="s2">"</span><span class="nv">$RUN_NEW</span><span class="s2">"</span>
        sed -i <span class="s2">"s|SIM_TIME=.*|SIM_TIME=</span><span class="nv">$SIM_TIME</span><span class="s2">|"</span> <span class="s2">"</span><span class="nv">$RUN_NEW</span><span class="s2">"</span>
    <span class="nb">popd</span>
<span class="o">}</span>

<span class="k">function</span> usage
<span class="o">{</span>
    <span class="nb">echo</span> <span class="s2">"Usage: </span><span class="nv">$0</span><span class="s2">"</span>
    <span class="nb">echo</span> <span class="s2">"Queue up a job to run a particular git commit"</span>
    <span class="nb">echo</span> <span class="s2">"</span><span class="nv">$0</span><span class="s2"> &lt;git_commit&gt; &lt;number_nodes&gt;"</span>
<span class="o">}</span>

<span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="nv">$#</span><span class="s2">"</span> -ne <span class="m">2</span> <span class="o">]</span><span class="p">;</span>
<span class="k">then</span>
    <span class="nb">echo</span> <span class="s2">"Error occurred. Exiting..."</span>
    <span class="nb">echo</span> <span class="s2">"Received </span><span class="nv">$#</span><span class="s2"> arguments. Expected: 3"</span>
    usage
    <span class="nb">exit</span> -1
<span class="k">fi</span>

<span class="nv">GIT_COMMIT</span><span class="o">=</span><span class="s2">"</span><span class="nv">$1</span><span class="s2">"</span>
<span class="nv">NUM_NODES</span><span class="o">=</span><span class="s2">"</span><span class="nv">$2</span><span class="s2">"</span>
setup_env
queue_task

<span class="nb">exit</span> 0
</pre>
<p>This takes two arguments, as the <code>usage</code> function will tell you. The first argument is the commit you want to run the simulation for, and the second is the number of nodes you want to use. It'll clone your repository to a temporary location and checkout this specified commit. Then, it'll modify the first script <code>run-sim.sh</code> to set up the correct path to the code and also correctly specify the number of nodes you'd want to request. Finally, once all this is done, it'll call <code>qsub run-sim.sh</code> to queue up your job. I use unique date stamps as directory names to distinguish between simulation runs, but you can use another unique identifier.</p>
<p>Now, this copy of your code, at the specified commit will be used for the job you've queued. You can merrily go about tinkering with the main source repo without affecting queued up jobs. Yay!</p>
<p>Even though I've used Python here, you can use similar scripts for compiled languages. You'll simply have to compile your executable after you checkout the required commit.</p>
</div>
<div class="section" id="other-miscellaneous-stuff">
<h2>Other miscellaneous stuff</h2>
<p>My lab mate, Alex, recently introduced me to <a class="reference external" href="https://www.continuum.io/downloads">Anaconda</a>. It's a great tool for that lets you install packages in your user specific directory. It contains quite a few python and other related packages. No need to use <code>sudo</code> with it, and you can use <code>pip</code> etc. with it too. It even lets you set up virtual environments and things.</p>
<p>I think that's it for today. I'll update the post with other things I find/learn as I continue my adventures with the cluster.</p>
</div>

            <p class="text-muted">in 'Ankur Sinha' on May 31, 2016 06:17 PM. <a href="http://ankursinha.in/blog/2016/05/31/some-tips-and-tricks-for-running-simulations-on-a-cluster.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>The Jinx on the NASA software defect data sets.</h4>

            <p>Jean Petrić is scheduled to present two papers at the <a class="reference external" href="http://ease2016.lero.ie/">20th International Conference on Evaluation and Assessment in Software Engineering in Limerick, Ireland</a>:</p>
<ul class="simple">
<li>Using different characteristics of machine learners to identify different defect families (doctoral symposium paper)</li>
<li>The Jinx on the NASA Software Defect Data Sets (short paper)</li>
</ul>
<p>In this journal club session, he presents the papers to the research group to gather additional feedback.</p>
<p><strong>Date:</strong> 27/05/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>

            <p class="text-muted">in 'UH Biocomputation group' on May 25, 2016 09:27 AM. <a href="http://biocomputation.herts.ac.uk/2016/05/25/the-jinx-on-the-nasa-software-defect-data-sets.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>What does the nose know and how does it know it.</h4>

            <p><a class="reference external" href="http://bower-lab.org/">James Bower</a> joins us for a special journal club session where he discusses olfactory processing.</p>
<hr class="docutils" />
<p>Since Lucretius published his epic poem, De rerum natura (On the Nature of Things) in 66 BC, philosophical and scientific thinking about the sense of smell has been built on the assumption that the olfactory system detects odours through a process of classification based on analytical chemical structures.  Somewhat similarly, starting with Linnaeus in the mid 18th century, various efforts have been made to regularize odour perception by identifying different scales or perceptual groupings.  For the last 100 years many attempts have been made to correlate chemical characteristics believed important to detection to these classification schemes for perception.  All have failed.  This talk will describe the origins and implications of the alternative view that the olfactory system, both detection and perception is organized around the biological significance of an odorant molecule rather than its strict chemical form.  Evidence in support will be presented from a range of approaches from human psychophysics to receptor ligand binding studies to neuronal modelling.  The talk will also consider the possible implications for the function of cerebral cortex as a whole, given the likely olfactory origin of the cerebral cortical processing algorithm.</p>
<p><strong>Date:</strong> 20/05/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>

            <p class="text-muted">in 'UH Biocomputation group' on May 13, 2016 09:48 AM. <a href="http://biocomputation.herts.ac.uk/2016/05/13/what-does-the-nose-know-and-how-does-it-know-it.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Open Position: PhD studentship in Computational Neuroscience.</h4>

            <hr class="docutils" />
<p>We welcome applications for a funded PhD position in the Biocomputation Research Group at the University of Hertfordshire.</p>
<p>The successful applicant will work on a project related to the detailed modelling of neuronal dynamics arising through dendritic processing and/or the analysis of morphological and circuit data. Potential projects in the fields of neuroinformatics and computational neuroscience include (but are not limited to):</p>
<ul class="simple">
<li>Analysis of neuronal morphology and micro-circuitry.</li>
<li>Simulation of development of neuronal morphologies and tissues.</li>
<li>Simulation of dendritic processing on hardware.</li>
<li>Sensory processing and behaviour generation in individual invertebrate neurons.</li>
<li>Development of experimental robot controllers based on dendritic computation.</li>
<li>Structural plasticity at the single neuron and micro-circuitry level.</li>
</ul>
<p>More project ideas can be found here: <a class="reference external" href="http://www.dendrites.club/Positions.html">http://www.dendrites.club/Positions.html</a></p>
<p>The successful candidate will have extensive programming experience, preferably in Python (and/or other programming languages depending on the precise project). Depending on the project, experience with parallel programming (MPI, ZMQ), meshing software (VTK, CGAL, ITK, ...), or statistical analysis in R or Python are an advantage. In addition, we greatly value curiosity and a personal motivation to find out how things work.</p>
<p>We collaborate closely with leading experimentalists and theoreticians all over the world, such as Prof. Adrian Moore (RIKEN, Japan), Prof. Erik De Schutter (OIST, Japan) and Dr. Marylka Uusisaari (Erasmus Medical Center Rotterdam, The Netherlands).</p>
<p>The student will be based in the <a class="reference external" href="http://biocomputation.herts.ac.uk">Biocomputation Group</a> at the University of Hertfordshire and will be supervised by Drs. Ben Torben-Nielsen (b.torben-nielsen at herts.ac.uk) and Volker Steuber (v.steuber at herts.ac.uk) to whom informal enquiries can be sent.</p>
<p>Successful candidates are eligible for a research studentship award from the University (approximately GBP 14,250 per annum bursary plus the payment of the student fees). Application forms can be obtained from:</p>
<p>Mrs Lorraine Nicholls, <br />
Research Student Administrator, <br />
STRI, <br />
University of Hertfordshire, <br />
College Lane, <br />
Hatfield, Herts, <br />
AL10 9AB, <br />
Tel: +44 01707 286083, <br />
l.nicholls @ herts.ac.uk.</p>
<p>The short-listing process will begin on 30 May, 2016.</p>

            <p class="text-muted">in 'UH Biocomputation group' on April 28, 2016 10:57 PM. <a href="http://biocomputation.herts.ac.uk/2016/04/28/open-position-phd-studentship-in-computational-neuroscience.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Open Position: PhD studentship in Olfactory Biocomputation.</h4>

            <hr class="docutils" />
<p>Applications are invited for a fully funded PhD position in the Biocomputation Research group at the University of Hertfordshire. Our research on Olfactory Biocomputation encompasses the following topics:</p>
<ul class="simple">
<li>Olfactory computing in insects and vertebrates</li>
<li>The role of stimulus dynamics in olfaction</li>
<li>Chemical “receptive fields” of odorant receptors</li>
<li>Neuromorphic computing and bio-inspired signal processing for chemical sensing</li>
</ul>
<p>Our spectrum of methods covers data science and machine learning, simulation of spiking networks, cheminformatics, and brain-like computing on neuromorphic hardware. The successful candidate should ideally have previous experience in one or more of these methods, but a keen interest in our research topics and enthusiasm for interdisciplinary research is considered essential. Excellent programming skills are required and should be documented upon application. Most of our code is written in Python.</p>
<p>Depending on the area of work, the successful candidate will join our collaborative research efforts with excellent experimental research groups, as e.g. led by Prof. Andreas Schaefer (Francis Crick Institute, London), Dr. Markus Knaden and Dr. Silke Sachse (Max-Planck Institute for Chemical Ecology, Jena, Germany). For a list of recent projects and publications please refer to the web pages of the <a class="reference external" href="http://biomachinelearning.net">BioMachineLearning Project</a> and the <a class="reference external" href="http://biocomputation.herts.ac.uk/">Biocomputation Group</a>.</p>
<p>The student will be supervised by Drs. Michael Schmuker (m.schmuker @ biomachinelearning.net) and Volker Steuber (v.steuber @ herts.ac.uk). Informal enquiries by email prior to application are encouraged and very welcome.</p>
<p>Successful candidates are eligible for a research studentship award from the University (approximately GBP 14,250 per annum bursary plus payment of the student fees).</p>
<p>Research in Computer Science at the University of Hertfordshire has been recognized as excellent by the latest Research Excellence Framework Assessment, with 50% of the research submitted being rated as world leading or internationally excellent. The Science and Technology Research Institute provides a very stimulating environment, offering a large number of specialized and interdisciplinary seminars as well as general training and researcher development opportunities. The University of Hertfordshire is situated in Hatfield, in the green belt just north of London.</p>
<p>Application forms can be obtained from:</p>
<p>Mrs Lorraine Nicholls, <br />
Research Student Administrator, <br />
STRI, <br />
University of Hertfordshire, <br />
College Lane, <br />
Hatfield, Herts, <br />
AL10 9AB, <br />
Tel: +44 01707 286083, <br />
l.nicholls @ herts.ac.uk.</p>
<p>The short-listing process will begin on 30 May, 2016.</p>

            <p class="text-muted">in 'UH Biocomputation group' on April 28, 2016 04:32 PM. <a href="http://biocomputation.herts.ac.uk/2016/04/28/open-position-phd-studentship-in-olfactory-biocomputation.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Open Position: PhD studentship in Data Clustering.</h4>

            <hr class="docutils" />
<p>Applications are invited for a fully funded PhD position in the Machine Learning team, under the Biocomputation Research Group, at the University of Hertfordshire. Our research in data clustering encompasses the following topics:</p>
<ul class="simple">
<li>Unsupervised feature weighting.</li>
<li>Metric learning.</li>
<li>Recovering the number of clusters in data sets.</li>
<li>Applications of the above in security and natural language processing.</li>
</ul>
<p>The successful candidate should ideally have previous experience in at least one of the above topics; those without experience must be able to demonstrate a keen interest in our research. Excellent programming skills are required and should be documented upon application.</p>
<p>The student will be supervised by Dr. Renato Cordeiro de Amorim (r dot amorim at herts dot ac dot uk). Informal enquires by email prior to application are encouraged and very welcome.</p>
<p>We collaborate closely with leading scientists from all over the world, including Prof. Boris Mirkin (National Research University Higher School of Economics and Birkbeck University of London), Prof. Vladimir Makarenkov (University of Quebec at Montreal), Dr. Christian Hennig (University College London), and Dr. Marcos Zampieri (Saarland University). For a list of recent publications please refer to <a class="reference external" href="http://homepages.herts.ac.uk/~comqra">http://homepages.herts.ac.uk/~comqra</a>.</p>
<p>Successful candidates are eligible for a research studentship award from the University (approximately GBP 14,250 per annum bursary plus payment of the student fees).</p>
<p>Research in Computer Science at the University of Hertfordshire has been recognized as excellent by the latest Research Excellence Framework Assessment, with 50% of the research submitted being rated as world leading or internationally excellent. The Science and Technology Research Institute provides a very stimulating environment, offering a large number of specialized and interdisciplinary seminars as well as general training and researcher development opportunities. The University of Hertfordshire is situated in Hatfield, in the green belt just north of London.
Application forms can be obtained from:</p>
<p>Mrs Lorraine Nicholls, <br />
Research Student Administrator, <br />
STRI, <br />
University of Hertfordshire, <br />
College Lane, <br />
Hatfield, Herts, <br />
AL10 9AB, <br />
Tel: +44 01707 286083, <br />
l.nicholls @ herts.ac.uk.</p>
<p>The short-listing process will begin on 30 May, 2016.</p>

            <p class="text-muted">in 'UH Biocomputation group' on April 28, 2016 03:41 AM. <a href="http://biocomputation.herts.ac.uk/2016/04/28/open-position-phd-studentship-in-data-clustering.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Using watertight polygon meshes for neuronal morphology representation.</h4>

            <p>I will report on the progress of my work to use polygon meshes as
a way to represent neuronal morphologies. The presentation is
composed of two parts. The first part discusses the acquisition
of neuronal morphology data from microscopy and the generation of
computer representations using the SWC format. It is intended to
provide a background on the second part of the presentation,
which focuses on using watertight polygon meshes as a way to
represent neuronal morphology. We shall cover the advantages of
this approach and the difficulties faced. In this context shall
discuss the paper by McDougal et al. [1]</p>
<p>[1] McDougal, Robert A., Michael L. Hines, and William
W. Lytton. "Water-tight membranes from neuronal morphology
files." Journal of neuroscience methods 220.2 (2013): 167-178.</p>
<p><strong>Date:</strong> 29/04/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>

            <p class="text-muted">in 'UH Biocomputation group' on April 27, 2016 05:11 PM. <a href="http://biocomputation.herts.ac.uk/2016/04/27/using-watertight-polygon-meshes-for-neuronal-morphology-representation.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Forests are TREES 2 - Dendritic tree topology revisited.</h4>

            <p><a class="reference external" href="https://scholar.google.com/citations?user=IpKlv7kAAAAJ">Felix Effenberger</a> joins us for a special journal club session where he discusses preliminary results on the statistics of the branching structure of dendritic trees.</p>
<hr class="docutils" />
<p>We report on preliminary results on the statistics of the branching structure of dendritic trees. Such trees can be considered to be binary trees since exactly two branches emerge from each branch point. Previous work has compared dendritic topology with random branching processes. Here we investigate a number of statistics over the topology (i.e. branching structure) of dendritic trees using a large sample of reconstructions of real dendritic trees from the NeuroMorpho.org database. First results indicate that real dendritic morphologies span the entire space of possible binary trees. This result indicates that precise dendritic topology might not be a relevant factor determining dendritic computation.</p>
<p>The reconstructions were accessed directly through the TREES toolbox in Matlab using a newly developed software interface that allows easy access to the database from third party applications. The API supports a rich query language enabling the user to conveniently perform sophisticated queries and obtain the reconstructions matching the query parameters. This is harnessed by a first client implemented as part of a forthcoming version of the TREES toolbox that handles populations of reconstructions. In cooperation with the NeuroMorpho.org team we plan to soon make the API available to other parties.</p>
<p><strong>Date:</strong> 22/04/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>

            <p class="text-muted">in 'UH Biocomputation group' on April 19, 2016 09:45 AM. <a href="http://biocomputation.herts.ac.uk/2016/04/19/forests-are-trees-2-dendritic-tree-topology-revisited.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Open Positions: Early Career Research Fellowships in systems biology/machine learning for food and disease.</h4>

            <hr class="docutils" />
<p>Salary: £31,656 - £37,768 per annum depending on skills and experience. <br />
Closing date: 17 May 2016 <br /></p>
<p>The University of Hertfordshire is investing in its future research staff and infrastructure, and is in the process of transitioning the delivery of its research under six Themes: Food; Global Economy; Health and Wellbeing; Heritage, Cultures and Communities; Information and Security; Space. These will assist in the further development of research excellence and provide both increased external profile and internal focus for Hertfordshire’s research activities.</p>
<p>Six new Research Fellow posts are each offered for a five year term in the first instance. It is our expectation, however, that successful appointees will grow their research activities to become permanent academic staff members by the end of that period.</p>
<div class="section" id="qualifications-required">
<h2>Qualifications required</h2>
<p>You must have a first degree in a science, such as biology, computer science, mathematics or a relevant subject, and a doctoral degree in bioinformatics, machine learning, quantitative genetics or a related subject area.  Experience in systems biology, big data science or genomics will be particularly relevant.</p>
</div>
<div class="section" id="research-focus-and-environment">
<h2>Research focus and environment</h2>
<p>This Fellowship will focus on emerging methods in biocomputation that generate and exploit large data sets of biological information available from genomics, transcriptomics, proteomics and metabolomics to better understand mechanisms of host resistance/immunity and/or resistance breakdown.  The Fellow will generate an improved understanding of relevant biological systems to develop specific strategies to combat infectious diseases caused by plant, animal or human pathogens.  This Fellowship will be supported by existing collaborations between colleagues in Schools of Life &amp; Medical Sciences (Kukol, Stotz, Barling, Fitt) and Computer Science (Steuber).  The Fellow is expected to use the University’s high performance computer cluster.</p>
</div>
<div class="section" id="experience-and-skills-required-for-the-post">
<h2>Experience and skills required for the post</h2>
<ul class="simple">
<li>Considerable experience with big data analysis and machine learning, including working knowledge of scripting languages like Perl, Python and/or R;</li>
<li>Knowledge of genomic research techniques, such as next-generation sequencing, proteomics and/or metabolic profiling;</li>
<li>Practical experience with the application of numerical analysis and/or mathematical models to biological datasets, for example in genomics or quantitative genetics;</li>
<li>Evidence of original research published in high impact journals.</li>
</ul>
</div>
<div class="section" id="research-expectations">
<h2>Research expectations</h2>
<p>The Fellow is expected to develop a collaborative research program with our academic partners.  We envisage that the Research Fellow will become a permanent staff member, supported by funding from successful research grant applications and developing new areas of teaching, especially at the post-graduate level. To ensure this, the two Schools will provide career training for the Fellow. The Fellow will have established collaborations with companies and successfully obtained co-funded industry-government projects. The Fellow will continue to publish high-impact papers and be leading an internationally recognised research team.</p>
</div>
<div class="section" id="description-of-schools">
<h2>Description of Schools</h2>
<p>The Early Career Research Fellow will work with and receive support from the School of Life and Medical Sciences and the School of Computer Science.  The successful candidate can build on the strengths of both Schools and may combine experiment-based empirical research with data-based analysis.</p>
<p>Within the <a class="reference external" href="http://www.herts.ac.uk/apply/schools-of-study/life-and-medical-sciences/research">School of Life and Medical Sciences</a>, the Centre for Agriculture, Food and Environmental Management (CAFEM) is a research and teaching collaboration with the Royal Veterinary College, Rothamsted Research and Oaklands College.  The Fellow will work with researchers in CAFEM who have experience with systems biology applicable to crop protection, combining experimental field and lab research with computational modelling.  Within the School of Computer Science, research in the <a class="reference external" href="http://biocomputation.herts.ac.uk/">Biocomputation Research Group</a> involves development of computational models to study biological systems and application of biologically-inspired machine learning algorithms for the analysis of "real-world" data.  Members of the Biocomputation Group analyse and simulate computational models at different levels of complexity and collaborate closely with leading experimentalists in the UK and abroad.</p>
<hr class="docutils" />
<p>Informal enquiries are encouraged and should be made to: <br />
Professor Bruce Fitt, <br />
Professor of Plant Pathology, <br />
email: <a class="reference external" href="mailto:b.fitt@herts.ac.uk">b.fitt@herts.ac.uk</a>  <br />
Tel + 44 (0)1707 284751</p>
<p>or</p>
<p>Dr. Volker Steuber, <br />
Reader in Biocomputation and Head of the Biocomputation Research Group, <br />
email:  <a class="reference external" href="mailto:v.steuber@herts.ac.uk">v.steuber@herts.ac.uk</a> <br />
Tel: +44 (0)1707 284350.</p>
<p>Applications should be made through <a class="reference external" href="http://www.herts.ac.uk/contact-us/jobs-and-vacancies/research-vacancies">http://www.herts.ac.uk/contact-us/jobs-and-vacancies/research-vacancies</a>, job reference 013457.</p>
</div>

            <p class="text-muted">in 'UH Biocomputation group' on April 13, 2016 12:27 PM. <a href="http://biocomputation.herts.ac.uk/2016/04/13/open-position-early-career-research-fellowships-in-systems-biology-machine-learning-for-food-and-disease.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>The potential for using artificial intelligence techniques to improve e-Learning systems.</h4>

            <p>There has been significant progress in the development of techniques to deliver more effective e-Learning systems in both education and commerce but there are very few examples of comprehensive learning systems that exploit contemporary artificial intelligence (AI) techniques.  We have surveyed existing intelligent learning/training systems and explored the contemporary AI techniques which appear to offer the most promising contributions to e-Learning.  With the convergence of several of the required components for success increasingly in place the opportunity to make progress now appears to be much stronger.</p>
<p>In the field of education, the mining, extraction and exploitation of useful information and patterns from student data provides lecturers, trainers and organisations with the potential to tailor learning paths and materials to maximize teaching efficiency and to predict and influence student success rates. Progress in the area of student data analytics can provide useful techniques for exploitation in the development of adaptive learning systems. Student data often includes a combination of nominal and numeric data. A large variety of techniques are available to analyse numeric data, however there are fewer techniques applicable to nominal data.  We have explored potential correlations between student attributes in a freely available data set, including the application of what we believe to be a novel technique to analyse nominal data, providing the opportunity to focus on promising correlations for deeper analysis.</p>
<p><strong>Date:</strong> 8/04/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>

            <p class="text-muted">in 'UH Biocomputation group' on April 06, 2016 04:40 PM. <a href="http://biocomputation.herts.ac.uk/2016/04/06/the-potential-for-using-artificial-intelligence-techniques-to-improve-e-learning-systems.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Dendritic Computation.</h4>

            <p>Ankur Sinha's journal club session where he speaks about dendritic computation.</p>
<p><strong>Date:</strong> 01/04/2016 <br />
<strong>Time:</strong> 16:00 <br />
<strong>Location</strong>: LB252</p>

            <p class="text-muted">in 'UH Biocomputation group' on March 30, 2016 05:54 PM. <a href="http://biocomputation.herts.ac.uk/2016/03/30/dendritic-computation.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Calliope - helping you keep a diary - in LaTeX!.</h4>

            <p>Quite a few people write personal diaries - researchers tend to also keep research diaries where we note our generally brilliant ideas. I've used <a class="reference external" href="http://lifeograph.sourceforge.net/wiki/Main_Page">Lifeograph</a> for a number of years now. It's a great application with all the right features that a diary needs - chapters, tags, and  metrics. It doesn't quite work for a <em>research diary</em>, though - it doesn't support maths notation for a start, and we really do write a lot of very complicated maths from time to time. (The kinds with lots of symbols you see in the films? Think "<a class="reference external" href="http://www.imdb.com/title/tt0268978/">A beautiful mind</a>".)</p>
<p>The simple solution, of course, is <a class="reference external" href="http://lifeograph.sourceforge.net/wiki/Main_Page">LaTeX</a>. <a class="reference external" href="http://lifeograph.sourceforge.net/wiki/Main_Page">LaTeX</a> is used extensively in academic writing. While it does have a reputation for being complex and complicated (<a class="reference external" href="http://english.stackexchange.com/questions/10459/what-is-the-difference-between-complicated-and-complex">YES! There's a difference in the two words - they're not interchangeable!</a>) at times, it is by far the best tool for academic writing. It has everything a researcher needs - citation support, can be customised to fit multiple format, and if you pair it with <a class="reference external" href="https://git-scm.com/">Git</a> you even have versioning and <a class="reference external" href="http://ankursinha.in/blog/tag/zaphod/">change tracking</a>.</p>
<div class="section" id="calliope">
<h2>Calliope</h2>
<p>I went looking for packages that may provide this functionality in <a class="reference external" href="http://lifeograph.sourceforge.net/wiki/Main_Page">LaTeX</a> but didn't quite find any that had a convenient workflow and so on. I ran into a <a class="reference external" href="https://github.com/mikhailklassen/research-diary-project">this Github project</a> instead, which is a set of templates and scripts that does quite a good job. I've forked it and made some improvements. There's now a single script that takes arguments, for example. I've also added support for indexing - which works similar to tagging - it'll generate a nice clickable index at the end of the document. Of course, I've given it a fancy name, <a class="reference external" href="https://github.com/sanjayankur31/calliope">Calliope, and put it up on Github</a>.</p>
<p>Usage is quite straightforward:</p>
<pre class="code bash literal-block"><span class="o">[</span>asinha@cs-as14aho-2-herts-ac-uk  00_research_diary<span class="o">(</span>master %<span class="o">=)]</span>$ ./calliope.sh -h
    usage: ./calliope.sh options

    Master script file that provides functions to maintain a journal using LaTeX.

    OPTIONS:
    -h  Show this message and quit

    -t  Add new entry <span class="k">for</span> today

    -c  Compile today<span class="err">'</span>s entry

    -a  &lt;year&gt;
        Year to generate anthology of

    -p  &lt;year&gt;
        Compile all entries in this year

    -s  &lt;entry&gt; <span class="o">(</span>yyyy-mm-dd<span class="o">)</span>
        Compile specific entry
</pre>
<p>This is what the directory structure looks like:</p>
<pre class="code bash literal-block"><span class="o">[</span>asinha@cs-as14aho-2-herts-ac-uk  00_research_diary<span class="o">(</span>master %<span class="o">=)]</span>$ tree
.
├── calliope.sh
├── diary
│   ├── 2016
│   │   ├── 2016-03-04.tex
│   │   ├── 2016-03-05.tex
│   │   ├── images
│   │   ├── research_diary.sty -&gt; ../../templates/research_diary.sty
│   │   └── stdp_connection_symmetric.h
│   └── research_diary.sty -&gt; ../templates/research_diary.sty
├── pdfs
│   └── 2016
│       ├── 2016-03-04.pdf
│       └── 2016-03-05.pdf
├── README.rst
└── templates
    ├── entry.tex
    └── research_diary.sty

        <span class="m">6</span> directories, <span class="m">11</span> files
</pre>
<p>The script generates your source <a class="reference external" href="http://lifeograph.sourceforge.net/wiki/Main_Page">LaTeX</a> files and puts them in the folders in <tt class="docutils literal">diary/</tt>. Then you write up and use the script to compile it - the generated pdfs are collected in the <tt class="docutils literal">pdfs/</tt> folder. The script can also generate an anthology for a year you pick. The resultant pdf for a daily entry will look like this:</p>
<a class="reference external image-reference" href="http://ankursinha.in/blog/images/20160305-Calliope.png"><img alt="Screenshot showing pdf generated by Calliope" class="align-center" src="http://ankursinha.in/blog/images/20160305-Calliope.png" style="width: 500px;" /></a>
<p>That's pretty much it. Commit your entry to Git and you're done.</p>
<p>So, give it a go and please <a class="reference external" href="https://github.com/sanjayankur31/calliope/issues/">file issues</a> if you have any suggestions that would improve it.</p>
</div>

            <p class="text-muted">in 'Ankur Sinha' on March 05, 2016 02:07 PM. <a href="http://ankursinha.in/blog/2016/03/05/calliope-helping-you-keep-a-diary-in-latex.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>sli.vim - syntax file for the NEST simulator's SLI language.</h4>

            <p>I've been reading some of <a class="reference external" href="http://nest-simulator.org">NEST</a>'s <a class="reference external" href="http://www.nest-simulator.org/quickref/">SLI</a> examples to understand the simulation better. I noticed that these files had no syntax highlighting at all which made the code difficult to read. I couldn't find a syntax highlighting file for Vim anywhere so I've begun writing my own. It isn't complete, and I'm sure it's buggy, but it already seems to make reading and writing SLI easier. Here's what it makes an SLI file look like:</p>
<a class="reference external image-reference" href="http://ankursinha.in/blog/images/20160302-sli-vim.png"><img alt="Screenshot showing SLI syntax highlighting in Vim" class="align-center" src="http://ankursinha.in/blog/images/20160302-sli-vim.png" style="width: 500px;" /></a>
<div class="section" id="installation">
<h2>Installation</h2>
<p>It's just a syntax file. You can drop it in <tt class="docutils literal"><span class="pre">~/.vim/syntax/</span></tt> directory (on Linux) or you can use <a class="reference external" href="https://github.com/tpope/vim-pathogen">pathogen</a> and just clone the repository and so on. Once done, add this to your <tt class="docutils literal">vimrc</tt> file:</p>
<pre class="code vim literal-block"><span class="k">au</span> <span class="nb">BufRead</span><span class="p">,</span><span class="nb">BufNewFile</span> *.sli <span class="k">set</span> <span class="k">filetype</span><span class="p">=</span>sli
<span class="k">au</span> <span class="nb">FileType</span> sli <span class="k">setl</span> <span class="nb">foldenable</span> <span class="nb">foldmethod</span><span class="p">=</span><span class="nb">syntax</span>
</pre>
<p>The file is <a class="reference external" href="https://github.com/sanjayankur31/sli.vim">hosted on Github</a>. Feel free to open issues, or even better, pull requests ;)</p>
</div>

            <p class="text-muted">in 'Ankur Sinha' on March 02, 2016 10:53 AM. <a href="http://ankursinha.in/blog/2016/03/02/sli-vim-syntax-file-for-the-nest-simulators-sli-language.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>New Zaphod release - v0.5.7.</h4>

            <p><a class="reference external" href="http://ankursinha.in/blog/2016/02/13/zaphod-a-latex-change-tracking-tool.html">I'd written about Zaphod recently</a>. I've been making some tweaks to it - just some enhancements to the revision bit which will make it easier to use. The diff bit is still the same - I didn't see the need to make too many improvements there.</p>
<div class="section" id="new-revision-bits">
<h2>New revision bits</h2>
<p>Now, it looks like this when you start it up:</p>
<pre class="code bash literal-block"><span class="o">[</span>asinha@cs-as14aho-2-herts-ac-uk  latex-changes<span class="o">(</span>201602281328-latexdiff-annotated<span class="o">)]</span>$ python3 ../zaphod/zaphod.py revise -m paper.tex -s src
<span class="o">[</span>Zaphod<span class="o">]</span> LaTeX files with annotations:
<span class="o">[</span>1<span class="o">]</span> src/discussion.tex
<span class="o">[</span>2<span class="o">]</span> src/introduction.tex
<span class="o">[</span>3<span class="o">]</span> src/paper.tex
<span class="o">[</span>4<span class="o">]</span> src/methods.tex

Pick file to revise? 1-4/Q/q:
</pre>
<p>The idea here is that the user should be able to pick what file they want to edit. Previously, Zaphod just went file after file.</p>
<p>Once you pick a file, it'll look like this:</p>
<pre class="code bash literal-block">....
Pick file to revise? 1-4/Q/q: <span class="nv">1</span>

<span class="o">======</span> src/discussion.tex <span class="o">======</span>
+++ Addition found +++
<span class="se">\s</span>ection<span class="o">{</span>Discussion<span class="o">}</span>

Add a new file.

+++ Addition found +++
Accept addition? Y/N/Q/y/n/q: y
<span class="o">[</span>Zaphod<span class="o">]</span> Addition accepted.

<span class="o">[</span>Zaphod<span class="o">]</span> File src/discussion.tex revised and saved.
<span class="o">[</span>Zaphod<span class="o">]</span> LaTeX files with annotations:
<span class="o">[</span>1<span class="o">]</span> src/introduction.tex
<span class="o">[</span>2<span class="o">]</span> src/paper.tex
<span class="o">[</span>3<span class="o">]</span> src/methods.tex

Pick file to revise? 1-3/Q/q:
</pre>
<p>But, you can also make partial revisions. This is handy in situations where you have a long file and do not have the time to go over all of it at once. So, here's an example. I go over some changes, but I need to stop there for the moment:</p>
<pre class="code bash literal-block">...
<span class="o">[</span>Zaphod<span class="o">]</span> LaTeX files with annotations:
<span class="o">[</span>1<span class="o">]</span> src/introduction.tex
<span class="o">[</span>2<span class="o">]</span> src/paper.tex
<span class="o">[</span>3<span class="o">]</span> src/methods.tex

Pick file to revise? 1-3/Q/q: <span class="nv">2</span>

<span class="o">======</span> src/paper.tex <span class="o">======</span>
--- Deletion found ---
Tracking
--- Deletion found ---
Accept deletion? Y/N/Q/y/n/q: y
<span class="o">[</span>Zaphod<span class="o">]</span> Deletion accepted.

<span class="o">======</span> src/paper.tex <span class="o">======</span>
+++ Addition found +++
Visualising
+++ Addition found +++
Accept addition? Y/N/Q/y/n/q: y
<span class="o">[</span>Zaphod<span class="o">]</span> Addition accepted.

<span class="o">======</span> src/paper.tex <span class="o">======</span>
+++ Addition found +++
<span class="se">\i</span>nput<span class="o">{</span>discussion<span class="o">}</span>

+++ Addition found +++
Accept addition? Y/N/Q/y/n/q: q
Save partial file? Y/N/y/n: y
<span class="o">[</span>Zaphod<span class="o">]</span> Some files still have latexdiff annotations:
<span class="o">[</span>1<span class="o">]</span> src/introduction.tex
<span class="o">[</span>2<span class="o">]</span> src/methods.tex

Generate pdf? Y/y/N/n: n
<span class="o">[</span>Zaphod<span class="o">]</span> Not generating pdf.
<span class="o">[</span>Zaphod<span class="o">]</span> Following files have been revised <span class="o">(</span>maybe partially<span class="o">)</span>:
<span class="o">[</span>1<span class="o">]</span> src/discussion.tex
<span class="o">[</span>2<span class="o">]</span> src/paper.tex

Commit current changes? Y/y/N/n: n
<span class="o">[</span>Zaphod<span class="o">]</span> Exiting without committing.
</pre>
<p>There's one catch here, though. Because I want to make absolutely sure that Zaphod doesn't make any changes "by mistake", you'll have to either stash or commit these changes before you can run Zaphod again. This is just to be on the safer side. A better way would probably be for Zaphod to remember what files were partially revised, but I haven't implemented it at the moment. I'd actually just commit the changes - I mean, that's why we've got Git, right?</p>
<pre class="code bash literal-block"><span class="o">[</span>asinha@cs-as14aho-2-herts-ac-uk  latex-changes<span class="o">(</span>201602281328-latexdiff-annotated *<span class="o">)]</span>$ python3 ../zaphod/zaphod.py revise -m paper.tex -s src
Modifed or untracked files found.
git status output:
 M src/discussion.tex
 M src/paper.tex

Please stash or commit and rerun Zaphod.
</pre>
<p>That's it. I think it's a lot easier to use now, and in this design addresses a lot more use cases than it did before.</p>
<p><a class="reference external" href="https://github.com/sanjayankur31/zaphod/releases">Give it a go</a> and <a class="reference external" href="https://github.com/sanjayankur31/zaphod/issues/new">let me know</a> if things break - I've tested it myself, but only on a mock document.</p>
</div>

            <p class="text-muted">in 'Ankur Sinha' on February 28, 2016 04:52 PM. <a href="http://ankursinha.in/blog/2016/02/28/new-zaphod-release-v0-5-7.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Nerd Food: Interesting....</h4>

            Nerd Food: Interesting…<div id="content"><p>Time to flush all those tabs again. Some interesting stuff I bumped into recently-ish. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">Finance, Economics, Politics</h2><div class="outline-text-2" id="text-1"><ul class="org-ul"><li><a href="http://www.ted.com/talks/yanis_varoufakis_capitalism_will_eat_democracy_unless_we_speak_up?utm_campaign=social&amp;utm_medium=referral&amp;utm_source=t.co&amp;utm_content=talk&amp;utm_term=global-social%2520issues#t-874630">Yanis Varoufakis: Capitalism will eat democracy – unless we speak up</a>: Very interesting Ted talk by Varoufakis. </li><li><a href="http://www.salon.com/2016/02/04/naomi_klein_there_are_no_non_radical_options_left_before_us_partner/">Naomi Klein: “There are no non-radical options left before us"</a>: I always have time for Naomi Klein even if I don't always agree with her. Very interesting post on market failures (predictably). </li><li><a href="http://www.theguardian.com/technology/2016/jan/28/apple-quarterly-results-iphone-silicon-valley-developers">Apple – losing out on talent and in need of a killer new device</a>: Very interesting post on Apple, and how it is not cool with the cool developers any longer. Good read and worrying one for Apple. </li><li><a href="http://www.spectator.co.uk/2016/01/the-low-tricks-of-high-finance-how-greedy-bankers-weak-politicians-and-timid-journalists-could-cause-a-new-crash/">The low tricks of high finance: how greedy bankers, weak politicians and timid journalists could cause a new crash</a>. Always have time for Michael Lewis. While waiting for the Big Short, this article kept me entertained. </li><li><a href="http://bottlerocketscience.blogspot.co.uk/2016/01/startup-geometry-ep-016-emanuel-derman.html">Startup Geometry EP 016 Emanuel Derman</a>: Podcast with uber nerd, quintessential Quant and fellow African Emanuel Derman. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">Startups et al.</h2><div class="outline-text-2" id="text-2"><ul class="org-ul"><li>Spotify engineering culture: <a href="https://labs.spotify.com/2014/03/27/spotify-engineering-culture-part-1/">Part I</a>, <a href="https://labs.spotify.com/2014/09/20/spotify-engineering-culture-part-2/">Part II</a>. "Oldie" but goodie. How a modern company is organised for raw efficiency. </li><li><a href="http://www.themacro.com/articles/2016/01/advice-startups-running-out-of-money/">Advice for Companies With Less Than 1 Year of Runway</a>: Lots of useful bits of advice for how to manage your runway. Source: Hacker News (twitter). </li><li><a href="http://dealbook.nytimes.com/2014/10/20/the-truth-hidden-by-ibms-buybacks/">The Truth Hidden by IBM’s Buybacks</a>: Something slightly dodgy seems to be going on in IBM, very strange financial transactions! </li><li><a href="http://www.wired.com/2016/02/ai-is-changing-the-technology-behind-google-searches/">AI Is Transforming Google Search. The Rest of the Web Is Next</a>: Google is moving from a "human algo" approach to AI in search. Very interesting. </li><li><a href="http://gavinandresen.ninja/a-guided-tour-of-the-2mb-fork">A Guided Tour of the 2mb Fork</a>: The BTC main man Gavin takes us on a detailed tour of one of the BTC forks. Source: Hacker News (twitter) </li><li><a href="http://www.coindesk.com/state-of-bitcoin-blockchain-2016/?utm_content=bufferccc2b&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer">State of Bitcoin and Blockchain 2016</a>: Blockchain Hits Critical Mass: A very detailed - some say <i>too detailed</i> - look at BTC in 2016. Source: CoinDesk (twitter). </li><li><a href="http://www.wired.com/2016/02/why-bitcoin-will-thrive-first-in-the-developing-world/?utm_content=buffer9ce0d&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer">Why Bitcoin Will Thrive First in the Developing World</a>: Most interesting hypothesis - that BTC will first gain lots of traction in the developing world - but to me, it fails slightly to provide enough evidence. It reminds me how I always thought that Linux would explode in the developing world, but in the end it was the developed world that took the lead, whereas the poorer nations simply pirated windows. I want to believe them, but unfortunately reality does not tend to be that linear. Source: CoinDesk (twitter) </li><li><a href="http://blog.nootch.net/2016/02/02/on-motivation-and-shipping/">On motivation, shipping and startups</a>: Great post on life in the start-up trenches. Source: Bruno Antunes (twitter) </li><li><a href="http://techcrunch.com/2016/01/18/why-big-companies-keep-failing-the-stack-fallacy/#.xiisrb:9sQZ">Why Big Companies Keep Failing: The Stack Fallacy</a>: Interesting hypothesis but not sure if totally buy it: "Stack fallacy is the mistaken belief that it is trivial to build the layer above yours.". Does seem to explain some behaviour that appears to be pretty irrational otherwise though. </li><li><a href="https://backchannel.com/the-next-social-media-we-want-and-need-2d03a7e0551c#.a07nlopz1">The Next Social Media We Want and Need!</a>: The next social media revolution, apparently. Some good ideas but as always, I fear they overestimate people's demand for privacy - unfortunately. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">General Coding</h2><div class="outline-text-2" id="text-3"><ul class="org-ul"><li><a href="http://www.nytimes.com/2016/01/26/business/marvin-minsky-pioneer-in-artificial-intelligence-dies-at-88.html">Marvin Minsky, Pioneer in Artificial Intelligence, Dies at 88</a>: Minsky is no more. Sad day for our field. </li><li><a href="https://medium.com/backchannel/marvin-minsky-s-marvelous-meat-machine-f436aec02fdf#.qcarjjdif">Marvin Minsky’s Marvelous Meat Machine</a>: Levy's eulogy to Minsky. I met Minsky through <a href="http://www.amazon.co.uk/Hackers-Heroes-Computer-Revolution-Anniversary/dp/1449388396/ref=sr_1_3?ie=UTF8&amp;qid=1453930109&amp;sr=8-3&amp;keywords=hackers">Hackers</a> so this is particularly poignant. </li><li><a href="http://blog.stephenwolfram.com/2016/01/farewell-marvin-minsky-19272016/">Farewell, Marvin Minsky (1927–2016)</a>: Wolfram's eulogy to Minsky. Most excellent and, dare I say, almost humble. </li><li><a href="https://github.com/blog/2042-git-2-5-including-multiple-worktrees-and-triangular-workflows">Git 2.5, including multiple worktrees and triangular workflows</a>: I seemed to have missed this extremely useful new feature in Git. If you have too, check it out. </li><li><a href="http://sealedabstract.com/rants/nanomsg-postmortem-and-other-stories/">nanomsg postmortem and other stories</a>: Extremely interesting post on FOSS projects, project governance and personalities. Hat tip: Bruno Antunes (twitter) </li><li><a href="http://www.iron.io/blog/2016/01/microcontainers-tiny-portable-containers.html">Microcontainers – Tiny, Portable Docker Containers</a>: <a href="http://www.iron.io/">iron.io</a> has a repo of Dockerfiles with really small images. Source: Hacker News (twitter) </li><li><a href="https://www.brianchristner.io/docker-is-moving-to-alpine-linux/">Docker Official Images are Moving to Alpine Linux</a>: After the whole excitement around <a href="http://www.iron.io/">iron.io</a>, we all started to pay attention to Alpine and it seems so did docker. It certainly would be great to have sensible sized base images, but not quite sure about using a different libc. Lets see how this plays out! Source: Hacker News (twitter) </li><li><a href="http://www.eweek.com/virtualization/coreos-launches-docker-rival-rkt-1.0.html">CoreOS Launches Docker Rival Rkt 1.0</a>: Rocket reaches 1.0. Still haven't used it, but still rooting on the sidelines - docker needs competition. Source: Hacker News (twitter) </li><li><a href="https://vimeo.com/56748054">Kevlin Henney - It Is Possible to Do Object-Oriented Programming in Java</a>: haven't seen it yet, but being a Kevlin presentation I recommend it without hesitation. Can't wait to watch it. </li><li><a href="https://yow.eventer.com/yow-2013-1080/the-solid-design-principles-deconstructed-by-kevlin-henney-1386">The SOLID Design Principles Deconstructed</a>: Another Henney special, next on the play list. </li><li><a href="http://web.media.mit.edu/~minsky/papers/sciam.inherit.html">Will Robots Inherit the Earth?</a>: As we morn Minsky, we start to rediscover his papers. Oldie but goodie. The man was a true genius. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-4"><h2 id="sec-4">Databases</h2><div class="outline-text-2" id="text-4"><ul class="org-ul"><li><a href="http://dailytechvideo.com/video-435-simon-riggs-databases-the-long-view/">Databases - the Long View</a>: good presentation on databases and Postgres in particular, giving you a perspective of how things changed over time. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-5"><h2 id="sec-5">C++</h2><div class="outline-text-2" id="text-5"><ul class="org-ul"><li><a href="https://github.com/ipkn/crow">Crow</a>: New find. Simple library to write web services in C++. If you need to quickly expose some code as a web service, this may be easier than using <a href="https://github.com/Microsoft/cpprestsdk">Casablanca</a>. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-6"><h2 id="sec-6">Layperson Science</h2><div class="outline-text-2" id="text-6"><ul class="org-ul"><li><a href="http://www.sciencefriday.com/segments/when-water-flows-uphill/">When Water Flows Uphill</a>: How science can be great fun. Dying to try this with my kids. Source: Hacker News (twitter) </li><li><a href="http://gizmodo.com/heres-why-finding-gravitational-waves-would-be-such-a-b-1752286165">Why Finding Gravitational Waves Would Be Such a Big Deal</a>: Layperson introduction to gravitational waves and why they are important. </li><li><a href="https://tincman.wordpress.com/2011/01/04/research-paper-management-with-emacs-org-mode-and-reftex/">Research Paper Management with Emacs, org-mode and RefTeX</a>: I personally have been using <a href="https://github.com/mcraveiro/referencer">Gnome Referencer</a> for my reference management, but I should have known there would be an Emacs solution. Will move over to this when I have the time. </li><li><a href="https://github.com/emacsmirror">Emacs Mirror</a>: Lots and lots of emacs packages. I am currently using this as an inspiration to find new packages such as <a href="https://github.com/emacsmirror/wsd-mode">wsd-mode</a>, a WebSequenceDiagrams mode - pretty nifty. Its all in ELPA/MELPA etc but somehow the GitHub interface seems to make it more discoverable? </li></ul></div></div> <div class="outline-2" id="outline-container-sec-7"><h2 id="sec-7">Other</h2><div class="outline-text-2" id="text-7"><ul class="org-ul"><li><a href="http://www.bbc.co.uk/iplayer/episode/b06vm9qp/empire-of-the-tsars-romanov-russia-with-lucy-worsley-1-reinventing-russia">Empire of the Tsars: Romanov Russia</a>: Great BBC documentary about Russian history. </li><li><a href="http://www.bbc.co.uk/iplayer/episode/b06y8hyr/the-brain-with-david-eagleman-1-what-is-reality">The Brain with David Eagleman</a>: BBC documentary about the brain. </li><li><a href="http://www.openculture.com/2012/08/bob_dylan_and_the_grateful_dead_rehearse_together_in_summer_1987_listen_to_74_tracks.html">Bob Dylan &amp; The Grateful Dead Rehearse Together in Summer 1987: Hear 74 Tracks</a>: The name says it all. Deeply personal tracks. </li><li><a href="http://www.neilgaiman.com/Cool_Stuff/Short_Stories/The_Return_of_the_Thin_White_Duke">The return of the Thin White Duke</a>: Gaiman on Bowie. Great read. </li></ul></div></div></div><div class="status" id="postamble"><p class="date">Created: 2016-02-08 Mon 22:29</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>

            <p class="text-muted">in 'Marco Craveiro' on February 10, 2016 09:14 AM. <a href="http://mcraveiro.blogspot.com/2016/02/nerd-food-interesting.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Nerd Food: Tooling in Computational Neuroscience - Part III: Data.</h4>

            Nerd Food: Tooling in Computational Neuroscience - Part III: Data<div id="content"><table border="0"><tbody><tr><td width="50%"></td><td width="50%"><p class="verse" style="text-align: left;"><small>In God we trust; all others must bring data. <i>-- <a href="https://en.wikipedia.org/wiki/W._Edwards_Deming">W. Edwards Deming</a></i></small></p></td></tr></tbody></table> <p>Welcome to yet another instalment in our series of posts about tooling in Computational Neuroscience. Previously, we have discussed <a href="http://mcraveiro.blogspot.co.uk/2015/11/nerd-food-tooling-in-computational.html">simulators</a> - a <a href="https://en.wikipedia.org/wiki/Neuron_(software)">popular one</a>, in particular - and <a href="http://mcraveiro.blogspot.co.uk/2015/11/nerd-food-tooling-in-computational_30.html">microscopes</a>. We shall now talk about <i>data</i> in Computational Neuroscience, a seemingly broad and somewhat mundane topic but one which is central to any attempt in understanding the <i>status quo</i> of the discipline. The target audience remains as it was - the lay person - but I'm afraid things are getting increasingly technical. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">More Data! We Need More Data!</h2><div class="outline-text-2" id="text-1"><p>Computational Neuroscience by itself is not particularly interesting if there are no inputs to the models we carefully craft nor detailed outputs to allow us to know what the models are doing. Similarly, one needs to be able to use experimental data to inform our modeling choices and in order to baseline expectations; if this data is not available, one cannot tell how close or how far models are from the real thing. As everywhere else, data is of crucial importance here; we need lots of it and of many different kinds. </p> <p>Once you need data, you soon need to worry about data representation: how should information be encoded? Clearly, in order for the data to be useful in a general sense, it must be accompanied by a formal or informal specification or else users will not know how to interpret it. Furthermore, given the highly technical nature of the data in question, the specification must be very precise or the data becomes useless or even dangerous; "Was that in microns or nanometres?" is not the sort of question you want to be asking. In a world where producers and consumers of data can be anywhere geographically, the specification assumes an ever larger degree of importance. </p> <p>In summary, it is just not practical to allow everyone to come up with their own data formats: </p> <ul class="org-ul"><li>writing a clear and concise specification for data interchange is hard work, and requires a lot of experience in both the domain and the specification process in general. The first attempts would probably prove to be incomplete, inconsistent or impractical. </li><li>writing code to read and write files according to a specification and in multiple programming languages is also demanding engineering work. </li><li>writing code to convert from one data specification to another is even more complicated because it requires intimate knowledge of both. </li><li>some data is generated directly by hardware, making it impractical to adapt to different requirements. </li></ul> <p>Another aspect worth highlighting is the "big data" nature of a lot of the data sets used in this field. Anything to do with the brain gets pretty complex pretty quickly, and this manifests itself in the data dimension by having ever larger data sets with greater levels of detail. On the plus side, thanks to Moore's Law <a href="https://en.wikipedia.org/wiki/Sigmoid_function">sigmoid</a>, detailed information at all levels is allowing us to answer questions that were unanswerable not so long ago. The flip side is that all those details come at a cost: the data sets are becoming <i>huge</i>. For example, the resolution of the data coming out of microscopy is now so high that a single data set can take as much as 500 TB. And of course, not only are individual data sets getting larger and larger, but we are able to generate more of them at an ever increasing pace because the processes are more streamlined. It is a fire-hose of data. </p> <p>All of these difficulties are not unique to Computational Neuroscience or even to Neuroscience as a whole, but the complexity of the domain has the effect of greatly exacerbating an already thorny problem. </p></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">Neuroinformatics to the Rescue</h2><div class="outline-text-2" id="text-2"><p>If you think we're exaggerating then think again. The management of data in Neuroscience is so complex <i>it is a field on its own right</i>, with the cool-sounding name of <a href="https://en.wikipedia.org/wiki/Neuroinformatics">Neuroinformatics</a>. Wikipedia tells us that: </p> <blockquote><p>Neuroinformatics is a research field concerned with the organization of neuroscience data by the application of computational models and analytical tools. These areas of research are important for the integration and analysis of increasingly large-volume, high-dimensional, and fine-grain experimental data. Neuroinformaticians provide computational tools, mathematical models, and create interoperable databases for clinicians and research scientists. </p></blockquote> <p>In layman's terms, Neuroinformatics concerns itself with Neuroscience data and the places where said data is to be stored. It is also implied that one has to deal with a variety of <i>types</i> of data, e.g.: data from experiments (of which there can be many kinds), model inputs, model outputs, the models themselves when viewed as data, etc. The classification of this data is in itself a Neuroinformatics task.  Finally, Neuroinformatics also is responsible for the tooling necessary to acquire the data, manipulate it, analyse it, visualise it and so on. Given such a broad definition, one is forced to conclude that there is a big overlap between Computational Neuroscience - the modeling activity - and Neuroinformatics - the management of the data required by it. This lack of clarity is common in science, particularly as new fields develop; take for example Mathematics and Computer Science at its inception. </p> <p>In truth, such definitions and demarcations are only as useful as the tangible benefits they provide. It is perhaps more fruitful to think of Neuroinformatics as a hat you don on as and when your Computational Science work requires; the definition is there then to allow one to be aware of the separation between the analytic work in modeling and the data storage / retrieval work. For the purposes of this article, we'll continue to refer to the "Neuroinformatics Scientist" and the Computational Neuroscientist personas, but bear in mind they may resolve to the same person in practice.<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.1" id="fnr.1" name="fnr.1">1</a></sup></p> <p>Before we move on, I'd like to point out another interesting challenge Neuroinformatics has to address, and one that is common to all Medical Sciences: the need to handle human-derived data very carefully. After all, making data sets available widely must not have implications for the original patients, so its often a requirement that the data is <i>de-identified</i>; in the cases where the data is patient sensitive, additional requirements may be made to users of the data to avoid leaking this information, such as requiring a registration, etc. This illustrates the peculiar nature of Neuroinformatics, with the constant tension between making data as widely available as possible but at the same time having to ensure there are no side-effects of doing so. Presumably, <i>Primum non nocere</i> - first, do no harm. </p></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">Databases, Repositories and Archives</h2><div class="outline-text-2" id="text-3"><p>Thanks to the efforts of Neuroinformatics, there is now a wealth of Neuroscience data available to all on the Internet. The roots of this growth were sowed in the nineties when labs started sharing research results online. Sharing always existed in one way or another, of course, but the rise of the Internet simply changed the magnitude of the process. It soon became apparent that there was a need to organise central repositories of data, and to ensure the consistency of the shared data. Papers with a distinct Neuroinformatics tone were written, such as <a href="http://www.ncbi.nlm.nih.gov/pubmed/9821633">An on-line archive of reconstructed hippocampal neurons</a> (1999). Repositories grew, multiplied, morphed and in many cases died, as these things do, and the evolutionary process left us with the survivors. I'd like to highlight some of the ones I have bumped into so far are (with descriptions in their own words): </p> <ul class="org-ul"><li><a href="https://senselab.med.yale.edu/modeldb/">ModelDB</a>: "ModelDB provides an accessible location for storing and efficiently retrieving computational neuroscience models. ModelDB is tightly coupled with NeuronDB. Models can be coded in any language for any environment. Model code can be viewed before downloading and browsers can be set to auto-launch the models." </li><li><a href="https://senselab.med.yale.edu/neurondb/">NeuronDB</a>: "NeuronDB provides a dynamically searchable database of three types of neuronal properties: voltage gated conductances, neurotransmitter receptors, and neurotransmitter substances. It contains tools that provide for integration of these properties in a given type of neuron and compartment, and for comparison of properties across different types of neurons and compartments." </li><li><a href="http://neuromorpho.org/">NeuroMorpho</a>: "NeuroMorpho.Org is a centrally curated inventory of digitally reconstructed neurons associated with peer-reviewed publications. It contains contributions from over 100 laboratories worldwide and is continuously updated as new morphological reconstructions are collected, published, and shared. To date, NeuroMorpho.Org is the largest collection of publicly accessible 3D neuronal reconstructions and associated metadata." </li><li><a href="http://fcon_1000.projects.nitrc.org/">Functional Connectomes Project</a>: "Following the precedent of full unrestricted data sharing, which has become the norm in molecular genetics, the FCP entailed the aggregation and public release (via www.nitrc.org) of over 1200 resting state fMRI (R-fMRI) datasets collected from 33 sites around the world." </li><li><a href="https://openfmri.org/">OpenfMRI</a>: "[…] project dedicated to the free and open sharing of functional magnetic resonance imaging (fMRI) datasets, including raw data." </li><li><a href="http://www.opensourcebrain.org/projects">Open Source Brain</a>: "resource for sharing and collaboratively developing computational models of neural systems." </li></ul> <p>As you can see from this small list - rather incomplete, I'm sure - there is a wealth of information out there, covering all sorts of aspects of the brain. We never had so much data as we do today. And, in many ways, this is fast becoming a problem. As an example, data from each of Neuroscience's plethora of divisions and sub-fields is not designed to talk to each other: Electron Microscopy (EM) data is disconnected from data obtained by Magnetic Resonance Imaging (MRI), which is also totally separate from connectome information<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.2" id="fnr.2" name="fnr.2">2</a></sup> and so forth. In many cases, these sub-fields have evolved in fairly separate paths, and developed their own technical vocabulary in isolation and over long periods of time - an approach perfectly suitable for a "disconnected" world but less than ideal for a world where multiple sources of data are required to make sense of complex phenomena. If one can't even agree on what to call things, how can one be able to explain them? </p> <p>Thus, the early Neuroinformatics approach is best described as "evolutionary". It is not as if someone sat down and generated a well defined set of file formats for data interchange, covering all different aspects of the areas under study. Instead, what has been emerging is a multitude of file formats in each sub-field, all calling out for attention, and all of them designed for the immediate goal at hand rather than the greater good of Neuroscience. </p></div></div> <div class="outline-2" id="outline-container-sec-4"><h2 id="sec-4">Taming the Sea of Data</h2><div class="outline-text-2" id="text-4"><p>From a Software Engineering perspective, an evolutionary approach makes perfect sense; after all, the <a href="http://c2.com/cgi/wiki?MakeItWorkMakeItRightMakeItFast">Real Programmers had said</a>: "first make it work, then make it right, and, finally, make it fast." In many ways, we are reaching the "make it right" phase, with an increasing interest in efforts towards the creation of broad standards. There have been several papers and initiatives on the subject, such as the Neuroscience Information Framework, or NIF, described in a paper: <a href="http://www.neuinfo.org/about/publications/nif_knowledge_environment.pdf">The Neuroscience Information Framework: A Data and Knowledge Environment for Neuroscience</a>. The paper outlined a lot of the problems that are hampering research, such as: </p> <ul class="org-ul"><li>the need for specialised search engines that are domain aware, and advanced query tools too; </li><li>the need to aid integration and to provide connectivity across related data and findings; </li><li>a requirement to provide new and enhanced forms of analysing existing data, as data reuse is extremely important - new insights can be obtained on already existing data, often long after the data was generated, and by using it in ways that were not at all envisioned by the original authors; </li><li>the need to make contribution to online repositories easier; lowering the "contribution barrier" is important to increase data availability but must be done in ways that do not compromise the quality of the data; </li><li>a requirement to make all code open source such that any lab can make use of it, and the community as a whole can share the maintenance load; </li><li>a need for an online repository for all tooling, to avoid reinventing the wheel; </li><li>the need to create a multi-domain standard vocabulary. </li></ul> <p>There are many worthwhile points in this paper, and it is highly recommended to anyone interested in the subject matter. For instance, the section discussing the design of the NIF also covers the requirements for any specification that wishes to solve the problems outlined above. They are worth highlighting as - in my humble and lay opinion - they are very well thought out. </p> <ul class="org-ul"><li>The design of such a framework must combine technical specifications choices and broad community support; "open data, access and exchange, via open source and platform, aid Framework-enabled open discover for Neuroscience." </li><li>A common framework would reduce costs and enhance benefits of data sharing and knowledge sharing; it would "reduce the cost/benefit ration for data acquisition and utilization." </li><li>The framework must be designed by the broader community and with the needs of this broader community in mind, and it must build upon prior development in Neuroinformatics. </li><li>A focus on interoperability is crucial, and it is not a static target but one that must be looked after over time. In addition, there is also a need to keep in mind that different resources have very different interoperability potential. In order to maximise interoperability, we should aim to standardise as much as possible all aspects of the process such as user interfaces, terminologies, formats, etc. </li></ul> <p>To the untrained eye, the NIF initiative appears to be a great effort to solve fundamental problems in the field. It also seems to have spawned and/or helped popularise many useful and lasting resources such as <a href="http://neuromorpho.org/">NeuroMorpho</a>. However, the impression one gets from the outside is that the NIF didn't quite fulfil all of its potential. Having said that, I am keenly looking for up-to-date documents that describe the current status across all of its many aspects - alas, I have not yet succeeded in finding any such document. If indeed it is the case that the initiative petered out, it did highlight a few potential problems for anyone working in this space: </p> <ul class="org-ul"><li>large undertakings are hard to pull off; small, organic, incremental changes are easier to do, but of course, that is why we have the problems we currently have. </li><li>large initiatives require large amounts of funding; work is technical and very expensive. </li><li>it is not easy to understand NIFs deliverables from looking at their documentationa and website. One can clearly see it was an ambitious project, and one which took on the brunt of the problem areas highlighted above, but perhaps it needed a slightly more self-contained view of their achievements rather than a whole-or-nothing approach. This allows preserving some components even whilst others are failing to gain traction. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-5"><h2 id="sec-5">XML strikes back</h2><div class="outline-text-2" id="text-5"><p>Another interesting attempt to tackle these problems is what I call the "XML suite". These are basically a set of different XML-based standards that are able to interoperate and augment each other, a bit like a stack of building blocks. You can find more details in this paper: <a href="http://www.brains-minds-media.org/archive/228#documentContent">XML for Model Specification in Neuroscience</a>. Some of the components of the XML Suite are (with descriptions on their own words, copied from the above paper and a link for more details): </p> <ul class="org-ul"><li><a href="http://lems.github.io/LEMS/">LEMS</a>: "the Low Entropy Model Specification […] is being developed to provide a compact, minimally redundant, human-readable, human-writable, declarative way of expressing models of biological systems. It differs from other systems such as CellML or SBML in its requirement to be human writable and the inclusion of basic physical concepts such as dimensionality and physical nesting as part of the language." </li><li><a href="https://www.neuroml.org/">NeuroML</a>: "supports the use of declarative model specifications for neuroscience modeling efforts at different scales, from intracellular mechanisms to networks of reconstructed neurons." </li><li><a href="https://www.neuroml.org/">MorphML</a>: "provides a common format for exchange of neuronal morphology data. It can also be used to specify cell structure for modeling efforts as part of NeuroML." </li><li><a href="http://neurobot.bio.auth.gr/2006/brainml-a-standard-xml-metaformat-for-exchanging-neuroscience-data/">BrainML</a>: "application for representing time series data, spike trains, experimental protocols, and other data relevant to neurophysiology experiments." </li><li><a href="http://www.sbml.org/">SBML</a>: "(Systems Biology Markup Language) is an application for specifying models of biochemical reaction networks such as metabolic networks, cell-signaling pathways and gene regulatory networks." </li><li><a href="https://www.cellml.org/">CellML</a>: "is designed for the specification of biological models of cellular and sub-cellular processes such as calcium dynamics, metabolic pathways, signal transduction, and electrophysiology." </li><li><a href="https://www.w3.org/Math/">MathML</a>: "provides the means for describing the structure and content of mathematical notation in order to serve, receive, and process mathematics on the web. Other XML applications often use MathML language elements for representing mathematical equations." </li></ul> <p>A positive aspect of the XML Suite is its "discrete" nature. Each of these file formats are free to evolve in isolation, and the nature of their cooperation is very loose in most cases. For example MathML is not at all related to Neuroscience and has the support of the Maths community (to some extent). In addition, the "stacking" approach is also a very interesting one, allowing a good domain focus. For example, NeuroML is built on top of LEMS, so in theory each of these should cover different domains and there should be minimal redundancy. </p> <p>The key challenge for the XML Suite is for each of their components to find a sustainable user base and sustainable funding to go along with it. This is a broader problem of Neuroinformatics: researchers do not want to spend time on work that is not contributing directly to their research and so the developer pool to do fundamental work on the file formats is limited. Once the developer pool becomes too limited, the file format ends up with a small user base because it is not fit for purpose, and thus starts a downward spiral. This appears to have been the fate of projects such as BrainML. </p></div></div> <div class="outline-2" id="outline-container-sec-6"><h2 id="sec-6">Conclusion</h2><div class="outline-text-2" id="text-6"><p>This post provided an overview of the data landscape in Computational Neuroscience and introduced the sub-field of Neuroinformatics. We also looked at some of the available data stores and reviewed a few of the more popular initiatives to solve the fundamental data problems in the field. </p> <p>Stay tuned for the next instalment! </p></div></div><div id="footnotes"><h2 class="footnotes">Footnotes: </h2><div id="text-footnotes"> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.1" id="fn.1" name="fn.1">1</a></sup> <p class="footpara">For a bit more details on the two fields see <a href="https://www.maths.nottingham.ac.uk/personal/sc/cnn/CNN2A.pdf">What are Computational Neuroscience and Neuroinformatics?</a></p></div> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.2" id="fn.2" name="fn.2">2</a></sup> <p class="footpara">"A connectome is a comprehensive map of neural connections in the brain, and may be thought of as its "wiring diagram". From <a href="https://en.wikipedia.org/wiki/Connectome">this</a> page. </p></div>  </div></div></div><div class="status" id="postamble"><p class="date">Created: 2016-02-08 Mon 21:41</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>

            <p class="text-muted">in 'Marco Craveiro' on February 08, 2016 09:41 PM. <a href="http://mcraveiro.blogspot.com/2016/02/nerd-food-tooling-in-computational.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Nerd Food: Interesting....</h4>

            Nerd Food: Interesting…<div id="content"><p>Time to flush all those tabs again. Some interesting stuff I bumped into recently-ish. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">Finance, Economics, Politics</h2><div class="outline-text-2" id="text-1"><ul class="org-ul"><li><a href="https://www.project-syndicate.org/commentary/marginal-pricing-end-of-western-oil-producers-by-anatole-kaletsky-2015-12">Why Big Oil Should Kill Itself</a>: This is a really, really interesting article. The gist of it is that the entire logic around oil exploration is now a fallacy and it makes more economic sense to simply give up looking for oil because all oil that is left is just to expensive to commercialise. It also has a very interesting take on the valuation of oil companies (and sources of take overs) but I won't spoil it for you. If you are into oil (or against it), its a must read. </li><li><a href="http://krugman.blogs.nytimes.com/2016/01/16/oil-goes-nonlinear/">Oil Goes Nonlinear</a>: Short but thought provoking. I don't tend to agree with Krugman on a lot of things, but quite like this analysis. </li><li><a href="http://foreignpolicy.com/2015/12/31/africas-boom-is-over/?utm_content=bufferc093b&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer">Africa’s Boom Is Over</a>: And the bad news continue. Totally spot on analysis of what will befall us. </li><li><a href="http://startupboy.com/2016/01/15/american-spring/">American Spring</a>: interesting take on the state of affairs of American politics. Not sure I agree with everything, but definitely food for thought. "Statistically speaking, what are the odds that the two most qualified candidates to be president out of 300 million people are siblings? Or married?" Indeed. </li><li><a href="https://www.project-syndicate.org/commentary/sovereign-default-wave-emerging-markets-by-carmen-reinhart-2015-12#Z3gIvCtPUzZmf8PF.01">A Year of Sovereign Defaults?</a>: Very good and very scary. This has to be on the cards, the only question is the timing. </li><li><a href="https://www.washingtonpost.com/news/wonk/wp/2015/12/30/really-rich-people-are-suddenly-paying-quite-a-bit-more-in-taxes/">Really rich people are suddenly paying quite a bit more in taxes</a>: some good news on the equality front I guess. But not quite sure it makes much of a difference in the big scheme of US things. </li><li><a href="http://www.latimes.com/world/mexico-americas/la-fg-argentina-economy-new-president-20151230-story.html">Argentina's 'little trees' getting chopped down by new president</a>: Seems like Argentina is going to go through yet another turbulent period, with some good and bad news coming out. Interesting take on the impact to the less well off of the new policies. The chap is certainly a doer, it seems: <a href="http://linkis.com/www.economist.com/ne/HiAjy">A fast start</a>. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">Startups et al.</h2><div class="outline-text-2" id="text-2"><ul class="org-ul"><li><a href="https://www.oreilly.com/ideas/the-wtf-economy">The WTF Economy</a>: Tim O'Reilly (of publishing house fame) is setting up a conference in the future of work. Sounds extremely interesting. Hopefully, they will have a section dedicated to the developing world.  Source: Tim O'Reilly (Twitter) </li><li><a href="https://medium.com/@jgarzik/bitcoin-is-being-hot-wired-for-settlement-a5beb1df223a#.vn9b7chtk">Bitcoin is Being Hot-Wired for Settlement</a>: Garzik is at it again. Interesting news of cryptos in the settlement front. Source: Jeff Garzik (Twitter) </li><li><a href="http://www.wired.com/2015/12/elon-musks-billion-dollar-ai-plan-is-about-far-more-than-saving-the-world/?mbid=social_fb">Elon Musk’s Billion-Dollar AI Plan Is About Far More Than Saving the World</a>: So it seems Musk and Altman want to ensure AI plays nice. Not quite sure he's right on this one. Steven Levy's version is available <a href="https://medium.com/backchannel/how-elon-musk-and-y-combinator-plan-to-stop-computers-from-taking-over-17e0e27dd02a#.f3ydovlgu">here</a>, more of an interview with Musk. </li><li><a href="https://medium.com/backchannel/license-to-not-drive-6dbea84b9c45#.w9jh0xlyw">License to (Not) Drive</a>: Levy gets to try the Google self-driving cars. Very interesting. </li><li><a href="http://arches.io/2016/01/hire-literally-anyone/">Hire Literally Anyone</a>: Extremely interesting. I always thought the existing hiring practices are not very well thought out, but this article makes me realise that the flaws are deeper than I expected. While we are on this topic, this ain't too bad either: <a href="https://medium.com/swlh/how-to-hire-34f4ded5f176#.mb0pcnhda">How to Hire</a>. </li><li><a href="https://medium.com/@octskyward/the-resolution-of-the-bitcoin-experiment-dabb30201f7#.vk8lilnkk">The resolution of the Bitcoin experiment</a>: Great - nay - insanely great analysis on the state of affairs in the BTC world. Spoken with authority. </li><li><a href="https://tonyarcieri.com/on-the-dangers-of-a-blockchain-monoculture">On the dangers of a blockchain monoculture</a>: Pours more petrol in the raging BTC fire. Very interesting. Never saw BTC as a monoculture, but actually it so is. </li><li><a href="http://www.bloomberg.com/news/articles/2015-12-30/the-final-days-of-the-bitcoin-foundation-">The Final Days of the Bitcoin Foundation?</a>: And yet some more on the BTC impending doom. I just gotta stop reading about it now, the whole saga is far too depressing. Lets hope the technology survives where humans failed. </li><li><a href="http://www.coindesk.com/ibm-open-ledger-blockchain/?utm_content=buffer601ae&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer">IBM Talks Open Ledger Project, Bright Future for Blockchain</a>: Still trying to catch my breath on all the BTC articles coming out, and lo-and-behold, I missed the whole Open Ledger thing. </li><li><a href="https://www.policyalternatives.ca/publications/monitor/apploitation-city-instaserfs">Apploitation in a city of instaserfs</a>: Scary. Very scary. Reminiscent of the older Mirani article <a href="http://qz.com/312537/the-secret-to-the-uber-economy-is-wealth-inequality/">The secret to the Uber economy is wealth inequality</a>. San Francisco is becoming more like Mumbai and that is not good news. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">General Coding</h2><div class="outline-text-2" id="text-3"><ul class="org-ul"><li><a href="https://medium.com/@henrikjohansen/feeding-graph-databases-a-third-use-case-for-modern-log-management-platforms-d5dac8a80d53#.tqmmc91uy">Feeding Graph databases - a third use-case for modern log management platforms</a>: Very interesting ideas on how to use logging data in a graph database. Sounds extremely counter-intuitive, and then you start reading at which point its like "Damn, why didn't I think of that before!".  Source: Hacker News </li><li><a href="http://www.agner.org/optimize/blog/read.php?i=417">Moores law hits the roof</a>: Seems like the exponential function is revealing itself as a sigmoid, as everyone knew it would. Some of the cracks that are already present in Moore's law. Interesting to note that a transistor is now only a few silicon atoms wide - meaning we can't really make it much smaller. Source: Hacker News </li><li><a href="http://robotlolita.me/2016/01/09/no-i-dont-want-to-configure-your-app.html">No, I Don't Want To Configure Your App</a>: Call to arms to get us all thinking on just how many configuration knobs you need to use something. Source: Hacker News </li><li><a href="http://jameshunt.us/writings/your-ide-is-killing-you.html">Your IDE Is Killing You</a>: Somewhat preaching to the choir, since I am an Emacs user of old, but still a very cogent argument on why relying too much on IDEs is not a good thing. Source: Bruno Antunes (twitter) </li><li><a href="http://jlongster.com/Starters-and-Maintainers">Starters and Maintainers</a>: The different personas around an open source project. Interesting, its good to be aware of which hat you are wearing when. </li><li><a href="https://medium.com/backchannel/i-moved-to-linux-and-it-s-even-better-than-i-expected-9f2dcac3f8fb#.aakpzoln9">I Moved to Linux and It’s Even Better Than I Expected</a>: A feel good story about the Linux desktop. Given how slowly things are progressing on that front, we all need one of these some times to cheer us up. Main value of the article though. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-4"><h2 id="sec-4">Databases</h2><div class="outline-text-2" id="text-4"><ul class="org-ul"><li><a href="http://lwn.net/Articles/667946/">Encrypted databases with ZeroDB</a>: I'm not exactly impressed with the technology itself, but more with the ideas one can extract from it. Briefly: what if the database only stores encrypted data, which only each client can decrypt? This is certainly a very useful thing for certain types of information and a PostgreSQL extension would be most useful. Source: Hacker News </li><li><a href="http://rachbelaid.com/introduction-to-postgres-physical-storage/">Introduction to PostgreSQL physical storage</a>: Great article on Postgres low-level details. One to read if you want to get serious about the Elephant but are not yet in the know. </li><li><a href="http://tech.valgog.com/2012/01/schema-based-versioning-and-deployment.html">Schema based versioning and deployment for PostgreSQL</a>: Tips on how to manage versions for your stored procs, and also contains links for table management. For those of us not totally taken by NoSQL. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-5"><h2 id="sec-5">C++</h2><div class="outline-text-2" id="text-5"><ul class="org-ul"><li><a href="http://webcache.googleusercontent.com/search?q=cache:z7PWAldSxdQJ:sourceforge.net/p/sobjectizer/wiki/Lessons%252520learnt%252520from%25252010%252B%252520years%252520with%252520actors%252520in%252520C%252B%252B/+&amp;cd=1&amp;hl=en&amp;ct=clnk&amp;gl=uk">Lessons learnt from 10+ years with actors in C++</a>: The voice of experience talks about what they learned from using Actors over more than a decade. Worth reading if you are into that pattern. </li><li><a href="http://blog.scottfrees.com/automating-a-c-program-from-a-node-js-web-app">Automating a C++ program from a Node.js web app</a>: If you are considering exposing your C++ code into JS, this is a series of posts to read. </li><li><a href="https://medium.com/swlh/starting-a-tech-startup-with-c-6b5d5856e6de#.tocwuwbe8">Starting a tech startup with C++</a>: lots of libraries I never heard of and an insight on the performance differences between python and c++. </li><li><a href="https://medium.com/hacker-daily/writing-high-performance-servers-in-modern-c-7cd00926828#.hksbtpyoh">Writing modern C++ servers using Wangle:</a> The follow up to the previous post, explaining how to write servers with Facebook technologies. </li><li><a href="http://www.di.unipi.it/~nids/docs/i_want_my_pony_or_why_you_cannot_have_cpp_exceptions_with_a_stack_trace.html">I want my pony! Or why you cannot have C++ exceptions with a stack trace</a>: very interesting. Since I started using Boost.Exception I never missed the stack traces either. Source: Hacker News </li></ul></div></div> <div class="outline-2" id="outline-container-sec-6"><h2 id="sec-6">Layman Science</h2><div class="outline-text-2" id="text-6"><ul class="org-ul"><li><a href="http://www.forbes.com/sites/startswithabang/2015/12/23/why-string-theory-is-not-science/">Why String Theory Is Not A Scientific Theory</a>: Doesn't say a lot of new things, but its good to remind ourselves on what exactly do we mean when we say "Science". This would save us from a lot of grief, such as considering Economics as a Science. </li><li><a href="https://aeon.co/essays/why-do-scientists-dismiss-the-possibility-of-cold-fusion">The cold fusion horizon</a>: … talking about Science, I was surprised to find out that people are still talking seriously about cold fusion. Interesting article, because it takes the flip side of the Science coin: nothing should <i>not</i> be science unless it is <i>not</i>using the scientific method. Whilst up til now cold fusion has been more of a hoax, we should not discredit people who work on it provided they are following scientific principles. Who knows, they may be right in the end. Science is all about long-shots. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-7"><h2 id="sec-7">Other</h2><div class="outline-text-2" id="text-7"><ul class="org-ul"><li><a href="http://www.blastr.com/2015-12-23/exit-sandman-neil-gaiman-goes-depth-overture-one-2015s-best-comics">Exit Sandman: Neil Gaiman goes in-depth with Overture, one of 2015's best comics</a>: For the Sandman fans, the new (and last) Sandman book is all the rage. A great interview by the man himself. </li><li><a href="https://www.youtube.com/watch?v=MpkqfZ95jtw">Dear Zachary</a>: bumped into this via <i>Wait But Why</i>, and, as usual, great tip. Fantastic documentary. </li><li><a href="https://www.youtube.com/watch?v=GG9Anstjlro&amp;feature=youtu.be">Solaris</a>: Always wanted to watch this Tarkovsky movie and now it seems it is available online! This is part of an initiative described by Open Culture <a href="http://www.openculture.com/2010/07/tarkovksy.html">here</a>. Source: Bruno Antunes (twitter) </li><li><a href="https://www.youtube.com/watch?v=8BoKjQfMihs">Wittgenstein: A Wonderful Life</a>: Found a Wittgenstein documentary, but sadly haven't had time to watch it just yet. In my watch list though. </li><li><a href="http://therealnews.com/t2/index.php?option=com_content&amp;task=view&amp;id=31&amp;Itemid=74&amp;jumival=14293">Je ne suis pas Charlie</a>: Haven't yet watched it but seems thought-provoking. Watch listed. </li><li><a href="https://www.youtube.com/watch?v=THKCteQocns">Tulipa Ruiz - Efêmera - Album Completo</a>: New musical find in the Brazilian space (Portuguese). </li></ul></div></div></div><div class="status" id="postamble"><p class="date">Created: 2016-01-18 Mon 12:49</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>

            <p class="text-muted">in 'Marco Craveiro' on January 18, 2016 12:52 PM. <a href="http://mcraveiro.blogspot.com/2016/01/nerd-food-interesting.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Nerd Food: On Product Backlog.</h4>

            Nerd Food: On Product Backlog<div id="content"><table border="0"><tbody><tr><td width="50%"></td><td width="50%"><p class="verse" style="text-align: left;"><small>Would be be good to have a better bug-tracking setup? Yes. But I think it takes man-power, and it would take something *fundamentally* better than bugzilla. <i>-- <a href="http://yarchive.net/comp/linux/bug_tracking.html">Linus</a></i></small></p></td></tr></tbody></table> <p>Many developers in large companies tend to be exposed to a strange variation of agile which I like to call "Enterprise Grade Agile", but I've also heard it called "Fragile" and, most aptly, "Cargo-Cult Agile". However you decide to name the phenomena, the gist of it is that these setups contain nearly all of the ceremony of agile - including stand-ups, sprint planning, retrospectives and so on - but none of its spirit. Tweets such as this are great at capturing the essence of the problem: </p> <blockquote class="twitter-tweet" lang="en"><p dir="ltr" lang="en">Top tip: if you need to bring a notepad to the daily stand up to tell us what you did yesterday that's too many details</p>— Fran Buontempo (@fbuontempo) <a href="https://twitter.com/fbuontempo/status/686856528696086528">January 12, 2016</a></blockquote>  <p>Once you start having that nagging feeling of doing things "because you are told to", and once your stand-ups become more of a status report to the "project manager" and/or "delivery manager" - the existence of which, in itself, is rather worrying - your Cargo Cult Agile alarm bells should start ringing. As I see it, agile is a toolbox with a number of tools, and they only start to add value once you've adapted them to your personal circumstances. The fitness function that determines if a tool should be used is how much value it adds to all (or at least most) of its users. If it does not, the tool must be further adapted or removed altogether. And, crucially, you learn about agile tools by using them and by reflecting on the lessons learned. There is no other way. </p> <p>This post is one such exercise and the tool I'd like to reflect on is the <i>Product Backlog</i>. Now, before you read through the whole rant, its probably worth saying that this post takes a slightly narrow and somewhat "advanced" view of agile, with a target audience of those already using it. If you require a more introductory approach, you are probably better off looking at other online resources such as <a href="http://zerodollarbill.blogspot.co.uk/2012/06/how-to-learn-scrum-in-10-minutes-and.html">How to learn Scrum in 10 minutes and clean your house in the process</a>. Having said that, I'll try to define terms best I can to make sure we are all on the same page. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">Working Definition</h2><div class="outline-text-2" id="text-1"><p>Once your company has grokked the basics of agile and starts to move away from those lengthy specification documents - those that no one reads properly until implementation and those that never specified anything the customer wanted, but everything we thought the customer wanted and then some - you will start to use the product backlog in anger. And that's when you will realise that it is not quite as simple as memorising text books. </p> <p>So what do the "text books" say? Let's take a fairly typical definition - this one from <a href="https://en.wikipedia.org/wiki/Scrum_(software_development)">Scrum</a>: </p> <blockquote><p>The agile product backlog in Scrum is a prioritized features list, containing short descriptions of all functionality desired in the product. When applying Scrum, it's not necessary to start a project with a lengthy, upfront effort to document all requirements. Typically, a Scrum team and its product owner begin by writing down everything they can think of for agile backlog prioritization. This agile product backlog is almost always more than enough for a first sprint. The Scrum product backlog is then allowed to grow and change as more is learned about the product and its customers.<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.1" id="fnr.1" name="fnr.1">1</a></sup></p></blockquote> <p>This is a good working definition, which will suffice for the purposes of this post. It is deceptively simple. However, as always, one must remember Yogi Berra: "In theory, there is no difference between theory and practice. But in practice, there is." </p></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">Potmenkin Product Backlogs</h2><div class="outline-text-2" id="text-2"><p>Many teams finish reading one such definition, find it amazingly inspiring, install the "agile plug-in" on their bug-tracking software of choice and then furiously start typing in those tickets. But if you look closely, you'd be hard-pressed to find any difference between the bug tickets of old versus the "stories" in the new and improved "product backlog" that apparently you are now using. </p> <p>This is a classic management disconnect, whereby a renaming exercise is applied and suddenly, <a href="https://en.wikipedia.org/wiki/Potemkin_village">Potemkin village-style</a>, we are now in with the kool kids and our company suddenly becomes a modern and desirable place to work. But much like Potemkin villages were not designed for real people to live in, so "Potmenkin Product Backlogs" are not designed to help you manage the lifecycle of a real product; they are there to give you the <i>appearance</i> of doing said management, for the purposes of reporting to the higher eschelons and so that you can tell stakeholders that "their story has been added to the product backlog for prioritisation". </p> <p>Alas, very soon you will find that the bulk of the "user stories" are nothing but glorified one-liners that no one seems to recall what exactly they're supposed to mean, and those few elaborately detailed tickets end up rotting because they keep being deprioritised and now describe a world long gone. Soon enough you will find that your sprint planning meetings will cover less and less of the product backlog - after all, who is able to prioritise this mess?  Some stories don't even make any sense! The final act is when all stories worked on are stories raised directly on the sprint backlog, and the product backlog is nothing but the dumping ground for the stories that didn't make it on a given sprint. At this stage, the product backlog is in such a terrible mess that no one looks at it, other than for the occasional historic search for valuable details on how a bug was fixed. Eventually the product backlog is zeroed - maybe a dozen or so of the most recent stories make it through the cull - and the entire process begins anew. Alas, enlightenment is never achieved, so you are condemned to repeat this cycle for all eternity. </p> <p>As expected, the Potmenkin Product Backlog adds very little value - in fact it can be argued that it detracts value - but it must be kept because "agile requires a product backlog". </p></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">Bug-Trackers: Lessons From History</h2><div class="outline-text-2" id="text-3"><p>In order to understand the difficulties with a product backlog, we turn next to their logical predecessors: bug-tracking systems such as <a href="https://www.bugzilla.org/">Bugzilla</a> or <a href="https://www.atlassian.com/software/jira">Jira</a>. This post starts with a quote from the kernel's Benevolent Dictator that illustrates the problem with these. Linus has long taken the approach that there is no need for a bug-tracker in kernel development, although he does not object if someone wants to use one for a subsystem. You may think this is a very primitive approach but in some ways it is also a <i>very</i> modern approach, very much in line with agile; if you have a bug-tracking system which is taking time away from developers without providing any value, you should <i>remove</i> the bug-tracking system. In kernel development, there simply is no space for ceremony - or, for that matter, for anything which slows things down<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.2" id="fnr.2" name="fnr.2">2</a></sup>. </p> <p>All of which begs the question: what makes bug-tracking systems so useless? From experience, there are a few factors: </p> <ul class="org-ul"><li>they are a "fire and forget" capture system. Most users only care about entering new data, rather than worrying about the lifecycle of a ticket. Very few places have some kind of "ticket quality control" which ensures that the content of the ticket is vaguely sensible, and those who do suffer from another problem: </li><li>they require dedicated teams. By this I don't just mean running the bug-tracking software - which you will most likely have to do in a proprietary shop; I also mean the entire notion of Q&amp;A and Testing as separate from development, with reams of people dedicated to setting "environments" up (and keeping them up!), organising database restores and other such activities that are incompatible with current best practices of software development. </li><li>they are temples of ceremony: a glance at the myriad of fields you need to fill in - and the rules and permutations required to get them exactly right - should be sufficient to put off even the most ardent believer in process. Most developers end up memorising some safe incantation that allows them to get on with life, without understanding the majority of the data they are entering. </li><li>as the underlying product ages, you will be faced with <a href="http://tinyletter.com/programming-beyond-practices/letters/the-sad-graph-of-software-death">the sad graph of software death</a>. The main problem is that resources get taken away from systems as they get older, a phenomena that manifests itself as a growth in the delta between the number of open tickets against the number of closed tickets. This is actually a <i>really</i> useful metric but one that is often ignored.<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.3" id="fnr.3" name="fnr.3">3</a></sup>. </li></ul> <p>And what of the newest iterations on this venerable concept such as <a href="https://guides.github.com/features/issues/">GitHub Issues</a>? Well, clearly they solve a number of the problems above - such as lowering the complexity and cost barriers - and certainly they do serve a very useful purpose: they allow the efficient management of user interactions. Every time I create an issue - such as this <a href="https://github.com/flycheck/flycheck/issues/852">one</a> - it never ceases to amaze me how easily the information flows within GitHub projects; one can initiate comms with the author(s) or other users with <i>zero setup</i> - something that previously required mailinglist membership, opening an account on a bug-tracker and so forth. We now take all of this for granted, of course, but it is important to bear in mind that many open source projects would probably not even have <i>any</i> form of user interaction support, were it not for GitHub. After all, most of them are a one-person shop with very little disposable time, and it makes no sense to spend part of that time maintaining infrastructure for the odd person or two who may drop by to chat. </p> <p>However, for all of its glory, it is also important to bear in mind that GitHub Issues is <b>not</b> a product backlog solution. What I mean by this is that the product backlog must be owned by the team that owns the product and, as we shall see, it must be carefully groomed if it is to be continually useful. This is at loggerheads with allowing free flow of information from users. Your Issues will eventually be filled up with user requests and questions which you may not want to address, or general discussions which may or may not have a story behind it. They are simply different tools for different jobs, albeit with an overlap in functionality. </p> <p>So, history tells us what does not work. But is the product backlog even worth all this hassle? </p></div></div> <div class="outline-2" id="outline-container-sec-4"><h2 id="sec-4">Voyaging Through Strange Seas of Thought</h2><div class="outline-text-2" id="text-4"><p>One of the great things about agile is how much it reflects on itself; a strange loop of sorts. Presentations such as Kevlin Henney's <a href="http://www.infoq.com/presentations/architecture-uncertainty">The Architecture of Uncertainty</a> are part of this continual process of discovery and understanding, and provide great insights about the fundamental nature of the development process. The product backlog plays - or should play - a crucial role exactly because of this uncertain nature of software development. We can explain this by way of a device. </p> <p>Imagine that you start off by admitting that you know very little about what it is that you are intending to do and that the problem domain you are about to explore is vast and complex. In this scenario, the product backlog is the sum total of the knowledge gained whilst exploring this space that has yet not been transformed into source code. Think of it like the explorer's maps in the fifteen-hundreds. In those days, "users" knew that much of it was incorrect and a great part was sketchy and ill-defined, but it was all you had. Given that the odds of success were stacked against you, you'd hold that map pretty tightly while the storms were raging about you. Those that made it back would provide corrections and amendments and, over time, the maps eventually converged with the real geography. </p> <p>The product backlog does something similar, but of course, the space you are exploring does not have a fixed geometry or topography and your knowledge of the problem domain can actively <i>change</i> the domain itself too - an unavoidable consequence of dealing with pure thought stuff. But the general principle applies. Thus, in the same way <a href="http://www.joelonsoftware.com/articles/fog0000000069.html">a code base is precious</a> because it embodies the sum total knowledge of a domain - heck, in many ways it <i>is</i> the sum total knowledge of a domain! - so the product backlog is precious because it captures all the known knowledge of these yet-to-be-explored areas. In this light, you can understand statements such as this: </p> <blockquote class="twitter-tweet" lang="en"><p dir="ltr" lang="en">When your product backlog is empty, your product is dead - <a href="https://twitter.com/KevlinHenney">@KevlinHenney</a><a href="https://twitter.com/hashtag/agileotb?src=hash">#agileotb</a></p>— Marc Johnson (@marcjohnson) <a href="https://twitter.com/marcjohnson/status/507522331900915712">September 4, 2014</a></blockquote> <p>So, if the backlog is this important, how should one manage it? </p></div></div> <div class="outline-2" id="outline-container-sec-5"><h2 id="sec-5">Works For Me, Guv!</h2><div class="outline-text-2" id="text-5"><p>Up to this point - whilst we were delving into the problem space - we have been dealing with a fairly general argument, likely applicable to many. Now, as we enter the solution space, I'm afraid I will have to move from the general to the particular and talk only about the specific circumstances of my one-man-project <a href="https://github.com/DomainDrivenConsulting/dogen">Dogen</a>. You can find Dogen's product backlog <a href="https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/product_backlog.org">here</a>. </p> <p>This may sound like a bit of a cop out, you may say, and not without reason: how on earth are you supposed to extrapolate conclusions from a one-person open source project to a team of N working on a commercial product? However, it is also important to take into account what I said at the start: agile is what you make of it. I personally think of it as a) the smallest amount of processes required to make your development process work smoothly and b) and the continual improvement of those processes. Thus, there are no one-size-fits-all solutions; all one can do is to look at others for ideas. So, lets look at my findings<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.4" id="fnr.4" name="fnr.4">4</a></sup>. </p> <p>The first and most important thing I did to help me manage my product backlog was to use a simple text file in <a href="http://orgmode.org/">Org Mode</a> notation. Clearly, this is not a setup that is workable for a development team much larger than a set of one, or one that doesn't use Emacs (or <a href="https://github.com/hsitz/VimOrganizer">Vim</a>). But for my particular circumstances it has worked <i>wonders</i>: </p> <ul class="org-ul"><li>the product backlog is close to the code, so wherever you go, you take it with you. This means you can always search the product backlog and - most importantly - add to it <i>wherever</i> you are and <i>whenever</i> an idea happens to come by. I use this flexibility frequently. </li><li>the Org Mode interface makes it really easy to move stories up and down (order is taken to mean priority here) and to create "buckets" of stories according to whatever categorisation you decide to use, up to any level of nesting. At some point you end up converging to a reasonable level of nesting, of course. It is surprising how one can manage <b>very</b> large amounts of stories thanks to this flexible tree structure. </li><li>it's trivial to move stories in and out of a sprint, keeping track of all changes to a story - they are just text that can be copy and pasted and committed. </li><li>Org Mode provides a very capable <a href="http://orgmode.org/manual/Tags.html">tagging system</a>. I first started by overusing these, but when tagging got too fine grained it became unmaintainable. Now we use too few - just <code>epic</code> and <code>story</code> - so this will have to change again in the near future. For example, it should be trivial to add tags for different components in the system or to mark stories as bugs or features, etc. <a href="http://orgmode.org/manual/Tag-searches.html#Tag-searches">Searching</a> then allows you to see a subset of the stories that match those labels. </li></ul> <p>A second decision which has proven to be a very good one has been to groom the product backlog <i>very often</i>. And by this I don't just mean a cursory look, but a deep inspection of <i>all</i> stories, fixing them where required. Again, the choice of format has proved very helpful: </p> <ul class="org-ul"><li>it is easy to mark all stories as "non-reviewed" or some other suitable tag in Org Mode, and then unmark them as one finishes the groom - thereby ensuring all stories get some attention. As the product backlog becomes larger, a full groom could take multiple sprints, but this is not an issue once you understand its value and the cost of having it rot. </li><li>because the product backlog is with the code, any downtime can be used for grooming; those idle weekends or that long wait at the airport are perfect candidates to get a few stories looked at. Time spent waiting for the build is also a good candidate. </li><li>you get an HTML representation of the Org Mode file for free in GitHub, meaning you can read your backlog from your phone. And with the new editing functionality, you can also edit stories too. </li></ul> <p>Thirdly, I decided to take a "multi-pass" approach at managing the story lifecycle. These are some of the key aspects of this lifecycle management: </p> <ul class="org-ul"><li>stories can only be captured if they are aligned with the <a href="https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/vision.org">vision</a>. This filter saves me from adding all sorts of ideas which are just too "out of the left field" to be of practical use, but keeps <a href="https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/product_backlog.org#visionary-work-and-random-ideas">those that may sound crazy</a> are but aligned with the vision. </li><li>stories can only be captured if there is no "prior art". I always perform a number of searches in the backlog to look for anything which covers similar ground. If found, I append to that. </li><li>new stories tend to start with very little content - just the minimum required to allow resetting state back to the idea I was trying to capture. Due to this, very little gets lost. At this point, we have a "proto-story". </li><li>as time progresses, I end up having more ideas on this space, and I update the story with those ideas - mainly bullet points with one liners and links. </li><li>at some point the story begins to mature; there is enough on it that we can convert the "proto-story" to a full blown story. After a number of grooms, the story becomes fully formed and is then a candidate to be moved to a sprint backlog for implementation. It may stay in this state <i>ad-infinitum</i>, with periodic updates just to make sure it does not rot. </li><li>A candidate story can still get refined: trimmed in scope, re-targeted, or even cancelled because it no longer fits with the current architecture or even the vision. Cancelled stories are important because we may came back to them - its just very unlikely that we do. </li><li>every sprint has a "sprint mission"<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.5" id="fnr.5" name="fnr.5">5</a></sup>. When we start to move stories into the sprint backlog, we look for those which resonate with the sprint mission. Not all of them are fully formed, and the work on the sprint can entail the analysis required to create a full blown story. But many will be implementable directly off of the product backlog. </li><li>some times I end up finding related threads in multiple stories and decide to merge them. Merging of related stories is done by simply copying and pasting them into a single story; over time, with the multiple passes done in the grooms, we end up again with a single consistent story. </li></ul> <p>What all of this means is that a story can evolve over time in the product backlog, only to become the exact thing you need at a given sprint; at that point you benefit from the knowledge and insight gained over that long period of time. Some stories in Dogen's backlog have been there for years, and when I finally get to them, I find them extremely useful. Remember: they are a map to the unknown space you are exploring. </p> <p>With all of this machinery in place, we've ended up with a very useful product backlog for Dogen - one that certainly adds a lot of value. Don't take me wrong, the cost of maintenance is high and I'd rather be coding instead of maintaining the product backlog, especially given the limited resources. But I keep it because I can see on a daily basis how much it improves the overall quality of the development process. It is a price I find worth paying, given what I get in return. </p></div></div> <div class="outline-2" id="outline-container-sec-6"><h2 id="sec-6">Final Thoughts</h2><div class="outline-text-2" id="text-6"><p>This post was an attempt to summarise some of the thoughts I've been having on the space of product backlogs. One of its main objectives was to try to convey the importance of this tool, and to provide ideas on how you can improve the management of your own product backlog by discussing the approach I have taken with Dogen. </p> <p>If you have any suggestions or want to share your own tips on how to manage your product backlog please reach me on the comments section - there is always space for improvement. </p></div></div><div id="footnotes"><h2 class="footnotes">Footnotes: </h2><div id="text-footnotes"> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.1" id="fn.1" name="fn.1">1</a></sup> <p class="footpara">Source: <a href="https://www.mountaingoatsoftware.com/agile/scrum/product-backlog">Scrum Product Backlog</a>, Mountain Goat Software. </p></div> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.2" id="fn.2" name="fn.2">2</a></sup> <p class="footpara">A topic which I covered some time ago here: <a href="http://mcraveiro.blogspot.co.uk/2008/06/nerd-food-on-evolutionary-methodology.html">On Evolutionary Methodology</a>. It is also interesting to see how the kernel processes are organised for speed: <a href="http://lwn.net/Articles/670209/">How 4.4's patches got to the mainline</a>. </p></div> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.3" id="fn.3" name="fn.3">3</a></sup> <p class="footpara">Another topic which I also covered here some time ago: <a href="http://mcraveiro.blogspot.co.uk/2007/05/nerd-food-on-maintenance.html">On Maintenance</a>. </p></div> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.4" id="fn.4" name="fn.4">4</a></sup> <p class="footpara">I am self-plagiarising a little bit here and rehashing some of the arguments I've used before in <a href="http://mcraveiro.blogspot.co.uk/2014/09/nerd-food-dogen-lessons-in-incremental.html">Lessons in Incremental Coding</a>, mainly from section DVCS to the Core. </p></div> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.5" id="fn.5" name="fn.5">5</a></sup> <p class="footpara">See the <a href="https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/sprint_backlog_78.org">current sprint backlog</a> for an example. </p></div>  </div></div></div><div class="status" id="postamble"><p class="date">Created: 2016-01-17 Sun 23:55</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>

            <p class="text-muted">in 'Marco Craveiro' on January 18, 2016 12:01 AM. <a href="http://mcraveiro.blogspot.com/2016/01/nerd-food-on-product-backlogs.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Nerd Food: Dogen: The Package Management Saga.</h4>

            Nerd Food: Dogen: The Package Management Saga<div id="content"><p>We've just gone past <a href="https://github.com/DomainDrivenConsulting/dogen">Dogen's</a> <a href="https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/sprint_backlog_75.org">Sprint 75</a>, so I guess it's time for one of those "reminiscing posts" - something along the lines of what we did for <a href="http://mcraveiro.blogspot.co.uk/2014/09/nerd-food-dogen-lessons-in-incremental.html">Sprint 50</a>. This one is a bit more practical though; if you are only interested in the practical side, keep scrolling until you see "Conan". </p> <p>So, package management. Like any other part-time C++ developer whose professional mainstay is C# and Java, I have keenly felt the need for a package manager when in C++-land. The problem is less visible when you are working with mature libraries and dealing with just Linux, due to the huge size of the package repositories and the great tooling built around them. However, things get messier when you start to go cross-platform, and messier still when you are coding on the bleeding edge of C++: either the package you need is not available in the distro's repos or even <a href="https://launchpad.net/ubuntu/+ppas">PPA's</a>; or, when it is, its rarely at the version you require. </p> <p>Alas, for all our sins, that's exactly where we were when <a href="https://github.com/DomainDrivenConsulting/dogen">Dogen</a> got started. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">A Spoonful of Dogen History</h2><div class="outline-text-2" id="text-1"><p>Dogen sprung to life just a tad after C++-0x became <a href="https://en.wikipedia.org/wiki/C%252B%252B11">C++-11</a>, so we experienced first hand the highs of a quasi-new-language followed by the lows of feeling the brunt of the bleeding edge pain. For starters, <i>nothing</i> we ever wanted was available out of the box, on any of the platforms we were interested in. Even Debian testing was a bit behind - probably stalled due to a compiler transition or other, but I can't quite recall the details. In those days, Real Programmers were Real Programmers and mice were mice: we had to <a href="http://mcraveiro.blogspot.co.uk/2012/06/nerd-food-c-11-with-gcc.html">build and install the C++ compilers ourselves</a> and, even then, C++-11 support was new, a bit flaky and limited. We then had to use those compilers to compile all of the dependencies in C++-11 mode. </p></div> <div class="outline-3" id="outline-container-sec-1-1"><h3 id="sec-1-1">The PFH Days</h3><div class="outline-text-3" id="text-1-1"><p>After doing this manually once or twice, it soon stopped being fun. And so we solved this problem by creating the PFH - the Private Filesystem Hierarchy - a gloriously over-ambitious name to describe a set of wrapper scripts that helped with the process of downloading tarballs, unpacking, building and finally installing them into well-defined locations. It worked well enough in the confines of its remit, but we were often outside those, having to apply out-of-tree patches, adding new dependencies and so on. We also didn't use Travis in those days - not even sure it existed, but if it did, the rigmarole of the bleeding edge experience would certainly put a stop to any ideas of using it. So we used a local install of CDash with a number of build agents on OSX, Windows (MinGW) and Linux (32-bit and 64-bit). Things worked beautifully when nothing changed and the setup was stable; but, every time a new version of a library - or god forbid, of a compiler - was released, one had that sense of dread: do I <b>really</b> need to upgrade? </p> <p>Since one of the main objectives of Dogen was to learn about C++-11, one has to say that the pain was worth it. But all of the moving parts described above were not ideal and they were certainly not the thing you want to be wasting your precious time on when it is very scarce. They were certainly not scalable. </p></div></div> <div class="outline-3" id="outline-container-sec-1-2"><h3 id="sec-1-2">The Good Days and the Bad Days</h3><div class="outline-text-3" id="text-1-2"><p>Things improved slightly for a year or two when distros started to ship C++-11 compliant compilers and recent boost versions. It was all so good we were able to move over to <a href="https://travis-ci.org/DomainDrivenConsulting/dogen">Travis</a> and ditch almost all of our private infrastructure. For a while things looked really good. However, due to Travis' <a href="https://wiki.ubuntu.com/LTS">Ubuntu LTS</a> policy, we were stuck with a rapidly ageing Boost version. At first PPAs were a good solution for this, but soon these became stale too. We also needed to get latest CMake as there are a lot of developments on that front, but we certainly could not afford (time-wise) to revert back to the bad old days of the PFH. At the same time, it made no sense to freeze dependencies in time, providing a worse development experience. So the only route left was to break Travis and hope that some solution would appear. Some alternatives were tried such as <a href="https://drone.io/github.com/DomainDrivenConsulting/dogen">Drone.io</a> but nothing was successful. </p> <p>There was nothing else for it; what was needed was a package manager to manage the development dependencies. </p></div></div> <div class="outline-3" id="outline-container-sec-1-3"><h3 id="sec-1-3">Nuget Hopes Dashed</h3><div class="outline-text-3" id="text-1-3"><p>Having used <a href="https://www.nuget.org/">Nuget</a> in anger for both C# and C++ projects, and given Microsoft's recent change of heart with regards to open source, I was secretly hoping that Nuget would get some traction in the wider C++ world. To recap, Nuget worked <a href="http://mcraveiro.blogspot.co.uk/2014/05/nerd-food-using-mono-in-anger-part-ii_3422.html">well enough in Mono</a>; in addition, C++ support for Windows was added <a href="http://blogs.msdn.com/b/vcblog/archive/2013/04/26/nuget-for-c.aspx">early on</a>. It was somewhat limited and a bit quirky at the start, but it kept on getting better, to the point of usability. Trouble was, their focus was just Visual Studio. </p> <p>Alas, nothing much ever came from my Nuget hopes. However, there have been a couple of recent announcements from Microsoft that make me think that they will eventually look into this space: </p> <ul class="org-ul"><li><a href="http://blogs.msdn.com/b/vcblog/archive/2015/12/04/introducing-clang-with-microsoft-codegen-in-vs-2015-update-1.aspx">Clang with Microsoft CodeGen in VS 2015 Update 1</a></li><li><a href="http://blogs.msdn.com/b/vcblog/archive/2015/12/15/support-for-android-cmake-projects-in-visual-studio.aspx">Support for Android CMake projects in Visual Studio</a></li></ul> <p>Surely the logical consequence is to be able to manage packages in a consistent way across platforms? We can but hope. </p></div></div> <div class="outline-3" id="outline-container-sec-1-4"><h3 id="sec-1-4">Biicode Comes to the Rescue?</h3><div class="outline-text-3" id="text-1-4"><p>Nuget did not pan out but what did happen was even more unlikely: some crazy-cool Spaniards decided to create a stand alone package manager. Being from the same peninsula, I felt compelled to use their wares, and was joyful as they went from strength to strength - including the success of their <a href="https://www.biicode.com/biicode-open-source-challenge">open source campaign</a>. And I loved the fact that it integrated really well with <a href="https://cmake.org">CMake</a>, and that <a href="https://www.jetbrains.com/clion/">CLion</a>provided Biicode integration very early on. </p> <p>However, my biggest problem with Biicode was that it was just too complicated. I don't mean to say the creators of the product didn't have very good reasons for their technical choices - lord knows creating a product is hard enough, so I have nothing but praise to anyone who tries. However, for me personally, I never had the time to understand why Biicode needed its own version of CMake, nor did I want to modify my CMake files too much in order to fit properly with Biicode and so on. Basically, I needed a solution that worked well and required minimal changes at my end. Having been brought up with Maven and Nuget, I just could not understand why there wasn't a simple "packages.xml" file that specified the dependencies and then some non-intrusive CMake support to expose those into the CMake files. As you can see from some of <a href="http://forum.biicode.com/t/building-out-of-tree-using-biicode/460">my posts</a>, it just seemed it required "getting" Biicode in order to make use of it, which for me was not an option. </p> <p>Another thing that annoyed me was the difficulty on knowing what the "real" version of a library was. I wrote, at the time: </p> <blockquote><p>One slightly confusing thing about the process of adding dependencies is that there may be more than one page for a given dependency and it is not clear which one is the "best" one. For RapidJson there are three options, presumably from three different Biicode users: </p> <ul class="org-ul"><li><a href="https://www.biicode.com/fenix/rapidjson">fenix</a>: authored on 2015-Apr-28, v1.0.1. </li><li><a href="https://www.biicode.com/hithwen/rapidjson">hithwen</a>: authored 2014-Jul-30 </li><li><a href="https://www.biicode.com/denis/rapidjson">denis</a>: authored 2014-Oct-09 </li></ul> <p>The "fenix" option appeared to be the most up-to-date so I went with that one. However, this illustrates a deeper issue: how do you know you can trust a package? In the ideal setup, the project owners would add Biicode support and that would then be the one true version. However, like any other project, Biicode faces the initial adoption conundrum: people are not going to be willing to spend time adding support for Biicode if there aren't a lot of users of Biicode out there already, but without a large library of dependencies there is nothing to draw users in. In this light, one can understand that it makes sense for Biicode to allow anyone to add new packages as a way to bootstrap their user base; but sooner or later they will face the same issues as all distributions face. </p> <p>A few features would be helpful in the mean time: </p> <ul class="org-ul"><li>popularity/number of downloads </li><li>user ratings </li></ul> <p>These metrics would help in deciding which package to depend on. </p></blockquote> <p>For all these reasons, I never found the time to get Biicode setup and these stories lingered in Dogen's backlog. And the build continued to be red. </p> <p>Sadly Biicode the company <a href="http://blog.biicode.com/biicode-just-the-company-post-mortem/">didn't make it either</a>. I feel very sad for the guys behind it, because their heart was on the right place. </p> <p>Which brings us right up to date. </p></div></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">Enter Conan</h2><div class="outline-text-2" id="text-2"><p>When I was a kid, we were all big fans of Conan. No, not <a href="https://en.wikipedia.org/wiki/Conan_the_Barbarian">the barbarian</a>, the Japanese Manga <a href="https://en.wikipedia.org/wiki/Future_Boy_Conan">Future Boy Conan</a>. For me the name Conan will always bring back great memories of this show, which we watched in the original Japanese with Portuguese subtitles. So I was secretly pleased when I found <a href="https://www.conan.io/">conan.io</a>, a new package management system for C++. The guy behind it seems to be one of the original Biicode developers, so a lot of lessons from Biicode were learned. </p> <p>To cut a short story short, the great news is I managed to add Conan support to Dogen in roughly <a href="https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/sprint_backlog_77.org#add-support-for-conanio">3 hours</a> and with very minimal knowledge about Conan. This to me was a litmus test of sorts, because I have very little interest in package management - creating my own product has proven to be challenging enough, so the last thing I need is to divert my energy further. The other interesting thing is that roughly half of that time was taken by trying to get Travis to behave, so its not quite fair to impute it to Conan. </p></div> <div class="outline-3" id="outline-container-sec-2-1"><h3 id="sec-2-1">Setting Up Dogen for Conan</h3><div class="outline-text-3" id="text-2-1"><p>So, what changes did I do to get it all working? It was a very simple 3-step process. First I installed Conan using a Debian package from <a href="https://www.conan.io/downloads">their site</a>. </p> <p>I then created a <code>conanfile.txt</code> on my top-level directory: </p> <pre class="example"><br />[requires]<br />Boost/1.60.0@lasote/stable<br /><br />[generators]<br />cmake<br /></pre> <p>Finally I modified my top-level <code>CMakeLists.txt</code>: </p> <pre class="example"><br /># conan support<br />if(EXISTS "${CMAKE_BINARY_DIR}/conanbuildinfo.cmake")<br />    message(STATUS "Setting up Conan support.")<br />    include("${CMAKE_BINARY_DIR}/conanbuildinfo.cmake")<br />    CONAN_BASIC_SETUP()<br />else()<br />    message(STATUS "Conan build file not found, skipping include")<br />endif()<br /></pre> <p>This means that it is entirely possible to build Dogen without Conan, but if it is present, it will be used. With these two changes, all that was left to do was to build: </p> <pre class="example"><br />$ cd dogen/build/output<br />$ mkdir gcc-5-conan<br />$ conan install ../../..<br />$ make -j5 run_all_specs<br /></pre> <p><i>Et voila</i>, I had a brand spanking new build of Dogen using Conan. Well, actually, <i>not quite</i>. I've omitted a couple of problems that are a bit of a distraction on the Conan success story. Let's look at them now. </p></div></div> <div class="outline-3" id="outline-container-sec-2-2"><h3 id="sec-2-2">Problems and Their Solutions</h3><div class="outline-text-3" id="text-2-2"><p>The first problem was that Boost 1.59 does not appear to have an overridden <code>FindBoost</code>, which means that I was not able to link. I moved to Boost 1.60 - which I wanted to do any way - and it worked out of the box. </p> <p>The second problem was that Conan seems to get confused with <a href="https://ninja-build.org/manual.html">Ninja</a>, my build system of choice. For whatever reason, when I use the Ninja generator, it fails like so: </p> <pre class="example"><br />$ cmake ../../../ -G Ninja<br />$ ninja -j5<br />$ ninja: error: '~/.conan/data/Boost/1.60.0/lasote/stable/package/ebdc9c0c0164b54c29125127c75297f6607946c5/lib/libboost_system.so', needed by 'stage/bin/dogen_utility_spec', missing and no known rule to make it<br /></pre> <p>This is very strange because boost system is clearly available in the Conan download folder. Using make solved this problem. I am going to open a ticket on the Conan GitHub project to investigate this. </p> <p>The third problem is more boost related than anything else. Boost Graph has not been as well maintained as it should, really. Thus users now find themselves carrying patches, and all because no one seems to be able to apply them upstream. Dogen is in this situation as we've hit the issue described here: <a href="http://stackoverflow.com/questions/25395805/compile-error-with-boost-graph-1-56-0-and-g-4-6-4">Compile error with boost.graph 1.56.0 and g++ 4.6.4.</a> Sadly this is still present on Boost 1.60; the patch exists in Trac but remains unapplied (<a href="https://svn.boost.org/trac/boost/ticket/10382">#10382</a>). This is a tad worrying as we make a lot of use of Boost Graph and intend to increase the usage in the future. </p> <p>At any rate, as you can see, none of the problems were showstoppers, nor can they all be attributed to Conan. </p></div></div> <div class="outline-3" id="outline-container-sec-2-3"><h3 id="sec-2-3">Getting Travis to Behave</h3><div class="outline-text-3" id="text-2-3"><p>Once I got Dogen building locally, I then went on a mission to convince Travis to use it. It was painful, but mainly because of the lag between commits and hitting an error. The core of the changes to my YML file were as follows: </p> <pre class="example"><br />install:<br />&lt;snip&gt;<br />  # conan<br />  - wget https://s3-eu-west-1.amazonaws.com/conanio-production/downloads/conan-ubuntu-64_0_5_0.deb -O conan.deb<br />  - sudo dpkg -i conan.deb<br />  - rm conan.deb<br />&lt;snip&gt;<br />script:<br />  - export GIT_REPO="`pwd`"<br />  - cd ${GIT_REPO}/build<br />  - mkdir output<br />  - cd output<br />  - conan install ${GIT_REPO}<br />  - hash=`ls ~/.conan/data/Boost/1.60.0/lasote/stable/package/`<br />  - cd ~/.conan/data/Boost/1.60.0/lasote/stable/package/${hash}/include/<br />  - sudo patch -p0 &lt; ${GIT_REPO}/patches/boost_1_59_graph.patch<br />  - cmake ${GIT_REPO} -DWITH_MINIMAL_PACKAGING=on<br />  - make -j2 run_all_specs<br />&lt;snip&gt;<br /></pre> <p>I probably should have a bash script by know, given the size of the YML, but hey - if it works. The changes above deal with installation of the package, applying the boost patch and using Make instead of Ninja. Quite trivial in the end, even though it required a lot of iterations to get there. </p></div></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">Conclusions</h2><div class="outline-text-2" id="text-3"><p>Having a red build is a very distressful event for a developer, so you can imagine how painful it has been to have red builds for <i>several months</i>. So it is with unmitigated pleasure that I got to see <a href="https://travis-ci.org/DomainDrivenConsulting/dogen/builds/98304957">build #628</a> in a shiny emerald green. As far as that goes, it has been an unmitigated success. </p> <p>In a broader sense though, what can we say about Conan? There are many positives to take home, even at this early stage of Dogen usage: </p> <ul class="org-ul"><li>it is a lot less intrusive than Biicode and easier to setup. Biicode was very well documented, but it was easy to stray from the beaten track and that then required reading a lot of different wiki pages. It seems easier to stay on the beaten track with Conan. </li><li>as with Biicode, it seems to provide solutions to Debug/Release and multi-platforms and compilers. We shall be testing it on Windows soon and reporting back. </li><li>hopefully, since it started Open Source from the beginning, it will form a community of developers around the source with the know-how required to maintain it. It would also be great to see if a business forms around it, since someone will have to pay the cloud bill. </li></ul> <p>In terms of negatives: </p> <ul class="org-ul"><li>I still believe the most scalable approach would have been to extend Nuget for the C++ Linux use case, since Microsoft is willing to take patches and since they foot the bill for the public repo. However, I can understand why one would prefer to have total control over the solution rather than depend on the whims of some middle-manager in order to commit. </li><li>it seems publishing packages requires getting down into Python. Haven't tried it yet, but I'm hoping it will be made as easy as importing packages with a simple text file. The more complexity around these flows the tool adds, the less likely they are to be used. </li><li>there still are no "official builds" from projects. As explained above, this is a chicken and egg problem, because people are only willing to dedicate time to it once there are enough users complaining. Having said that, since Conan is easy to setup, one hopes to see some adoption in the near future. </li><li>even when using a GitHub profile, one still has to define a Conan specific password. This was not required with Biicode. Minor pain, but still, if they want to increase traction, this is probably an unnecessary stumbling block. It was sufficient to make me think twice about setting up a login, for one. </li></ul> <p>In truth, these are all very minor negative points, but still worth making them. All and all, I am quite pleased with Conan thus far. </p></div></div></div><div class="status" id="postamble"><p class="date">Created: 2015-12-22 Tue 14:00</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>

            <p class="text-muted">in 'Marco Craveiro' on December 22, 2015 02:01 PM. <a href="http://mcraveiro.blogspot.com/2015/12/nerd-food-dogen-package-management-saga.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Nerd Food: Interesting....</h4>

            Nerd Food: Interesting…<div id="content"><p>Time to flush all those tabs again. Some interesting stuff I bumped into recently-ish. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">Finance, Economics, Politics</h2><div class="outline-text-2" id="text-1"><ul class="org-ul"><li><a href="http://qz.com/564513/a-not-so-brief-history-of-the-fall-and-fall-of-the-nigerian-naira/">A (not so) brief history of the fall and fall of the Nigerian naira</a>: Very good read for Angolans; if nothing else, it makes us understand that our precious Kwanza behaves in many ways like any other petro-currency. Source: <a href="https://twitter.com/KingDouyeAlfred/status/675280673561710592">King Alfred (twitter)</a>. </li><li><a href="https://www.youtube.com/watch?v=SRjwZvLo_hI">#ThisIsACoup - Episode 1- "Angela, suck our balls"</a>: A rather political take on the recent-ish financial mess in Greece. On a similar vein, BBC's <a href="http://www.bbc.co.uk/programmes/b06s1s5x">A Greek Drama</a> is worth a listen. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">Startups et al.</h2><div class="outline-text-2" id="text-2"><ul class="org-ul"><li><a href="http://techcrunch.com/2015/12/16/brazils-congress-has-shut-down-whatsapp-tonight-and-the-rest-of-the-social-web-could-be-next/?ncid=rss#.xiisrb:Oo9T">Brazilian Judge Shuts Down WhatsApp And Brazil’s Congress Wants To Shut Down The Social Web Next</a>: One of the most enlightened internet countries decides to shut it all down. Sad day for the Internet and for all Portuguese speakers. Source: Hacker News (twitter) </li><li><a href="http://www.wired.com/2015/12/bitcoins-creator-satoshi-nakamoto-is-probably-this-unknown-australian-genius/">Bitcoin’s Creator Satoshi Nakamoto Is Probably This Unknown Australian Genius</a>: So they found Satoshi (again). Hesitated in adding this link, to be totally honest - there have been far too many fakes to recount and the whole process is such a media circus that its best avoiding it altogether. But after reading it - questionable media behaviour notwhitstanding - it does appear to provide some insights into these bitcoin early days. Useful to anyone who likes BTC. There is also the <a href="http://gizmodo.com/this-australian-says-he-and-his-dead-friend-invented-bi-1746958692">Gizmodo report</a>, with additional evidence. This is all getting a bit too much for my liking though. </li><li><a href="https://blog.jolla.com/jolla-back-business/">Jolla is back in business!</a>: Good to hear Jolla is still going. Now that my Firefox OS phone is no longer supported, I am keen on getting a Jolla. Source: Hacker News (twitter) </li><li><a href="https://bitcoinmagazine.com/articles/tech-and-banking-giants-join-forces-with-the-linux-foundation-to-create-new-open-source-blockchain-hyperledger-1450384716">Tech and Banking Giants Join Forces with the Linux Foundation to Create New Open Source Blockchain 'Hyperledger'</a>: In truth, hard not to be sceptical - even though it's coming from the Linux Foundation. I guess - in this world of <a href="http://radar.oreilly.com/2015/01/blockchain-scalability.html">scalability wars</a> - this must come as good news. However, I still think there is a lot of misunderstanding around Bitcoin and the Blockchain, and there are far too many "AOLs" out there trying to create their gated communities, failing to understand history (again). Not quite sure on which side of the fence to place this initiative but, alas, I'm more inclined towards the AOL side. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">General Coding</h2><div class="outline-text-2" id="text-3"><ul class="org-ul"><li><a href="http://spectrum.ieee.org/view-from-the-valley/computing/software/yahoos-engineers-move-to-coding-without-a-net">Yahoo’s Engineers Move to Coding Without a Net</a>: How removing a testing team can help reduce the bug count and ramp up productivity. Source: <a href="https://twitter.com/newsycombinator/status/675420147365060608">Hacker News (twitter)</a></li><li><a href="http://githubengineering.com/move-fast/">Move Fast and Fix Things</a>: An <i>incredible</i> tale of real engineering from the GitHub guys with lots of take-ins - <a href="https://github.com/github/scientist">Scientist</a> is a pretty neat idea, for one. Worth a read and a re-read. Logically related to the previous article. Source: Hacker News (twitter) </li><li><a href="https://medium.com/@thi.ng/the-jacob-s-ladder-of-coding-4b12477a26c1#.v80mhs3cv">The Jacob’s Ladder of coding</a>: Reminiscences on our beloved profession of coding. Long and deep, so still parsing. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-4"><h2 id="sec-4">Databases</h2><div class="outline-text-2" id="text-4"><ul class="org-ul"><li><a href="https://wiki.postgresql.org/wiki/What's_new_in_PostgreSQL_9.5">What's new in PostgreSQL 9.5</a>: The RC's are starting and 9.5 looks to continue the trend of amazing Postgres releases. My only missing wish is for native (and full) support for bitemporality really, though to be fair <a href="http://pgxn.org/dist/temporal_tables/">Temporal Tables</a> is probably enough for <a href="http://clarkdave.net/2015/02/historical-records-with-postgresql-and-temporal-tables-and-sql-2011/">my needs</a>. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-5"><h2 id="sec-5">C++</h2><div class="outline-text-2" id="text-5"><ul class="org-ul"><li><a href="http://www.agner.org/optimize/optimizing_cpp.pdf">Optimizing software in C++</a>: One to bookmark now but to digest later. A whole load of stuff on optimisation. </li><li><a href="http://blogs.msdn.com/b/vcblog/archive/2015/12/15/support-for-android-cmake-projects-in-visual-studio.aspx">Support for Android CMake projects in Visual Studio</a>: So, as if the latest patches to Clang hadn't been enough, MS now decides to add support for CMake in Visual Studio. A bit embryonic, and a bit too android focused, but surely it should be extensible for more regular C++ use. Whats going on at MS? This is all far too cool to be true. </li><li><a href="http://probablydance.com/2015/12/19/quickly-loading-things-from-disk/">Quickly Loading Things From Disk</a>: interesting analysis about the state of affairs of serialisation in C++. I'll probably require a few passes to fully digest it. </li><li><a href="https://www.youtube.com/watch?v=FYtBv_OosYw">Beyond ad-hoc automation: leveraging structured platforms</a>: I've been consuming this presentation slowly but steadily. It deals with a lot of the questions we all have about the new world of containers and microservices, and it seems vital to learn from experience before one finds oneself in a much bigger mess than the monolith could ever get you into. Bridget Kromhout talks intelligently about the subject. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-6"><h2 id="sec-6">Layman Science</h2><div class="outline-text-2" id="text-6"><ul class="org-ul"><li><a href="http://wavewatching.net/2014/03/31/the-church-of-d-wave/">The Church of D-Wave</a>: So is D-Wave a quantum computer or not? It appears the verdict is "not", even with the 2X and the <a href="http://googleresearch.blogspot.co.uk/2015/12/when-can-quantum-annealing-win.html">Google paper</a>. </li><li><a href="https://www.youtube.com/watch?v=qZM9JREjnp4">Intelligence and the Brain</a>: Oldish but still very good and relevant. Another high-level introduction to HTM. </li><li><a href="https://www.newscientist.com/article/dn28452-nasa-probe-shows-how-solar-burps-may-have-stripped-mars-of-water/">NASA probe shows how solar burps may have stripped Mars of water</a>: How the sun could be responsible for stripping water away from the red planet. </li><li><a href="https://www.youtube.com/watch?v=GcQWZG50zX0">Artificial Intelligence Through Hierarchical Temporal Memory</a>: Continuing my adventures in the HTM space, Dr. Paul Cottrell is my latest find. I'm still not totally sure I understand all concepts in this video but what I do understand - assuming they have succeeded in doing what he describes - seem mondo-cool. Basically, it's all about the application of HTM to Finance and trading. He also introduces the idea of adding sub-cortical machinery to HTM (which is just cortical); a most puzzling concept. Once I finish parsing this video, I intend to move to <a href="https://www.youtube.com/watch?v=dDD7D-fm7Wc&amp;feature=youtu.be">Neuroscience Foundation For Artificial Intelligence</a>. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-7"><h2 id="sec-7">Other</h2><div class="outline-text-2" id="text-7"><ul class="org-ul"><li><a href="https://www.youtube.com/watch?v=6FFAQuJZmOA">Benjamin Clementine - Le Ring - Live</a>: Haven't totally made up my mind about Benjamin Clementine, but certainly a very interesting performance. </li></ul></div></div></div><div class="status" id="postamble"><p class="date">Created: 2015-12-21 Mon 23:31</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>

            <p class="text-muted">in 'Marco Craveiro' on December 21, 2015 11:32 PM. <a href="http://mcraveiro.blogspot.com/2015/12/nerd-food-interesting_21.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Nerd Food: Pull Request Driven Development.</h4>

            Nerd Food: Pull Request Driven Development<div id="content"><p>Being in this game for the best part of twenty years, I must confess that its not often I find something that revolutionises my coding ways. I do tend to try a lot of things, but most of them end up revealing themselves as fads or are incompatible with my flow. For instance, I never managed to get <a href="https://en.wikipedia.org/wiki/Behavior-driven_development">BDD</a> to work for me, try as I might. I will keep trying because it sounds really useful, but it hasn't clicked just yet. </p> <p>Having said all of that, these moments of enlightenment do occasionally happen, and when they do, nothing beats that life-changing feeling. "Pull Request Driven Development" (or PRDD) is my latest find. I'll start by confessing that "PRDD" as a name was totally made up for this post and hopefully you can see its rather tongue in cheek. However, the benefits of this approach are very real. In fact, I've been using PRDD for a while now but I just never really noticed its presence creeping in. Today, as I introduced a new developer to the process, I finally had the eureka moment and saw just how brilliant it has been thus far. It also made me realise that some people are not aware of this great tool in the developer's arsenal. </p> <p>But first things first. In order to explain what I mean by PRDD, I need to provide a bit of context. Everyone is migrating to git these days, even those of us locked behind corporate walls; in our particular case, the migration path implied exposure to <a href="https://en.wikipedia.org/wiki/Stash_(software)">Git Stash</a>. For those not in the know, picture it as an expensive and somewhat less featureful version of <a href="https://github.com/">GitHub</a>, but with most of the core functionality there. Of course, I'm sure GitHub is not that cheap for enterprises either, but hey at least its the tool everyone uses. Anyway - grumbling or not - we moved to Stash and all development started to revolve around Pull Requests (PRs), raised for each new <a href="https://www.atlassian.com/git/tutorials/comparing-workflows/feature-branch-workflow">feature</a>. </p> <p>Not long after PRs were introduced, a particularly interesting habit started to appear: developers begun opening the PRs earlier and earlier during the feature cycle rather than waiting to the very end. Taking this approach to the limit, the idea is that when you start to work on a new feature, you raise the ticket and the PR <i>before you write any code at all</i>. In practice - due to Stash's anachronisms - you need to push at least one commit, but the general notion is valid. This was never mandated anywhere, and there was no particular coordination. I guess one possible explanation for this behaviour is that one wants to get rid of the paperwork as quickly as possible to get to the coding. At any rate, the causes may be obscure but the emerging behaviour was not. </p> <p>When you combine early PRs with the <a href="https://sethrobertson.github.io/GitBestPractices/">commit early and commit often</a>approach - which you should be using anyway - the PR starts to become a living document; people see your development work as it progresses and they start commenting on it and possibly even sending you patches <i>as you go along</i>. In a way, this is an enabler for a very efficient kind of peer programming - particularly if you have a tightly knit team - because it gives you maximum parallelism but in a very subtle, non-noticeable way. The main author of the PR is coding as she would normally be, but whenever there is a lull in development - those moments where you'd be browsing the web for five minutes or so - you can quickly check for any comments on your PR and react to those. Similarly, other developers can carry on doing their own work and browse the PRs on their downtime; this allows them to provide feedback whenever it is convenient <i>to them</i>, and to choose the format of the feedback - lengthy or quick, as time permits. </p> <p>Quick feedback is many a times invaluable in large code bases because everyone tends to know their own little corner of the code and only very few old hands know how it all hangs together. Thus, seemingly trivial one liners such as "have you considered using API xyz instead of rolling your own" or "don't forget to do abc when you do that" could save you <i>many</i> hours of pain and enable knowledge to be transferred organically - something that no number of wiki pages could hope to achieve in a million years because its very difficult to find these pearls in a sea of uncurated content. And because you committed early and often, each commit is very small and very easy to parse in a small interval of time, so people are much more willing to review - as opposed to that several Kb (or even Mb!) patch that you will have to allocate a day or two for. Further: if you <a href="http://chris.beams.io/posts/git-commit/">take your commit message seriously</a> - as, again, you should - you will find that the number of reviewers will grow rapidly simply because developers are nosy and opinionated. </p> <p>Note that this review process involves no vague meetings and no lengthy and unfocused email chains; it is very high-quality because it is (or can be) very focused to specific lines of code; it causes no unwanted disruptions because you review where and when you choose to review; reviewers can provide examples and even fix things themselves if they so choose; it is totally inclusive because anyone who wants to participate can, but no one is forced to; and it equalises local and remote developers because they all have access to the same data (modulus some IRL conversations that always take place) - an important feature in this world of near-shoring, off-shoring and home-working. Most importantly, instead of finding out some fundamental errors of approach at the end of an intense period of coding, you now have timely feedback. This saves an <i>enormous</i> amount of time - an advantage that anyone who has been through lengthy code reviews and then spent a week or two reacting to that feedback can appreciate. </p> <p>I am now a believer in PRDD. So much so that whenever I go back to work on legacy projects in svn, I find myself cringing all the way to the end of the feature. It just feels so nineties. </p> <p><b>Update:</b> As I finished penning this post and started reflecting about it it suddenly dawned on me that a lot of things we now take for granted are only  possible because of git. And I don't mean DVCS', I specifically mean git. For  example PRDD is made possible to a large extent because committing in git is a  reversible process and history can be fluid if required. This means that people are not afraid of committing, which in turn enables a lot of the goodness I described  above. Many DVCS' didn't like this way of viewing history - and to be fair, I know of very few people that liked the idea until they started using it. Once you figure out what it is good for (and not so good for), it suddenly becomes an amazing tool. Git is full of little decisions like this that at first sight look either straight insane or just not particularly useful but then turn out to change entire development flows. </p> </div><div class="status" id="postamble"><p class="date">Created: 2015-12-11 Fri 13:12</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>

            <p class="text-muted">in 'Marco Craveiro' on December 11, 2015 03:48 PM. <a href="http://mcraveiro.blogspot.com/2015/12/nerd-food-pull-request-driven.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Nerd Food: Interesting....</h4>

            Nerd Food: Interesting…<div id="content"><p>Time to flush all those tabs again. Some interesting stuff I bumped into recently-ish. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">Finance, Economics, Politics</h2><div class="outline-text-2" id="text-1"><ul class="org-ul"><li><a href="https://www.propublica.org/article/debt-collection-lawsuits-squeeze-black-neighborhoods">The Color of Debt: How Collection Suits Squeeze Black Neighborhoods</a>: Another great example of how markets are not so efficient for certain things and not exactly fair. </li><li><a href="http://www.economist.com/news/briefing/21678215-world-entering-third-stage-rolling-debt-crisis-time-centred-emerging">Pulled back in</a>: The Economist's take on how the emerging markets credit bubble will play out. Not sure if I agree with their analysis, but its certainly very worrying to see so much EM debt piling up in such a volatile world. </li><li><a href="http://www.politico.com/magazine/story/2015/11/isil-whos-calling-the-shots-213360">ISIL: Who’s Calling the Shots?</a>: Interesting analysis, much better than the usual superficial take one is used to from mass-media. </li><li><a href="http://www.newyorker.com/magazine/2015/08/31/the-other-france">The Other France</a>: As with the previous article, I cannot help but be surprised - even more so with this one. Truly, an amazing, in-depth job. Surprisingly good coming from the American media. If you have watched <a href="http://www.imdb.com/title/tt0113247/">La Haine</a>, read this. If you have read this, watch La Haine. </li><li><a href="https://www.youtube.com/watch?v=iavquu6PP9g">Elon Musk talks Climate Change and Carbon Tax at the Sorbone (12.2.15)</a>: Musk raises some interesting points, as usual, such as why we need to tax carbon or else. </li><li><a href="http://www.theguardian.com/society/2015/nov/29/future-of-work-gig-sharing-economy-juggling-jobs">'My father had one job in his life, I've had six in mine, my kids will have six at the same time'</a>: The Guardian's take in this new world of job displacement and "job context switching". Very interesting. </li><li><a href="https://www.youtube.com/watch?v=LZbsxs_VGtQ&amp;feature=youtu.be">Ship it! QuantLib, IPython Notebook, and Docker</a>: QuantLib conference is over, and sadly there are very few videos. This one bucks the trend. The ever informative Luigi talks about how QuantLib is moving with the times. </li><li><a href="http://www.theguardian.com/business/2015/dec/07/morgan-stanley-axes-400-bankers-bonds-jobs?CMP=Share_AndroidApp_Seesmic">Morgan Stanley axes 400 bankers as bond-trading income dives</a>: The contraction of the traditional banking industry continues, even as cryptos are growing insanely. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">Startups et al.</h2><div class="outline-text-2" id="text-2"><ul class="org-ul"><li><a href="http://blog.erratasec.com/2015/12/tesla-is-copying-apples-business-model.html#.VmL8A3VX9hG">Tesla is copying Apple's business model</a>: very interesting comparison between Tesla and Apple's businesses. I don't fully agree with the article, but to be fair it does raise a number of interesting points. I definitely think that when Tesla can deliver mass-market quantities they will dominate sales in a similar fashion to the iPhone. </li><li><a href="http://www.theguardian.com/technology/2015/nov/29/arm-cambridge-britain-tech-company-iphone">ARM: Britain's most successful tech company you've never heard of</a>: Short history of ARM. It would be great to have a book about these guys! </li><li><a href="https://medium.com/backchannel/doordash-wants-to-own-the-last-mile-27c03098a657">DoorDash Wants to Own the Last Mile</a>: interesting story of a startup that focuses on "last mile" delivery. </li><li><a href="https://www.bitpesa.co">BitPesa</a>: cool African start-up in the BitCoin / MPesa space. </li><li><a href="http://ventureburn.com/2015/10/lulalend-true-fintech-company-mixing-tech-finance/">LulaLend</a>: Another cool African start-up that is doing well in the payments space. </li><li><a href="https://www.youtube.com/watch?v=SqEo107j-uw">Elon Musk and Y Combinator President on Thinking for the Future</a>: Altman and Musk discuss the future. Shame the presenter is not a bit geekier or it could have been one of the best. </li><li><a href="https://www.youtube.com/watch?v=WwrEQklDoyE">Elon Musk with his Brother Kimbal Musk on a panel</a>: Since we're doing the Musk fanboy thing, here's a great panel with Elon and his brother. A more personal view of his achievements. </li><li><a href="http://www.bloomberg.com/news/articles/2015-11-24/jeff-bezos-vs-elon-musk-a-thrilling-new-space-race">Jeff Bezos vs. Elon Musk: A Thrilling, New Space Race</a>: More Musk fanboying; lets go all the way and read up on the latest about the space race. Very interesting. </li><li><a href="https://www.youtube.com/watch?v=u6IZRjP39do">Tesla Shareholders Meeting June 2015</a>: Final Musk fanboying. I think Tesla is one of the few companies where non-shareholders tune in just to listen and get inspiration. Elon, nerdy and awkward but great and inspiring as always. Choice quote: "I'd expect SpaceX to go public once we get regular flights to mars." - very few people could get away with a statement like that. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">General Coding</h2><div class="outline-text-2" id="text-3"><ul class="org-ul"><li><a href="http://www.nytimes.com/2015/11/13/technology/gene-amdahl-pioneer-of-mainframe-computing-dies-at-92.html?smprod=nytcore-ipad&amp;smid=nytcore-ipad-share">Gene Amdahl, Pioneer of Mainframe Computing, Dies at 92</a>: I've heard the name a lot but never really read about the man. </li><li><a href="http://jvns.ca/blog/2015/11/21/why-you-should-understand-a-little-about-tcp/">Why you should understand (a little) about TCP</a>: The new generation discovers the joys of understanding low-level protocols. And Nagle (yes, he of <a href="https://en.wikipedia.org/wiki/Nagle%2527s_algorithm">Nagle Algorithm</a> fame) replies on that thread. </li><li><a href="https://www.youtube.com/channel/UCvq_RgZp3kljp9X8Io9Z1DA">systemd.conf</a>: Videos from the conference. Have watched a couple, seemed like a lively conference. Hard to imagine an init system with its own conference though! </li></ul></div></div> <div class="outline-2" id="outline-container-sec-4"><h2 id="sec-4">Databases</h2><div class="outline-text-2" id="text-4"><ul class="org-ul"><li><a href="http://blog.2ndquadrant.com/when-are-we-going-to-contribute-bdr-to-postgresql/">When are we going to contribute BDR to PostgreSQL?</a>: For those (like me) who keep moaning about the lack of <a href="https://en.wikipedia.org/wiki/Multi-master_replication">BDR</a> in Postgres, a great explanation of how the patchset is being merged. Great work by the 2nd Quadrant guys. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-5"><h2 id="sec-5">C++</h2><div class="outline-text-2" id="text-5"><ul class="org-ul"><li><a href="http://blog.llvm.org/2015/11/new-elf-linker-from-llvm-project.html">New ELF Linker from the LLVM Project</a>: LLVM keeps on delivering! Now a new ELF linker. To be totally honest, I haven't even started using <a href="https://en.wikipedia.org/wiki/Gold_(linker)">Gold</a> in anger - I get the feeling the LLVM linker is going to be transitioned in much quicker than Gold. </li><li><a href="http://blogs.msdn.com/b/vcblog/archive/2015/12/04/introducing-clang-with-microsoft-codegen-in-vs-2015-update-1.aspx">Clang with Microsoft CodeGen in VS 2015 Update 1</a>: OMG, OMG how cool is this - MSFT decided to create a backend for Clang that is totally compatible with MSVC <span class="underline">AND</span> open source it! This is just insane. This means for example that you now can develop C++ on Windows without ever having to use MSVC and Visual Studio. It also means you can cross-compile from Linux into Windows with 100% certainty things will work. It means that projects like <a href="https://www.winehq.org/">Wine</a> and <a href="https://www.reactos.org/">ReactOS</a> can start thinking about a migration path into Clang (not quite as simple as it may sound but surely makes sense). <a href="https://www.jetbrains.com/clion/">CLion</a> with Clang on Windows will rock. The possibilities are just endless. I never quite understood what C2 was all about until I read this announcement - <a href="http://www.theregister.co.uk/2015/10/21/microsoft_promises_clang_for_windows_in_november_visual_c_update/">suddenly it all makes sense</a>. This is <i>fantastic</i> news. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-6"><h2 id="sec-6">Layman Science</h2><div class="outline-text-2" id="text-6"><ul class="org-ul"><li><a href="http://www.wired.com/brandlab/2015/05/jeff-hawkins-firing-silicon-brain/">Jeff Hawkins on Firing Up the Silicon Brain</a>: OK, let me totally honest: I <span class="underline">love</span> Jeff Hawkins. I read On Intelligence far too many times to count and would be lying if I didn't admit that it had a little bit to do with my forays into Computational Neuroscience. So as you can imagine, I'm rather excited about <a href="https://en.wikipedia.org/wiki/Hierarchical_temporal_memory">HTM</a>and <a href="https://en.wikipedia.org/wiki/Numenta">Numenta's</a> latest developments. This article is a good catch-up, if slightly high-level. If you want something slightly more technical but still very approachable, <a href="https://www.youtube.com/watch?v=6ufPpZDmPKA">Principles of Hierarchical Temporal Memory (HTM): Foundations of Machine Intelligence</a> is a must watch. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-7"><h2 id="sec-7">Other</h2><div class="outline-text-2" id="text-7"><ul class="org-ul"><li><a href="https://www.youtube.com/watch?v=lWJkrP4WPFw">NoiseRV Live</a>: Still discovering this Portuguese musician, but love his work. Great concert. Could do a little bit less talking between songs, but still - artists prerogative and all that. </li><li><a href="http://bff.fm/broadcasts/4499">Warm Focus: Winging It</a>: Interesting set of "intelligent dance music" as we used to call it back in the day. </li><li><a href="https://overcast.fm/+Bj7wZZ3Mg">Mosaic - The “First” Web Browser</a>: Super-cool podcasts about internet history. It would be great to have something like this for UNIX! </li><li><a href="https://www.youtube.com/watch?v=0va3F2PWBJc">Jackson C. Frank (1965)</a>: Tragic musician from the 60s. Great tunes. </li><li><a href="http://www.gutenberg.org/files/15000/15000-h/vol1.html">Reason in common sense</a>: Always wanted to read Santayana properly. Started, but I guess it will be a <span class="underline">very</span> long exercise. Interesting, if somewhat strange book. </li><li><a href="https://www.youtube.com/watch?v=OSD1mud8JZ8">Ceu - jazz baltica Live (2010)</a>: New find, Brazilian musician Ceu. </li></ul></div></div></div><div class="status" id="postamble"><p class="date">Created: 2015-12-09 Wed 12:49</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>

            <p class="text-muted">in 'Marco Craveiro' on December 09, 2015 03:02 PM. <a href="http://mcraveiro.blogspot.com/2015/12/nerd-food-interesting.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Nerd Food: Tooling in Computational Neuroscience - Part II: Microscopy.</h4>

            Nerd Food: Tooling in Computational Neuroscience - Part II: Microscopy<div id="content"><p class="verse" style="text-align: right;"><small>Research is what I'm doing when I don't know what I'm doing. <br /><i>Wernher von Braun</i></small></p> <p>Welcome to the second instalment of our second series on Computational Neuroscience for lay people. You can find the first post of the previous series <a href="http://mcraveiro.blogspot.co.uk/2015/08/nerd-food-neurons-for-computer-geeks.html">here</a>, and the first post of the current series <a href="http://mcraveiro.blogspot.co.uk/2015/11/nerd-food-tooling-in-computational.html">here</a>. As you'd expect, this second series is slightly more advanced, and, as such, it is peppered with unavoidable technical jargon. Having said that, we shall continue to pursue our ambitious target of making things as easy to parse as possible (but no easier). If you read the first series, the second should hopefully make some sense.<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.1" id="fnr.1" name="fnr.1">1</a></sup></p> <p>Our <a href="http://mcraveiro.blogspot.co.uk/2015/11/nerd-food-tooling-in-computational.html">last post</a> discussed <a href="https://en.wikipedia.org/wiki/Computational_neuroscience">Computational Neuroscience</a> as a discipline, and the kind of things one may want to do in this field. We also spoke about models and their composition, and the desirable properties of a platform that runs simulations of said models. However, it occurred to me that we should probably build some kind of "end-to-end" understanding; that is, by starting with the simulations and models we are missing a vital link with the physical (i.e. non-computational) world. To put matters right, this part attempts to provide a high-level introduction on how data is acquired from the real world and can then be used - amongst other things - to inform the modeling process. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">Macro and Micro Microworlds</h2><div class="outline-text-2" id="text-1"><p>For the purposes of this post, the data gathering process starts with the microscope. Of course, keep in mind that we are focusing only on the <i>morphology</i> at present - the shape and the structures that make up the neuron - so we are ignoring other important activities in the lab. For instance, one can conduct experiments to measure voltage in a neuron, and these measurements provide data for the functional aspects of the model. Alas, we will skip these for now, with the promise of returning to them at a later date<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.2" id="fnr.2" name="fnr.2">2</a></sup>. </p> <p>So, microscopes then. <a href="https://en.wikipedia.org/wiki/Microscopy">Microscopy</a> is the technical name for the observation work done with the microscope. Because neurons are so small - some 4 to 100 microns in size - only certain types of microscopes are suitable to perform neuronal microscopy. To make matters worse, the sub-structures inside the neuron are an important area of study and they can be ridiculously small: a <a href="https://en.wikipedia.org/wiki/Dendritic_spine">dentritic spine</a> - the minute protrusions that come out of the dendrites - can be as tiny as 500 nanometres; the lipid bylayer itself is only 2 or 3 nanometres thick, so you can imagine how incredibly small ion channels and pumps are. Yet these are some of the things we want to observe and measure. Lets call this the "micro" work. On the other hand, we also want to understand connectivity and other larger structures, as well as perform observations of the evolution of the cell and so on. Lets call this the "macro" work. These are not technical terms, by the by, just so we can orient ourselves. So, how does one go about observing these differently sized microworlds? </p>  <div class="figure"><p><img alt="F1.large.jpg" height="300px" src="http://www.pnas.org/content/106/39/16877/F1.large.jpg" width="300px" /></p><p><span class="figure-number">Figure 1:</span> Example of measurements one may want to perform on a dendrite. Source: <a href="http://www.pnas.org/content/106/39/16877.abstract">Reversal of long-term dendritic spine alterations in Alzheimer disease models</a></p></div></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">Optical Microscopy</h2><div class="outline-text-2" id="text-2"><p>The "macro" work is usually done using the <a href="https://en.wikipedia.org/wiki/Optical_microscope">Optical</a> "family" of microscopes, which is what most of us think of when hearing the word microscope. As it was with <a href="https://en.wikipedia.org/wiki/Microscope">Van Leeuwenhoek's</a> tool in the sixteen hundreds, so it is that today's optical microscopes still rely on light and lenses to perform observations. Needless to say, things did evolve a fair bit since then, but standard optical microscopy has not completely removed the shackles of its limitations. These are of three kinds, as Wikipedia helpfully <a href="https://en.wikipedia.org/wiki/Microscopy#Optical_microscopy">tells us</a>: a) the objects we want to observe must be dark or strongly refracting - a problem, since the internal structures of the cell are transparent; b) visible light's <a href="https://en.wikipedia.org/wiki/Diffraction-limited_system">diffraction limit</a> means that we cannot go much lower than 200 nanometres - pretty impressive, but unfortunately not quite low enough for detailed sub-structure analysis; and c) out of focus light hampers image clarity. </p> <p>Workarounds to these limitations have been found in the guise of <i>techniques</i>, with the aim of augmenting the abilities of standard optical microscopy. There are many of these techniques. There is the <a href="https://en.wikipedia.org/wiki/Confocal_microscopy">Confocal Microscopy</a><sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.3" id="fnr.3" name="fnr.3">3</a></sup> - improving resolution and contrast; the <a href="https://en.wikipedia.org/wiki/Fluorescence_microscope">Fluorescence microscope</a>, which uses a <i><a href="https://en.wikipedia.org/wiki/Microscopy#Sub-diffraction_techniques">sub-diffraction technique</a></i>to reconstruct some of the detail that is missing due to diffraction; or the incredible-looking movies produced by <a href="http://blogs.scientificamerican.com/expeditions/journey-through-the-brain-multiphoton-microscopy/">Multiphoton Microscopy</a>. And of course, it is possible to combine multiple techniques in a single microscope, as is the case with the <a href="https://en.wikipedia.org/wiki/Multiphoton_fluorescence_microscope">Multiphoton Fluorescence Microscopes</a> (MTMs) and many others. </p> <p>In fact, given all of these developments, it seems there is no sign of optical microscopy dying out. Presumably some of this is due to the relative lower cost of this approach as well as to the ease of use. In addition, optical microscopy is complementary to the other more expensive types of microscopes; it is the perfect tool for "macro" work that can then help to point out where to do "micro" work. For example, you can use an optical microscope to assess the larger structures and see how they evolve over time, and eventually decide on specific areas that require more detailed analysis. And when you do, you need a <i>completely</i> different kind of microscope. </p></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">Electron Microscopy</h2><div class="outline-text-2" id="text-3"><p>When you need <i>really</i> high-resolution, there is only one tool to turn to: the <a href="https://en.wikipedia.org/wiki/Electron_microscope">Electron Microscope (EM)</a>. This crazy critter can provide <i>insane</i> levels of magnification by using a beam of electrons instead of visible light. Just how insane, you ask? Well, if you think that an optical microscope lives in the range of 1500x to 2000x - that is, can magnify a sample up to two thousand times - an EM can magnify as much as 10 <span class="underline">million times</span>, and provide a sub-nanometre resolution<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.4" id="fnr.4" name="fnr.4">4</a></sup>. It is mind boggling. If fact, we've already seen images of atoms using EM in <a href="http://mcraveiro.blogspot.co.uk/2015/08/nerd-food-neurons-for-computer-geeks_31.html">part II</a>, but perhaps it wasn't easy to appreciate just how amazing a feat that is. </p> <p>Of course, EM is itself a family - and a large one at that, with many and diverse members. As with optical microscopy, each member of the family specialises on a given technique or combination of techniques. For example, the <a href="https://en.wikipedia.org/wiki/Scanning_electron_microscope">Scanning Electron Microscope</a> (SEM) performs a scan of the object under study, and has a resolution of 1 nanometre or higher; the <a href="https://en.wikipedia.org/wiki/Scanning_confocal_electron_microscopy">Scanning Confocal Electron Microscope (SCEM)</a>uses the same confocal technique mentioned above to provide higher depth resolution; and <a href="https://en.wikipedia.org/wiki/Transmission_electron_microscopy">Transmission Electron Microscopy</a> (TEM) has the ability to penetrate inside the specimen during the imagining process, given samples with thickness of 100 nanometres or less. </p> <p>A couple of noteworthy points are required at this juncture. First, whilst some of these EM techniques may sound new and exciting, most have been around for a <i>very</i> long time; it just seems they keep getting better and better as they mature. For example, TEM was used in the fifties to show that neurons communicate over synaptic junctions but its still wildly popular today. Secondly, its important to understand that the entire imaging process is not at all trivial - certainly not for TEM, nor EM in general and probably not for Optical Microscopy either. It just is a <i>very</i> labour intensive and <i>very</i>specialised process - most likely done by an expert human neuroanatomist - and the difficulties range from the chemical preparation of the samples all the way up to creating the images. The end product may give the impression it was easy to produce, but easy it was not. </p> <p>At any rate, whatever the technical details, the fact is that the imagery that results from all these advances is truly evocative - haunting, even. Take this image produced by SEM: </p>  <div class="figure"><p><img alt="2014_06_26_human_ipsc_derived_neuron_deerinck.jpg" height="300px" src="http://ucsdnews.ucsd.edu/news_uploads/2014_06_26_human_ipsc_derived_neuron_deerinck.jpg" width="300px" /></p><p><span class="figure-number">Figure 2:</span> Human neuron. <a href="http://ucsdnews.ucsd.edu/pressrelease/new_reprogramming_method_makes_better_stem_cells">Source: New Reprogramming Method Makes Better Stem Cells</a></p></div> <p>Personally, I think it is incredibly beautiful; simultaneously awe-inspiring and depressing because it really conveys the messiness and complexity of wetware. By way of contrast, look at the neatness of man-made micro-structures: </p>  <div class="figure"><p><img alt="bluegeneq%20x%20420.jpg" height="300px" src="http://m.eet.com/media/1118299/bluegeneq%20x%20420.jpg" width="300px" /></p><p><span class="figure-number">Figure 3:</span> The BlueGene/Q chip. Source: <a href="http://www.eetimes.com/document.asp?doc_id=1260096">IBM plants transactional memory in CPU</a></p></div></div></div> <div class="outline-2" id="outline-container-sec-4"><h2 id="sec-4">Stacks and Stacks of 'Em</h2><div class="outline-text-2" id="text-4"><p>Technically, pictures like the ones above are called <a href="https://en.wikipedia.org/wiki/Micrograph">micrographs</a>. As you can see in the neuron micrograph, these images provide a great visual description of the topology of the object we are trying to study. You also may notice a slight coloration of the cell in that picture. This is most likely due to the fact that the people doing the analysis <a href="https://en.wikipedia.org/wiki/Staining">stain</a> the neuron to make it easier to image. Now, in practice - at least as far as I have seen, which is not very far at all, to be fair - 2D grayscale images are preferred by researchers to the nice, Public Relations friendly pictures like the one above; those appear to be more useful for magazine covers. The working micrographs are not quite as exciting to the untrained eye but very useful to the professionals. Here's an example: </p>  <div class="figure"><p><img alt="fetch.php?w=900&amp;tok=d88a10&amp;media=wiki:biomed-neurons.jpg" height="200px" src="http://www.leet.it/home/giusti/website/lib/exe/fetch.php?w=900&amp;tok=d88a10&amp;media=wiki:biomed-neurons.jpg" width="600px" /></p><p><span class="figure-number">Figure 4:</span> The left-hand side shows the original micrograph. On the right-hand side it shows the result of processing it with machine learning. Source: <a href="http://papers.nips.cc/paper/4741-deep-neural-networks-segment-neuronal-membranes-in-electron-microscopy-images.pdf">Deep Neural Networks Segment Neuronal Membranes in Electron Microscopy Images</a></p></div> <p>Let's focus on the left-hand side of this image for the moment. It was taken using <i>ssTEM</i> - serial-section TEM, an evolutionary step in TEM. The <i>ss</i> part of ssTEM is helpful in creating <i>stacks</i> of images, which is why you see the little drawings on the left of the picture; they are there to give you the idea that the top-most image is one of 30 in a stack<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.5" id="fnr.5" name="fnr.5">5</a></sup>. The process of producing the images above was as follows: they started off with a neuronal tissue sample, which is prepared for observation. The sample had 1.5 micrometres and was then sectioned into 30 slices of 50 nanometres. Each of these slices was imaged, at a resolution of 4x4 nanometres per pixel. </p> <p>As you can imagine, this work is extremely sensitive to measurement error. The trick is to ensure there is some kind of visual continuity between images so that you can recreate a 3D model from the 2D slices. This means for instance that if you are trying to figure out connectivity, you need some way to relate a dendrite to it's soma and say to the axon of the neuron it connects to - and that's one of the reasons why the slices have to be so thin. It would be no good if the pictures miss this information out as you will not be able to recreate the connectivity faithfully. This is actually really difficult to achieve in practice due to the minute sizes involved; a slight tremor that displaces the sample by some nanometres would cause shifts in alignment; even with the high-precision the tools have, you can imagine that there is always some kind of movement in the sample's position as part of the slicing process. </p> <p>Images in a stack are normally stored using traditional formats such as <a href="https://en.wikipedia.org/wiki/Tagged_Image_File_Format">TIFF</a><sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.6" id="fnr.6" name="fnr.6">6</a></sup>. You can see an example of the raw images in a stack <a href="https://github.com/unidesigner/groundtruth-drosophila-vnc/tree/master/stack2/raw">here</a>. Its worth noticing that, even though the images are 2D grey-scale, since the pixel size is only a few nanometres wide (4x4 in this case), the full size of an image is very large. Indeed, the latest generation of microscopes produce stacks on the 500 Terabyte range, making the processing of the images a "big-data" challenge. </p></div></div> <div class="outline-2" id="outline-container-sec-5"><h2 id="sec-5">What To Do Once You Got the Images</h2><div class="outline-text-2" id="text-5"><p>But back to the task at hand. Once you have the stack, the next logical step is to try to figure out what's what: which objects are in the picture. This is called segmentation and labelling, presumably because you are breaking the one big monolithic picture into discrete objects and give them names. Historically, segmentation has been done manually, but its a painful, slow and error-prone process. Due to this, there is a lot of interest in automation, and it has recently become feasible to do so - what with the abundance of cheap computing resources as well as the advent of "useful" <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning</a> (rather than the theoretical variety). Cracking this puzzle is gaining traction amongst the programming herds, as you can see by the popularity of challenges such as this one: <a href="http://fiji.sc/Segmentation_of_neuronal_structures_in_EM_stacks_challenge_-_ISBI_2012">Segmentation of neuronal structures in EM stacks challenge - ISBI 2012</a>. It is from this challenge we sourced the stack and micrograph above; the right-hand side is the finished product after machine learning processing. </p> <p>There are also open source packages to help with segmentation. A couple of notable contenders are <a href="http://fiji.sc/Fiji">Fiji</a> and <a href="http://ilastik.org/">Ilastik</a>. Below is a screenshot of Ilastik. </p>  <div class="figure"><p><img alt="Figure-2-a.png" height="300px" src="https://raw.githubusercontent.com/ilastik/ilastik.github.io/master/gallery/Figure-2-a.png" width="400px" /></p><p><span class="figure-number">Figure 5:</span> Source: <a href="http://ilastik.org/gallery.html">Ilastik gallery</a>.</p></div> <p>An activity that naturally follows on from segmentation and labelling is <a href="https://en.wikipedia.org/wiki/Neuronal_tracing">reconstruction</a>. The objective of reconstruction is to try to "reconstruct" morphology given the images in the stack. It could involve inferring the missing bits of information by mathematical means or any other kind of analysis which transforms the set of discrete objects spotted by segmentation into something looking more like a bunch of connected neurons. </p> <p>Once we have a reconstructed model, we can start performing <i>morphometric analysis</i>. As wikipedia tells us, <a href="https://en.wikipedia.org/wiki/Morphometrics">Morphometry</a> is "the quantitative analysis of form"; as you can imagine, there are a lot of useful things one may want to measure in the brain structures and sub-structures such as lengths, volumes, surface area and so on. Some of these measurements can of course be done in 2D, but life is made easier if the model is available in 3D. One such tool is <a href="http://wiki.blender.org/index.php/Extensions:2.6/Py/Scripts/Neuro_tool">NeuroMorph</a>. It is an open source extension written in Python for the popular open source 3D computer graphics software <a href="https://en.wikipedia.org/wiki/Blender_(software)">Blender</a>. </p>  <div class="figure"><p><img alt="NeuroMorph_screenshot.png" height="300px" src="http://wiki.blender.org/uploads/9/98/NeuroMorph_screenshot.png" width="300px" /></p><p><span class="figure-number">Figure 6:</span> Source: <a href="http://figshare.com/articles/Segmented_anisotropic_ssTEM_dataset_of_neural_tissue/856713">Segmented anisotropic ssTEM dataset of neural tissue</a></p></div></div></div> <div class="outline-2" id="outline-container-sec-6"><h2 id="sec-6">Conclusion</h2><div class="outline-text-2" id="text-6"><p>This post was a bit of a world-wind tour of some of the sources of real world data for Computational Neuroscience. As I soon found out, each of these sections could have easily been ten times bigger and still not provide you with a proper overview of the landscape; having said that, I hope that the post at least gives some impression of the terrain and its main features. </p> <p>From a software engineering perspective, its worth pointing out the lack of standardisation in information exchange. In an ideal world, one would want a pipeline with components to perform each of the steps of the complete process, from data acquisition off of a microscope (either opitical or EM), to segmentation, labelling, reconstruction and finally morphometric analysis. This would then be used as an input to the models. Alas, no such overarching standard appears to exist. </p> <p>One final point in terms of Free and Open Source Software (FOSS). On one hand, it is encouraging to see the large number of FOSS tools and programs being used. Unfortunately - at least for the lovers of Free Software - there are also some proprietary tools that are widely used such as <a href="http://www.mbfbioscience.com/neurolucida">NeuroLucida</a>. Since the software is so specialised, the fear is that in the future, the better funded commercial enterprises will take over more and more of the space. </p> <p>That's all for now. Don't forget to tune in for the next instalment! </p></div></div><div id="footnotes"><h2 class="footnotes">Footnotes: </h2><div id="text-footnotes"> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.1" id="fn.1" name="fn.1">1</a></sup> <p class="footpara">As it happens, what we are doing here is to apply a well-established learning methodology called the <a href="https://www.farnamstreetblog.com/2012/04/learn-anything-faster-with-the-feynman-technique/">Feynman Technique</a>. I was blissfully unaware of its existence all this time, even though <a href="https://en.wikipedia.org/wiki/Richard_Feynman">Feynman</a> is one of my heroes and even though I had read a fair bit about the man. On this topic (and the reason why I came to know about the Feynman Technique), its worth reading <a href="https://www.farnamstreetblog.com/2015/01/richard-feynman-knowing-something/">Richard Feynman: The Difference Between Knowing the Name of Something and Knowing Something</a>, where Feynman discusses his disappointment with science education in Brazil. Unfortunately the Portuguese and the Brazilian teaching systems have a lot in common - or at least they did when I was younger. </p></div> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.2" id="fn.2" name="fn.2">2</a></sup> <p class="footpara">Nor is the microscope the only way to figure out what is happening inside the brain. For example, there are <a href="https://en.wikipedia.org/wiki/Neuroimaging">neuroimagining</a> techniques which can provide data about both structure and function. </p></div> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.3" id="fn.3" name="fn.3">3</a></sup> <p class="footpara">Patented by <a href="https://en.wikipedia.org/wiki/Marvin_Minsky">Marvin Minsky</a>, no less - yes, he of Computer Science and AI fame! </p></div> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.4" id="fn.4" name="fn.4">4</a></sup> <p class="footpara">And, to be fair, sub-nanometre just doesn't quite capture just how low these things can go. For an example, read <a href="http://www.ncbi.nlm.nih.gov/pubmed/21844593">Electron microscopy at a sub-50 pm resolution</a>. </p></div> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.5" id="fn.5" name="fn.5">5</a></sup> <p class="footpara">For a more technical but yet short and understandable take, read <a href="http://www.jneurosci.org/content/26/47/12101.full">Uniform Serial Sectioning for Transmission Electron Microscopy</a>. </p></div> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.6" id="fn.6" name="fn.6">6</a></sup> <p class="footpara">On the topic of formats: its probably time we mention the <a href="https://www.openmicroscopy.org/site">Open Microscopy Environment</a> (OME). The microscopy world is dominated by hardware and as such its the perfect environment for corporations, their proprietary formats and expensive software packages. The OME guys are trying to buck the trend by creating a suite of open source tools and protocols, and by looking at some of <a href="http://help.openmicroscopy.org/viewing-data.html#screen">their stuff</a>, they seem to be doing alright. </p></div>  </div></div></div><div class="status" id="postamble"><p class="date">Created: 2015-11-30 Mon 23:12</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>

            <p class="text-muted">in 'Marco Craveiro' on December 01, 2015 04:43 PM. <a href="http://mcraveiro.blogspot.com/2015/11/nerd-food-tooling-in-computational_30.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Nerd Food: Tooling in Computational Neuroscience - Part I: NEURON.</h4>

            Nerd Food: Tooling in Computational Neuroscience - Part I<div id="content"><p>In the <a href="http://mcraveiro.blogspot.co.uk/2015/09/nerd-food-neurons-for-computer-geeks_16.html">previous series of posts</a> we did a build up of theory - right up to the point where we were just about able to make sense of <i>Integrate and Fire</i> - one of the simpler families of neuron models. The series used a <a href="https://en.wikipedia.org/wiki/Reductionism">reductionist</a> approach - or bottom up, if you prefer<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.1" id="fnr.1" name="fnr.1">1</a></sup>. We are now starting a new series with the opposite take, this time coming at it from the top. The objective is to provide a (very) high-level overview - in laymen's terms, still - of a few of the "platforms" used in computational neuroscience. As this is a rather large topic, we'll try to tackle a couple of platforms each post, discussing a little bit of their history, purpose and limitations - whilst trying to maintain a focus on <i>file formats</i>or DSLs. "File formats" may not sound particularly exciting at first glance, but it is important to keep in mind that these are instances of meta-models of the problem domain in question, and as such, their expressiveness is very important. Understand those and you've understood a great deal about the domain and about the engineering choices of those involved. </p> <p>But first, let's introduce <i>Computational Neuroscience</i>. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">Computers and the Brain</h2><div class="outline-text-2" id="text-1"><p><a href="http://mcraveiro.blogspot.co.uk/2015/09/nerd-food-neurons-for-computer-geeks_7.html">Part V</a> of our previous series discussed some of the reasons why one would want to model neurons (section <i>Brief Context on Modeling</i>). What we did not mention is that there is a whole scientific discipline dedicated to this endeavour, called Computational Neuroscience. Wikipedia has a <a href="https://en.wikipedia.org/wiki/Computational_neuroscience">pretty good working definition</a>, which we will take wholesale. It states: </p> <blockquote><p>Computational neuroscience […] is the study of brain function in terms of the information processing properties of the structures that make up the nervous system. It is an interdisciplinary science that links the diverse fields of neuroscience, cognitive science, and psychology with electrical engineering, computer science, mathematics, and physics. </p> <p>Computational neuroscience is distinct from psychological connectionism and from learning theories of disciplines such as machine learning, neural networks, and computational learning theory in that it emphasizes descriptions of functional and biologically realistic neurons (and neural systems) and their physiology and dynamics. These models capture the essential features of the biological system at multiple spatial-temporal scales, from membrane currents, proteins, and chemical coupling to network oscillations, columnar and topographic architecture, and learning and memory. </p> <p>These computational models are used to frame hypotheses that can be directly tested by biological or psychological experiments. </p></blockquote> <p>Lots of big words, of course, but hopefully they make <i>some</i> sense after the previous posts. If not, don't despair; what they all hint at is an "interdisciplinary" effort to create biologically plausible models, and to use these to provide insights on how the brain is performing certain functions. Think of the Computational Neuroscientist as the right-hand person of the Neuroscientist - the "computer guy" to the "business guy", if you like. The Neuroscientist (particularly the experimental Neuroscientist) gets his or her hands messy with wetware and experiments, which end up providing data and a better biological understanding; the Computational Neuroscientist takes these and uses them to make improved computer models, which are used to test hypothesis or to make new ones, which can then validated by experiments and so on, in a virtuous feedback loop.<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.2" id="fnr.2" name="fnr.2">2</a></sup>Where the "interdisciplinary" part comes in is that many of the people doing the role of "computer guys" are actually not computer scientists but instead come from a variety of backgrounds such as biology, physics, chemistry and so on. This variety adds a lot of value to the discipline because the brain is such a complex organ; understanding it requires all kinds of skills - and then some. </p></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">It's Models All the Way Down</h2><div class="outline-text-2" id="text-2"><p>At the core, then, the work of the Computational Neuroscientist is to create models. Of course, <a href="http://mcraveiro.blogspot.co.uk/2015/09/nerd-food-neurons-for-computer-geeks_7.html">as we already seen</a>, one does not just walk straight into Mordor and starts creating the "most biologically plausible" model of the brain possible; all models must have a scope as narrow as possible, if they are to become a) understandable and b) computationally feasible. Thus engineering trade-offs are crucial to the discipline. </p> <p>Also, it is important to understand that creating a model does not always imply writing things from scratch. Instead, most practitioners rely on a wealth of software available, all with different advantages and disadvantages. </p> <p>At this juncture you are probably wondering just what exactly are these "models" we speak so much of. Are they just equations like IaF? Well, yes and no. As it happens, all models have roughly the following structure: </p> <ul class="org-ul"><li><i>a morphology definition</i>: we've already <a href="http://mcraveiro.blogspot.co.uk/2015/08/nerd-food-neurons-for-computer-geeks.html">spoken a bit</a> about morphology; think of it as the definition of the entities that exist in your model, their characteristics and relationships. This is actually closer to what we, computer scientists think the word modeling means. For example, the morphology defines how many neurons you have, how many axons and dendrites, connectivity, spatial positioning and so on. </li><li><i>a functional, mathematical or physical definition</i>: I've heard it named in many ways, but fundamentally, what it boils down to is the definition of the equations that your model requires. For example, are you modeling electrical properties or reaction/diffusion? </li></ul> <p>For the simpler models, the morphology gets somewhat obscured - after all, in LIF, there is very little information about a neuron because all we are interested in are the spikes. For other models, a lot of morphological details are required. </p></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">The Tooling Landscape</h2><div class="outline-text-2" id="text-3"></div><div class="outline-3" id="outline-container-sec-3-1"><h3 id="sec-3-1">Idealised…</h3><div class="outline-text-3" id="text-3-1"><p>It is important to keep in mind that these models are to be used in a <i>simulation</i>; that is, we are going to run the program for a period of time (hours or days) and observe different aspects of its behaviour. Thus the functional definition of the model provides the equations that describe the dynamics of the system being simulated and the morphology will provide some of the inputs for those equations. </p> <p>From here one can start sketch the requirements for a system for the Computational Neuroscientist: </p> <ul class="org-ul"><li>a platform of some kind to provide simulation control: starting, stopping, re-running, storing the results and so on. As the simulations can take a long time to run, the data sets can be quite large - on the hundreds of gigs range - so efficiently handling of the output data is a must. </li><li>some kind of DSL that provides a user friendly way to define their models, ideally with a graphical user interface that helps author the DSL. The DSL must cover the two aspects we mention above. </li><li>efficient libraries of numerical routines to help solve the equations. The libraries must be exposed in someway to the DSL so that users can make use of these when defining the functional aspects of the model. </li></ul> <p>Architecturally, the ability to use a cluster or GPUs would of course be very useful, but we shall ignore those aspects for now. Given this idealised platform, we can now make a bit more sense of what actually exists in the wild. </p></div></div> <div class="outline-3" id="outline-container-sec-3-2"><h3 id="sec-3-2">… vs Actual</h3><div class="outline-text-3" id="text-3-2"><p>The multidisciplinary nature of Computational Neuroscience poses some challenges when it comes to software development: as mentioned, many of the practitioners in the field do not have a Software Engineering background; of those that do have, most tend not to have strong biology and neuroscience backgrounds. As a result, the landscape is fragmented and the quality is uneven. On one side, most of the software is open source, making reuse a lot less of a problem. On the other hand, things such as continuous integration, version control, portability, user interface guide lines, organised releases, packaging and so on are still lagging behind most "regular" Free and Open Source projects<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.3" id="fnr.3" name="fnr.3">3</a></sup>. </p> <p>In some ways, to enter Computational Neuroscience is a bit like travelling in time to a era before git, before GitHub, before Travis and all other things we take for granted. Not everywhere, of course, but still in quite a few places, particularly with the older and more popular projects. One cannot help but get the feeling that the field could do with some of the general energy we have in the FOSS community, but the technical barriers to contributing tend to be large since the domain is so complex. </p> <p>So after all of this boring introductory material, we can finally look at our first system. </p></div></div></div> <div class="outline-2" id="outline-container-sec-4"><h2 id="sec-4">NEURON</h2><div class="outline-text-2" id="text-4"><p>Having to choose, one feels compelled to start with <a href="http://www.neuron.yale.edu/neuron/">NEURON</a> - the most venerable of the lot, with roots in the 80s<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.4" id="fnr.4" name="fnr.4">4</a></sup>. NEURON is a simulation environment with great depth of functionality and a comprehensive user manual published as a (non-free) <a href="http://ebooks.cambridge.org/ebook.jsf?bid=CBO9780511541612">book</a>. For the less wealthy, an <a href="http://www.neuron.yale.edu/neuron/static/papers/hbtnn2/overviewforhbtnn2e.pdf">overview paper</a> is available, as are many other <a href="http://www.neuron.yale.edu/neuron/docs">online resources</a>. The software itself is fully open source, with a <a href="http://www.neuron.yale.edu/hg/neuron/nrn/file/5b5889f69d6e/src">public mercurial repo</a>. </p> <p>As with many of the older tools in this field, NEURON development has not quite kept up the pace with the latest and greatest. For instance, it still has a Motif'esque look to its UI but, alas, do not be fooled - its not Motif but <a href="https://en.wikipedia.org/wiki/InterViews">InterViews</a> - a technology I never heard of, but seems to have been popular in the 80's and early 90's. One fears that NEURON may just be the last widely used program relying on InterViews - and the fact that they carry <a href="http://www.neuron.yale.edu/hg/neuron/iv/file/91e22c4a0a0c/README">their own fork of it</a> does not make me hopeful. </p>  <div class="figure"><p><img alt="subset0.gif" height="300px" src="http://www.neuron.yale.edu/neuron/static/docs/cbtut/stylized/figs/subset0.gif" width="400px" /></p><p><span class="figure-number">Figure 1:</span> Source: NEURON Cell Builder</p></div> <p>However, once one goes past these layers of legacy, the domain functionality of the tool is very impressive. This goes some way to explain why so many people rely on it daily and why so many papers have been written using it - over 600 papers at the last count. </p> <p>Whilst NEURON is vast, we are particularly interested in only two aspects of it: <i>hoc</i> and <i>mod</i> (in its many incarnations). These are the files that can be used to define models. </p></div> <div class="outline-3" id="outline-container-sec-4-1"><h3 id="sec-4-1">Hoc</h3><div class="outline-text-3" id="text-4-1"><p><a href="https://en.wikipedia.org/wiki/Hoc_(programming_language)">Hoc</a> has a fascinating history and a pedigree to match. It is actually the creation of Kernighan and Pike, two UNIX luminaries, and has as contenders tools like bc and dc and so on. NEURON took hoc and extended it both in terms of syntax as well as the number of available functions; <a href="http://www.neuron.yale.edu/neuron/static/docs/refman/hoc.html">NEURON Hoc</a> is now an interpreted object oriented language, albeit with some limitations such as lack of inheritance. Programs written in hoc execute in an interpreter called <code>oc</code>. There are a few variations of this interpreter, with different kinds of libraries made available to the user (UI, neuron modeling specific functionality, etc) but the gist of it is the same, and the strong point is the interactive development with rapid feedback. On the GUI versions of the interpreter, the script can specify it's UI elements including input widgets for parameters and widgets to display the output. Hoc is then used as a mix between model/view logic and morphological definition language. </p> <p>To get a feel for the language, here's a very simple sample <a href="http://www.neuron.yale.edu/neuron/static/docs/elementarytools/writcode.htm">from the manual</a>: </p> <pre class="example"><br />create soma    // model topology<br />access soma    // default section = soma<br /><br />soma {<br />   diam = 10   // soma dimensions in um<br />   L = 10/PI   //   surface area = 100 um^2<br />}<br /></pre></div></div> <div class="outline-3" id="outline-container-sec-4-2"><h3 id="sec-4-2">NMODL</h3><div class="outline-text-3" id="text-4-2"><p>The second language supported by NEURON is <a href="http://www.neuron.yale.edu/neuron/static/docs/help/neuron/nmodl/nmodl.html">NMODL</a> - The NEURON extended MODL (Model Description Language). NMODL is used to specify a physical model in terms of equations such as simultaneous nonlinear algebraic equations, differential equations and so on. In practice, there are actually different versions of NMODL for different NEURON versions, but to keep things simple I'll just abstract these complexities and refer to them as one entity<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.5" id="fnr.5" name="fnr.5">5</a></sup>. </p> <p>As intimated above, NMODL is a descendant of MODL. As with Hoc, the history of MODL is quite interesting; it was a language was defined by the National Biomedical Simulation Resource to specify models for use with SCoP - the Simulation Control Program<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.6" id="fnr.6" name="fnr.6">6</a></sup>. From what I can gather of SCoP, its main purpose was to make life easier when creating simulations, providing an environment where users could focus on what they were trying to simulate rather than nitty-gritty implementation specific details. </p> <p>NMODL took MODL syntax and extended it with the primitives required by its domain; for instance, it added the NEURON block to the language, which allows multiple instances of "entities". As with MODL, NMODL is translated into efficient C code and linked against supporting libraries that provide the numerics; the NMODL translator to C also had to take into account the requirement of linking against NEURON libraries rather than SCoP. </p> <p>The below is a snippet of NMODL code, copied from the <a href="http://ebooks.cambridge.org/ebook.jsf?bid=CBO9780511541612">NEURON book</a>(chapter 9, listing 9.1): </p> <pre class="example"><br />NEURON {<br />  SUFFIX leak<br />  NONSPECIFIC_CURRENT i<br />  RANGE i, e, g<br />}<br /><br />PARAMETER {<br />  g = 0.001  (siemens/cm2)  &lt; 0, 1e9 &gt;<br />  e = -65    (millivolt)<br />}<br /><br />ASSIGNED {<br />  i  (milliamp/cm2)<br />  v  (millivolt)<br />}<br /></pre> <p>NMODL and hoc are used together to form a model; hoc to provide the UI, parameters and morphology and NMODL to provide the physical modeling. The website <a href="https://senselab.med.yale.edu/modeldb/default.cshtml">ModelDB</a> provides a database of models in a variety of platforms with the main objective of making research reproducible. <a href="https://senselab.med.yale.edu/modeldb/showModel.cshtml?model=83319&amp;file=/destexhe_benchmarks/NEURON/README">Here</a> you can see an example of a production NEURON model in its full glory, with a mix of hoc and NMODL files - as well as a few others such as session files, which we can ignore for our purposes. </p></div></div> <div class="outline-3" id="outline-container-sec-4-3"><h3 id="sec-4-3">Thoughts</h3><div class="outline-text-3" id="text-4-3"><p>NEURON is more or less a standard in Computational Neuroscience - together with a few other tools such as GENESIS, which we shall cover later. Embedded deeply in it source code is the domain logic learned painstakingly over several decades. Whilst software engineering-wise it is creaking at the seams, finding a next generation heir will be a non-trivial task given the features of the system, the amount of models that exist out there, and the knowledge and large community that uses it. </p> <p>Due to this, a solution that a lot of next-generation tools have developed is to use NEURON as a backend, providing a shiny modern frontend and then generating the appropriate hoc and NMODL required by NEURON. This is then executed in a NEURON environment and the results are sent back to the user for visualisation and processing using modern tools. Le Roi Est Mort, Vive Le Roi! </p></div></div></div> <div class="outline-2" id="outline-container-sec-5"><h2 id="sec-5">Conclusions</h2><div class="outline-text-2" id="text-5"><p>In this first part we've outlined what Computational Neuroscience is all about, what we mean by a model in this context and what services one can expect from a platform in this domain. We also covered the first of such platforms. Tune in for the next instalment where we'll cover more platforms. </p></div></div><div id="footnotes"><h2 class="footnotes">Footnotes: </h2><div id="text-footnotes"> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.1" id="fn.1" name="fn.1">1</a></sup> <p class="footpara">I still owe you the final post of that series, coming out soon, hopefully. </p></div> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.2" id="fn.2" name="fn.2">2</a></sup> <p class="footpara">Of course, once you scratch the surface, things get a bit murkier. <a href="http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000078">Erik De Schutter</a> states: </p> <blockquote><p>[…] The term is often used to denote theoretical approaches in neuroscience, focusing on how the brain computes information. Examples are the search for “the neural code”, using experimental, analytical, and (to a limited degree) modeling methods, or theoretical analysis of constraints on brain architecture and function. This theoretical approach is closely linked to systems neuroscience, which studies neural circuit function, most commonly in awake, behaving intact animals, and has no relation at all to systems biology.  […] Alternatively, computational neuroscience is about the use of computational approaches to investigate the properties of nervous systems at different levels of detail. Strictly speaking, this implies simulation of numerical models on computers, but usually analytical models are also included […], and experimental verification of models is an important issue. Sometimes this modeling is quite data driven and may involve cycling back and forth between experimental and computational methods. </p></blockquote></div> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.3" id="fn.3" name="fn.3">3</a></sup> <p class="footpara">This is a problem that has not gone unnoticed; for instance, this paper provides an interesting and thorough review of the state onion in Computational Neuroscience: <a href="http://arxiv.org/pdf/1205.3025.pdf">Current practice in software development for computational neuroscience and how to improve it.</a> In particular, it explains the dilemmas faced by the maintainers of neuroscience packages. </p></div> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.4" id="fn.4" name="fn.4">4</a></sup> <p class="footpara">The early story of NEURON is available <a href="http://neuron.duke.edu/userman/4/neuron.html">here</a>; see also the <a href="http://www.scholarpedia.org/article/Neuron_simulation_environment">scholarpedia page</a>. </p></div> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.5" id="fn.5" name="fn.5">5</a></sup> <p class="footpara">See the <a href="http://www.neuron.yale.edu/neuron/static/docs/help/neuron/nmodl/nmodl.html">NMODL page</a> for details, in the history section. </p></div> <div class="footdef"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.6" id="fn.6" name="fn.6">6</a></sup> <p class="footpara">As far as I can see, in the SCoP days MODL it was just called the <a href="http://www.neuron.yale.edu/ftp/ted/neuron/scop/scopman.html">SCoP Language</a>, but as the related paper is under a paywall I can't prove it either way. Paper: SCoP: An interactive simulation control program for micro- and minicomputers, from <a href="http://link.springer.com/article/10.1007/BF02459691">Springer</a>. </p></div>  </div></div></div><div class="status" id="postamble"><p class="date">Created: 2015-11-11 Wed 17:59</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>

            <p class="text-muted">in 'Marco Craveiro' on November 16, 2015 02:48 PM. <a href="http://mcraveiro.blogspot.com/2015/11/nerd-food-tooling-in-computational.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Nerd Food: Interesting....</h4>

            Nerd Food: Interesting…<div id="content"><p>Time to flush all those tabs again. Some interesting stuff I bumped into recently-ish. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">Finance</h2><div class="outline-text-2" id="text-1"><ul class="org-ul"><li><a href="https://medium.com/backchannel/how-bitcoins-blockchain-could-power-an-alternate-internet-bb501855af67">There’s a blockchain for that</a>!: The rise and rise of the blockchain… </li><li><a href="http://www.joecoin.com/2015/02/crypto-20-and-other-misconceptions.html">Crypto 2.0–And Other Misconceptions</a>: … but maybe we are getting a bit ahead of ourselves, and bitcoin is really what matters! </li><li><a href="http://www.michaelnielsen.org/ddi/how-the-bitcoin-protocol-actually-works/">How the Bitcoin protocol actually works</a>: Gory details of bitcoin's internals. Must say that the <a href="http://shop.oreilly.com/product/0636920032281.do">Bitcoin book</a> already provides a pretty good explanation, but interesting nonetheless. </li><li><a href="http://blogs.wsj.com/moneybeat/2015/11/03/bitbeat-bitcoin-surges-past-400-on-back-of-the-new-shining-star/">BitBeat: Bitcoin Surges Past $400 on Back of the New ‘Shining Star’</a>: Bitcoin is up again! Rollercoaster ride? </li><li><a href="http://modval.org/home/">ModVal</a>: How cool is that, a site for financial models. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">Startups et. al.</h2><div class="outline-text-2" id="text-2"><ul class="org-ul"><li><a href="http://www.newyorker.com/magazine/2015/02/23/shape-things-come">The Shape of Things to Come</a>: Jonathan Ive seems like a cool fellow, actually. Even though I'm not much of an apple fan. </li><li><a href="http://blog.ycombinator.com/yc-continuity-fund">Y Combinator Posthaven</a>: thoughts from the combinator. 1000 companies funded! </li><li><a href="https://medium.com/@EskoKilpi/movement-of-thought-that-led-to-airbnb-and-uber-9d4da5e3da3a#.d2dvu2nub">The Future of Firms. Is There an App for That?</a>: What does it mean to be a company in this world of change? </li></ul></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">General Coding</h2><div class="outline-text-2" id="text-3"><ul class="org-ul"><li><a href="https://medium.com/@landongn/12-years-later-what-i-ve-learned-about-being-a-software-engineer-d6e334d6e8a3">What I’ve learned so far about software development</a>: Tales from the trenches. </li><li><a href="https://codewords.recurse.com/issues/two/git-from-the-inside-out">Git from the inside out</a>: Gory details about git. And I mean <b>really</b>gory and <b>really</b> detailed. As with bitcoin, the <a href="http://shop.oreilly.com/product/9780596520137.do">git book</a> was already pretty detailed but interesting nonetheless. </li><li><a href="http://chris.beams.io/posts/git-commit/">How to Write a Git Commit Message</a>: jeez, each to their own! Here's a true geek of git commit messages. But very useful though. </li><li><a href="http://www.benstopford.com/2015/04/28/elements-of-scale-composing-and-scaling-data-platforms/">Elements of Scale: Composing and Scaling Data Platforms</a>: Interesting take on data, should help navigate the SQL/NoSQL debate. </li><li><a href="http://apihandyman.io/do-you-really-know-why-you-prefer-rest-over-rpc/">Do you really know why you prefer REST over RPC?</a>: Title says it all, interesting take on the RESTification of the world. </li><li><a href="http://highscalability.com/blog/2015/10/12/making-the-case-for-building-scalable-stateful-services-in-t.html">Making The Case For Building Scalable Stateful Services In The Modern Era</a>: Instead of knee-jerk reactions about statefulness, think deeply before you decide. With presentation: <a href="https://www.youtube.com/watch?v=H0i_bXKwujQ">"Building Scalable Stateful Services" by Caitie McCaffrey</a></li><li><a href="https://www.youtube.com/watch?v=9RMOc0SwRro">"Apache Kafka and the Next 700 Stream Processing Systems" by Jay Kreps</a>: Improved my understanding of Kafka somewhat. And the title made me curious, so I ended up reading <a href="http://www.cs.cmu.edu/~crary/819-f09/Landin66.pdf">The Next 700 Programming Languages</a>. </li><li><a href="http://www.theatlantic.com/technology/archive/2015/11/where-was-the-internet-born/413221/">The Room Where the Internet Was Born</a>: A quest for understanding the cloud. Rather long but great for those that like computer history. </li><li><a href="http://www.aaron-gray.com/a-criticism-of-scrum/">A Criticism of Scrum</a>: quite well thought out actually. I love agile but I must say, I agree with many of the points made. I guess in the end, the key is not to fall in love with ceremony. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-4"><h2 id="sec-4">Databases</h2><div class="outline-text-2" id="text-4"><ul class="org-ul"><li><a href="http://gotocon.com/dl/goto-berlin-2013/slides/HenningJacobs_and_ValentineGogichashvili_WhyZalandoTrustsInPostgreSQL.pdf">Why Zalando trusts in PostgreSQL</a>: Great to see how the elephant is used in anger. Picked up a few tips. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-5"><h2 id="sec-5">C++</h2><div class="outline-text-2" id="text-5"><ul class="org-ul"><li><a href="https://code.facebook.com/posts/1661982097368498">Futures for C++11 at Facebook</a>: futures are all the rage… </li><li><a href="http://instagram-engineering.tumblr.com/post/121930298932/c-futures-at-instagram">C++ Futures at Instagram</a>: … everywhere! </li><li><a href="https://www.livecoding.tv/videos/c-cplusplus/?sort=newest">Livestream</a>: WOT, C++ live coding? Man this is a weird notion! </li><li><a href="https://www.youtube.com/watch?v=nXaxk27zwlk&amp;feature=youtu.be">CppCon 2015: Chandler Carruth "Tuning C++: Benchmarks, and CPUs, and Compilers! Oh My!</a>: Chandler at his best - hilarious but extremely informative. </li><li><a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4367.html">Comparison in C++</a>: A weird but weirdly useful paper. Deep thinking about comparisons. For good measure, you should also watch the presentation: <a href="https://www.youtube.com/watch?v=fi0CQ7laiXE">CppCon 2015: Lawrence Crowl "Comparison is not simple, but it can be simpler"</a></li><li><a href="https://www.youtube.com/watch?v=mFUXNMfaciE">CppCon 2015: Eric Niebler "Ranges for the Standard Library"</a>: Ranges, ranges, ranges!! Can't wait! For good measure, you can also read <a href="http://bartoszmilewski.com/2014/10/17/c-ranges-are-pure-monadic-goodness/">C++ Ranges are Pure Monadic Goodness</a>. </li><li><a href="https://cryptocoding.net/index.php/Coding_rules">Crypto coding rules</a>: haven't parsed the entire document, but already found a few very useful points. </li><li><a href="https://github.com/emil-e/rapidcheck">RapidCheck</a>: Didn't know of QuickCheck or RapidCheck, but this may come in handy at some point… </li></ul></div></div> <div class="outline-2" id="outline-container-sec-6"><h2 id="sec-6">Layman Science</h2><div class="outline-text-2" id="text-6"><ul class="org-ul"><li><a href="https://nolaymanleftbehind.wordpress.com/2011/07/10/linear-algebra-what-matrices-actually-are/">Linear Algebra</a>: What matrices actually are: an attempt to make matrices accessible. </li><li><a href="http://betterexplained.com/articles/a-gentle-introduction-to-learning-calculus/">A Gentle Introduction To Learning Calculus</a>: Helpful when trying to remember all the stuff one did all those years ago… </li><li><a href="http://betterexplained.com/articles/a-visual-intuitive-guide-to-imaginary-numbers/">A Visual, Intuitive Guide to Imaginary Numbers</a>: … continued. </li><li><a href="http://esciencecommons.blogspot.co.uk/2011/01/new-theories-reveal-nature-of-numbers.html">New theories reveal the nature of numbers</a>: A <a href="http://www.imdb.com/title/tt0787524/">Ramanujan movie</a> is due out soon, and these are the guys doing the maths behind the scenes. Can't wait for the movie! </li><li><a href="http://v.cx/2010/04/feynman-brazil-education">Richard Feynman on education in Brazil</a>: Hilarious, but somewhat reminiscent of my own education, in a different country but culturally very similar and certainly with a very similar approach to science. </li><li><a href="http://neuralnetworksanddeeplearning.com/chap1.html">Using neural nets to recognize handwritten digits</a>: nice introduction to neural nets with a good example. </li><li><a href="http://nautil.us/issue/15/turbulence/your-brain-is-on-the-brink-of-chaos">Your Brain Is On the Brink of Chaos</a>: <b>Very</b> interesting. This is particularly interesting because I have been reading up on the delicate balance between inhibitory and excitatory neurons, but the literature always gives you this static impression of balance. If you assume chaos on the other hand… </li></ul></div></div> <div class="outline-2" id="outline-container-sec-7"><h2 id="sec-7">Other</h2><div class="outline-text-2" id="text-7"><ul class="org-ul"><li><a href="http://www.newyorker.com/magazine/2015/06/01/extreme-city-specter">Extreme City</a>: Luanda, my beloved, just keeps on getting crazier and crazier. Interesting - if somewhat expat-oriented - take on the city. </li><li><a href="http://www.slate.com/blogs/schooled/2015/09/17/kiera_wilmot_arrest_florida_teenager_reacts_to_ahmed_mohamed_story.html">This Florida Teenager Knows What Ahmed Mohamed Is Going Through. It Happened to Her in 2013</a>: sad, really. Whatever the real truth was about Ahmed. </li><li><a href="http://www.nytimes.com/2015/10/11/opinion/sunday/will-you-ever-be-able-to-upload-your-brain.html?_r=1">Will You Ever Be Able to Upload Your Brain?</a>: er., spoiler alert - not really. Interesting though. </li><li><a href="https://dl.dropboxusercontent.com/u/50282823/Flash%2520BBG%25202015-%2520October-Taleb.pptx.pdf">Dealing with “power laws” with upper (lower) bound</a>: most certainly not for laypeople. Taleb is back at it. Would be great to have this translated to laymen's maths. </li><li><a href="https://www.youtube.com/watch?v=5mcyUUf20Ng&amp;feature=youtu.be&amp;list=PL37ZVnwpeshH37NxpV6XbgdDpY-w48hMd">Lieke Boon: Unconscious Bias</a>: we're all guilty: How to be a bit more aware of your own the biases is my take on it. </li></ul></div></div></div><div class="status" id="postamble"><p class="date">Created: 2015-11-09 Mon 23:57</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>

            <p class="text-muted">in 'Marco Craveiro' on November 10, 2015 05:54 PM. <a href="http://mcraveiro.blogspot.com/2015/11/nerd-food-interesting.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Nerd Food: Neurons for Computer Geeks - Part VI: LIF At Long Last!.</h4>

            Nerd Food: Neurons for Computer Geeks - Part VI: Integrate and Fire!<div id="content"><p>Welcome to part VI of a multi-part series on modeling neurons. In <a href="http://mcraveiro.blogspot.co.uk/2015/09/nerd-food-neurons-for-computer-geeks_7.html">part V</a> we added a tad more theory to link electricity with neurons, and also tried to give an idea of just how complex neurons are. Looking back on that post, I cannot help but notice I skipped one bit that is rather important to understanding Integrate-and-Fire (IAF) models. So lets look at that first and then return to our trail. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">Resting Potential and Action Potential</h2><div class="outline-text-2" id="text-1"><p>We have spoken <a href="http://mcraveiro.blogspot.co.uk/2015/09/nerd-food-neurons-for-computer-geeks_7.html">before</a> about the <a href="https://en.wikipedia.org/wiki/Membrane_potential">membrane potential</a> and the resting membrane potential, but we did so with such a high degree of hand-waving it now warrants revisiting. When we are talking about the <i>resting</i> membrane potential we mean just that - the value for the membrane potential when nothing much is happening. That is the magical circa -65mv we discussed before - with all of the related explanations on conventions around negative voltages. However, time does not stand still and things happen. The cell receives input from other neurons, and this varies over time. Some kinds of inputs can cause events to trigger on the receiving neuron: active ion channels may get opened or shut, ions move around, concentrations change and so forth, and thus, the cell will change its membrane potential in response. When these changes result in a higher voltage - such as moving to -60mv - we say a <i>depolarisation</i> is taking place. Conversely, when the voltage becomes more negative, we say <i>hyperpolarisation</i> is occurring. </p> <p>Now, it may just happen that there is a short-lived but "strong" burst of depolarisation, followed by equally rapid hyperpolarisation - and, as a result of which, the Axon's terminal decides to release <i>neurotransmitters</i> into the synapse (well, into the <i>synaptic gap</i> or <i>synaptic cleft</i> to be precise). This is called an <i><a href="https://en.wikipedia.org/wiki/Action_potential">action potential</a></i>, and it is also known by many other names such as "nerve impulses" or "spikes". When you hear that "a neuron has fired" this means that an action potential has just been emitted. If you record the neuron's behaviour over time you will see a <i>spike train</i> - a plot of the voltage over time, clearly showing the spikes. Taking a fairly random example: </p>  <div class="figure"><p><img alt="Simulation_of_hrose_neuron.png" height="300px" src="https://upload.wikimedia.org/wikipedia/commons/1/1b/Simulation_of_hrose_neuron.png" width="300px" /></p><p><span class="figure-number">Figure 1:</span> Source: Wikipedia, <a href="https://en.wikipedia.org/wiki/Neural_oscillation">Neural oscillation</a></p></div> <p>One way of picturing this is as a kind of "chain-reaction" whereby something triggers the voltage of the neuron to rise, which triggers a number of gates to open, which then trigger the voltage to rise and so on, until some kind of magic voltage threshold is reached where the inverse occurs: the gates that were causing the voltage to rise shut and some other gates that cause the voltage to decrease open, and so on, until we fall back down to the resting membrane potential. The process feeds back on itself, first as a positive feedback and then as a negative feedback. In the case of the picture above, something else triggers us again and again, until we finally come to rest. </p> <p>This spiking or firing behaviour is what we are trying to model. </p></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">Historical Background</h2><div class="outline-text-2" id="text-2"><p>As it happens, we are not the first ones to try to do so. A couple of years after Einstein's <i>annus mirabilis</i>, a french chap called <a href="https://en.wikipedia.org/wiki/Louis_Lapicque">Louis Lapicque</a> was also going through his own personal moment of inspiration, the output of which was the seminal <a href="http://www.snv.jussieu.fr/brette/papers/Lap07.pdf">Recherches quantitatives sur l'excitation électrique des nerfs traitée comme une polarisation</a>. It is summarised <a href="http://neurotheory.columbia.edu/~larry/AbbottBrResBul99.pdf">here</a> in fairly accessible English by Abbot. </p> <p>Lapicque had the insight of imagining the neuron as an RC circuit, with the membrane potential's behaviour explained as the interplay between capacitor and resistor; the action potential is then the capacitor reaching a threshold followed by a discharge. Even with our faint understanding of the subject matter, one cannot but appreciate Lapique's brilliance to have the ability to reach these conclusions in 1907. Of course, he also had to rely on the work of many others to get there, let's not forget. </p> <p>This model is still considered a useful model today, even though we know so much more about neurons now - a great example of what we mentioned <a href="http://mcraveiro.blogspot.co.uk/2015/09/nerd-food-neurons-for-computer-geeks_7.html">before</a> in terms of the choices of the level of detail when modeling. Each model is designed for a specific purpose and it should be as simple as possible for the stated end (but no simpler). As <a href="http://neurotheory.columbia.edu/~larry/AbbottBrResBul99.pdf">Abbot</a>says: </p> <blockquote><p>While Lapicque, because of the limited knowledge of his time, had no choice but to model the action potential in a simple manner, the stereotypical character of action potentials allows us, even today, to use the same approximation to avoid computation of the voltage trajectory during an action potential. This allows us to focus both intellectual and computation resources on the issues likely to be most relevant in neural computation, without expending time and energy on modeling a phenomenon, the generation of action potentials, that is already well understood. </p></blockquote></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">The IAF Family</h2><div class="outline-text-2" id="text-3"><p>Integrate-and-Fire is actually a family of models - related because all of them follow Lapicque's original insights. Over time, people have addressed shortcomings in the model by adding more parameters and modifying it slightly and from this other models were born. </p> <p>In general, models in the IAF family are single neuron models with a number of important properties (as per <a href="http://cns-classes.bu.edu/cn510/Papers/Izhikevich_Ch8.pdf">Izhikevich</a>): </p> <ul class="org-ul"><li>The spikes are all or none; that is, we either spike or we don't. This is a byproduct of the way spikes are added to the model, as we shall see later. This also means all spikes are identical because the are all created the same way. </li><li>The threshold for the spike is well defined and there is no ambiguity as to whether the neuron will fire or not. </li><li>It is possible to add a <i>refractory period</i>, similarly to how we add the spike. The refractory period is a time during which the neuron is less excitable (e.g. ignores inputs) and occurs right after the spike. </li><li>Positive currents are used as excitatory inputs and negative currents as inhibitory inputs. </li></ul> <p>But how do the members of this family look like? We will take a few examples from <a href="https://en.wikipedia.org/wiki/Biological_neuron_model">Wikipedia</a> to make a family portrait and then focus on LIF. </p></div> <div class="outline-3" id="outline-container-sec-3-1"><h3 id="sec-3-1">IAF: Integrate-and-Fire</h3><div class="outline-text-3" id="text-3-1"><p>This the Lapicque model. It is also called a "perfect" or "non-leaky" neuron. The formula is as follows: </p> \begin{align} I(t) = C_m \frac{dV_m(t)}{dt} \end{align}  <p>The <i>m</i>'s are there to signify <i>membrane</i>, nothing else. Note that its the job of the user to determine θ - that is the point at which the neuron spikes - and then to reset everything to zero and start again. If you are wondering why it's called "integrate", that's because the differential equation must be integrated before we can compare the current value to a threshold and then, if we're passed it, well - fire!. Hence Integrate-and-Fire. </p> <p>Wikipedia states this in a classier way, of course: </p> <blockquote><p>[This formula] is just the time derivative of the law of capacitance, Q = CV. When an input current is applied, the membrane voltage increases with time until it reaches a constant threshold Vth, at which point a delta function spike occurs and the voltage is reset to its resting potential, after which the model continues to run. The firing frequency of the model thus increases linearly without bound as input current increases. </p></blockquote></div></div> <div class="outline-3" id="outline-container-sec-3-2"><h3 id="sec-3-2">Integrate-and-Fire with Refractory Period</h3><div class="outline-text-3" id="text-3-2"><p>It is possible to extend IAF to take the refractory period into account. This is done by adding a period of time <i>t ref</i> during which the neuron does not fire. </p></div></div> <div class="outline-3" id="outline-container-sec-3-3"><h3 id="sec-3-3">LIF: Leaky Integrate-and-Fire</h3><div class="outline-text-3" id="text-3-3"><p>One of the problems of IAF is that it will "remember" stimulus, regardless of the time that elapses between stimuli. By way of example: if a neuron gets some input below the firing threshold at some time (say <i>ta</i>), then nothing for a long period of time and then subsequent stimulus at say <i>tb</i>, this will cause the neuron to fire (assuming the two inputs together are above the threshold). In the real world, neurons "forget" about below-threshold stimulus after certain amount of time has elapsed. This problem is solved in LIF by adding a <i>leak</i> term to IAF. The Wikipedia's formula is like so: </p> \begin{align} I_m(t) - \frac{V_m(t)}{R_m} = C_m \frac{dV_m(t)}{dt} \end{align}  <p>We will discuss it in detail later on. </p></div> <div class="outline-4" id="outline-container-sec-3-3-1"><h4 id="sec-3-3-1">Interlude: Leaky Integrators and Low-Pass Filters</h4><div class="outline-text-4" id="text-3-3-1"><p><b>Update</b>: this section got moved here from an earlier post. </p> <p>Minor detour into the world of "Leaky Integrators". As it turns out, mathematicians even have a name to describe functions like the one above: they are called <i><a href="https://en.wikipedia.org/wiki/Leaky_integrator">Leaky Integrators</a></i>. A leaky integrator is something that takes an input and "integrates" - that is, sums it over a range - but by doing so, starts "leaking" values out. In order words, a regular sum of values over a range should just result in an ever growing output. With a leaky integrator, we add up to a point, but then we start leaking, resetting the value of the sum back to where we started off. </p> <p>It turns out these kind of functions have great utility. For example, imagine that you have a range of inputs varying from some arbitrary low number to some other arbitrary high-number. When you supply these inputs to a leaky integrator, it can be used to "filter out" the high numbers; input numbers higher than a certain cut-off point just result in zeros in the output. This is known as a <i><a href="https://en.wikipedia.org/wiki/Low-pass_filter">low-pass filter</a></i>. One can conceive of a function that acted in the opposite way - a <i>high-pass filter</i>. </p></div></div></div> <div class="outline-3" id="outline-container-sec-3-4"><h3 id="sec-3-4">Exponential Integrate-and-Fire</h3><div class="outline-text-3" id="text-3-4"><p>In this model, spike generation is exponential: </p> \begin{align} \frac{dX}{dt} = \Delta_\tau exp(\frac{X - X_t}{\Delta_\tau}) \end{align}  <p>Wikipedia explains it as follows: </p> <blockquote><p>where X is the membrane potential, X<sub>T</sub> is the membrane potential threshold, and Δ<sub>T</sub> is the sharpness of action potential initiation, usually around 1 mV for cortical pyramidal neurons. Once the membrane potential crosses X<sub>T</sub>, it diverges to infinity in finite time. </p></blockquote></div></div> <div class="outline-3" id="outline-container-sec-3-5"><h3 id="sec-3-5">Others</h3><div class="outline-text-3" id="text-3-5"><p>We could continue and look into other IAF models, but you get the point. Each model has limitations, and as people work through those limitations - e.g. try to make the spike trains generated by the model closer to those observed in reality - they make changes to the model and create new members of the IAF family. </p></div></div></div> <div class="outline-2" id="outline-container-sec-4"><h2 id="sec-4">Explaining the LIF Formula</h2><div class="outline-text-2" id="text-4"><p>Let's look at a slightly more familiar formulation of LIF: </p> \begin{align} \tau_m \frac{dv}{dt} = -v(t) + RI(t) \end{align}  <p>By now this should make vague sense, but lets do it step by step breakdown just to make sure we are all on the same page. First, we know that the current of the RC circuit is defined like so: </p> \begin{align} I(t) = I_R + I_C \end{align}  <p>From Ohm's Law we also know that: </p> \begin{align} I_R = \frac {v}{R} \end{align}  <p>And from the <a href="http://mcraveiro.blogspot.co.uk/2015/09/nerd-food-neurons-for-computer-geeks_5.html">rigmarole of the capacitor</a> we also know that: </p> \begin{align} I_C = C \frac{dv}{dt} \end{align}  <p>Thus its not much of a leap to say: </p> \begin{align} I(t) = \frac {v(t)}{R} + C \frac{dv}{dt} \end{align}  <p>Now, if we now multiply both sides by R, we get: </p> \begin{align} RI(t) = v(t) + RC \frac{dv}{dt} \end{align}  <p>Remember that RC is τ, the <a href="https://en.wikipedia.org/wiki/RC_time_constant">RC time constant</a>; in this case, we are dealing with the membrane so hence the <i>m</i>. With that, the rest of the rearranging to the original formula should be fairly obvious. </p> <p>Also, if you recall, we mentioned <a href="https://en.wikipedia.org/wiki/Leaky_integrator">Leaky Integrators</a> before. You should hopefully be able to see the resemblance between these and our first formula. </p> <p>Note that we did not model spikes explicitly with this formula. However, when it comes to implementing it, all that is required is to look for a threshold value for the membrane potential - called the <i>spiking threshold</i>; when that value is reached, we need to reset the membrane potential back to a lower value - the <i>reset potential</i>. </p> <p>And with that we have enough to start thinking about code… </p></div></div> <div class="outline-2" id="outline-container-sec-5"><h2 id="sec-5">Method in our Madness</h2><div class="outline-text-2" id="text-5"><p>.. Or so you may think. First, a quick detour on discretisation. As it happens, computers are rather fond of discrete things rather than the continuous entities that inhabit the world of calculus. Computers are very much of the same opinion as <a href="https://en.wikipedia.org/wiki/George_Berkeley">the priest</a> <a href="http://www.maths.tcd.ie/pub/HistMath/People/Berkeley/Analyst/Analyst.pdf">who said</a>: </p> <blockquote><p>And what are these same evanescent Increments? They are neither finite Quantities nor Quantities infinitely small, nor yet nothing. May we not call them the Ghosts of departed Quantities? </p></blockquote> <p>So we cannot directly represent differential equations in the computer - not even the simpler ordinary differential equations (ODEs), with their single independent variable. Instead, we need to approximate them with a <i>method</i> for <i>numerical integration</i> of the ODE. Remember: when we say <i>integration</i> we just mean "summing". </p> <p>Once we enter the world of <i>methods</i> and <i>numerical analysis</i> we are much closer to our ancestral home of Software Engineering. The job of numerical analysis is to look for ways in which one can make discrete approximations of the problems in mathematical analysis - like, say, calculus. The little recipes they come up with are called <i>numerical methods</i>. A method is nothing more than an algorithm, a set of steps used iteratively. One such method is the <a href="https://en.wikipedia.org/wiki/Euler_method">Euler Method</a>: "[a] numerical procedure for solving ordinary differential equations (ODEs) with a given initial value", as Wikipedia tells us, and as it happens that is exactly what we are trying to do. </p> <p>So how does the Euler method work? Very simply. First you know that: </p> \begin{align} y(t_0) = y_0 \\ y'(t) = f(t, y(t)) \end{align}  <p>That is, at the beginning of time we have a known value. Then, for all other <i>t</i>'s, we use the current value in <i>f</i> in order to be able to compute the next value. Lets imagine that our steps - how much we are moving forwards by - are of a size <i>h</i>. You can then say: </p> \begin{align} t_{n+1} = t_n + h \\ y_{n+1} = y_n + h * f(x_n, t_n) \end{align}  <p>And that's it. You just need to know where you are right now, by how much you need to scale the function - e.g. the step size - and then apply the function to the current values of <i>x</i> and <i>t</i>. </p> <p>In code: </p> <div class="org-src-container"> <pre class="src src-c++">template&lt;typename F&gt;<br />void euler(F f, double y0, double start, double end, double h) {<br />    double y = y0;<br />    for (auto t(start); t &lt; end; t += h) {<br />        y += h * f(t, y, h);<br />    }<br />}<br /></pre></div> <p>We are passing <i>h</i> to the function <i>F</i> because it needs to know about the step size, but other than that it should be a pretty clean mapping from the maths above. </p> <p>This method is also known as <i>Forward Euler</i> or <i>Explicit Euler</i>. </p></div></div> <div class="outline-2" id="outline-container-sec-6"><h2 id="sec-6">What next?</h2><div class="outline-text-2" id="text-6"><p>And yet again, we run out of time yet again before we can get into serious coding. In the next instalment we shall cover the implementation of the LIF model. </p></div></div></div><div class="status" id="postamble"><p class="date">Created: 2015-09-16 Wed 18:05</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>

            <p class="text-muted">in 'Marco Craveiro' on September 16, 2015 05:13 PM. <a href="http://mcraveiro.blogspot.com/2015/09/nerd-food-neurons-for-computer-geeks_16.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Nerd Food: Neurons for Computer Geeks - Part IV: More Electricity.</h4>

            Nerd Food: Neurons for Computer Geeks - Part IV: More Electricity<div id="content"><p><a href="http://mcraveiro.blogspot.co.uk/2015/08/nerd-food-neurons-for-computer-geeks.html">Part I</a> of this series looked at a neuron from above; <a href="http://mcraveiro.blogspot.co.uk/2015/08/nerd-food-neurons-for-computer-geeks_31.html">Part II</a> attempted to give us the fundamental building blocks in electricity required to get us on the road to modeling neurons. We did a quick interlude with a bit of coding in <a href="http://mcraveiro.blogspot.co.uk/2015/09/nerd-food-neurons-for-computer-geeks_4.html">part III</a> but now, sadly, we must return to boring theory once more. </p> <p>Now that we grok the basics of electricity, we need to turn our attention to the <i>RC circuit</i>. As we shall see, this circuit is of particular interest when modeling neurons. The RC circuit is so called because it is a circuit, and it is composed of a Resistor and a Capacitor. We've already got some vague understanding of circuits and resistors, so lets start by having a look at this new crazy critter, <i>the capacitor</i>. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">Capacitors</h2><div class="outline-text-2" id="text-1"><p>Just like the battery is a source of current, one can think of the capacitor as a temporary store of current. If you plug a capacitor into a circuit with just a battery, it will start to "accumulate" charge over time, up to a "maximum limit". But how exactly does this process work? </p> <p><a href="https://www.khanacademy.org/science/physics/circuits-topic/circuits-with-capacitors/v/capacitors-and-capacitance">In simple terms</a>, the capacitor is made up of two metal plates, one of which will connect to the positive end of the battery and another which connects to the negative end. At the positive end, the metal plate will start to lose negative charges because these are attracted to the positive end of the battery. This will make this metal plate positively charged. Similarly, at the negative end, the plate will start to accumulate negative charges. This happens because the electrons are repelled by the negative end of the battery. Whilst this process is taking place, the capacitor is <i>charging</i>. </p> <p>At some point, the process reaches a kind of equilibrium, whereby the electrons in the positively charged plate are attracted equally to the plate as they are to the positive end of the battery, and thus stop flowing. At this point we say the capacitor is <i>charged</i>. It is interesting to note that both plates of the capacitor end up with the same "total" charge but different signs (i.e. <code>-q</code> and <code>+q</code>). </p></div> <div class="outline-3" id="outline-container-sec-1-1"><h3 id="sec-1-1">Capacitance</h3><div class="outline-text-3" id="text-1-1"><p>We mentioned a "maximum limit". A few things control this limit: how big the plates are, how much space there is between them and the kind of material we place between them, if any. The bigger the plates and the closer they are - without touching - the more you can store in the capacitor. The material used for the plates is, of course, of great importance too - it must be some kind of metal good at conducting. </p> <p>In a more technical language, this notion of a limit is captured by the concept of <i>capacitance</i>, and is given by the following formula: </p> \begin{align} C = \frac{q}{V} \end{align}  <p>Lets break it down to its components to see what the formula is trying to tell us. The role of <code>V</code> is to inform us about the potential difference between the two plates. This much is easy to grasp; since one plate is positively charged and other negatively charged, it is therefore straightforward to imagine that a charge will have a different electric potential in each plate, and thus that there will be an electric potential difference between them. <code>q</code> tells us about the magnitude of the charges that we placed on the plates - i.e. ignoring the sign. It wouldn't be to great a leap to conceive that plates with a larger surface area would probably have more "space" for charges and so a larger <code>q</code> - and vice-versa. </p> <p>Capacitance is then the ratio between these two things; a measure of how much electric charge one can store for a given potential difference. It may not be very obvious from this formula, but capacitance is constant. That is to say, a given capacitor has a capacitance, influenced by the properties described above. This formula does not describe the discharging or charging process - but of course, capacitance is used in the formulas that describe those. </p> <p>Capacitance is measured in SI units of Farads, denoted by the letter  <code>F</code>. A farad is 1 coulomb over 1 volt: </p> \begin{align} 1F = \frac{C}{V} \end{align} </div></div> <div class="outline-3" id="outline-container-sec-1-2"><h3 id="sec-1-2">Capacitors and Current</h3><div class="outline-text-3" id="text-1-2"><p>After charging a capacitor, one may be tempted to discharge it. For that one could construct a simple circuit with just the capacitor. Once the circuit is closed, the negative charges will start to flow to the positively charged plate, at full speed - minus the resistance of the material. Soon enough both plates would be made neutral. At first glance, this may appear to be very similar to our previous circuit with a battery. However, there is one crucial difference: the battery circuit had a constant voltage and a constant current (for a theoretical battery) whereas a circuit with a discharging capacitor has voltage and current that <i>decay</i> over time. By "decaying", all we really mean is that we start at some arbitrarily high value and we move towards zero over a period of time. This makes intuitive sense: you cannot discharge the capacitor forever; and, as you discharge it, the voltage starts to decrease - for there are less charges in the plates and so less potential difference - and similarly, so does the current - for there is less "pressure" to make the charges flow. </p> <p>This intuition is formally captured by the following equation: </p> \begin{align} I(t) = C \frac{dV(t)}{dt} \end{align}  <p>I'm rather afraid that, at this juncture, we have no choice but to introduce Calculus. A proper explanation of Calculus a tad outside the remit of these posts, so instead we will have to make do with some common-sense but extremely hand-waved interpretations of the ideas behind it. If you are interested in a light-hearted but still comprehensive treatment of the subject, perhaps <a href="http://betterexplained.com/articles/a-gentle-introduction-to-learning-calculus/">A Gentle Introduction To Learning Calculus</a> may be to your liking. </p> <p>Let's start by taking a slightly different representation of the formula above and then compare these two formulas. </p> \begin{align} i = C \frac{dv}{dt} \end{align}  <p>In the first case we are talking about the current <code>I</code>, which normally is some kind of average current over some unspecified period. Up to now, <i>time</i> didn't really matter - so we got away with just talking about <code>I</code> in these general terms. This was the case with the Ohm's Law in <a href="http://mcraveiro.blogspot.co.uk/2015/08/nerd-food-neurons-for-computer-geeks_31.html">part II</a>. However, as we've seen, it is not so with capacitors - so we need to make the current specific to a point in time. For that we supply an "argument" to I - <code>I(t)</code>; here, a mathematician would say that that <code>I</code> is a function of <i>time</i>. In the second case, we make use of <code>i</code>, which is the <i>instantaneous current</i> through the capacitor. The idea is that, somehow, we are able to know - for any point in time - what the instantaneous current is. </p> <p>How we achieve that is via the magic of Calculus. The expression <code>dv/dt</code> in the second formula provides us with the instantaneous rate of change of the voltage over time. The same notion can be applied to <code>V</code>, as per first formula. </p> <p>These formulas may sound awfully complicated, but what they are trying to tell us is that the capacitor's current has the following properties: </p> <ul class="org-ul"><li>it varies as a "function" of time; that is to say, different time points have different currents. Well, that's pretty consistent with our simplistic notion of a decaying current. </li><li>it is "scaled" by the capacitor's capacitance <code>C</code>; "bigger" capacitors can hold on to higher currents for longer when compared to "smaller" capacitors. </li><li>the change in electric potential difference varies as a function of time. This is subtle but also makes sense: we imagined some kind of decay for our voltage, but there was nothing to say the decay would remain <i>constant</i> until we reached zero. This formula tells us it does not; voltage may decrease faster or slower at different points in time. </li></ul></div></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">Circuits: Parallel and Series</h2><div class="outline-text-2" id="text-2"><p>The RC circuit can appear in a parallel or series form, so its a good time to introduce these concepts. One way we can connect circuits is in <i>series</i>; that is, all components are connected along a single path, such that the current flows through <i>all</i> of them, one after the other. If any component fails, the flow will cease. </p> <p>This is best understood by way of example. Lets imagine the <a href="http://www.physicsclassroom.com/class/circuits/Lesson-4/Two-Types-of-Connections">canonical example</a> of a battery - our old friend the 1.5V AA battery - and a three small light bulbs. A circuit that connects them in series would be made up of a cable segment plugged onto one of the battery's terminals - say <code>+</code>, then connected to the first light bulb. A second cable segment would then connect this light bulb to another light bulb, followed by another segment and another light bulb. Finally, a cable segment would connect the light build to the other battery terminal - say <code>-</code>. Graphically - and pardoning my inability to use <a href="https://wiki.gnome.org/Apps/Dia/">Dia</a> to create circuit diagrams - it would look more or less like this: </p>  <div class="figure"><p><img alt="series_circuit.png" height="200px" src="https://github.com/mcraveiro/neurite/raw/master/doc/blog/images/series_circuit.png" width="300px" /></p><p><span class="figure-number">Figure 1:</span> Series circuit. Source: Author</p></div> <p>This circuit has a few interesting properties. First, if any of the light bulbs fail, all of them will stop working because the circuit is no longer closed. Second, if one were to add more and more light bulbs, the brightness of each light bulb will start to decrease. This is because each light bulb is in effect a resistor - the light shining being a byproduct of said resistance - and so they are each decreasing the current. So it is that in a series circuit the total resistance is given by the sum of all individual resistances, and the current is the same for all elements. </p> <p>Parallel circuits are a bit different. The idea is that two or more components are connected to the circuit <i>in parallel</i>, i.e. there are two or more paths along which the current can flow at the same time. So we'd have to modify our example to have a path to each of the light bulbs which exists in parallel to the main path - quite literally a segment of cable that connects the other segments of cable, more or less like so: </p>  <div class="figure"><p><img alt="parallel_circuit.png" height="200px" src="https://github.com/mcraveiro/neurite/raw/master/doc/blog/images/parallel_circuit.png" width="300px" /></p><p><span class="figure-number">Figure 2:</span> Parallel circuit. Source: Author</p></div> <p>Here you can see that if a bulb fails, there is still a closed loop in which current can flow, so the other bulbs should be unaffected. This also means that the voltage is the same for all components in the circuit. Current and resistance are now "relative" to each component, and it is possible to compute the overall current for the circuit via <a href="https://en.wikipedia.org/wiki/Kirchhoff%2527s_circuit_laws#Kirchhoff.27s_current_law_.28KCL.29">Kirchhoff's Current Law</a>. Simplifying it, it means that the current for the circuit is the sum of all currents flowing through each component. </p> <p>This will become significant later on when we finally return to the world of neurons. </p></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">The RC Circuit</h2><div class="outline-text-2" id="text-3"><p>With all of this we can now move to the <i>RC circuit</i>. In its simplest form, the circuit has a source of current with a resistor and a capacitor: </p>  <div class="figure"><p><img alt="Discharging_capacitor.svg" height="300px" src="https://upload.wikimedia.org/wikipedia/commons/a/a4/Discharging_capacitor.svg" width="300px" /></p><p><span class="figure-number">Figure 3:</span> Source: Wikipedia, <a href="https://en.wikipedia.org/wiki/RC_circuit">RC circuit</a></p></div> <p>Let's try to understand how the capacitor's voltage will behave over time. This circuit is rather similar to the one we analysed when discussing capacitance, with the exception that we now have a resistor as well. But in order to understand this, we must return to Kirchhoff's current law, which we hand-waved a few paragraphs ago. Wikipedia tells us that: </p> <blockquote><p>The algebraic sum of currents in a network of conductors meeting at a point is zero. </p></blockquote> <p>One way to understand this statement is to think that the total quantity of current entering a junction point must be identical to the total quantity leaving that junction point. If we consider entering to be positive and leaving to be negative, that means that adding the two together must yield zero. </p> <p>Because of Kirchhoff's law, we can state that, for the positive terminal of the capacitor: </p> \begin{align} i_c(t) + i_r(t) = 0 \end{align}  <p>That is: at any particular point in time <i>t</i>, the current flowing through the capacitor added to the current flowing through the resistor must sum to zero. However, we can now make use of the previous formulas; after all, our section on capacitance taught us that: </p> \begin{align} i_c(t) = C \frac{dv(t)}{dt} \end{align}  <p>And making use of Ohm's Law we can also say that: </p> \begin{align} i_r(t) = \frac{v(t)}{R} \end{align}  <p>So we can expand the original formula to: </p> \begin{align} C \frac{dv(t)}{dt} + \frac{v(t)}{R} \end{align}  <p>Or: </p> \begin{align} C \frac{dV}{dt} + \frac{V}{R} \end{align}  <p>I'm not actually going to follow the remaining steps to compute <code>V</code>, but you can see them <a href="http://www.digilentinc.com/classroom/realanalog/text/Chapter_2p4p2.pdf">here</a> and they are fairly straighforward, or at least as straightforward as calculus gets. The key point is, when you solve the differential equation for <code>V</code>, you get: </p> \begin{align} V(t) = V_0e^{-\frac{t}{RC}} \end{align}  <p>With <code>V0</code> being voltage when time is zero. This is called the circuit's <i>natural response</i>. This equation is <i>very important</i>. Note that we are now able to describe the behaviour of voltage over time with just a few inputs: the starting voltage, the time, the resistance and the capacitance. </p> <p>A second thing falls off of this equation: the RC Time constant, or τ. It is given by: </p> \begin{align} \tau = RC \end{align}  <p>The Time Constant is described in a very useful way <a href="http://www.tpub.com/neets/book2/3d.htm">in this page</a>, so I'll just quote them and their chart here: </p> <blockquote><p>The time required to charge a capacitor to 63 percent (actually 63.2 percent) of full charge or to discharge it to 37 percent (actually 36.8 percent) of its initial voltage is known as the TIME CONSTANT (TC) of the circuit. </p></blockquote>  <div class="figure"><p><img alt="32NE0159.GIF" src="http://www.tpub.com/neets/book2/32NE0159.GIF" /></p><p><span class="figure-number">Figure 4:</span> The RC Time constant. Source: <a href="http://www.tpub.com/neets/book2/1.htm">Concepts of alternating current</a></p></div></div></div> <div class="outline-2" id="outline-container-sec-5"><h2 id="sec-5">What next?</h2><div class="outline-text-2" id="text-5"><p>Now we understand the basic behaviour of the RC Circuit, together with a vague understanding of the maths that describe it, we need to return to the neuron's morphology. Stay tuned. </p></div></div></div><div class="status" id="postamble"><p class="date">Created: 2015-09-05 Sat 18:56</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>

            <p class="text-muted">in 'Marco Craveiro' on September 16, 2015 04:39 PM. <a href="http://mcraveiro.blogspot.com/2015/09/nerd-food-neurons-for-computer-geeks_5.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Nerd Food: Neurons for Computer Geeks - Part II: The Shocking Complexity of Electricity.</h4>

            Nerd Food: Neurons for Computer Geeks - Part II: The Shocking Complexity of Electricity<div id="content"><p>In <a href="http://mcraveiro.blogspot.co.uk/2015/08/nerd-food-neurons-for-computer-geeks.html">part I</a> we started to describe the basic morphology of the neuron. In order to continue, we now need to take a detour around the world of electricity. If you are an electricity nerd, I apologise in advance; this is what happens when a computer scientist escapes into your realm, I'm afraid. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">"Honor the charge they made!"</h2><div class="outline-text-2" id="text-1"><p>First and foremost, we need to understand the concept of <i>charge</i>. It is almost a tautology that atoms are made up of "sub-atomic" particles. These are the <i>proton</i>, the <i>neutron</i> and the <i>electron</i>. The neutron is not particularly interesting right now; however the electron and the proton are, and all because they have a magical property called <i>charge</i>. For our purposes, it suffices to know that "charge" means that certain sub-atomic particles attract or repeal each other, according to a well defined set of rules. </p> <p>You can think of a charge as a property attached to the sub-atomic particle, very much like a person has a weight or height, but with a side-effect; it is as if this property makes people push or hug each other when they are in close proximity, and they do so with the same strength when at the same distance. This "strength" is the <i>electric force</i>. How they decide whether to hug or push the next guy is based on the "sign" of the charge - that is, positive or negative - with respect to their own charge "sign". Positives push positives away but hug negatives and vice-versa. </p> <p>For whatever historical reasons, very clever people decided that an electron has one negative unit of charge and a proton has a positive unit of charge. The sign is, of course, rather arbitrary. We could have just as well said that protons are red and electrons are blue or some other suitably binary-like convention to represent these permutations. Just because protons and electrons have the same charge, it does not follow that they are similar in other respects. In fact, they are <i>very</i> different creatures. For example, the electron is very "small" when compared to the proton - almost 2000 times "smaller". The relevance of this "size" difference will become apparent later on. Physicists call this "size" <i>mass</i>, by the by. </p> <p>As it happens, all of these sub-atomic crazy critters are rather minute entities. So small in fact that it would be really cumbersome if we had to talk about charges in terms of the charge of an electron; the numbers would just be too big and unwieldy. So, the very clever people came up with a sensible way to bundle up the charges of the sub-atomic particles in bigger numbers, much like we don't talk about millimetres when measuring the distance to the Moon. However, unlike the nice and logical metric system, with its neat use of the decimal system, physicists came up instead with the <i>Coulomb</i>, or <i>C</i>, one definition of which is: </p> <ul class="org-ul"><li>1 Coloumb (1C) = 6.241 x 10<sup>18</sup> protons </li><li>-1 Coloumb (-1C) = 6.241 x 10<sup>18</sup> electrons </li></ul> <p>This may sound like a <i>very</i> odd choice - hey, why not just 1 x 10<sup>20</sup>or some other "round" number? - but just like a <a href="http://www.quora.com/Why-is-a-kilogram-equal-to-1000-grams-but-a-kilobyte-equals-1024-bytes">kilobyte is 1024 bytes rather 1000</a>, this wasn't done by accident either. In fact, all related <a href="https://en.wikipedia.org/wiki/International_System_of_Units">SI units</a> were carefuly designed to work together and make calculations as easy as possible. </p> <p>Anyway, whenever you see <code>q</code> or <code>Q</code> in formulas it normally refers to a charge in Coulombs. </p></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">Units, Dimensions, Measures, Oh My!</h2><div class="outline-text-2" id="text-2"><p>Since we are on the subject of SI, this is probably a good point to talk about units, dimensions, measurements, magnitudes, conversions and other such exciting topics. Unfortunately, these are important to understand how it all hangs together. </p> <p>A number such as <code>1A</code> makes use of the SI <i>unit of measure</i> "Ampere" and it exists in a <i>dimension</i>: the dimension of all units which can talk about electric charges. This is very much in the same way we can talk about time in seconds or minutes - we are describing points in the time dimension, but using different <i>units of measure</i> - or just <i>units</i>, because we're lazy. A <i>measurement</i> is the recording of a quantity with a unit in a dimension. Of course, it would be too simple to call it a "quantity", so instead physicists, mathematicians and the like call it <i>magnitude</i>. But for the lay person, its not too bad an approximation to replace "magnitude" with "quantity". </p> <p>Finally, it is entirely possible to have <i>compound dimensional units</i>; that is, one can have a unit of measure that refers to more than one dimension, such as say "10 kilometres per second". </p> <p>I won't discuss conversions just now, but you can easily imagine that formulas that contain multiple units may provide ways to convert from one unit to another. This will become relevant later on. </p></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">Go With the Flow</h2><div class="outline-text-2" id="text-3"><p>Now we have a way of talking about charge, and now we know these things can move - since they attract and repel each other - the next logical thing is to start to imagine <i>current</i>. The name sounds magical, but in reality it is akin to a current in a river: you are just trying to figure out how much water is coming past you every second (or in some other suitable unit in the time dimension). The exact same exercise could be repeated for the number of cars going past in a motorway or the number of runners across some imaginary point in a track. For our electric purposes, current tells you how many charges have zipped past over a period of time. </p> <p>In terms of SI units, current is measured in <i>Amperes</i>, which have the symbol <i>A</i>; an Ampere tells us how many Coloumbs have flown past in a second. Whenever you see <code>I</code> in formulas it normally refers to current. </p> <p>Now lets see how these two things - Coulombs and Amperes - could work together. Lets imagine an arbitrary "pipe" between two imaginary locations, one side of which with a pile of positive charges and, on the other side, a pile of negative charges - both measured in Coulombs, naturally. In this <i>extraordinarily</i> simplified and non-existing world, the negative charges would "flow" down the pipe, attracted by the positive charges. Because the positive charges are so huge they won't budge, but the negative charges - the lighter electrons - would zip across to meet them. The number of charges you see going past in a time tick is the current. </p></div></div> <div class="outline-2" id="outline-container-sec-4"><h2 id="sec-4">Resist!</h2><div class="outline-text-2" id="text-4"><p>Going back to our example of current in a river, one can imagine that some surfaces are better at allowing water to flow than others; for example, a river out in the open is a lot less "efficient" at flowing than say a plastic pipe designed for that purpose. One reason is that the river has to deal with twists and turns as it finds a path over the landscape whereas the pipe could be laid out as straight as possible; but it is also that the rocks and other elements of the landscape slow down water, whereas a nice flat pipe would have no such impediments. If one were to take these two extremes - a plastic pipe designed for maximum water flow versus a landscape - one could see that they affect flow differently; and one could be tempted to name the property of "slowing down the flow" <i>resistance</i>, because it describes how much "resistance" these things are offering to the water. If you put up a barrier to avoid flooding, you probably would want it to "resist" water quite a lot rather than allow it to flow; and you can easily imagine that sand and sandbags "resist" water in very different ways. </p> <p>Resistance is a fundamental concept in the electrical world. The gist of it is similar to the contrived examples above, in that not all materials behave the same way with regards to allowing charges to flow. Some allow them to flow freely nearly at maximum speed whereas others do not allow them to flow at all. </p> <p>Since we are dealing with physics, it is of course possible to measure resistance. We do so in SI units of <i>Ohms</i>, denoted by the Greek letter upper-case Ω. </p> <p>As we shall see, not all materials are nicely behaved when it comes to resistance. </p></div></div> <div class="outline-2" id="outline-container-sec-5"><h2 id="sec-5">You've Got Potential Baby!</h2><div class="outline-text-2" id="text-5"><p>Lets return to our non-existing "pipe that allows charges to flow" scenario, and take it one step further. Imagine that for whatever reason our pipe becomes clogged up with a blockage somewhere in the middle. Nothing could actually flow due to this blockage so our current drops to zero. </p> <p>According to the highly simplified rules that we have learned thus far, we do know that - were there to be no blockage - there <i>would</i> be movement (current). That is, the setup of the two bundles in space is such that, given the right conditions, we would start to see things flowing. But, alas, we do not have the right conditions because the pipe is blocked; hence no flow. You could say this setup has "the potential" to get some flow going, if only we could fix the blockage. </p> <p>In the world of electricity, this idea is captured by a few related concepts. If we highly simplify them, they amount to this: </p> <ul class="org-ul"><li><i>electric potential</i>: the idea that depending where you place a charge in space, it may have different "potential" to generate energy. We'll define energy a bit better latter on, but for now a layman's idea of it suffices. By way of an example: if you place a positive charge next to a lump of positive charges and let it go, it will move a certain distance away from the lump. Before you let the charge go, you know the charge has potential to move away. You can also see that the charge will move by different amounts depending how close you place it to the lump; the closer you place it, the more it will move. When we are thinking of electric potential, we think of just one charge. </li><li><i>electric potential energy</i>: clearly it would be possible to move two or three charges too, as we did for the one; and clearly they should produce more energy than a single charge. So one simple way of understanding electric potential energy is to think of it as the case of electric potential that deals with the total number of charges we're interested in, rather than just one. </li></ul> <p>Another way of imagining these two concepts is to think that electric potential is a good way to measure things when you don't particularly care about the number of charges involved; it is as if you scaled everything to just one unit of charge. Electric potential energy is more when you are thinking of a system with an actual number of charges. But both concepts deal with the notion that placing a charge at different points in space may have an impact in the energy you can get out of it. </p> <p>Having said all of that we can now start to think about <i>electric potential difference</i>. It uses the same approach as electric potential, in that everything is scaled to just one unit of charge, but as the name implies, it provides a measurement of <i>the difference</i>between the electric potential of two points. Electric potential difference is more commonly known as <i>voltage</i>. Interestingly, it is also known as <i>electric pressure</i>, and this may be the most meaningful of its names; this is because when there is an electric potential difference, it applies "pressure" on charges which force them to move. </p> <p>The SI unit <i>Volt</i> is used to measure electric potential, electric potential energy and electric potential difference amongst other things. This may sound a bit weird at first, but it is just because one is unfamiliar with these concepts. Take <i>time</i>, for example: we use minutes as a unit of measure of all sorts of things (duration of a football game, time it takes for the moon to go around the earth, etc.). We did not invent a new unit for each phenomenon because we recognised - at some point - that we were dealing with points in the same dimension. </p></div></div> <div class="outline-2" id="outline-container-sec-6"><h2 id="sec-6">Quick Conceptual Mop-Up</h2><div class="outline-text-2" id="text-6"><p>Before we move over to the formulas, it may be best to tie up a few loose ends. These are not strictly necessary, but just make the picture a bit more complete and moves us to a more realistic model - if still very simplistic. </p> <p>First, we should start with atoms; we mentioned charges but skipped them. Atoms are (mostly) a stable arrangement of charges, placed in such a way that the atoms themselves are neutral - i.e. contain exactly the same amount of negative and positive charges. We mentioned before that protons and electrons don't really get along, and neutrons are kind of just there, hanging around. In truth, neutrons and protons also really get along, via the aptly named <i>nuclear force</i>; this is what binds them together in the nucleus of the atom. Electrons are attracted to protons and live their existences in a "cloud" around the nucleus. Note that the nucleus is more than 99% of the mass of the atom, which gives you an idea of just how small electrons are. </p> <p>The materials we will deal with in our examples are made of atoms, as are, well, quite a few things in the universe. These materials are themselves stable arrangements of atoms, just like atoms are stable arrangements of protons, neutrons and electrons. As you can see in the picture, these look like lattices of some kind. </p>  <div class="figure"><p><img alt="carbon-atoms.jpg" src="https://sciencemonday.files.wordpress.com/2011/09/carbon-atoms.jpg" /></p><p><span class="figure-number">Figure 1:</span> Microscopic View of Carbon Atoms. Source: <a href="https://sciencemonday.wordpress.com/2011/09/04/quantum-physics-the-brink-of-knowing-something-wonderful/">Quantum Physics: The Brink of Knowing Something Wonderful</a></p></div> <p>In practice, copper wires are made up of a great many things rather than just atoms of copper. One such "kind of thing" is the <i>unbound electrons</i> - or free-moving electrons; basically electrons are not trapped into an atom. As we mentioned before, electrons are the ones doing most of the moving. Left to their own devices, electrons in a conducting material will just move around, bumping into atoms in a fairly random way. However, lets say you take one end of a copper wire and plug it to the <code>+</code> side of a regular AA battery and then take other end and plug it to the <code>-</code> side of the battery. According to all we've just learned, its easy to imagine what will happen: the electrons stored in the <code>-</code> side will zip across the copper to meet their proton friends at the other end. This elemental construction, with its circular path, is called a <i>circuit</i>. What you've done is to upset the neutral balance of the copper wire and got all the electrons to move in a coordinated way (rather than random) from the <code>-</code> side to the <code>+</code> side. </p> <p>It is at this juncture that we must introduce the concept of ions. An <i>ion</i> is basically an atom that is no longer neutral - either because it has more protons than electrons (called a <i>cation</i>) or more electrons than protons (called an <i>anion</i>). In either case, this comes about because the atom has gained or lost some electrons. Ions will become of great interest when we return to the neuron. </p> <p>One final word on resistance and its sister concept of <i>conductance</i>: </p> <ul class="org-ul"><li><i>Resistance</i> is in effect a <a href="http://education.jlab.org/qa/current_02.html">byproduct of the way the electrons are arranged in the electron cloud</a> and is related to the ionisation mentioned above; certain arrangements just don't allow electrons to flow across. </li><li><i>Conductance</i> is the inverse of resistance. When you talk about resistance you are focusing on the material's ability to impair movement of charges; when you talk about conductance you are focusing on the material's ability to let charge flow through. </li></ul> <p>The reason we choose copper or other metals for our examples is because they are good at <i>conducting</i> these pesky electrons. </p></div></div> <div class="outline-2" id="outline-container-sec-7"><h2 id="sec-7">Ohm's Law</h2><div class="outline-text-2" id="text-7"><p>We have now introduced all the main actors required for one of the main parts in the play: Ohm's Law. It can be stated very easily: </p> <pre class="example"><br />V = R x I<br /></pre> <p>And here's a picture to aid intuition. </p>  <div class="figure"><p><img alt="4KhUg.jpg" src="http://i.stack.imgur.com/4KhUg.jpg" /></p><p><span class="figure-number">Figure 2:</span> Source: <a href="http://physics.stackexchange.com/questions/161650/could-someone-intuitively-explain-to-me-ohms-law">Could someone intuitively explain to me Ohm's law?</a></p></div> <p>The best way to understand this law is to create a simple circuit. </p>  <div class="figure"><p><img alt="Ohm's_Law_with_Voltage_source_TeX.svg" src="https://upload.wikimedia.org/wikipedia/commons/b/b4/Ohm's_Law_with_Voltage_source_TeX.svg" /></p><p><span class="figure-number">Figure 3:</span> Simple electrical circuit. Source: Wikipedia, <a href="https://en.wikipedia.org/wiki/Electrical_network">Electrical network</a></p></div> <p>On the left we have a voltage source, which could be our 1.5V AA battery. On the right of the diagram we have a <i>resistor</i> - an electric component that is designed specifically to "control" the flow of the electric current. Without the resistor, we would be limited by how much current the battery can pump out and how much "natural" resistance the copper wire has, which is not a lot since it is very good at conducting. The resistor gives us a way to limit current flow from these theoretical maximum limitations. </p> <p>Even if you are not particularly mathematically oriented, you can easily see that Ohm's Law gives us a nice way to find any of these three variables, given the other two. That is to say: </p> <pre class="example"><br />R = V / I<br />I = V / R<br /></pre> <p>These tell us many interesting things such as: for the same resistance, current increases as the voltage increases. For good measure, we can also find out the conductance too: </p> <pre class="example"><br />G = I / V = 1 / R<br /></pre> <p>It is important to notice that not everything obeys Ohm's law - i.e. behave in a straight line. The conductors that obey this law are called <i>ohmic conductors</i>. Those that do not are called <i>non-ohmic conductors</i>. There are also things that obey to Ohm's Law, for the most part. These are called <i>quasi-ohmic</i>. </p></div> <div class="outline-3" id="outline-container-sec-7-1"><h3 id="sec-7-1">What next?</h3><div class="outline-text-3" id="text-7-1"><p>We have already run out of time for this instalment but there are still some more fundamental electrical concepts we need to discuss. The next part will finish these and start to link them back to the neuron. </p></div></div></div></div><div class="status" id="postamble"><p class="date">Created: 2015-08-31 Mon 19:27</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>

            <p class="text-muted">in 'Marco Craveiro' on September 14, 2015 04:39 PM. <a href="http://mcraveiro.blogspot.com/2015/08/nerd-food-neurons-for-computer-geeks_31.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Nerd Food: Neurons for Computer Geeks - Part I: A Neuron From Up On High.</h4>

            Nerd Food: Neurons for Computer Geeks - Part I: A Neuron From Up On High<div id="content"><p>As any computer geek would tell you, computer science is great in and of itself and many of us could live long and contented lives inside that box. But things certainly tend to become interesting when there is a whole problem domain to model, and doubly so when that domain is outside of our comfort zone. As it happens, I have managed to step outside said zone - rather, quite far outside - so it seemed like a good idea to chronicle these adventures here. </p> <p>The journey we are about to embark starts with a deceptively simple mission: to understand how one can use computers to model neurons. The intended audience of these posts is anyone who loves coding but has no idea about electricity, circuits, cells and so on - basically someone very much like me. We shall try to explain, at least to a degree, all of the required core concepts in order to start coding. As it turns out, there are quite a few. </p> <p>But hey, as <a href="http://skeptics.stackexchange.com/questions/8742/did-einstein-say-if-you-cant-explain-it-simply-you-dont-understand-it-well-en">they say</a>, "If you can't explain something to a six year-old, you really don't understand it yourself". So lets see if I got it or not. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">I'm a Cell, Get Me Out Of Here!</h2><div class="outline-text-2" id="text-1"><p>A neuron is a <i>cell</i>, so it makes sense to start with cells. Cells are a basic building block in biology and can be considered as the smallest unit of a living organism - at least for our purposes, if nothing else. The key idea behind a cell is as obvious as you'd like: there is the inside, the outside, and the thing that separates both. </p> <p>Of course, this being biology, we need to give it complicated names. Accordingly, the inside of the cell is the <i>cytoplasm</i> and the thing that separates the cell from the outside world is the <i>membrane</i>. You can think of it as a <i>tiny</i> roundy-box-like thing, with some gooey stuff inside. The material of the box is the membrane. The gooey stuff is the cytoplasm. When we start describing the different cellular structures - as we are doing here - we are talking about the cell's <i>morphology</i>. </p> <p>Living beings are made up of many, many cells - according to some estimates, a human body would have several trillion - and cells themselves come in many, <i>many</i> kinds. Fortunately, we are interested in just one kind: the <i>neuron</i>. </p></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">The Neuron Cell</h2><div class="outline-text-2" id="text-2"><p>The neuron is a nerve cell. Of course, there are many, <i>many</i> kinds of neurons - nature just seems to love complexity - but they all share things in common, and those things define their neuron-ness. </p> <p>Unlike the "typical" cell we described above (i.e. "roundy-box-like thing"), the neuron is more like a roundy-box-like thing with some branches coming out of it. The box-like thing is the cell body and is called <i>soma</i>. There are two types of branches: axons and dendrites. A <i>dendrite</i> tends to be short, and it branches like a tree with a very small trunk. The <i>axon</i> tends to be long and it also branches off like a tree, but with a very long trunk. As we said, there are many kinds of neurons, but a fair generalisation is that they tend to have few axons (one or maybe a couple) and many dendrites (in the thousands). </p>  <div class="figure"><p><img alt="8808542_f520.jpg" src="http://usercontent1.hubimg.com/8808542_f520.jpg" /></p><p><span class="figure-number">Figure 1:</span> Source: <a href="http://mariexotoni.hubpages.com/hub/What-is-a-Neuron2">What is a Neuron?</a></p></div> <p>This very basic morphology is already sufficient to allows to start to think of a neuron as a "computing device" - a strange kind of device where the dendrites provide inputs and the axon outputs. The neuron receives all these inputs, performs some kind of computation over them, and produces an output. </p> <p>The next logical question for a computer scientist is, then: "where do the outputs come from and where do they go?". Imagining an idealised neuron, the dendrites would be "connecting" to other dendrites or to axons. At this juncture (pun not intended), we need to expand on what exactly these "connections" are. In truth, its not that the axon binds directly to the dendrite; there is always a gap between them. But this gap is a special kind of gap, first because it is a very small gap and second because it is one over which things can travel, from the axon into the dendrite. This kind of connectivity between neurons is called a <i>synapse</i>. </p> <p>From this it is an easy leap to imagine that these sets of neurons connected to other neurons begin to form "networks" of connectivity, and these networks will also have computational-device-like properties, just like a neuron. These are called <i>neural networks</i>. Our brain happens to be one of these "neural networks", and a pretty large one at that: it can have <a href="http://www.nature.com/scitable/blog/brain-metrics/are_there_really_as_many">as many as 80-100 billion neurons</a>, connected over some 1 quadrillion synapses. In these days of financial billions and trillions, it is easy to be fooled into thinking 100 billion is not a very large number, so to get a sense of perspective lets compare it to another large network. The biggest and fastest growing human-made network is the Internet, estimated to have <a href="http://www.gartner.com/newsroom/id/2905717">some 5 billion connected devices</a> but less than <a href="http://bgp.potaroo.net/">600k connections in its core</a> - and yet we are already <a href="http://research.dyn.com/2014/08/internet-512k-global-routes/">creacking at the seams</a>. </p></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">The Need To Go Lower</h2><div class="outline-text-2" id="text-3"><p>Alas, we must dig deeper before we start to understand how these things behave in groups. Our skimpy first pass at the neuron morphology left a lot of details out, which are required to understand how they behave. As we explained, neurons have axons and dendrites, and these are responsible for hooking them together. However, what is interesting is what they talk about once they are hooked. </p> <p>A neuron is can be thought of as an <i>electrical device</i>, and much of its power (sorry!) stems from this. In general, as computer scientists, we don't like to get too close to the physical messiness of the world of hardware; we deem it sufficient to understand some high-level properties, but rarely do we want to concern ourselves with transistors or even - regrettably - registers or pipelines in the CPU. With neurons, we can't get away with it. We need to understand the hardware - or better, the wetware - and for that we have to go <i>very</i> low-level. </p> <p>We started off by saying cells have a membrane that separates the outside world from the cytoplasm. That was a tad of an oversimplification; after all, if the membrane did not allow anything in, how would the cell continue to exist - or even come about in the first place? In practice these membranes are permeable - or to be precise, <i>semi-permeable</i>. This just means that it allows some stuff in and some stuff out, under controlled circumstances. This is how a cell gets energy <i>in</i> to do its thing and how it expels its unwanted content <i>out</i>. Once things started to move in and out selectively, something very interesting can start to happen: the build up of "electric potential". However, rather unfortunately, in order to understand what we mean by this, we need to cover the fundamentals of electricity. </p> <p>Onward and downwards we march. Stay tuned for Part II. </p></div></div></div><div class="status" id="postamble"><p class="date">Created: 2015-08-31 Mon 17:25</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>

            <p class="text-muted">in 'Marco Craveiro' on September 14, 2015 04:32 PM. <a href="http://mcraveiro.blogspot.com/2015/08/nerd-food-neurons-for-computer-geeks.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Nerd Food: Neurons for Computer Geeks - Part V: Yet More Theory.</h4>

            Nerd Food: Neurons for Computer Geeks - Part V: Yet More Theory<div id="content"><p>Welcome to part V of a multi-part series on modeling neurons. In <a href="http://mcraveiro.blogspot.co.uk/2015/09/nerd-food-neurons-for-computer-geeks_5.html">part IV</a> we introduced the RC Circuit by making use of the foundations we painstakingly laid in previous posts. In truth, we could now move on to code and start looking at the <a href="http://icwww.epfl.ch/~gerstner/SPNM/node26.html">Leaky Integrate-and-Fire</a> (LIF) model, since we've already covered most required concepts. However, we are going to do just a little bit more theory before we get to that. </p> <p>The main reason for this detour is that I do not want to give you the impression neurons are <i>easy</i>; if there is one thing that they are <b>not</b> is <i>easy</i>. So we're going to resume our morphological and electrical exploits to try to provide a better account of the complexity inside the neuron, hopefully supplying enough context to appreciate the simplifications done in LIF. </p> <p>The content of this post is highly inspired from <a href="http://www.cambridge.org/us/academic/subjects/life-sciences/neuroscience/principles-computational-modelling-neuroscience">Principles of Computational Modelling in Neuroscience</a>, a book that is a must read introduction if you decide to become serious on this subject. If so, you may also want to check the Gerstner videos: <a href="http://klewel.com/conferences/epfl-neural-networks/index.php?talkID=1">Neural networks and biological modeling</a>. </p> <p>But you need not worry, casual reader. Our feet are firmly set in layman's land and we'll remain so until the end of the series. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">Brief Context on Modeling</h2><div class="outline-text-2" id="text-1"><p>Before we get into the subject matter proper, I'd like us to ponder a few "meta-questions" in terms of modeling. </p></div> <div class="outline-3" id="outline-container-sec-1-1"><h3 id="sec-1-1">Why Model?</h3><div class="outline-text-3" id="text-1-1"><p>A layperson may think that we model neurons because we want to build a "computer brain": one that is similar to a real brain, with its amazing ability to learn, and one which at some point may even <i>think and be conscious</i>. Hopefully, after you finish this series of posts, you will appreciate the difficulty of the problem and see that it's not very likely we'll be able to make a "realistic" "computer brain" any time soon - for sensible values of "realistic", "computer brain" and "any time soon". </p> <p>Whilst we have good models that explain part of the behaviour of the neuron and good models for neural networks too, it is not the case that we can put all of these together to form some kind of "unified neuron model", multiply it by 80 billion, add a few quadrillion synapses and away we go: artificial consciousness. Given what we know at the moment, this approach is far too computationally demanding to be feasible. Things would change if there was a massive leap in computational power, of course, but not if they stay at present projections - even with <a href="https://en.wikipedia.org/wiki/Moore%2527s_law">Moore's Law</a>. </p> <p>So if we are not just trying to build a computer brain, then why bother? Well, if you set your sights a little lower, computational models are actually amazingly useful: </p> <ul class="org-ul"><li>one can use code to explore a small portion of the problem domain, making and validating predictions using computer models, and then test those predictions in the lab with real wetware. The iterative process is orders of magnitude faster. </li><li>computer models are now becoming quite sophisticated, so in some cases they are good representations of biological processes. This tends to be the case for small things such as individual cells or smaller. As computers get faster and faster according to <a href="https://en.wikipedia.org/wiki/Moore%2527s_law">Moore's Law</a>, the power and scope of these models grows too. </li><li>distributing work with Free and Open Source Software licences means it is much easier for researchers to reproduce each others work, as well as for them to explore avenues not taken by those who did the work originally, speeding things up considerably. Standing on the shoulders of giants and all that. </li></ul></div></div> <div class="outline-3" id="outline-container-sec-1-2"><h3 id="sec-1-2">What Tools Do We Model With?</h3><div class="outline-text-3" id="text-1-2"><p>The focus of these posts is on writing models from scratch, but that's not how most research is conducted. In the real world, people try their best to reuse existing infrastructure - of which there is plenty. For example there is <a href="https://www.neuron.yale.edu/neuron/">NEURON</a>, <a href="http://neuralensemble.org/PyNN/">PyNN</a>, <a href="http://briansimulator.org/">Brian</a> and much more. Tools and processes have evolved around these ecosystems, and there is a push to try to standardise around the more successful frameworks. </p> <p>There is also a push to find some kind of standard "language" to describe models so that we can all share information freely without having to learn the particulars of each others representations. The world is not quite there yet, but initiatives such as <a href="https://www.neuroml.org/">NeuroML</a> are making inroads in this direction. </p> <p>However, the purpose of our this series is simplification, so we will swerve around all of this. Perhaps material for another series. </p></div></div> <div class="outline-3" id="outline-container-sec-1-3"><h3 id="sec-1-3">At What Level Should One Model?</h3><div class="outline-text-3" id="text-1-3"><p>A related question to the previous ones - and one that is not normally raised in traditional software engineering, but is very relevant in biology - is the level of detail at which one should model. </p> <p>Software Engineers tend to believe there is <i>a model</i> for <i>a problem</i>, and once you understand enough about the problem domain you will come up with it and <i>all will be light</i>. Agile and sprints are just a way to converge to it, to the perfection that exists somewhere in the platonic cloud. Eric Evans with <a href="https://domainlanguage.com/ddd/">DDD</a> started to challenge that assumption somewhat by making us reflect on just what it is that we mean by "model" and "modeling", but, in general, we have such an ingrained belief in this idea that is very hard to shake it off or to even realise the belief is there in the first place. Most of us still think of the code representation of the domain model as <i>the model</i> - rather than accept it is one of a multitude of possible representations, each suitable for a given purpose. </p> <p>Alas, all of this becomes incredibly obvious when you are faced with a problem like modeling a neuron or a network of neurons. Here, there is just no such thing as the "right model"; only a set of models at a different perspectives, each with a different set of trade-offs, and any of them only make sense in the context of what one is trying to study. It may make sense to model neurons like networks, ignoring the finer details of each one and looking at their behaviour as a group, or it may make sense to model individual bits of the neuron as an entity. What makes it "right" or "wrong" is what it is that we are using the model for and how much computational power one has at one's disposal. </p> <p>Having said all of that, lets resume our morphology adventures. </p></div></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">Electricity and Neurons</h2><div class="outline-text-2" id="text-2"><p>We started off with <a href="http://mcraveiro.blogspot.co.uk/2015/08/nerd-food-neurons-for-computer-geeks.html">an overview of the neuron</a> and then moved over to <a href="http://mcraveiro.blogspot.co.uk/2015/08/nerd-food-neurons-for-computer-geeks_31.html">lots</a> and <a href="http://mcraveiro.blogspot.co.uk/2015/09/nerd-food-neurons-for-computer-geeks_5.html">lots</a> of electricity; now it's time to see how those two fit together. </p> <p>As we explained in <a href="http://mcraveiro.blogspot.co.uk/2015/08/nerd-food-neurons-for-computer-geeks.html">part I</a>, there is a electric potential difference between the inside of the cell and the outside, called the <i>membrane potential</i>. The convention to compute this potential is to subtract the potential inside the cell to the potential outside the cell; current is positive when there is a flow of positive charge from the inside to the outside and negative otherwise. Taken into account these definitions, one should be able to make sense of the <i>resting membrane potential</i>: it is around -65mv. But how does this potential change? </p></div> <div class="outline-3" id="outline-container-sec-2-1"><h3 id="sec-2-1">Ion Channels</h3><div class="outline-text-3" id="text-2-1"><p><a href="http://mcraveiro.blogspot.co.uk/2015/08/nerd-food-neurons-for-computer-geeks_31.html">Earlier</a>, we spoke about ions - atoms that either lost or gained electrons and so are positively or negatively charged. We also said that, in general, the cell's membrane is impermeable, but there are tiny gaps in the membrane which allow things in and out of the cell. Now we can expand a bit further. <i>Ion channels</i> are one such gap, and they have that name because they let ions through. There are <i>many</i> kinds of ion channels. One way of naming them is to use the ion they are most permeable to - but of course, this being biology, the ion channels don't necessarily always have a major ion they are permeable to. </p> <p>Another useful categorisation distinguishes between <i>passive</i> and <i>active</i> ion channels. Active channels are those that change their permeability depending on external factors such as the membrane potential, the concentration of certain ions, and so on. For certain values they are open - i.e. permeable - whereas for other values they are closed, not allowing any ions through. Passive channels are simpler, they just have a fixed permeability behaviour. </p> <p>There are also <i>ionic pumps</i>. These are called pumps because they take one kind of ion out, exchanging it for another kind. For instance, the sodium-potassium pump pushes potassium into the cell and expels sodium out. A pump has a <i>stoichiometry</i>, which is a fancy word to describe the ratio of ions being pumped in and out. </p></div></div> <div class="outline-3" id="outline-container-sec-2-2"><h3 id="sec-2-2">Complexity Starts To Emerge</h3><div class="outline-text-3" id="text-2-2"><p>As you can imagine, the key to understating electric behaviour is understanding how these pesky ions move around. Very simplistically, ions tend to move for two reasons: because there is a potential difference between the inside and the outside of the cell, or because of the <i>concentration gradient</i> of said ion. The concentration gradient just means that, left to their own devices, concentration becomes uniform over time. For example, if you drop some ink in a glass of water, you will start by seeing the ink quite clearly; given enough time, the ink will diffuse in the water, making it all uniformly coloured. The same principle applies to ions - they want to be uniformly concentrated. </p> <p>It should be fairly straightforward to work out that a phenomenal number of permutations is possible here. Not only do we have a great number of channels, all with different properties - some switching on and off as properties change around the cell - but we also have the natural flow of ions being affected by the membrane's potential and the concentration gradient, all of which are changing over time. To make matters worse, factors interact with each other such that even if you have simple models to explain each aspect individually, the overall behaviour is still incredibly complex. </p> <p>Now imagine more than <a href="http://pubs.acs.org/doi/abs/10.1021/jp0120662">50 thousand</a> such ion channels - of over one hundred (known) types - in just a single neuron and you are starting to get an idea of the magnitude of the task. </p></div></div> <div class="outline-3" id="outline-container-sec-2-3"><h3 id="sec-2-3">Equivalent Circuit for a Patch of Membrane</h3><div class="outline-text-3" id="text-2-3"><p>But lets return to simplicity. The very clever people determined that it is possible to model the behaviour of ions and its electric effects by thinking of it as an electric circuit. Taking a patch of membrane as an example, it can be visualised as an electric circuit like so: </p>  <div class="figure"><p><img alt="Cell_membrane_equivalent_circuit.svg" height="500px" src="https://upload.wikimedia.org/wikipedia/commons/e/e5/Cell_membrane_equivalent_circuit.svg" width="500px" /></p><p><span class="figure-number">Figure 1:</span> Source: Wikipedia, <a href="https://en.wikipedia.org/wiki/Membrane_potential">Membrane Potential</a></p></div> <p>What this diagram tells us is that the membrane itself acts as a capacitor, with its capacitance determined by the properties of the <i>lipid bilayer</i>. We didn't really discuss the lipid bilayer before so perhaps a short introduction is in order. The membrane is made up of two sheets of lipids (think fatty acids), which when layered so, have interesting properties: the outside of the sheets are impermeable to most things such as water molecules and ions. The membrane itself is pretty thin, at around 5nm. </p> <p>The membrane capacitance is considered constant. We then have a series of ion channels: sodium, potassium, chlorine, calcium. Each of these can be thought of as a pairing of a resistor with variable conductance coupled with a battery. Note that the resistor and the battery are in series, but the ion channels themselves form a parallel circuit. The voltages for each pathway are determined by the different concentrations of the ion inside and outside the cell. </p> <p>If we further assume fixed ion concentrations and passive ion channels, we can perform an additional simplification on the circuit above and we finally end up with an RC Circuit: </p>  <div class="figure"><p><img alt="Cell_membrane_reduced_circuit.svg" height="300px" src="https://upload.wikimedia.org/wikipedia/commons/b/b6/Cell_membrane_reduced_circuit.svg" width="300px" /></p><p><span class="figure-number">Figure 2:</span> Source: Wikipedia, <a href="https://en.wikipedia.org/wiki/Membrane_potential">Membrane Potential</a></p></div> <p>The circuit now has one resistance, which we call the membrane resistance, and a membrane battery. </p></div></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">What next?</h2><div class="outline-text-2" id="text-3"><p>Hopefully you can start to see both the complexity around modeling neurons and the necessity to create simpler models to make them computationally feasible - just look at the amount of simplification that was required for us to get to an RC Circuit! </p> <p>But at least we can now look forward to implementing LIF. </p></div></div></div><div class="status" id="postamble"><p class="date">Created: 2015-09-07 Mon 17:12</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>

            <p class="text-muted">in 'Marco Craveiro' on September 07, 2015 04:29 PM. <a href="http://mcraveiro.blogspot.com/2015/09/nerd-food-neurons-for-computer-geeks_7.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Nerd Food: Neurons for Computer Geeks - Part III: Coding Interlude.</h4>

            Nerd Food: Neurons for Computer Geeks - Part III: Coding Interlude<div id="content"><p>If you are anything like me, the first two parts of this series have already bored you silly with theory (<a href="http://mcraveiro.blogspot.co.uk/2015/08/nerd-food-neurons-for-computer-geeks.html">Part I</a>, <a href="http://mcraveiro.blogspot.co.uk/2015/08/nerd-food-neurons-for-computer-geeks_31.html">Part II</a>) and you are now hankering for some code - any code - to take away the pain. So part III is here to do exactly that. However, let me prefix that grandiose statement by saying this is not the best code you will ever see. Rather, its just a quick hack to introduce a few of the technologies we will make use of for the remainder of these series, namely: </p> <ul class="org-ul"><li><a href="http://www.cmake.org/">CMake</a> and <a href="http://martine.github.io/ninja/">Ninja</a>: this is how we will build our code. </li><li><a href="http://www.webtoolkit.eu/wt">Wt</a>: provides a quick way to knock-up a web frontend for C++ code. </li><li><a href="http://www.boost.org/">Boost</a>: in particular <a href="http://www.boost.org/doc/libs/1_59_0/doc/html/boost_units.html">Boost Units</a> and later on <a href="http://www.boost.org/doc/libs/1_59_0/libs/numeric/odeint/doc/html/index.html">Boost OdeInt</a>. Provides us with the foundations for our numeric work. </li></ul> <p>What I mean by a "quick hack" is: there is no validation, no unit tests, no "sound architecture" and none of the things you'd expect from production code. But it should serve as an introduction to modeling in C++. </p> <p>All the code is available in GitHub under <a href="https://github.com/mcraveiro/neurite">neurite</a>. Lets have a quick look at the project structure. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">CMake</h2><div class="outline-text-2" id="text-1"><p>We just took a slimmed down version of the <a href="https://github.com/DomainDrivenConsulting/dogen">Dogen</a> build system to build this code. We could have gotten away with a much simpler CMake setup, but I intend to use it for the remainder of this series so that's why its a bit more complex than what you'd expect. It is made up of the following files: </p> <ul class="org-ul"><li>Top-level <code>CMakeLists.txt</code>: ensures all of the dependencies can be found and configured for building, sets up the version number and debug/release builds. </li><li><code>build/cmake</code>: any Find* scripts that are not supplied with the CMake distribution. We Google for these and copied them here. </li><li><code>projects/CMakeLists.txt</code>: sets up all of the compiler and linker flags we need to build the project. Uses pretty aggressive flags such as <code>-Wall</code> and <code>-Werror</code>. </li><li><code>projects/ohms_law/src/CMakeLists.txt</code>: our actual project, the bit that matters for this article. </li></ul></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2"><code>ohms_law</code> Project</h2><div class="outline-text-2" id="text-2"><p>The project is made up of two classes, in files <code>calculator.[hc]pp</code>and <code>view.[hc]pp</code>. The names are fairly arbitrary but they try to separate View from Model: the user interface is in <code>view</code> and the "number crunching" is in <code>calculator</code>. </p></div> <div class="outline-3" id="outline-container-sec-2-1"><h3 id="sec-2-1">The View</h3><div class="outline-text-3" id="text-2-1"><p>Lets have a quick look at <code>view</code>. In the header file we simply define a Wt application with a few widgets: </p> <pre class="example"><br />class view : public Wt::WApplication {<br />public:<br />  view(const Wt::WEnvironment&amp; env);<br /><br />private:<br />  Wt::WLineEdit* current_;<br />  Wt::WLineEdit* resistance_;<br />  Wt::WText* result_;<br />};<br /></pre> <p>It is implemented in an equally trivial manner. We just setup the widgets and hook them together. Finally, we create a trivial event handler that performs the "computations" when the button is clicked. </p> <pre class="example"><br />view::view(const Wt::WEnvironment&amp; env) : Wt::WApplication(env) {<br />  setTitle("Ohm's Law Calculator");<br /><br />  root()-&gt;addWidget(new Wt::WText("Current: "));<br />  current_ = new Wt::WLineEdit(root());<br />  current_-&gt;setValidator(new Wt::WDoubleValidator());<br />  current_-&gt;setFocus();<br /><br />  root()-&gt;addWidget(new Wt::WText("Resistance: "));<br />  resistance_ = new Wt::WLineEdit(root());<br />  resistance_-&gt;setValidator(new Wt::WDoubleValidator());<br /><br />  Wt::WPushButton* button = new Wt::WPushButton("Calculate!", root());<br />  button-&gt;setMargin(5, Wt::Left);<br />  root()-&gt;addWidget(new Wt::WBreak());<br />  result_ = new Wt::WText(root());<br /><br />  button-&gt;clicked().connect([&amp;](Wt::WMouseEvent&amp;) {<br />      const auto current(boost::lexical_cast&lt;double&gt;(current_-&gt;text()));<br />      const auto resistance(boost::lexical_cast&lt;double&gt;(resistance_-&gt;text()));<br /><br />      calculator c;<br />      const auto voltage(c.voltage(resistance, current));<br />      const auto s(boost::lexical_cast&lt;std::string&gt;(voltage));<br />      result_-&gt;setText("Voltage: " + s);<br />    });<br />}<br /></pre></div></div> <div class="outline-3" id="outline-container-sec-2-2"><h3 id="sec-2-2">The Model</h3><div class="outline-text-3" id="text-2-2"><p>The model is equally as simple as the view. It is made up of a single class, <code>calculator</code>, whose job is to compute the voltage using Ohm's Law. It does this by making use of Boost Units. This is obviously not necessary, but we wanted to take the opportunity to explore this library as part of this series of articles. </p> <pre class="example"><br />double calculator::<br />voltage(const double resistance, const double current) const {<br />  boost::units::quantity&lt;boost::units::si::resistance&gt;<br />    R(resistance * boost::units::si::ohms);<br />  boost::units::quantity&lt;boost::units::si::current&gt;<br />    I(current * boost::units::si::amperes);<br />  auto V(R * I);<br />  return V.value();<br />}<br /></pre></div></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">Compiling and Running</h2><div class="outline-text-2" id="text-3"><p>If you are on a debian-based distribution, you can do the following steps to get the code up and running. First install the dependencies: </p> <pre class="example"><br />$ sudo apt-get install libboost-all-dev witty-dev ninja-build cmake clang-3.5<br /></pre> <p>Then obtain the source code from GitHub: </p> <pre class="example"><br />$ git clone https://github.com/mcraveiro/neurite.git<br /></pre> <p>Now you can build it: </p> <pre class="example"><br />cd neurite<br />mkdir output<br />cd output<br />cmake ../ -G Ninja<br />ninja -j5<br /></pre> <p>If all went according to plan, you should be able to run it: </p> <pre class="example"><br />$ stage/bin/neurite_ohms_law --docroot . --http-address 0.0.0.0 --http-port 8080<br /></pre> <p>Now using a web browser such as chrome, connect to <a href="http://127.0.0.1:8080">http://127.0.0.1:8080</a> and you should see a "shiny" Ohm's Law calculator! Sorry, just had to be done to take away the boredom a little bit. Lets proceed with the more serious matters at hand, with the promise that the real code will come later on. </p></div></div></div><div class="status" id="postamble"><p class="date">Created: 2015-09-04 Fri 17:16</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>

            <p class="text-muted">in 'Marco Craveiro' on September 05, 2015 02:31 PM. <a href="http://mcraveiro.blogspot.com/2015/09/nerd-food-neurons-for-computer-geeks_4.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Nerd Food: A Prelude of Things to Come.</h4>

            Nerd Food: A Prelude of Things to Come<div id="content"><p>This sprint I found myself making one of those historical transitions: moving my entire Emacs infrastructure from a old, creaking at the seams approach, to the new all-singing-all-dancing way of doing things. This post documents the start of this transition. </p> <div class="outline-2" id="outline-container-sec-1"><h2 id="sec-1">The Road to Cunene</h2><div class="outline-text-2" id="text-1"><p>I have been using <a href="http://www.gnu.org/software/emacs/">Emacs</a> since around 1998. One of the biggest reasons to use the great old editor is its infinite configurability. Really, to call Emacs "configurable" is rather like saying that <a href="http://en.wikipedia.org/wiki/Leonhard_Euler">Euler</a> wasn't bad with numbers. In truth - and it takes you a while to really grok this - Emacs is just a lisp platform with a <span class="underline">giant</span> editing library built on top; a library that keeps on getting extended on a daily basis by a large number of Emacs users. And, of course, you configure Emacs using lisp, so that the lines between "configuration" and "development" are, at best, blurry. </p> <p>But lets go back to the beginning. Like every other Emacs newbie in those days, I too started with a plain (i.e. non-configured) Emacs and soon evolved to a very simple <span class="underline"><a href="http://www.emacswiki.org/emacs/InitFile">.emacs</a></span> - this file being one of the possible places in which to store its configuration. The reason why almost all Emacs users start configuring Emacs very early on is because its defaults are astonishingly atrocious. It still amazes me to the day that some people are able to use plain Emacs and come out at the other end as Emacs users. In some ways, I guess it is a test of fire: do you <span class="underline">really</span> want to use Emacs? There are two responses to this test: most give up, but a few persist and soon start changing the editor to behave in a slightly saner manner. </p> <p>The <span class="underline">.emacs</span> starts small, especially if you are not familiar with lisp. Sooner or later it occurs to you that, <span class="underline">surely</span>, someone must have already done one of these before, and then you find the amazing world of <span class="underline">.emacs</span> "development". This opens up entire new vistas of the Emacs landscape, because with each <span class="underline">.emacs</span> you find, you discover untold numbers of configuration knobs and - much more importantly - many new <span class="underline">modes</span> to install. In Emacs lingo, a <span class="underline">mode</span> is kind of like a "plug-in" for Eclipse or Visual Studio users. But this is just an approximation; as with everything "Emacs", there is actually no real equivalent way of describing Emacs terminology with analogies outside of Emacs. The problem with IDEs and most other editors is that they can only be extended in ways that their designers thought useful. In Emacs, <span class="underline">everything</span> is extensible. And I do mean <span class="underline">everything</span>. I remember the day I realised that a key press was really just the invocation of the <code>self-insert-command</code> function and, like any other function, it too could be changed in a myriad of ways. </p> <p>But I digress. As with most users, my <span class="underline">.emacs</span> evolved over the years as I found more and more modes. I soon found that it was very painful to keep all my machines with the same setup; invariably I would change something at work but forget to change it at home or Uni or vice-versa. To make matters worse, some machines were on Windows. And in those days, there was no Emacs package management support, so you ended up copying lots of modes around. Life was painful and brute in my first decade of Emacs. </p> <p>Around six years ago, things got a lot better: I started to use git in anger, refactored my <span class="underline">.emacs</span> into something slightly saner and called it Cunene - after <a href="http://en.wikipedia.org/wiki/Cunene_River">the river</a> in Southern Angola. Eventually I <a href="https://github.com/mcraveiro/cunene">put it on GitHub</a>. I believe - but don't recall exactly - that most of the refactoring ideas were stolen from Phil Hagelberg's <a href="https://github.com/technomancy/emacs-starter-kit">Starter Kit</a> and <a href="https://github.com/alexott/emacs-configs">Alex Ott's .emacs</a>. </p> <p>Whatever the source of ideas, the improvements were undeniable. Cunene offered a all-in-one place to go to for my <span class="underline">.emacs</span>, and it combined all the experience I had in seeing other people's <span class="underline">.emacs</span>. At over twenty megs it wasn't exactly svelte, but my objective was to have a "zero-conf" setup; given a new machine, all I wanted to do was to <code>git clone</code> cunene, start Emacs and have exactly the same environment as everywhere else. </p> <p>Further, I could update Cunene from any machine and push it back to GitHub. Cunene contained all the modes I needed, all byte-compiled, and all at trusted versions and with some (very minor) patches. I could easily upgrade one or more modes from one machine and then just <code>git pull</code> from all other machines. It also handled any Windows-specific workarounds, ensuring things worked well out of the box there too. </p> <p>To be fair, for the last 6 years, this setup has served me well, but time also revealed its limitations: </p> <ul class="org-ul"><li>package management support was limited. I tried using <a href="http://emacswiki.org/emacs/ELPA">Elpa</a> but, at the time, not many packages were available. Package management has evolved in leaps and bounds - <a href="http://melpa.org/#/">Melpa</a>, <a href="https://marmalade-repo.org/">Marmelade</a>, etc - but Cunene was still stuck with the old Elpa support. </li><li>the accumulation of modes over such a long period meant that starting Emacs took quite a long time. And to make matters worse, only a small percentage of the modes were truly useful. </li><li>most of the modes were at stale versions. Since things worked for me, I had no incentive to keep up with latest and greatest - and for all the easiness, it was still not exactly trivial to upgrade modes. This meant that I ended up having to put up with bugs that had long been fixed in HEAD, and worse, whenever I upgraded to latest, I saw massive changes in behaviour. </li><li>I was stuck on Emacs 23. For whatever reason, some parts of Cunene did not work with Emacs 24 properly and I was never able to get to the bottom of this. Being on an old version of Emacs has been a problem because I make use of C++-11 but Emacs 23 doesn't really indent it properly. And of course, Emacs 24 is just improved all around. </li><li>Cunene had a lot of boilerplate code. Since I never really learnt how to code in Emacs lisp, I was most likely writing a lot of non-idiomatic code. Also, the Emacs API has moved on considerably in fifteen years, so certain things were not being done in the best way possible. </li><li>Cedet and Org-mode are now part of Emacs but we were still carrying our own copies. I never managed to get Cedet to work properly either. </li><li>many new modes have appeared of late that provide much better solutions to some of the problems I had, but Cunene insulated me from these developments. In addition, adding new modes would only add to the complexity so I had no incentive to do so. </li></ul> <p>There had to be a better way of doing things; something that combined the advantages of Cunene but fixed its shortcomings. </p> <p>Then I heard of <a href="https://github.com/bbatsov/prelude#automated">Prelude</a>. </p></div></div> <div class="outline-2" id="outline-container-sec-2"><h2 id="sec-2">The Road to Prelude</h2><div class="outline-text-2" id="text-2"><p>According to the official documentation: </p> <blockquote><p>Prelude is an Emacs distribution that aims to enhance the default Emacs experience. Prelude alters a lot of the default settings, bundles a plethora of additional packages and adds its own core library to the mix. The final product offers an easy to use Emacs configuration for Emacs newcomers and lots of additional power for Emacs power users. </p></blockquote> <p>I am still finding my way around - so don't quote me - but from what I have seen, it seems to me that Prelude is like the Cunene "framework" but done by people that know what they are doing. It covers all of the advantages described above, but shares none of its disadvantages. In particular: </p> <ul class="org-ul"><li>it provides a sensible set of baseline defaults that "we all can agree on". I found it quite surprising that a plain Prelude looked almost like Cunene. Of course, no two Emacs users agree on anything, really, so there is still a lot to be tweaked. Having said that, the great thing is you can start by seeing what Prelude says and giving it a good go using it; if the baseline default does not work for you, you can always override it. Just because you have been doing something in a certain way for a long time does not mean its the best way, and the move to Prelude provides an opportunity to reevaluate a lot of "beliefs". </li><li>all the framework code is now shared by a large number of Emacs users. This means it is well designed and maintained, and all you have to worry about is your small extensibility points. With over 1k forks in GitHub, you can rest assured that Prelude will be around for a long time. In addition, if you find yourself changing something that is useful to the Prelude community, you can always submit a pull request and have that code shared with the community. You no longer have to worry about staleness or non-idiomatic code. </li><li>Prelude integrates nicely with several package managers and handles updates for you. </li><li>There are lots of examples of Prelude users - you just need to follow the GitHub forks. It would be nice to have a list of "good examples" though, because at 1K forks its not easy to locate those. </li><li>If you fork Prelude the right way, you should be able to update from upstream frequently without having too many conflicts. I am still getting my head around this, but the model seems sound at first blush. </li></ul> <p>But to know if it worked required using it in anger, and that's what will cover in the next few sections. </p></div> <div class="outline-3" id="outline-container-sec-2-1"><h3 id="sec-2-1">From Cunene to Prelude</h3><div class="outline-text-3" id="text-2-1"><p>Emacs users are creatures of habit and changing your entire workflow is not something to take lightly. Having said that, I always find that the best way to do it is to just go for it. After all, you can always go back to how you did things before. In addition, I did not want to do a wholesale port of Cunene for two reasons: </p> <ul class="org-ul"><li>I didn't want to bring across any bad habits when Prelude was already solving a problem properly. </li><li>I wanted to get rid of all of the accumulated cruft that was no longer useful. </li></ul> <p>What follows are my notes on the porting work. This is a snapshot of the work, a few days into it. If there is a reason, I may do further write-ups to cover any new developments. </p></div> <div class="outline-4" id="outline-container-sec-2-1-1"><h4 id="sec-2-1-1">Initial Setup</h4><div class="outline-text-4" id="text-2-1-1"><p>Prelude recommends you to create a fork and then add to it your personal configuration. I decided to create a branch in which to store the personal configuration rather than pollute master. This has two advantages: </p> <ul class="org-ul"><li>pulling from upstream will always be conflictless; </li><li>if I do decide to submit a pull request in the future, I can have a clean feature branch off of master that doesn't have any of the personal cruft in it. </li></ul> <blockquote><p>As it happens, I later found out that other Prelude users also use this approach such as <a href="https://github.com/danielwuz">Daniel Wu</a>, as you can see <a href="https://github.com/danielwuz/prelude/tree/personal/personal">here</a>. I ended up using Daniel's approach in quite a few cases. </p></blockquote> <p>I created <a href="https://github.com/mcraveiro/prelude">my prelude fork</a> in GitHub using the web interface. Once the fork was ready, I moved Cunene out of the way by renaming the existing <code>.emacs.d</code> directory and performed the following setup: </p> <pre class="example"><br />$ curl -L https://github.com/bbatsov/prelude/raw/master/utils/installer.sh -o installer.sh<br />$ chmod +x installer.sh<br />$ ./installer.sh -s git@github.com:mcraveiro/prelude.git<br /></pre> <p>This created a Prelude-based <code>~/.emacs.d</code>, cloned off of my fork. I then setup upstream: </p> <pre class="example"><br />$ cd ~/.emacs.d<br />$ git remote add upstream git@github.com:bbatsov/prelude.git<br /></pre> <p>This means I can now get latest from upstream by simply doing: </p> <pre class="example"><br />$ git checkout master<br />$ git pull upstream master<br />$ git push origin master<br /></pre> <p>I then setup the <code>personal</code> branch: </p> <pre class="example"><br /> $ git branch --track personal origin/personal<br /> $ git branch<br />   master<br /> * personal<br /></pre> <p>For good measure, I also setup <code>personal</code> to be the default branch in GitHub. This hopefully means there is one less configuration step when setting up new machines. Once all of that was done, I got ready to start Emacs 24. The version in Debian Testing at present is 24.4.1 - not quite the latest (24.5 is out) but recent enough for those of us stuck in 23. </p> <p>The start-up was a bit slow; Prelude downloaded a number of packages, taking perhaps a couple of minutes and eventually was ready. For good measure I closed Emacs and started it again; the restart took a few seconds, which was quite pleasing. I was ready to start exploring Prelude. </p></div></div> <div class="outline-4" id="outline-container-sec-2-1-2"><h4 id="sec-2-1-2">The "Editor" Configuration</h4><div class="outline-text-4" id="text-2-1-2"><p>My first step in configuration was to create a <code>init.el</code> file under <code>.emacs.d/personal</code> and add <code>prelude-personal-editor.el</code>. I decided to follow this naming convention by looking at the Prelude core directory; seems vaguely in keeping. This file will be used for a number of minor tweaks that are not directly related to an obvious major mode (at least from a layman's perspective). </p></div> <ul class="org-ul"><li><a id="sec-2-1-2-1" name="sec-2-1-2-1"></a>Fonts, Colours and Related Cosmetics<br /><div class="outline-text-5" id="text-2-1-2-1"><p>The first thing I found myself tweaking was the default colour theme. Whilst I actually quite like <a href="https://github.com/bbatsov/zenburn-emacs">Zenburn</a>, I find I need a black background and my font of choice. After consulting a number of articles such as <a href="http://stackoverflow.com/questions/20781746/emacs-prelude-background-color">Emacs Prelude: Background Color</a> and the <a href="http://emacswiki.org/emacs/SetFonts">Emacs Wiki</a>, I decided to go with this approach: </p> <div class="org-src-container"> <pre class="src src-emacs-lisp">;; set the current frame background and font.<br />(set-background-color "black")<br />(set-frame-font "Inconsolata Bold 16" nil t)<br /><br />;; set the font and background for all other frames.<br />(add-to-list 'default-frame-alist<br />             '(background-color . "black")<br />             '(font .  "Inconsolata Bold 16"))<br /></pre></div> <p>The font works like a charm, but for some reason the colour gets reset during start-up. On the plus side, new frames are setup correctly. I have raised an issue with Prelude: <a href="https://github.com/bbatsov/prelude/issues/855">What is the correct way to update the background colour in personal configuration?</a> For now there is nothing for it but to update the colour manually. Since I don't restart Emacs very often this is not an urgent problem. </p> <p>One nice touch was that <code>font-lock</code> is already global so there is no need for additional configuration there. </p></div></li> <li><a id="sec-2-1-2-2" name="sec-2-1-2-2"></a>Widgets and Related Cosmetics<br /><div class="outline-text-5" id="text-2-1-2-2"><p>Pleasantly, Prelude already excludes a lot of annoying screen artefacts and it comes with mouse wheel support out of the box - which is nice. All and all, a large number of options where already setup the way I like it: </p> <ul class="org-ul"><li>no splash screen; </li><li>no menu-bars or tool-bars; </li><li>good frame title format with the buffer name; </li><li>no annoying visible bell; </li><li>displaying of column and line numbers, as well as size of buffers out of the box; </li><li>not only search had highlight, but the all shiny <a href="https://github.com/syohex/emacs-anzu">Anzu mode</a> is even niftier! </li><li>no need for hacks like <code>fontify-frame</code>. </li></ul> <p>However, Preludes includes scroll-bars and tool-tips - things I do not use since I like to stick to the keyboard. It also didn't have date and time in the mode line; and for good measure, I disabled clever window splitting as I found it a pain in the past. Having said that, I am still not 100% happy with time and date since it consumes a lot of screen real estate. This will be revisited at some point in the context of <a href="http://www.emacswiki.org/emacs/DiminishedModes">diminish</a> and other mode line helpers. </p> <div class="org-src-container"> <pre class="src src-emacs-lisp">;; disable scroll bar<br />(scroll-bar-mode -1)<br /><br />;; disable tool tips<br />(when window-system<br />  (tooltip-mode -1))<br /><br />;; time and date<br />(setq display-time-24hr-format t)<br />(setq display-time-day-and-date t)<br />(display-time)<br /></pre></div> <p>One note on line highlighting. Whilst I quite like this feature in select places such as grep and dired, I am not a fan of using it globally like Prelude does. However, I decided to give it a try and disable it later if it becomes too annoying. </p></div></li> <li><a id="sec-2-1-2-3" name="sec-2-1-2-3"></a>Tabs, Spaces, Newlines and Indentation<br /><div class="outline-text-5" id="text-2-1-2-3"><p>In the realm of "spacing", Prelude scores well: </p> <ul class="org-ul"><li>no silly adding of new lines when scrolling down, or asking when adding a new line at save; </li><li>pasting performs indentation automatically (yank indent etc)- default handling of tabs and spaces is fairly sensible - except for the eight spaces for a tab! A few minor things are missing such as <code>untabify-buffer</code>. These may warrant a pull request at some point in the near future. </li><li>a nice whitespace mode which is not quite the same as I had it in Cunene but seems to be equally as capable so I'll stick to it. </li></ul></div></li> <li><a id="sec-2-1-2-4" name="sec-2-1-2-4"></a>To Prompt or Not to Prompt<br /><div class="outline-text-5" id="text-2-1-2-4"><p>There are a few cases where me and Prelude are at odds when it comes to prompts. First, I seem to try to exit Emacs by mistake and I do that <span class="underline">a lot</span>. As any heavy Emacs user will tell you, there is nothing more annoying than exiting Emacs by mistake (in fact, when else do you exit Emacs?). I normally have more than 50 buffers open and not only does it take forever to bring up Emacs with that much state, but it never quite comes back up exactly the way I left it. Anyway, suffices to say that I strongly believe in the "are you sure you want to exit Emacs" prompt, so I had that copied over from Cunene. And, of course, one does not like typing "yes" when "y" suffices: </p> <div class="org-src-container"> <pre class="src src-emacs-lisp">;; Make all "yes or no" prompts show "y or n" instead<br />(fset 'yes-or-no-p 'y-or-n-p)<br /><br />;; confirm exit<br />(global-set-key<br /> (kbd "C-x C-c")<br /> '(lambda ()<br />    (interactive)<br />    (if (y-or-n-p-with-timeout "Do you really want to exit Emacs ?" 4 nil)<br />        (save-buffers-kill-emacs))))<br /></pre></div> <p>There is a nice touch in Prelude enabling a few disabled modes such as upper/down casing of regions - or perhaps the powers that be changed that for Emacs 24. Whoever is responsible, its certainly nice not to have to worry about it. </p></div></li> <li><a id="sec-2-1-2-5" name="sec-2-1-2-5"></a>Keybindings<br /><div class="outline-text-5" id="text-2-1-2-5"><p>One of the biggest cultural shocks, inevitably, happened with keybindings. I am giving Prelude the benefit of the doubt - even though my muscle memory is not happy at all. The following has proved annoying: </p> <ul class="org-ul"><li>Apparently arrow keys are discouraged. Or so I keep hearing in my minibuffer every time I press one. As it happens, the warnings are making me press them less. </li><li><code>C-b</code> was my ido key. However, since I should really not be using the arrow keys, I had to get used to using the slightly more standard <code>C-x b</code>. </li><li>Eassist include/implementation toggling was mapped to <code>M-o</code> and <code>M-i</code> was my quick way of opening includes in semantic (more on that later). However, these bindings don't seem to work any more. </li><li><a href="http://emacswiki.org/emacs/PcSelectionMode">pc-select</a> is a bit screwed in some modes such as C++ and Emacs lisp. But that's alright since you shouldn't be using the arrow keys right? What is annoying is that it works ok'ish in Org-mode so I find that I behave differently depending on the mode I'm on. </li><li>in addition, win-move is using the default shift-arrow keys and its not setup to handle multiple frames. This is a problem as I always have a few frames. These will have to be changed, if nothing else just to preserve my sanity. </li><li>talking about pc-select, I still find myself pasting with <code>C-v</code>. I just can't help it, its buried too deeply into the muscle memory. But it must be said, it's rather disconcerting to see your screen move up when you press <code>C-v</code>; it makes you think your paste has totally screwed up the buffer, when in reality its just the good old muscle memory biting again. </li><li><code>C-x u</code> now doesn't just undo like it used to. On the plus side, undo-tree just rocks! We'll cover it below. </li><li><code>C-backspace</code> doesn't just delete the last word, it seems to kill a whole line. Will take some getting used to. </li></ul> <p>All and all, after a few days, the muscle memory seems to have adapted well enough. I'm hoping I'll soon be able to use <code>C-b</code> and <code>C-f</code>without thinking, like a real Emacs user. </p></div></li></ul></div> <div class="outline-4" id="outline-container-sec-2-1-3"><h4 id="sec-2-1-3">Modes From Cunene</h4><div class="outline-text-4" id="text-2-1-3"><p>Unfortunately, package management was not quite as complete as I had hoped and so, yet again, I ended up with a number of modes that had to be copied into git. Fortunately these are a lot less in number. I decided to place them under <a href="https://github.com/mcraveiro/prelude/tree/personal/personal/vendor">personal/vendor</a> as I wasn't sure what the main <span class="underline">vendor</span> folder was for. </p></div> <ul class="org-ul"><li><a id="sec-2-1-3-1" name="sec-2-1-3-1"></a>Cedet<br /><div class="outline-text-5" id="text-2-1-3-1"><p>After almost losing my mind trying to configure Cedet from Emacs 24, I decided to bite the bullet and upgrade to the latest development version. In the past this was a safe bet; I'm afraid to report it still is the best way to get Cedet up and running. In fact, I got it working within minutes after updating to develop versus a whole day of fighting against the built-in version. Pleasantly, it is now available in git: </p> <pre class="example"><br />git clone http://git.code.sf.net/p/cedet/git cedet<br /></pre> <p>Building it was a simple matter of calling make, both at the top-level and in contrib: </p> <pre class="example"><br />$ cd cedet<br />$ make EMACS=emacs24<br />$ cd contrib<br />$ make EMACS=emacs24<br /></pre> <p>The setup was directly copied from their INSTALL document, so I recommend reading that. </p> <p>Still in terms of Cedet, a very large win was the move to <a href="https://github.com/randomphrase/ede-compdb">EDE Compilation Database</a>. I really cannot even begin to do justice to the joys of this mode - it is truly wonderful. I did the tiniest of changes to my build process by defining an extra macro: </p> <pre class="example"><br />cmake ../../../dogen -G Ninja -DCMAKE_EXPORT_COMPILE_COMMANDS=TRUE<br /></pre> <p>With just that - and a couple of lisp incantations (see the <a href="https://github.com/mcraveiro/prelude/blob/personal/personal/init-cedet.el#L78">cedet init file</a>) - and suddenly I stopped having to worry about supplying flags to flymake (well, <span class="underline">flycheck</span> - but that's another story), semantic, the whole shebang. I haven't quite worked out all of the details just yet, but with very little configuration the compilation database seems to just get everything working magically. </p> <p>Because of this, I am now finding myself using Cedet a lot more; the intelisense seems to just work on the majority of cases. The only snag is the annoyance of old: having Emacs block on occasion whilst it builds some semantic database or other. It doesn't happen often but its still a pain when it does. Which gave me the idea of <a href="http://sourceforge.net/p/cedet/mailman/message/34145936/">replacing it</a>with a Clang based "semantic database generator". Lets see what the Cedet mailinglist says about it. </p> <p>All and all, Cedet is much improved from the olden days; so much so I feel it warrants a proper review after a few months of using it in anger. In fact, I feel so brave I may even setup <a href="https://github.com/chrisbarrett/emacs-refactor">emacs-refactor</a> or <a href="https://github.com/tuhdo/semantic-refactor">semantic-refactor</a>. It is also high-time to revisit <a href="http://tuhdo.github.io/c-ide.html">C/C++ Development Environment for Emacs</a> and pick up some new tips. </p></div></li> <li><a id="sec-2-1-3-2" name="sec-2-1-3-2"></a>Git-emacs<br /><div class="outline-text-5" id="text-2-1-3-2"><p><a href="https://github.com/tsgates/git-emacs">Git-emacs</a> makes me a bit sad. In truth, I am a perfectly content magit user (more on that later) except for <span class="underline">one</span> feature - the file status "dot". This is something I got used from the svn days and still find it quite useful. Its silly really, especially in these days of <a href="https://github.com/syohex/emacs-git-gutter">git-gutter</a>, but I still like to know if there have been any changes to a file or not, and I haven't found a good way of doing this outside of git-emacs. It provides a nice little red or green dot in the modeline, like so: </p>  <div class="figure"><p><img alt="git-emacs.png" src="https://raw.githubusercontent.com/DomainDrivenConsulting/dogen/master/doc/blog/git-emacs.png" /></p><p><span class="figure-number">Figure 1:</span> Git-emacs state modeline</p></div> <p>However, there are no packaged versions of git-emacs and since everyone uses magit these days, I can't see it making to Elpa. Also, it is rather annoying having to load the whole of git-emacs for a dot, but there you go. </p></div></li> <li><a id="sec-2-1-3-3" name="sec-2-1-3-3"></a>Doxymacs<br /><div class="outline-text-5" id="text-2-1-3-3"><p>Very much in the same vein as git-emacs, <a href="http://doxymacs.sourceforge.net/">doxymacs</a> is also one of those more historical modes that seem a bit unmaintained. And very much like git-emacs, I only use it for the tiniest of reasons: it syntax-highlights my doxygen comments. I know, I know. On the plus side, it seems to do a whole load of other stuff - I just never quite seem to need any other feature besides the nice syntax highlighting of comments. </p></div></li></ul></div> <div class="outline-4" id="outline-container-sec-2-1-4"><h4 id="sec-2-1-4">Modes From Prelude or Emacs 24</h4><div class="outline-text-4" id="text-2-1-4"><p>In this section we cover modes that are either new/updated for Emacs 24 or available from Prelude via Elpa. </p></div> <ul class="org-ul"><li><a id="sec-2-1-4-1" name="sec-2-1-4-1"></a>Dired<br /><div class="outline-text-5" id="text-2-1-4-1"><p>Dired is configured in a fairly sensible manner out of the box. For example, one no longer has the annoying prompts when deleting/copying directories with files - it never occurred to me you could configure that away for some reason. </p> <p>On the down side, it is not configured with <a href="http://emacswiki.org/emacs/DiredReuseDirectoryBuffer">dired-single</a>, so the usual proliferation of dired buffers still occurs. I have decided not to setup dired-single for a few days and see how bad it gets. </p> <p>The other, much more annoying problem was that hidden files are displayed by default. I first tried solving this problem with dired-omit as per <a href="https://truongtx.me/2013/04/24/dired-as-default-file-manager-3-dired-details/%0A">this page</a>: </p> <div class="org-src-container"> <pre class="src src-emacs-lisp">(setq-default dired-omit-mode t)<br />(setq-default dired-omit-files "^\\.?#\\|^\\.$\\|^\\.\\.$\\|^\\.")<br /></pre></div> <p>However, I found that omit with regexes is not that performant. So I ended up going back to the old setup of <code>ls</code> flags: </p> <pre class="example"><br />(setq dired-listing-switches "-l")<br /></pre></div></li> <li><a id="sec-2-1-4-2" name="sec-2-1-4-2"></a>Undo-tree and browse-kill-ring<br /><div class="outline-text-5" id="text-2-1-4-2"><p>As mentioned before, <code>C-x u</code> is not just undo, it's undo-tree! Somehow I had missed this mode altogether up til now. Its pretty nifty, as it allows you to navigate the undo-tree - including forks. It is quite cool. </p> <p>I also found that the latest version of browse-kill-ring is very nice; so much so that I find myself using it a lot more now. The management of the clipboard will never be the same. </p></div></li> <li><a id="sec-2-1-4-3" name="sec-2-1-4-3"></a>Org-mode<br /><div class="outline-text-5" id="text-2-1-4-3"><p>One rather annoying thing was that with the latest Org-mode, the clock-table is a bit broken. I quickly found out I wasn't the only one to notice: <a href="http://emacs.stackexchange.com/questions/9528/is-it-possible-to-remove-emsp-from-clock-report-but-preserve-indentation">Is it possible to remove ' ' from clock report but preserve indentation?</a></p> <p>This link implies the problem is fixed in Emacs 24.4, but I am running it and sadly it doesn't seem to be the case. I also found out that the automatic resizing of clock tables is no longer… well, automatic. Instead, we now have to supply the size. My final setup for the clock-table is as follows: </p> <pre class="example"><br />#+begin: clocktable :maxlevel 3 :scope subtree :indent nil :emphasize nil :scope file :narrow 75<br /></pre> <p>This seems to generate a table that is largely like the ones we had prior to upgrading. </p> <p>Other than that, Org-mode has behaved - but then again, I'm not exactly a poweruser. </p></div></li> <li><a id="sec-2-1-4-4" name="sec-2-1-4-4"></a>Bongo<br /><div class="outline-text-5" id="text-2-1-4-4"><p>I use the amazing <a href="https://github.com/dbrock/bongo">Bongo</a> media player to play the few internet radio stations I listen to - mainly SomaFM, to be honest. Its good to see it in Melpa. It's still not quite as straightforward as you'd like to save a playlist - I always find that loading the buffer itself does not trigger bongo mode for some reason - but other than that, it works fine. </p> <p>On the downside, I use the venerable <a href="http://www.emacswiki.org/emacs/Mpg123">mpg123</a> to play random albums and that hasn't made it to Melpa yet. I've decided to try to use Bongo for this use case too, but if that doesn't work out then I'll have to add it to vendor… </p></div></li> <li><a id="sec-2-1-4-5" name="sec-2-1-4-5"></a>Shell<br /><div class="outline-text-5" id="text-2-1-4-5"><p>Prelude comes with eshell configured by default. I must confess I have always been a bash user - simple and easy. I'll persevere with eshell for a couple of days, but I can already see that this may be a bridge too far. </p></div></li> <li><a id="sec-2-1-4-6" name="sec-2-1-4-6"></a>Flycheck<br /><div class="outline-text-5" id="text-2-1-4-6"><p>One of the main reasons that made me consider moving to prelude was <a href="http://flymake.sourceforge.net/">Flymake</a>. I added it to cunene fairly early on, some 6 years ago, and I was amazed at how I had managed to use Emacs for over a decade without using Flymake. However, after a good 6 years of intensive usage, I can attest that Flymake is showing its age. The main problem is how it locks up Emacs whilst updating. If you combine that with the insane errors one gets in C++, all you need is an angle-bracket out of place and your coding flow is disrupted for potentially several minutes. To be fair, this happens very infrequently, but its still a major nuisance. So I was keen to explore <a href="https://github.com/flycheck/flycheck">Flycheck</a>. </p> <p>All I can say is: wow! The same feeling of amazement I felt for Flymake when I first used has been repeated with Flycheck. Not only its blazingly fast, it supports multiple checkers and the errors buffer is a dream to work with. And with the Compilation Database integration it means there is no configuration required. I can't believe I survived this long without Flycheck! </p></div></li> <li><a id="sec-2-1-4-7" name="sec-2-1-4-7"></a>Magit<br /><div class="outline-text-5" id="text-2-1-4-7"><p>One of my favourite modes in Emacs - at least of the new generation of modes - is <a href="http://magit.vc/">Magit</a>. So much so that I find that I rarely use git from anywhere else, it's just so easy to do it from Magit. Which makes me extremely sensitive to any changes to Magit's interface. </p> <p>The version in Prelude - presumably from Melpa - is a tad different from the legacy one I was using in Cunene. On the plus side, most of the changes are improvements such as having a "running history" in the git process buffer, with font-lock support. The main Magit buffer also looks very nice, with lots of little usability touches. A tiny few changes did result in slow-downs of my workflow, such as a sub-menu on commit. Its not ideal but presumably one will get used to it. </p> <p>The only negative change seems to be that Magit is not quite as responsive as it used to be. Hard to put a finger yet, but I was used to having pretty much zero wait time on all operations in Magit, and yet now it seems that a few things are no longer instantaneous. It will require some more analysis to properly point the finger, but its a general feel. </p></div></li></ul></div></div></div> <div class="outline-2" id="outline-container-sec-3"><h2 id="sec-3">Conclusions</h2><div class="outline-text-2" id="text-3"><p>It's still early days, but the move to Emacs 24 and Prelude is already paying off. The transition has not been entirely straightforward, and it certainly has slowed things down for the moment - if not for anything else, just due to the keybinding changes! But one can already see that this is the future for most Emacs users, particularly those that are not power-users like myself but just like the editor. </p> <p>The future is certainly bright for Emacs. And we haven't yet started covering the latest and greatest modes such as <a href="https://github.com/Malabarba/smart-mode-line">smart-mode-line</a>. But that's a story for another blog post. </p></div></div></div><div class="status" id="postamble"><p class="date">Created: 2015-05-27 Wed 00:18</p><p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.4.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p><p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p></div>

            <p class="text-muted">in 'Marco Craveiro' on May 26, 2015 11:19 PM. <a href="http://mcraveiro.blogspot.com/2015/05/nerd-food-prelude-of-things-to-come.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Nerd Food: Start-ups at the Gate: Trends in the Technology Industry.</h4>

            Nerd Food: Start-ups at the Gate: Trends in the Technology Industry  <div id="preamble"> </div> <div id="content"> <p>It is very difficult to convey the vast scale at which the largest Internet companies operate. To make matters worse, we are fast becoming immune to statistics such as <a href="http://mashable.com/2014/04/23/facebook-1-billion-mobile-users/">one billion users</a> and <a href="http://www.statisticbrain.com/google-searches/">five trillion searches per day</a>, surrounded as we are by a sea of large numbers on a daily basis. Having said that, any Information Technology (IT) professional worth his or her salt cannot help but feel in awe at what has been achieved. It is not just that these platforms are big; they work at a scale that is <i>qualitatively</i> different from anything that has come before. The sort of things that are possible at this scale are mind-boggling, and we have only begun to scratch the surface<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.1" name="fnr.1">1</a></sup>. </p><p>Perhaps even more revolutionary is the fact that these companies have made it possible for anyone to start thinking about data in the same way as they do, and to start handling it using the very same tools they use. There is now a never-ending archive of the very best large-scalability tools, all available for free, with code that anyone can inspect, modify and optimise to meet their specific requirements. The tools come with a wealth of practical documentation on how to put solutions together - either freely available or at low-cost - and with a number of passionate user communities that provide expert advice and are eager to accept modifications. </p><p>The ecosystem they have created is truly staggering. As an example, Facebook has open sourced almost <a href="https://code.facebook.com/posts/292625127566143/9-9-million-lines-of-code-and-still-moving-fast-facebook-open-source-in-2014/">10M lines of code</a> to date. Twitter, Google and LinkedIn are not far behind<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.2" name="fnr.2">2</a></sup>. It is also important to notice that non-Internet companies are making extremely large contributions too, such as Microsoft and IBM. All told, the overall pool of open source code is growing exponentially, as demonstrated by a <a href="http://dirkriehle.com/publications/2008-2/the-total-growth-of-open-source/">2008 study</a>. In most cases, these are full-fledged products, tested in the most challenging production conditions imaginable. Of course, one must also not forget the contributions made to projects that are not under company control such as the Linux Kernel, the Apache web-server and the GNU Compiler GCC. </p><p>In order to understand why modern start-ups provide such a compelling financial case, one must first understand how we got to the amazing technology landscape we have today. To do so, we shall divide recent technology history into eras, and explain each era's contribution. We will then focus on modern start-ups, and explain how this model can be deployed to a large gamut of industries and in particular to the financial sector. </p> <div class="outline-2" id="outline-container-1"><h2 id="sec-1">First Era: Dot-com Bubble</h2><div class="outline-text-2" id="text-1">  <p>Silicon Valley was and still is the world's start-up factory so, unsurprisingly, it was ground zero for the start-up revolution that took place at the end of the nineties. It would eventually be known as <a href="http://en.wikipedia.org/wiki/Dot-com_bubble">The Dot-com Bubble</a>. Most people remember those days as a heady time, where each and every idea was packaged as a website and sold for millions or in some cases billions of dollars. Of course, we all had a steep price to pay when the bubble burst - an extinction event that decimated the young Internet sector and IT companies in general. </p><p>There is however another way to look at this bubble: it was a gigantic experiment to determine whether there were successful business models to be found in the large scale of the Internet. Whilst much mal-investment occurred, the bubble still produced or pushed forward several of the giants of today such as Google, Amazon and Yahoo. </p><p>Most of these companies share a similar technology story. Originally faced with a dearth of investment but with bright young engineers, they found themselves relying on Free and Open Source Software (FOSS) and cheap, off-the shelf hardware. Once they became big enough, it just didn't make sense to replace all of that infrastructure with software and hardware supplied by commercial vendors. </p><p>This turn of events was crucial. If these companies had had larger budgets and less skilled engineers, they would have relied on the cutting edge technology of the time. The short-term gain would reveal itself as long term pain, for their ability to scale would be inevitably restricted. In addition, many of the business models wouldn't have worked due to this cost structure<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.3" name="fnr.3">3</a></sup>. As it was, since they couldn't even afford the relatively cheap licences of commercial software, they had to make do with what was available for free. </p><p>The engineers in these companies - and many others that didn't make it through the dot-com filter - spent countless hours improving FOSS tools and gave back much of these improvements to communities such as Linux, MySQL, Apache, GCC and so on. However, they kept private the plumbing work done to manage the large cluster of cheap machines, as well as the domain related technology - in industry-speak, the <i>Secret Sauce</i>. </p><p>By the time the dot-com bubble had run its course and the dust settled, the landscape looked as follows: </p><ul><li>A model had been created whereby a small number of engineers could   bootstrap an Internet-based company at very low cost, serving a   small number of users initially. </li><li>The model had been stretched to very large numbers of users and had   been found to scale extremely well; as the business proved itself   and investment came in, it was possible increase the size of the   computing infrastructure to cope with demand. </li><li>Because of the open nature of the technologies involved, the ideas   became widespread over the internet. </li></ul>  <p>The basic high-scalability FOSS stack - ready for start-ups - was born; the Data Centre, where large amounts of computing are available at low cost, soon followed. It would eventually morph into the Cloud. </p></div> </div> <div class="outline-2" id="outline-container-2"><h2 id="sec-2">Second Era: Social Media</h2><div class="outline-text-2" id="text-2">  <p>The bursting of the dot-com bubble did not dampen the entrepreneurial spirits, but it did dry up all the easily available capital and thus pushed the aspiring start-ups to be ever more frugal. In addition, VCs started to look for better ways to evaluate prospects. The problem they faced was no different from what they had faced during the dot-com days: how to figure out the potential of a company with no defined business model and nothing else to compare it against. </p><p>Google had proved comprehensively that the traditional valuation methods did not make sense in the world of start-ups. After all, here was a company which it's founders couldn't sell for 1M USD and yet a few years later was generating billions of dollars in revenues. Very few saw this coming. VCs were keen not to make the same mistake with the next Google<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.4" name="fnr.4">4</a></sup>. </p><p>So it was that a system to determine potential by proxy emerged over the years, using indicators such as the size of the user base, time spent by users on the platform and so on - effectively, any attribute that was deemed to have given a competitive advantage to Google and other successful dot-com companies. </p><p>In this environment, <i>social media</i> start-ups took took centre stage. Following on from the examples of their predecessors, these companies took for granted that they were to operate on very large data sets. They inherited a very good set of scalable tools, but found that much still had to be built on top. Unlike their predecessors, many chose to do some or all of the infrastructure work out in the open, joining or creating new communities around the tools. This was in no small part due to the scarcity of funds, which encouraged collaboration. </p><p>The social media start-ups soon found themselves locked in an arms race for size, where the biggest would be the winner and all others would be doomed to irrelevance<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.5" name="fnr.5">5</a></sup>. The size of the user base of the successful companies exploded<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.6" name="fnr.6">6</a></sup>, and the tooling required to manage such incredibly large volumes of data had to improve at the same pace or faster. Interestingly, these start-ups continued to view in-house code largely as a cost, not an asset, even after they started to bring in large revenue. The size of the secret sauce was to be kept at a minimum and the pace of open sourcing accelerated over time<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.7" name="fnr.7">7</a></sup>. </p><p>A final factor was the rise of the next iteration of the data centre, popularised by Amazon with <a href="http://en.wikipedia.org/wiki/Amazon_Web_Services">AWS and EC2</a>. It allowed <i>any</i> company to scale out without ever having to concern themselves with physical hardware. This was revolutionary because it allowed razor-thin costs for scalability: </p><ul><li><b>Pay only for what you use</b>: the <i>elastic</i> nature of EC2 meant that   one could grow or shrink one's cluster based on real time traffic   demands and availability of capital. </li><li><b>Zero-cost software</b>: FOSS was available in Amazon from the very   beginning and was extremely popular with start-ups. </li><li><b>Fully automated environments via APIs</b>: resource constrained   start-ups could now start to automate all aspects of the product   life-cycle. This meant they could release faster, which in turn   allowed them to fight more effectively for their user base. This   would in time become the <a href="http://en.wikipedia.org/wiki/DevOps">DevOps movement</a>. </li></ul>  <p>By the end of the decade, the scalability tooling was largely complete. It was now possible for a small start-up to create a small website and to see it scale from hundreds to millions, restricted only by their ability to bring in capital. </p></div> </div> <div class="outline-2" id="outline-container-3"><h2 id="sec-3">Third Era: Mobile</h2><div class="outline-text-2" id="text-3">  <p>Mobile phones have been growing close to an exponential rate for over two decades. However, the rise of the smart phones was a game changer, and the line in the sand was drawn with the release of the iPhone. What makes mobile so important to our story is it's penetration. Until smart phones became ubiquitous, there was a large segment of the population that was either totally inaccessible or accessible for limited periods of time. With increasingly large numbers of people carrying smart phones as they go about their day, many use cases that were never before thought possible came to the table. So whilst we call this "the Mobile era", the true heroes are smart phones and, to a smaller extent, the tablets. </p><p>The mobile era started with simple apps. Smart phones were still new and applications for each platform were novelty. There was a need to reinvent all that existed before in the world of PCs and adapt it to the new form factor. It was during this phase that the economies of scale of mobile phones became obvious. Whereas consumer PC software had prices on the range of tens to hundreds of dollars, mobile phones bootstrapped a completely different pricing model, with many apps selling for less than one dollar. Volume made up for the loss in revenue per unit. The model was so incredibly successful that a vibrant environment of apps sprung up around each of the successful platforms, carefully nurtured by the companies running the show via their <i>app stores</i>. </p><p>Soon enough the more complex apps came about. Companies like Four Square and WhatsApp were trailblazers in the mobile space, merging it with ideas from social media. Many others like Spotify took their wares from the stagnant PC environment and moved to the ever growing mobile space. Complex apps differed from the simple apps in that they required large backends to manage operations. Since these companies were cash strapped - a perennial condition of all start-ups - they found themselves reusing all of the technology developed by the social media companies and became part of the exact same landscape. Of course, the social media companies were eventually forced to jump on the mobile bandwagon - lest they got crushed by it. </p><p>So it was that the circle was closed between the three eras. </p></div> </div> <div class="outline-2" id="outline-container-4"><h2 id="sec-4">Evolutionary Pressures and Auto-Catalytic Processes</h2><div class="outline-text-2" id="text-4">  <p>The changes just described are so revolutionary that one cannot help but look for models to approximate some kind of explanation for what took place. Two stand out. The first is to imagine the population of start-up companies as a small segment of the overall company population that was submitted to an unbelievably harsh fitness function: to grow the data volumes exponentially while growing costs less than linearly. This filter generated new kinds of companies, new kinds of technologies and new kinds of ways of managing technology. </p><p>Secondly, there is the auto-catalytic nature of the processes that shaped the current technology landscape. Exponential growth tends to have at its root this kind of self-reinforcing cycle, whereby improvements in an area A trigger improvements in another area B, which in turn forces A to improve. The process keeps on repeating itself whilst it manages to retain stability. </p><p>It is this relationship we currently have between start-ups and FOSS: the better the software gets, the cheaper it is to create new start-ups and the faster these can grow with the same amount of capital. By the same token, the more start-ups rely on FOSS, the more they find themselves contributing back or else risk falling behind - both technologically and cost-wise. This feedback loop is an emerging property of the entire system and it has become extremely pronounced over time. </p></div> </div> <div class="outline-2" id="outline-container-5"><h2 id="sec-5">Finance and the Age of Disruption</h2><div class="outline-text-2" id="text-5">  <p>The concept of <i>disruption</i> was developed in the nineties by Clayton Christensen in <a href="http://www.amazon.co.uk/Innovators-Dilemma-Technologies-Management-Innovation/dp/142219602X/ref=sr_1_1?ie=UTF8&amp;qid=1411676026&amp;sr=8-1&amp;keywords=the+innovator%27s+dilemma">Innovator's Dilemma</a>. This book has seen a resurgence in popularity as well as in criticism<sup><a class="footref" href="http://mcraveiro.blogspot.com/feeds/posts/default#fn.8" name="fnr.8">8</a></sup>. For good or bad, the ideas in this book became the intellectual underpinnings of a new generation of start-ups. </p><p>They seek to combine all of the advances of the previous start-ups to create solutions to problems far outside the traditional IT realm. Examples are the hotel industry (<a href="http://mcraveiro.blogspot.com/feeds/posts/default#www.airbnb.co.uk">AirBnB</a>), the taxi industry (<a href="http://mcraveiro.blogspot.com/feeds/posts/default#www.uber.com">Uber</a>, <a href="https://www.lyft.com/">Lyft</a>) and even the banking industry (<a href="https://www.simple.com/">Simple</a>). Whilst it's still early days, and whilst there have been many teething problems such as issues with regulation, the destination of travel is already clear: there will be more and more start-ups following the disruptive route. </p><p>What makes these companies a compelling proposition to VCs is that they are willing to take on established concerns, with cost structures that are orders of magnitude larger than that of these start-ups. Their thinking is two-fold: the established companies are leaving a lot of money on the table, consumed by their inefficiency; and they are not exploiting the opportunities to their full potential because they do not understand how to operate at a vast scale. </p><p>It is in this context that finance scene comes into the picture - as part of the expansionary movement of the disruption movement. VCs have longed eyed enviously the financial industry because they believed that the problems being solved in trading are not that dissimilar to those faced by many large scale start-ups. And yet the rewards are disproportional large in Finance, when compared with say social media. </p><p><i>Fintech</i> soon emerged. As applied to start-ups, Fintech is the umbrella name given to the ecosystem of start-ups and VCs that focus specifically on financial technology. This ecosystem has grown from 930M USD in 2008 to around 3Bn in 2013 <a href="http://www.accenture.com/Microsites/fsinsights/capital-markets-uk/Documents/Accenture-Global-Boom-in-Fintech-Investment.pdf">according to Accenture</a>. Centred mainly in London, but with smaller offshoots in other financial centres, the Fintech scene is starting to attract established players in the world of Finance. For instance, Barclays has joined the fray by creating an incubator. They farmed off the work to a third-party (Tech Stars) but allowed all the start-ups in the programme to have unprecedented access to their Mobile APIs. Their target is to own the next generation of financial applications on Mobile devices. </p><p>Whist Barclays is disrupting from the outside, it is obvious that the investment banking legacy platforms are a fertile ground for start-ups. This is where the scalability stack has a near-perfect fit. A typical example is <a href="http://mcraveiro.blogspot.com/feeds/posts/default#www.opengamma.com">OpenGamma</a>. The start-up designed an open source Risk platform, initially focused on back office use. They have received over <a href="http://www.opengamma.com/about-us">20M USD in funding as of 2014</a> and have already been the recipient of several of the <a href="http://www.riskfocus.com/opengamma-wins-waters-sell-side-technology-award-for-best-market-risk-product">industry's awards</a>. There are now several open source trading platforms to choose from including TradeLink and OpenGamma, as well as the popular quantitative analytics library QuantLib. </p><p>As we have seen in the previous sections, there is an auto-catalytic process at play here. Once source code becomes widely available, the cost of creating the next Financial startup goes down dramatically because they can reuse the tools. This in turn means many more start-ups will emerge, thus improving the general quality of the publicly available source code. </p></div> </div> <div class="outline-2" id="outline-container-6"><h2 id="sec-6">Conclusions</h2><div class="outline-text-2" id="text-6">  <p>The objective of this article was to provide a quick survey of the impact of start-up companies in the technology landscape, and how these relate to finance. We now turn our attention to the logical conclusions of these developments. </p><ul><li><b>Finance will increasingly be the target of VCs and start-ups</b>: The   Fintech expansion is to continue over the coming years and it will   affect everyone involved in the industry, particularly the   established participants. More companies will take the route of   Barclays, trying to be part of the revolution rather than dethroned   by it. </li><li><b>Banks and other established companies will begin to acquire   start-ups</b>: Related to the previous item in some ways; but also with   a twist. As part of the <a href="http://www2.deloitte.com/global/en/pages/technology-media-and-telecommunications/articles/tmt-predictions-2013-technology-media-telecommunications-report.html">Deloitte TMT predictions</a> event, Greg   Rogers - the manager of Barclays Accelerator - stated that the   acquisition of non-financial start-ups by banks was on the cards. He   was speaking about Facebook's acquisition of WhatsApp for 18Bn USD,   one of the largest of the year. As Google and Facebook begin   integrating payments into their social platforms, banking firms will   find their traditional business models under attack and will have no   option but to retaliate. </li><li><b>Finance will turn increasingly to FOSS</b>: The cost structure that   finance firms had up to 2008 is not suitable to the post 2008   world. At present, the volume of regulatory work is allowing these   cost structures to persist (and in cases increase). However,   eventually banks will have to face reality and dramatically reduce   their costs, in line with the new kind of revenues they are expected   to make in a highly-regulated financial world. There will be a   dramatic shift away from proprietary technologies of traditional   vendors, unless these become much more competitive against their   fierce FOSS rivals. </li><li><b>A FOSS financial stack will emerge over the next five years</b>:   Directly related to the previous point, but taking it further. Just   as it was with social media companies, so it seems likely that   financial firms will eventually realise that they cannot afford to   maintain all the infrastructure code. Once an investment bank takes   the leap and starts relying on FOSS for trading or back-office, the   change will ripple through the industry. The state of the FOSS code   is production ready, and a number of hedge funds are already using   it in anger. All that is required is for the cost structure to be   squeezed even further in the investment banking sector. </li></ul>  <div id="footnotes"><h2 class="footnotes">Footnotes: </h2><div id="text-footnotes"><p class="footnote"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.1" name="fn.1">1</a></sup> As one of many examples, see <a href="http://en.wikipedia.org/wiki/Google_Flu_Trends">Google Flu Trends</a>. It is a predictor of outbreaks of the flu virus, with a prediction rate of about 97%. For a more comprehensive - if somewhat popular - take on the possibilities of large data sets, see <a href="http://www.amazon.co.uk/Big-Data-Revolution-Transform-Think/dp/1848547927">Big Data: A Revolution That Will Transform How We Live, Work and Think</a>. For a very different take - highliting the dangers of Big Data - see Taleb's views on the ever decreasing noise to signal ratio: <a href="https://dl.dropboxusercontent.com/u/50282823/Noise%20Bottleneck.pdf">The Noise Bottleneck or How Noise Explodes Faster than Data</a>. </p> <p class="footnote"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.2" name="fn.2">2</a></sup> In fact, by some measures, Google has contributed several times that amount. For one such take, see <a href="http://readwrite.com/2014/02/04/open-source-5-companies-code-projects">Lauren Orsini's article</a>. </p> <p class="footnote"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.3" name="fn.3">3</a></sup> As an example, it was common practice for vendors to charge according to the number of processors, users and so on. Many of the better funded start-ups made use of technology from Cisco, Sun, Oracle and other large commercial vendors, but companies that did so are not very well represented in the population that survived the dot-com bubble, and they are not represented at all in the <a href="http://www.crn.com/slide-shows/channel-programs/240154736/the-25-biggest-tech-companies-on-the-fortune-500.htm">2014 Fortune 500 list</a>. Google, Amazon and E-Bay are the only Fortune 500 companies from that crop and they all relied to a very large extent on in-house technology. Note though that we are making an empirical argument here rather than a statistical one, both due to the lack of data available, as well as concern for <a href="http://en.wikipedia.org/wiki/Survivorship_bias">Survivorship Bias</a>. </p> <p class="footnote"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.4" name="fn.4">4</a></sup> For one of many takes on the attempt to sell Google, see <a href="http://techcrunch.com/2010/09/29/google-excite/">When Google Wanted To Sell To Excite For Under 1 Million~— And They Passed</a>. To get a flavour of how poorly understood Google's future was as late as 2000, see <a href="http://www.sfgate.com/business/article/Google-Senses-That-It-s-Time-to-Grow-Up-3237385.php">Google Senses That It's Time to Grow Up</a>. Finally, the success story is best told by the growth of revenues between 2001 and 2003 - see Google's <a href="https://investor.google.com/financial/2003/tables.html">2003 Financial Tables</a>. </p> <p class="footnote"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.5" name="fn.5">5</a></sup> Twitter, Facebook, YouTube, LinkedIn and the like were the victors, but for every victor, a worthwhile foe was defeated; MySpace, Hi5, Orkut and many others were all very popular at one time but lost the war and faded into obscurity. </p> <p class="footnote"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.6" name="fn.6">6</a></sup> As an example, the number of Facebook users grew at an exponential rate between 2004 and 2013 - see <a href="http://www.theguardian.com/news/datablog/2014/feb/04/facebook-in-numbers-statistics">Facebook: 10 years of social networking, in numbers</a>. </p> <p class="footnote"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.7" name="fn.7">7</a></sup> A possible explanation for this decision is the need for continuous scalability. Even companies as large as Facebook or Google cannot dedicate the resources required to adequately maintain every single tool they own; their code bases are just too large. At the same time, they cannot afford for code to become stale because it must continually withstand brutal scalability challenges. The solution to this conundrum was to open source aggressively and to create vibrant communities around tooling. Converting themselves to stewards of the tools, they could now place quasi-skeleton crews to give direction to development, and then rely on the swarms of new start-ups to contribute patches. Once there are enough improvements, the latest version of these tools can be incorporated into the internal infrastructure. This proved to be a very cost-effective strategy, even for large companies, and allowed continued investment across the technology stack. </p> <p class="footnote"><sup><a class="footnum" href="http://mcraveiro.blogspot.com/feeds/posts/default#fnr.8" name="fn.8">8</a></sup> There are quite a few to choose from but <a href="http://www.newyorker.com/magazine/2014/06/23/the-disruption-machine">Lepore's</a> is one of the best because it robustly attacks both the ideology and the quality of the data. </p></div></div> </div></div></div> <div id="postamble"><p class="date">Date: 2014-09-25 21:37:47 BST</p><p class="creator">Org version 7.8.02 with Emacs version 23</p><a href="http://validator.w3.org/check?uri=referer">Validate XHTML 1.0</a> </div>

            <p class="text-muted">in 'Marco Craveiro' on September 25, 2014 08:45 PM. <a href="http://mcraveiro.blogspot.com/2014/09/nerd-food-start-ups-at-gate-trends-in.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Nerd Food: Dogen: Lessons in Incremental Coding.</h4>

            Nerd Food: Dogen: Lessons in Incremental Coding  <div id="preamble"> </div> <div id="content"> <p>A lot of interesting lessons have been learned during the development of <a href="https://github.com/DomainDrivenConsulting/dogen">Dogen</a> and I'm rather afraid many more are still in store. As it is typical with agile, I'm constantly reviewing processes in search of improvements. One such idea was that putting pen to paper could help improving the retrospective process itself. The result is this rather long blog post, which hopefully is of use to developers in similar circumstances. Unlike the typical bullet-point based retrospective, this post it is a rambling narrative as it aims to provide context to the reader. Subsequent retrospectives will be a lot smaller and more to the point. </p><p>Talking about context: I haven't spoken very much about Dogen in this blog, so a small introduction is in order. Dogen is an attempt to create a domain model generator. The <a href="https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/manual/manual.org#fundamental-building-blocks">manual</a> goes into quite a bit more detail, but for the purposes of this exercise, it suffices to think of it as a C++ code generator. Dogen has been developed continuously since 2012 - with a few dry spells - and reached its <a href="https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/sprint_backlog_50.org">fiftieth sprint</a>recently. Having said that, our road to a finished product is still a <a href="https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/definition_of_done.org">long one</a>. </p><p>The remainder of this article looks at what what has worked and what has not worked so well thus far into Dogen's development history. </p> <div class="outline-2" id="outline-container-1"><h2 id="sec-1">Understanding Time</h2><div class="outline-text-2" id="text-1">  <p>Dogen was conceived when we were trying to do our <a href="http://kitanda.co.uk/html/index.html">first start up</a>. Once that ended - around the back end of 2012 - I kept working on the tool in my spare time, and this was a setup that has continued ever since. There are no other contributors; development just keeps chugging along, slowly but steadily, with no pressures other than to enjoy the sights. </p><p>Working on my own and in my spare time meant that I had two conflicting requirements: very little development resources and very ambitious ideas that required lots of work. With family commitments and a full time job, I quickly found out that there weren't a lot of spare cycles left. In fact, after some analysis, I realised I was in a conundrum. Whilst there is was a lot of "dead-time" in the average week, it was mostly "low-quality grade time": lots of discontinued segments of varying and unpredictable lengths. Summed together in a naive way it seemed like a lot, but - as every programmer knows - six blocks of ten minutes do not one solid hour make. </p><p>Nevertheless, one has to play the game with the cards that were dealt. I soon realised that the correct question to ask was: "what kind of development style makes one productive under these conditions?". The answer turned out to be opportunistic coding. This is rooted in having a better understanding of the different "qualities" of time and how best to exploit them. For example, when you have say five to fifteen minutes available, it makes sense to do small updates to the manual or fix trivial problems - a typo in the documentation, renaming variables in a function, mopping up the backlog and other activities of that ilk. A solid block of forty minutes to an hour affords you more: for instance, implementing part or the whole of stories for which the analysis has been completed, or doing some analysis for existing stories. On those rare cases where half-a-day or longer is available, one must make the most of it and take on a complex piece of work that requires sustained concentration. This sessions proved to be most valuable when the output is a set of well defined stories that are ready for implementation. </p><p>One needs very good processes in order to be able to manage the usage of time in this fashion. Luckily, agile provides it. </p></div> </div> <div class="outline-2" id="outline-container-2"><h2 id="sec-2">Slow Motion Agile</h2><div class="outline-text-2" id="text-2">  <p>Looking back on ~2.4k commits, one of the major wins in terms of development process was to think incrementally. Of course, agile already gives you a mental framework for that, and we had a functioning scrum process during our start up days: daily stand-ups, bi-weekly sprints, pre-sprint planning, post-sprint reviews, demos and all of that good stuff. It worked really well, and keep us honest and clean. We used a very simple org-mode file to keep track of all the open stories, and at one point we even built a simple burn-down chart generator to allow us to measure velocity. </p><p>Granted, when you are working alone in your spare time, a chunk of agile may not make sense; for instance, providing status updates to yourself may not be the most productive use of scarce time. Surprisingly, I found quite a bit of process to be vital. I've kept the bi-weekly sprint cycle, the sprint logs, the product backlog and the time-tracking we had originally setup and found them <b>extremely</b> useful - quite possibly the thing that has kept me going for such an extended period of time, to be brutally honest. When you are working on an open source project it is very easy to get lost in its open-ended-ness and find yourself giving up, particularly if you are not getting (or expecting) any user feedback. Even Linus himself has said many times he would have given up the kernel if it wasn't for other people bringing him problems to keep him interested. </p><p>Lacking Linus' ability to attract crowds of interested developers, I went for the next best thing: I made them up. Well, at least in metaphorical way, I guess, as this is what user stories are when you have no external users to drive them. As I am using the product in anger, I find it very easy to put myself in the head of a user and come up with requirements that push development forward. These stories really help, because they transform the cloud of possibilities into concrete, simple, measurable deliverables that one can choose to deliver or not. Once you have a set of stories, you have no excuse to be lazy because you can visualise in your head just how much effort it would require you to implement a story - and hey, since nerds are terrible at estimating, it's never that much effort at all. As everyone knows, it's not quite that easy in the end; but once you've started, you get the feeling you have to at least finish the task at hand, and so on, one story at a time, one sprint at a time, until a body of work starts building up. It's slow, excruciatingly slow, but it's steady like water working in geological time; when you look back 5 sprints, you cannot help but be amazed on how much can be achieved in such a incremental way - and how much is still left. </p><p>And then you get hooked into measurements. I now love measuring everything, from how long it takes me to complete a story, to where time goes in an sprint, to how many commits I do a day, to, well, everything that can easily be measured without adding any overhead. There is no incentive for you to game the system - hell, you could create a script that commits 20 times a day, if the commit count is all you care about. But it's not, so why bother. Due to this, statistics start to actually tell you valuable information about the world and to impel you forward. For instance, GitHub streaks mean that I always try to at least make one commit per day. Because of this, even on days when I'm tired, I always force my self to do <i>something</i>and sometimes that quick commit morphs into an hour or two of work that wouldn't have happened otherwise. </p><p>As I mentioned before, it was revealing to find out that there are different types of time. In order to to take advantage of this heterogeneity, one must make scrupulous use of the product backlog. This has proven invaluable, as you can attest by its <a href="https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/product_backlog.org">current</a>size. Whether we are part way through a story or just idly daydreaming, each and every idea must be added to the product backlog, with sufficient detail to allow one to reconstruct one's train of thought at that point in time. Once in the backlog, items can be continuously refined until eventually we find a suitable sprint to tackle them or they get deprecated altogether. But without an healthy backlog it is not possible to make the most these illusive time slots. Conversely, it is important to try to make each story as small and as focused as possible, and to minimise spikes unless they really are on the critical path of the story. This is mainly for psychological reasons: one needs to mark stories as complete, to feel like work has been done. Never-ending stories are just bad for morale. </p><p>In general, this extreme incrementalism has served us well. Not all is positive though. The worst problem has been a great difficulty in tackling complex problems - those that require several hours just to load them into your head. These are unavoidable in any sufficiently large code base. Having lots of discontinued segments of unpredictable duration have reduced efficiency considerably. In particular, I notice I have spent a lot more time lost in conceptual circles, and I've taken a lot longer to explore alternatives when compared to working full time. </p></div> </div> <div class="outline-2" id="outline-container-3"><h2 id="sec-3">DVCS to the Core</h2><div class="outline-text-2" id="text-3">  <p>We had already started to use git during the start-up days, and it had proved to be a major win at the time. After all, one never quite knows where one will be coding from, and whether internet access is available or not, so it's important to have a self-contained environment. In the end we found out it brought many, many more advantages such as great collaborative flows, good managed web interfaces/hosting providers (<a href="http://www.github.com">GitHub</a> and, to some extent, <a href="http://www.bitbucket.com">BitBucket</a>), amazing raw speed even on low-powered machines, and a number of other wins - all covered by lots and lots of posts around the web, so I won't bore you with that. </p><p>On the surface it may seem that DVCS is most useful on a multi-developer team. This is not the case. The more discontinued your time is, the more you start appreciating its distributed nature. This is because each "kind" of time has a more suitable device - perhaps a netbook for the train, a desktop at someone's house or even a phone while waiting somewhere. With DVCS you can easily to switch devices and continue exactly where you left off. With GitHub you can even author using the web interface, so a mobile phone suddenly becomes useful for reading and writing. </p><p>Another decision that turned out to be a major win is still not the done thing. Ever the trailblazers, we decided to put everything related to the project in version control. And by "everything" I do mean <b>everything</b>: documentation, bug reports, agile process, blog posts, the whole lot. It did seem a bit silly not to use GitHub's Wiki and Issues at the time, but, on hindsight, having everything in one versioned controlled place proved to be a major win: </p><ul><li>searching is never further than a couple of greps away, and it's not   sensitive to connectivity; </li><li>all you need is a tiny sliver of connectivity to push or pull, and   work can be batched to wait for that moment; </li><li>updates by other people come in as commits and can be easily   reviewed as part of the normal push/pull process - not that we got   any of late, to be fair; </li><li>changes can easily be diffed; </li><li>history can be checked using the familiar version control interface,   which is available wherever you go. </li></ul>  <p>When you have little time, these advantages are life-savers. </p><p>The last but very important lesson learned was to commit early and commit often. It's rather obvious in hindsight, really. After all, if you have very small blocks of time to do work, you want to make sure you don't break anything; last thing you need is to spend a week debugging a tricky problem, with no idea of where you're going or how far you still have to travel. So it's important to make your commits <i>very small</i> and <i>very focused</i> such that a bisection would almost immediately reveal a problem - or at least provide you with an obvious rollback strategy. This has proved itself to be invaluable far too many times to count. The gist of this approach it is to split changes in an almost OCD sort of way, to the point that anyone can look at the commit comment and the commit diff and make a judgement as to whether the change was correct or not. To be fair, it's not quite always that straightforward, but that has been the overall aim. </p></div> </div> <div class="outline-2" id="outline-container-4"><h2 id="sec-4">Struggling to stay Continuously Integrated</h2><div class="outline-text-2" id="text-4">  <p>After the commit comes the build, and the proof is in the pudding, as they say. When it comes to code, that largely means CI; granted, it may not be a very reliable proof, but nevertheless it is the best proof we've got. One of the major wins from the start up days was to setup CI, and to give it as wide a coverage as we could muster. We setup multiple build agents across compilers and platforms, added dynamic analysis, code coverage, packaging and basic sanity tests on those packages. </p><p>All of these have proven to be major steps in keeping the show on the road, and once setup, they were <i>normally</i> fairly trivial to maintain. We did have a couple of minor issues with <a href="http://www.cdash.org/">CDash</a> whilst we were running our own server. Eventually we moved over to the <a href="http://my.cdash.org/index.php?project=Dogen">hosted CDash server</a> but it has limitations on the number of builds, which meant I had to switch some build agents off. In addition to this, the main other stumbling block is finding the time to do large infrastructural updates to the build agents such as setting up new versions of <a href="http://www.boost.org/users/history/version_1_56_0.html">Boost</a>, new compilers and so on. These are horrendously time consuming across platforms because you never know what issues you are going to hit, and each platform has their own way of doing things. </p><p>The biggest lesson we learned here is that CI is vital but software products with no time at all should not waste time managing their own CI. There are just not enough hours in the day. I have been looking into <a href="https://travis-ci.org/">travis</a> to make this process easier in the future. Also, whilst being cross-platform is a very worthy objective, one has to weigh the costs with the benefits. If you have a tiny user base, it may make sense to stick to one platform and continue to do portable coding without "proof"; once users start asking for multiple platforms, it is then worth considering doing the work required to support them. </p><p>The packaging story was also a very good one to start off with - after all, most users will probably rely on those - but it turned out to be <b>much</b> harder than first thought. We spent quite a bit of time integrating with the GitHub API, uploading packages into their downloads section, downloading them from there, testing, and then renaming them for user consumption. Whilst it lasted, this setup was very useful. Unfortunately it didn't last very long as GitHub decided to decommission their downloads section. Since most of the upload and download code was GitHub specific, we could not readily move over to a different location. The lesson here was that this sort of functionality is extremely useful, and it is worth dedicating time to it, but one should always have a plan B and even a plan C. To make a long story short, the end result is that we don't have any downloads available at all - not even a stale ones - nor do we have any sanity checks on packages we produce; they basically go to <code>/dev/null</code>. </p><p>In summary, all of our pains led us to conclude that one should externalise early, externalise often and externalise everything. If there is a free (or cheap) provider in the cloud that can take on some or all of your infrastructure work away, you should always consider using them first rather than host your own infrastructure. And remember: your time is worth some money, and it is better spent coding. Of course, it is important to ensure that the provider is reliable, has been around for a while and is used by a critical mass. There is nothing worse than spending a lot of effort migrating to a platform, only to find out that it is about to dramatically change its APIs, prices, terms and conditions - or even worse, to be shutdown altogether. </p></div> </div> <div class="outline-2" id="outline-container-5"><h2 id="sec-5">Loosely Coupled</h2><div class="outline-text-2" id="text-5">  <p>Another very useful lesson I learned was to keep the <i>off-distro</i>dependencies to a minimum. This is rather related to the previous points on CI and cross-platform-ness, really. During the start up days we started off by requiring a C++ compiler with good C++ 11 support, and a Boost library with a few off-tree libraries - mainly <a href="http://www.boost.org/doc/libs/1_56_0/libs/log/doc/html/index.html">Boost.Log</a>. This meant we had to have our own little "chroot" with all of these, and we had to build them by hand, sprinkled with plenty of helper scripts. In those dark days, almost nothing was supplied by the distro and life was painful. It was just about workable when we had time on our hands, but this is really not the sort of thing you want to spend time maintaining if you are working on a project in your spare time. </p><p>To be fair, I had always intended to move to distro-supplied packages as soon as they caught up, and when that happened the transition was smooth enough. As things stand, we have a very small off-distro footprint - mainly <a href="http://www.codesynthesis.com/products/odb/">ODB</a> and <a href="http://epa.codeplex.com/">EOS</a>. The additional advantage of not having off-distro dependencies is that you can start to consider yourself for inclusion on a distro. Even in these days of Docker, being shipped by a distro is still a good milestone for any open source project, so it's important to aim for it. Once more, it's the old psychological factors. </p><p>All and all, it seems to me we took the right decisions as both C++ 11 and Boost.Log have proven quite useful; but in the future I certainly will think very carefully about adding dependencies to off-distro libraries. </p></div> </div> <div class="outline-2" id="outline-container-6"><h2 id="sec-6">Conclusions</h2><div class="outline-text-2" id="text-6">  <p>In general, the first fifty iterations of Dogen have been very positive. It has been a rather interesting journey, and dealing with pure uncertainty is not always easy - after all, one always wants to reach a destination. At the same time, much has been learned in the process, and a setup has been created that is sustainable given the available resources. In the near future I intend to improve the visibility of the project as I believe that, for all it's faults, it is still useful in its current form. </p></div></div></div> <div id="postamble"><p class="date">Date: 2014-09-07 22:02:42 BST</p><p class="creator">Org version 7.8.02 with Emacs version 24</p><a href="http://validator.w3.org/check?uri=referer">Validate XHTML 1.0</a> </div>

            <p class="text-muted">in 'Marco Craveiro' on September 08, 2014 09:03 AM. <a href="http://mcraveiro.blogspot.com/2014/09/nerd-food-dogen-lessons-in-incremental.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Nerd Food: Dogen: Old Demo.</h4>

            Nerd Food: Dogen: Old Demo  <div id="preamble"> </div> <div id="content"> <p>As part of my attempt to make the work in Dogen a bit more visible, I thought I'd repost an old demo here. The interface has changed very little since those days so it's still a useful introduction. </p>  </div> <div id="postamble"><p class="date">Date: 2014-09-07 22:23:58 BST</p><p class="creator">Org version 7.8.02 with Emacs version 24</p><a href="http://validator.w3.org/check?uri=referer">Validate XHTML 1.0</a> </div>

            <p class="text-muted">in 'Marco Craveiro' on September 07, 2014 09:25 PM. <a href="http://mcraveiro.blogspot.com/2014/09/nerd-food-dogen-old-demo.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Nerd Food: Using Mono In Anger - Part IV.</h4>

            Nerd Food: Using Mono In Anger - Part IV  <div id="preamble"> </div> <div id="content"> <p><i>In which we discuss the advances in MonoDevelop 5</i></p><p>This is the fourth and final part of a series of posts on my experiences using Mono for a fairly demanding project. For more context please read <a href="http://mcraveiro.blogspot.co.uk/2014/05/nerd-food-using-monodevelop-in-anger.html">part 1</a>, <a href="http://mcraveiro.blogspot.co.uk/2014/05/nerd-food-using-mono-in-anger-part-ii_3422.html">part 2</a> and <a href="http://mcraveiro.blogspot.co.uk/2014/05/nerd-food-using-mono-in-anger-part-iii.html">part 3</a>. </p><p>In this instalment we shall have a look at latest incarnation of MonoDevelop. </p> <div class="outline-2" id="outline-container-1"><h2 id="sec-1">Getting Latest and Greatest</h2><div class="outline-text-2" id="text-1">  <p>As I was part-way through these series of blog posts, Xamarin <a href="http://developer.xamarin.com/releases/studio/xamarin.studio_5.0/xamarin.studio_5.0/">announced</a> Xamarin Studio 5 - the commercial product based off of MonoDevelop. Clearly I had to get my hands on it. However, in this particular instance Debian unstable was proven to be rather… stable. The latest versions of Mono and MonoDevelop are rather quaint, and the <a href="http://lists.alioth.debian.org/pipermail/pkg-mono-devel/">packaging mailing list</a> is not the most active, as <a href="http://lists.alioth.debian.org/pipermail/pkg-mono-devel/2014-June/001053.html">my request</a> for news on packaging revealed. </p><p>Building is not an entirely trivial experience, as <a href="http://mcraveiro.blogspot.com/2014/05/nerd-food-using-mono-in-anger-part-ii_3422.html?showComment=1403591218536#c7416906974882038233">Brendan's comment</a>on a previous post demonstrated, so I was keen on going for binary packages. Surprisingly, there are not many private repos that publish up-to-date debian packages for mono. After much searching, I found an Ubuntu PPA that did: </p><pre class="example"><br />add-apt-repository 'deb  http://ppa.launchpad.net/ermshiperete/monodevelop/ubuntu quantal main'<br />apt-get install monodevelop-current<br /></pre>  <p>Running it was as easy as using the launcher script: </p><pre class="example"><br />/opt/monodevelop/bin/monodevelop-launcher.sh<br /></pre>  <p>And just as I was about to moan from the sidelines and beg Xamarin to try and help out Debian and Linux packagers in general, Miguel sent the following tweet: </p><blockquote> <p>Miguel de Icaza‏@migueldeicaza 4h Mono snapshots: @directhex just published our daily Linux packages <a href="http://mono-project.com/DistroPackages/Jenkins">http://mono-project.com/DistroPackages/Jenkins</a></p></blockquote>  <p>It's like Xamarin just reads my mind! </p><p>Haven't had the chance to play with these packages yet, and I didn't see any references to MonoDevelop in Jenkins (admittedly, it wasn't the deepest search I've done), but seems like a great step forward. </p></div> </div> <div class="outline-2" id="outline-container-2"><h2 id="sec-2">Playing with Latest and Greatest</h2><div class="outline-text-2" id="text-2">  <p>So what has changed? The UI may look identical to the previous version, but lord has the polish level gone up. Basically, almost all the problems I had bumped into have gone away. </p> </div> <div class="outline-3" id="outline-container-2-1"><h3 id="sec-2-1">NuGet support</h3><div class="outline-text-3" id="text-2-1"> <p><b>Update:</b> See <a href="http://lastexitcode.com/blog/2014/08/10/NuGetSupportInXamarinStudio5-2/">this post</a> by Matt Ward for more details on NuGet support.  </p><p>As I mentioned <a href="http://mcraveiro.blogspot.co.uk/2014/05/nerd-food-using-mono-in-anger-part-ii_3422.html">before</a>, whilst the NuGet plugin was great for basic usage, it did have a lot of corner cases including the certificates issues, full restore not working properly and so on. This has all been sorted out in MonoDevelop 5. It sports an internal implementation as explained in the release notes, and it has been flawless up till now. </p><p>I did bump into an annoying problem, but I think its more Visual Studio's fault than anything else. Basically, Microsoft decided to add some <code>NuGet.targets</code> to the solution by copying them to <code>.nuget</code>. Now, to their credit, they appear to have thought about mono: </p><pre class="example"><br />        &lt;!-- We need to launch nuget.exe with the mono command if we're not on windows --&gt;<br />       &lt;NuGetToolsPath&gt;$(SolutionDir).nuget&lt;/NuGetToolsPath&gt;<br /></pre>  <p>However, this fails miserably. The <code>DownloadNuGet</code> target does not appear to exist in mono, and copying <code>NuGet.exe</code> manually into <code>.nuget</code> also failed - apparently its not just a binary these days. The lazy man solution was to find the NuGet binaries in MonoDevelop and copy them across to the <code>.nuget</code> directory (had them at <code>monodevelop-5.0/external/nuget-binary</code>). Once this was done, building worked just fine. </p><p>Note also that I didn't have time to test the <code>.nuget</code> directory properly, by overriding the default directory with something slightly more sensible. However, I don't particularly like having my packages in the middle of the source tree so I'll be trying that very soon. </p><p>Overall, the NuGet experience is great, and package restoring Just Works (TM). </p></div> </div> <div class="outline-3" id="outline-container-2-2"><h3 id="sec-2-2">Intellisense and Friends</h3><div class="outline-text-3" id="text-2-2">  <p>I was already quite pleased with Intellisense in MonoDevelop 4, but I did find it was easy to confuse it when files got in to a bit of a state - say when pasting random chunks of code into a file. All of these problems are now gone with MonoDevelop 5. In more challenging situations, I have noticed the syntax highlighting disappearing for a little bit but as soon as the code is vaguely sensible, it returns straight away. </p><p>It is also a pleasure to use Ctrl-Shift-T to go to definitions, in some ways it seems even more powerful than ReSharper. It is certainly more responsive, even on my lowly NetBook with 1GB of RAM. </p><p>One slight snag is that extract interface seems to have gone missing - I was pretty sure I had used it on MonoDevelop 4, but for the life of me can't find it on 5. </p></div> </div> <div class="outline-3" id="outline-container-2-3"><h3 id="sec-2-3">NUnit</h3><div class="outline-text-3" id="text-2-3">  <p>I was a very happy user of the NUnit add-on for weeks on end and it performed flawlessly. However, today it got stuck loading tests and I ended up having to restart MonoDevelop to fix it. Bearing in mind I normally leave it running for weeks at a time, this annoyed me slightly. Of course, to be fair, I do restart Visual Studio every couple of days or so, so the odd MonoDevelop restart is not exactly the end of the world. </p><p>But in general, one complaint I have against both Visual Studio and MonoDevelop is with the opaqueness of unit testing. For me, it all started with shadow copying in NUnit UI and went downhill from there, really. If only one could see what exactly what it is that the IDE is trying to do, it would be fairly trivial to debug it; as it is, all I know is that my tests are "loading" but fail to load a few minutes later. </p><p>Anyway, that's just me ranting. Other than that, unit testing has worked really well, and I even started making use of the "Results Pad" and all - shiny charts! </p></div> </div> <div class="outline-3" id="outline-container-2-4"><h3 id="sec-2-4">Git FTW, UI Quirks and Resources</h3><div class="outline-text-3" id="text-2-4">  <p>I had mentioned before that there were some minor UI quirks. For instance I recall seeing a search box that was not properly drawn, and having problems with the default layout of the screen. I'm happy to report that all of my UI quirks have gone away with 5. It is quite polished in that regard. </p><p>I've also started making use of the version control support - to some extent, of course, as I still think that <a href="http://magit.github.io/">Magit</a> is above sliced bread. Having said that, its very useful to see a diff against what was committed or going up and down the history of a file without having to go to emacs. Version control is extremely quick. Even though Visual Studio now has git support integrated, it is a lot slower that MonoDevelop. I basically never wait at all for git on MonoDevelop. </p><p>Finally, a word on resources. I can still use MonoDevelop on my NetBook with its 1GB of RAM, much of it taken by Gnome 3 and Chrome. However, I did see it using over 250 MB of RAM on my desktop PC. I wonder if MonoDevelop is more aggressive on its usage of memory when it sees there is a lot available. </p></div></div> </div> <div class="outline-2" id="outline-container-3"><h2 id="sec-3">Conclusions</h2><div class="outline-text-2" id="text-3">  <p>Whilst I'll still be using MonoDevelop for a few weeks longer, I think we have done enough on this four part series. My main objective was really to pit Mono and MonoDevelop against Visual Studio 2013 on a fairly serious project, requiring all the usual suspects: .Net, Castle, Log4Net, MongoDB and so on. To my surprise, I found I had very few interoperability problems - on the whole, the exact same source code, configuration, etc just worked for both Windows and Linux. It says a lot on how far Mono has progressed. </p><p>Regrettably, I didn't get as far as playing around with vNext - the coding is taking a lot longer than expected - but if I do get as far as that I shall post an update. </p><p>It's great news that Xamarin is improving their Linux support; I can imagine that there must be a number of companies out there considering Docker for their .Net environments. Xamarin is going to be in a great position to win over these tight-Windows-shops with the great products they have. </p></div></div></div> <div id="postamble"><p class="date">Date: 2014-08-09 00:51:03 BST</p><p class="creator">Org version 7.8.02 with Emacs version 23</p><a href="http://validator.w3.org/check?uri=referer">Validate XHTML 1.0</a> </div>

            <p class="text-muted">in 'Marco Craveiro' on August 12, 2014 02:20 PM. <a href="http://mcraveiro.blogspot.com/2014/08/nerd-food-using-mono-in-anger-part-iv.html">(permalink)</a></p>
          </li>
          
          
          
          <li class="list-group-item"><h4>Nerd Food: Using Mono In Anger - Part III.</h4>

            Nerd Food: Using Mono In Anger - Part III  <div id="preamble"> </div> <div id="content"><p><i>In which we discuss the various libraries and tools used.</i></p><p>This is the third part of a series of posts on my experiences using Mono for a fairly demanding project. For more context please read <a href="http://mcraveiro.blogspot.co.uk/2014/05/nerd-food-using-monodevelop-in-anger.html">part 1</a> and <a href="http://mcraveiro.blogspot.co.uk/2014/05/nerd-food-using-mono-in-anger-part-ii_3422.html">part 2</a>. </p><p>In this instalment we shall focus more on the libraries, tools and technologies that I ended up using. </p> <div class="outline-2" id="outline-container-1"><h2 id="sec-1">Castle</h2><div class="outline-text-2" id="text-1">  <p>I've mentioned Castle a few times already. It appears to be the <i>de facto</i> IoC container for .Net, so its very important to have a good story around it. As I explained on the previous post, I added NuGet references to <i>Castle Core</i> and <i>Castle Windsor</i> and after that it was pretty much smooth sailing. I setup <a href="http://docs.castleproject.org/Windsor.Installers.ashx">Windor Installers</a> as described by Mark Seemann in his post <a href="http://blog.ploeh.dk/2010/01/26/IWindsorInstaller/">IWindsorInstaller</a> and that worked as described. My main program does exactly as Mark's: </p>   <pre class="example">var container = new WindsorContainer();<br />container.Install(new MyModule.WindsorInstaller(), new OtherModule.WindsorInstaller());<br />return container.Resolve&lt;IEntryPoint&gt;();<br /></pre>  <p>Basically, I have a number of IWindsorInstallers (e.g. <code>MyModule.WindsorInstaller()</code> etc.) that get installed, and then all that needs to be done is to resolve the "entry point" for the app - e.g. whatever your main workflow is. </p><p>All of this worked out of the box without any tweaking from my part. </p></div> </div> <div class="outline-2" id="outline-container-2"><h2 id="sec-2">MongoDB</h2><div class="outline-text-2" id="text-2">  <p>I've used MongoDB as the store for my test tool; I'll give a bit of context before I get into the Mono aspects. Mentally, I picture MongoDB somewhere in between PostgreSQL and <a href="http://www.oracle.com/technetwork/middleware/coherence/overview/index.html?ssSourceSiteId=opn">Coherence</a> / <a href="http://memcached.org/">MemCached</a>. That is, it's obviously not a relational database but one of those NoSQL specials: a schemaless, persistent, document database. You can do a lot of this stuff using <a href="http://www.postgresql.org/docs/9.4/static/hstore.html">hstore</a>, of course, and it now even sports something similar-but-not-quite-the-same-as <a href="http://bsonspec.org/">BSON</a> - <a href="http://www.depesz.com/2014/03/25/waiting-for-9-4-introduce-jsonb-a-structured-format-for-storing-json/">JSONB</a>, in the usual humorist Postgres way. MongoDB's setup is somewhat easier than Postgres, on both replicated and non-replicated scenarios. It also offers Javascript-based querying which, to be fair, <a href="http://blog.endpoint.com/2013/11/using-javascript-in-postgresql.html">Postgres also does</a>. I'd say that, if you have to choose between the two, go for MongoDB if you need a quick setup (replication included), if you <a href="http://jkb.netii.net/index.php/pub/sinosqldb/mongodb-security">don't care too much about security</a> and if you do not need any RDBMS support. Otherwise, use latest Postgres. And RTM. A Lot. </p><p>MongoDB is obviously also much easier to setup than Coherence. Of course, if you go for the trivial setup, Coherence is easy; but once you get into proper distributed setups I found it to be an absolute nightmare, requiring a lot of expertise just to understand why your data has been evicted. That's excluding the more complex scenarios such as invocation services, backing maps and so on. Sure, you can get the performance and the scalability, but you <span style="text-decoration: underline;">really</span> need to know what you are doing. And let's not mention the licence costs. Basically, for the plain in-memory cache job with an easy setup, just use Memcached. </p><p>But let's progress with MongoDB. Regrettably, there are no packages in Testing for it, but the wiki has a rather straightforward set of instructions under <a href="http://docs.mongodb.org/manual/tutorial/install-mongodb-on-debian/">Install MongoDB on Debian</a>. It boils down to: </p>   <pre class="example"># apt-key adv --keyserver keyserver.ubuntu.com --recv 7F0CEB10<br /># echo 'deb http://downloads-distro.mongodb.org/repo/debian-sysvinit dist 10gen' | sudo tee /etc/apt/sources.list.d/mongodb.list<br /># apt-get update<br /># apt-get install mongodb-org<br /></pre>  <p>Since I'm using <code>systemd</code> I was a bit apprehensive with their control scripts. As it turns out, it worked out of the box without any problems. I did find the installation to vary depending on the machines: on some I got <a href="http://blog.mongodb.org/post/33700094220/how-mongodbs-journaling-works">journaling</a> by default, but on my really low-end NetBook it was disabled. Also, the other thing to bear in mind is that if you have a small <code>root</code> or <code>var</code> partition - e.g. the one storing <code>/var/lib/mongodb</code> - you may run into trouble. I ended up symlinking this directory to a drive that had more space just to avoid problems. </p><p>Once MongoDB was up and running, it was time to find a management UI. Unfortunately, <a href="http://www.mongovue.com/">MongoVue</a> - the UI that all the Windows cool kids use - is not available on Linux. This is a bit disappointing because it seems rather full featured and well funded and - just to rub salt in the wounds - <i>it's a .Net application</i>. The old lack of cross-platform mentality surfaces yet again. Undeterred once more, I settled on <a href="http://robomongo.org/">RoboMongo</a> instead. Not quite as matured, but seemed good enough for my needs. Simple to setup too: </p>   <pre class="example">$ wget -O robomongo-0.8.4-x86_64.deb http://robomongo.org/files/linux/robomongo-0.8.4-x86_64.deb<br />$ gdebi-gtk robomongo-0.8.4-x86_64.deb<br /></pre>  <p>If you don't have <code>gdebi-gtk</code> any other debian installer would do, including <code>dpkg -i robomongo-0.8.4-x86_64.deb</code>. </p><p>If you are an emacs user, be sure to install the <a href="https://github.com/tobiassvn/inf-mongo">inferior mode</a> for Mongo. Works well on Linux but has the usual strange input-consumption problems one always gets on Windows. </p><p>Going back to Mono, all one needs to do is to use NuGet to install the <i>CSharp Mongo Driver</i>. Once that was done, reading, writing, updating etc all worked out of the box. </p></div> </div> <div class="outline-2" id="outline-container-3"><h2 id="sec-3">Log4Net</h2><div class="outline-text-2" id="text-3">  <p>Paradoxically, where I thought I was going to have the least amount of trouble ended up being the most troublesome of all of my dependencies. Getting log4net to work was initially really easy - the usual NuGet install. But then, not happy with such easy success, I decided I needed a single <code>log4net.config</code> file for all my projects. This is understandable since all that was different amongst them was the log file name; it seemed a bit silly to have lots of copy and paste XML lying around. So I decided to use Dynamic Properties, as explained in this blog post: <a href="http://kyleleneau.com/blog/2009/06/12/log4net-dynamic-properties-in-xml-configuration/">Log4net Dynamic Properties in XML Configuration</a>. This failed miserably. </p><p>As everyone knows, log4net is a pain in the backside to debug. For the longest time I didn't have the right configuration; eventually I figured out what I was doing wrong. It turns out the magic incantation is this (I missed the <code>type</code> bit): </p>   <pre class="example">        &lt;appender name="RollingFileAppender" type="log4net.Appender.RollingFileAppender"&gt;<br />            &lt;file type="log4net.Util.PatternString" value="APrefix.%property{ApplicationId}.log" /&gt;<br /></pre>  <p>Just when I thought I was out of the woods, I hit a Mono limitation: <code>CallContext.LogicalGetData</code> is not yet implemented in Mono 3.0. It is available on later versions of Mono, but these are not yet in Debian Testing. Undeterred, I decided to try to compile Mono from scratch. It turned out to be rather straightforward: </p>   <pre class="example">$ git clone https://github.com/mono/mono<br />$ cd mono<br />$ ./autogen.sh --prefix=${YOUR_INSTALL_LOCATION}<br />$ make -j${NUMBER_OF_CORES}<br />$ make install<br /></pre>  <p>Replace (or set) <code>${YOUR_INSTALL_LOCATION}</code> and <code>${NUMBER_OF_CORES}</code>as required. Once you got it installed, you need to tell MonoDevelop about the new runtime. Go to <i>Edit</i>, <i>Preferences</i> then choose <i>.Net Runtimes</i> and click on <i>Add</i>. Point to the top-level directory containing your installation (e.g. <code>${YOUR_INSTALL_LOCATION}</code>) and it should find the newly built Mono. I then set that as my default. Incredibly enough, from then on it all just worked. </p> <div class="figure"><p><img src="http://4.bp.blogspot.com/-KXopT6xb-Vc/U4UBNVmitwI/AAAAAAAAAnQ/5TrpusbNA7o/s1600/monodevelop_add_runtime.png" /></p><p>Runtimes in MonoDevelop</p></div> </div> </div> <div class="outline-2" id="outline-container-4"><h2 id="sec-4">NUnit</h2><div class="outline-text-2" id="text-4">  <p>As mentioned in the previous post, you should replace the NUnit references you get from MonoDevelop with NuGet ones. This is because you may be using some of the newer features of NUnit - which are not available with the version that ships with Mono. At any rate, it just gives you more confidence on the dependency rather than depending on the environment. </p><p>Another problem I found was disabling shadow copying. This does not seem to be an option in the MonoDevelop UI or the solution. It is rather annoying if you need to have some log4net config files in the test directory - as I did, due to the Dynamic Properties mentioned above. </p><p>Other than that, NUnit worked very well. </p></div> </div> <div class="outline-2" id="outline-container-5"><h2 id="sec-5">Libraries Overview</h2><div class="outline-text-2" id="text-5">  <p>Compiling Mono from source is obviously not ideal, but perhaps the main thing to worry about is how to get latest Mono packages. As with MongoDB, it perhaps would be better to have a repository supported by the Mono community that offers more up-to-date packages, at least for the more intrepid users. Although some of these existed in the past (particularly Ubuntu PPAs) they all seem to have gone stale. </p><p>Having said that, there are still no showstoppers - the code is working on both Visual Studio 2013 and Mono. </p></div></div></div> <div id="postamble"><p class="date">Date: 2014-05-27 22:29:38 BST</p><p class="creator">Org version 7.8.02 with Emacs version 23</p><a href="http://validator.w3.org/check?uri=referer">Validate XHTML 1.0</a> </div>

            <p class="text-muted">in 'Marco Craveiro' on May 27, 2014 09:30 PM. <a href="http://mcraveiro.blogspot.com/2014/05/nerd-food-using-mono-in-anger-part-iii.html">(permalink)</a></p>
          </li>
          
          
        </ul>
      </div>
      <div class="col-md-3">
        <ul class="list-group">
          
          <li class="list-group-item"><a href="http://ankursinha.in/blog/feeds/categories/research.atom.xml">ankursinha.in/blog</a></li>
          
          <li class="list-group-item"><a href="http://www.blogger.com/feeds/2672427473119923109/posts/default">Marco Craveiro</a></li>
          
          <li class="list-group-item"><a href="http://biocomputation.herts.ac.uk/feeds/all.atom.xml">UH Biocomputation Group</a></li>
          
        </ul>
      </div>
    </div>
    <footer id="site-footer">
      <p class="text-center text-muted">Source hosted on <a href="http://github.com/sanjayankur31/planet-neuroscience">Github</a>.</p>
      </div>
    </footer>
  </body>
</html>

